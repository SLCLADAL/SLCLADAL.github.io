<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.165">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dattatreya Majumdar">
<meta name="dcterms.date" content="2022-08-31">

<title>Reinforcement Learning in NLP</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VSGK4KYDQZ"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-VSGK4KYDQZ', { 'anonymize_ip': true});
</script>


</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./ladal_icon_cas_tran_white_trimed.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Language Technology and Data Analysis Laboratory</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">HOME</a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about-ladal" role="button" data-bs-toggle="dropdown" aria-expanded="false">ABOUT LADAL</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-about-ladal">    
        <li>
    <a class="dropdown-item" href="./people.html">
 <span class="dropdown-text">People | Collabs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./news.html">
 <span class="dropdown-text">News</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-events" role="button" data-bs-toggle="dropdown" aria-expanded="false">EVENTS</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-events">    
        <li>
    <a class="dropdown-item" href="./workshops.html">
 <span class="dropdown-text">Workshops</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./compthinking.html">
 <span class="dropdown-text">Computational Thinking in HASS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./webinars2022.html">
 <span class="dropdown-text">LADAL Webinar Series 2022</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./opening.html">
 <span class="dropdown-text">LADAL Webinar Series 2021</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./atapevents.html">
 <span class="dropdown-text">ATAP Events</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./tutorials.html">TUTORIALS</a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="button" data-bs-toggle="dropdown" aria-expanded="false">RESOURCES</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="./links.html">
 <span class="dropdown-text">Links</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./base.html">
 <span class="dropdown-text">Tutorial stylesheet</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./contact.html">CONTACT</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#article-summarisation" id="toc-article-summarisation" class="nav-link" data-scroll-target="#article-summarisation">Article Summarisation</a></li>
  <li><a href="#dialogue-generation" id="toc-dialogue-generation" class="nav-link" data-scroll-target="#dialogue-generation">Dialogue Generation</a></li>
  <li><a href="#neural-machine-translation" id="toc-neural-machine-translation" class="nav-link" data-scroll-target="#neural-machine-translation">Neural Machine Translation</a></li>
  </ul></li>
  <li><a href="#citation-session-info" id="toc-citation-session-info" class="nav-link" data-scroll-target="#citation-session-info">Citation &amp; Session Info</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Reinforcement Learning in NLP</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Dattatreya Majumdar </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 31, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="introduction" class="level1 unnumbered">
<h1 class="unnumbered">Introduction</h1>
<p>This tutorial introduces the concept of Reinforcement Learning <span class="citation" data-cites="sutton2018reinforcement wu2018study paulus2017deep">[see <a href="#ref-sutton2018reinforcement" role="doc-biblioref">1</a>, <a href="#ref-wu2018study" role="doc-biblioref">2</a>, <a href="#ref-paulus2017deep" role="doc-biblioref">3</a>]</span>, and how it can be applied in the domain of Natural Language Processing and linguistics.The code for this tutorial is provided in the following link. <a href="https://slcladal.github.io/content/reinfnlp.Rmd">here</a>.</p>
<p>Reinforcement Learning enables a machines and software agents to independently determine the optimal behaviour depending on a specific concept to enhance the overall performance. The system requires a reward feedback to learn its behaviour which is known as reinforcement signal. The schematic diagram of Reinforcement Learning (RL)is provided below: -</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="https://slcladal.github.io/images/Reinforcement.PNG" class="img-fluid" style="float:center; padding:10px;width:60.0%"></p>
</div>
</div>
<p>Any RL framework comprises of 3 major components:</p>
<ul>
<li><em>Action</em> determines all possible moves that the agent can make which is normally expressed as a mathematical function.</li>
<li><em>State</em> it is an explicit and quick circumstance that the agent can find itself in posed by the environment or any future circumstance</li>
<li><em>Reward</em> it is the feedback input from the environment which measure the achievement or failure of the agent’s activities.</li>
</ul>
<p>The are three broad categories of RL:</p>
<ul>
<li><em>Value Based</em> which determines the optimal value function and it is the maximum value achievable under any policy.</li>
<li><em>Policy Based</em> which identifies the optimal policy achieving maximum future reward</li>
<li><em>Model Based</em> involves a model which predicts attributes or provides representation of the environment</li>
</ul>
<p>Without going into the mathematical intricacies of RL we will focus on this tutorial the applications of deep RL on linguistic data. RL as of now is playing a pivotal role in various NLP applications some of which are highlighted below:</p>
<ul>
<li>Article Summarisation</li>
<li>Question Answering (QA)</li>
<li>Dialogue Generation</li>
<li>Dialogue System</li>
<li>Knowledge-based QA</li>
<li>Machine Translation</li>
<li>Text Generation</li>
</ul>
<p>In the following sections we will explore some of these use cases and interpret how deep RL can implement them.</p>
<section id="article-summarisation" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="article-summarisation">Article Summarisation</h2>
<p>A deep reinforced model for abstractive summarisation involves sequence of input tokens <em>x={x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>}</em> and produces a sequence of output (summary) tokens. A schematic presentation of the process is shown below:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="https://slcladal.github.io/images/deeprlartsumm.PNG" class="img-fluid" style="float:center; padding:10px;width:100.0%"></p>
</div>
</div>
<p>For the article summarisation objective the deep RL has the following components:</p>
<ul>
<li><em>Action</em> which involves a function <em>u<sub>t</sub></em> which copies and generates summary output <em>y<sub>t</sub></em></li>
<li><em>State</em> it encapsulates the hidden states of encoder and previous outputs</li>
<li><em>Reward</em> which generates a rough score determining the performance of the summarisation</li>
</ul>
</section>
<section id="dialogue-generation" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="dialogue-generation">Dialogue Generation</h2>
<p>In today’s digital world dialogue generation is a widely used application especially in chatbots. One widely used model in this regard is the Long Short Term Memory (LSTM) sequence-to-sequence (SEQ2SEQ) model. It is a neural generative model that maximizes the probability of generating a response given the previous dialogue. However SEQ2SEQ model has some constraints:</p>
<ul>
<li>They tend to generate highly generic responses</li>
<li>Often they are stuck in an infinite loop of repetitive responses</li>
</ul>
<p>This is where deep RL is much more efficient as it can integrate developer-defined rewards which efficiently mimics the true goal of chatbot development. In case of dialogue generation the component:</p>
<ul>
<li><em>Action</em> which involves a function that generates sequences of arbitrary lengths</li>
<li><em>State</em> it comprises of previous 2 dialogue turns [p<sub>i</sub>,q<sub>i</sub>]</li>
<li><em>Reward</em> which determines the ease of answering, information flow and semantic coherence</li>
</ul>
<p>The schematic diagram highlighting the dialogue simulation between 2 agents using deep RL is shown below:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="https://slcladal.github.io/images/dlsimrl.PNG" class="img-fluid" style="float:center; padding:10px;width:100.0%"></p>
</div>
</div>
</section>
<section id="neural-machine-translation" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="neural-machine-translation">Neural Machine Translation</h2>
<p>Most of Neural Machine Translation (NMT) models are based encoder-decoder framework with attention mechanism. The encoder initially maps a source sentence <em>x={x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>}</em> to a set of continuous representations <em>z={z<sub>1</sub>,z<sub>2</sub>,…,z<sub>n</sub>}</em> . Given <em>z</em> the decoder then generates a target sentence <em>y={y<sub>1</sub>,y<sub>2</sub>,…,y<sub>m</sub>}</em> of word tokens one by one. RL is used to bridge the gap between training and inference of of NMT by directly optimizing the loss function at training time. In this scenario the NMT model acts as the <em>agent</em> which interacts with the <em>environment</em> which in this case are the previous words and the context vector <em>z</em> available at each step <em>t</em>. This is a a policy based RL and in place of a state a policy will be assigned in every iteration. The critical components of the RL for NMT are discussed below:</p>
<ul>
<li><em>Policy</em> which is a conditional probability defined by the parameters of the agent</li>
<li><em>Action</em> is decided by the agent based on the policy and it will pick up a candidate word from the vocabulary</li>
<li><em>Reward</em> is evaluated once the agent generates a complete sequence which in case of machine translation is <em>Bilingual Evaluation Understudy (BLEU)</em>.BLEU is defined by comparing the generated sequence with the ground truth sequence.</li>
</ul>
<p>The schematic of the overall process is depicted below:</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="https://slcladal.github.io/images/NMT.PNG" class="img-fluid" style="float:center; padding:10px;width:60.0%"></p>
</div>
</div>
</section>
</section>
<section id="citation-session-info" class="level1 unnumbered">
<h1 class="unnumbered">Citation &amp; Session Info</h1>
<p>Majumdar, Dattatreya. 2020. <em>Reinforcement Learning in NLP</em>. Brisbane: The University of Queensland. url: https://slcladal.github.io/reinfnlp.html (Version 2020.11.20).</p>
<pre><code>@manual{Majumdar2020ta,
  author = {Majumdar, Dattatreya},
  title = {Reinforcement Learning in NLP},
  note = {https://slcladal.github.io/reinfnlp.html},
  year = {2020},
  organization = "The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/11/20}
}</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R version 4.2.1 (2022-06-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 22.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0

locale:
 [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    
 [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   
 [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] digest_0.6.29     jsonlite_1.8.0    magrittr_2.0.3    evaluate_0.15    
 [5] rlang_1.0.4       stringi_1.7.8     cli_3.3.0         rstudioapi_0.13  
 [9] rmarkdown_2.14    tools_4.2.1       stringr_1.4.0     htmlwidgets_1.5.4
[13] xfun_0.31         yaml_2.3.5        fastmap_1.1.0     compiler_4.2.1   
[17] htmltools_0.5.2   knitr_1.39       </code></pre>
</div>
</div>
<hr>
<p><a href="https://slcladal.github.io/index.html">Main page</a></p>
<hr>
</section>
<section id="references" class="level1 unnumbered">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-sutton2018reinforcement" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Sutton, R.S., Barto, A.G.: Reinforcement learning: An introduction. MIT press (2018).</div>
</div>
<div id="ref-wu2018study" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Wu, L., Tian, F., Qin, T., Lai, J., Liu, T.-Y.: A study of reinforcement learning for neural machine translation. arXiv preprint arXiv:1808.08866. (2018).</div>
</div>
<div id="ref-paulus2017deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Paulus, R., Xiong, C., Socher, R.: A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304. (2017).</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>