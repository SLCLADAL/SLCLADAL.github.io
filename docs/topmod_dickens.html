<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Gerold Schneider, Max Lauber" />

<meta name="date" content="2022-11-15" />

<title>Topic Modelling of Charles Dickens’ novels</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>
<link rel="stylesheet" href="styles.css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VSGK4KYDQZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VSGK4KYDQZ');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="/content/ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="about.html">ABOUT</a>
</li>
<li>
  <a href="events.html">EVENTS</a>
</li>
<li>
  <a href="tutorials.html">TUTORIALS</a>
</li>
<li>
  <a href="tools.html">TOOLS</a>
</li>
<li>
  <a href="resources.html">RESOURCES</a>
</li>
<li>
  <a href="contact.html">CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Topic Modelling of Charles Dickens’
novels</h1>
<h4 class="author">Gerold Schneider, Max Lauber</h4>
<h4 class="date">2022-11-15</h4>

</div>


<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial represents a case study on how to perform topic
modelling on literary data using R. The entire R markdown document for
the tutorial can be downloaded <a
href="%22https://slcladal.github.io/content/topmod_dickens.Rmd%22">here</a>.
The LADAL tutorial introducing topic modeling which provides more
background is available <a
href="https://ladal.edu.au/topic.html">here</a>.</p>
<p>The tutorial requires you to install and load a couple of packages
(in Python, these packages are also called libraries) to analyze
linguistic data. To help you, we directly include the commands in the
script and walk you through it step by step.</p>
<div class="warning"
style="padding:0.1em; background-color:rgba(215,209,204,.3); color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
To be able to follow this tutorial, we suggest you check out and
familiarize yourself with the content of the following tutorials:<br>
</p>
<p style="margin-top:1em; text-align:left">
<ul>
<li>
<a href="https://ladal.edu.au/intror.html">Getting started with R</a>
</li>
<li>
<a href="https://ladal.edu.au/load.html">Loading, saving, and generating
data in R</a>
</li>
<li>
<a href="https://ladal.edu.au/string.html">String Processing in R</a>
</li>
<li>
<a href="https://ladal.edu.au/regex.html">Regular Expressions in R</a>
</li>
<li>
<a href="https://ladal.edu.au/topicmodels.html">Topic modeling with
R</a>
</li>
</ul>
</p>
<p style="margin-top:1em; text-align:center">
Click <a
href="https://ladal.edu.au/content/topmod_dickens.Rmd"><strong>here</strong></a><a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> to
download the <strong>entire R Notebook</strong> for this
tutorial.<br><br> <a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Fdickens_cb.ipynb%26branch%3Dmain"><img
src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a><br> Click
<a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252F_dickens_cb.ipynb%26branch%3Dmain"><strong>here</strong></a>
to open an interactive Jupyter notebook that allows you to execute,
change, and edit the code as well as to upload your own data. <br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<div id="motivation" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Motivation</h2>
<p>There is an incredible amount of text that has been archived all over
the world. Probably, there is more text being produced on any given day
than a single person can ever hope to read. What are linguists and other
language-oriented scholars - be that from historical, literary,
sociological or beyond perspectives - going to do with this
embarrassment of riches? Change field, focus on a particular niche of
language or begin using automated language methods, most likely. If you
belong to the latter category, and have yet to acquaint yourself with
topic modelling, welcome.</p>
<p>So how does topic modelling help us get to grips with large
quantities of texts (or the Great Unread, as <span
class="citation">Tangherlini and Leonard (<a
href="#ref-tangherlini2013trawling">2013</a>)</span> appropriately call
it)? What it certainly does not do, is read or analyze a single
sentence, let alone a corpus of texts for you. It is more useful to
think of it as “a lens that allows researchers working on a problem to
view a relevant textual corpus in a different light and at a different
scale” <span class="citation">(<a href="#ref-mohr2013introduction">Mohr
and Bogdanov 2013, 560</a>)</span>.</p>
</div>
<div id="basic-idea-of-topic-modelling" class="section level2"
number="1.2">
<h2><span class="header-section-number">1.2</span> Basic Idea of Topic
Modelling</h2>
<p>The way topic modelling allows us to engage with large corpora of
text by identifying co-occurrence patterns, which, when done right, can
yield new perspectives on a set of texts. As such, the methodology is
one implementation of the Firthian hypothesis which states that “you
shall know a word by the company it keeps” <span class="citation">(<a
href="#ref-firth1957ling">Firth 1957, 11</a>)</span>. Basically, the
method exploits the fact that words which frequently appear in a similar
context are often representative of the same topic. To arrive at a point
where a model allows us to interpret anything meaningful about the
topics it captures, we need to mangle the text ever so slightly (to
downplay things somewhat): removing proper names, cutting out a lot of
fluff, perhaps some chopping up of text.</p>
<p>Sounds like fun, doesn’t it? There is a rationale to all of this, and
we will walk through it step by step. Once we arrive at the destination,
we will have a list of keywords which represent the topics in some of
Charles Dickens’ most lauded works and discuss how they allow us to
interpret specific aspects of these novels. This is not the most
technical or comprehensive introduction to topic modelling out there,
but it provides an actionable instruction to modelling topics in R and
points to further resources for those who want to dive in deeper.</p>
</div>
<div id="preparation-and-session-setup" class="section level2"
number="1.3">
<h2><span class="header-section-number">1.3</span> Preparation and
Session Setup</h2>
<p>As mentioned at the outset, this is an introduction to Topic
Modelling based on R. A rudimentary familiarity with R and RStudio are
helpful for getting the most out of this. If you have yet to install R
or are new to it, we can recommend <a
href="https://ladal.edu.au/intror.html">this introductory tutorial to
R</a> or <a
href="https://dlf.uzh.ch/openbooks/statisticsforlinguists/chapter/first-steps-in-r-importing-and-retrieving-corpus-data/">these</a>
<a
href="https://dlf.uzh.ch/openbooks/statisticsforlinguists/chapter/first-steps-in-r-importing-and-retrieving-corpus-data/">two</a>
chapters from our slow-paced introduction to Statistics for Linguists,
which walks you through the installation and shows a range of its
functionalities. In the following, we assume that you have downloaded
and installed both R and RStudio and take it from there.</p>
</div>
<div id="packages" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Packages</h2>
<p>Topic modelling is pretty package-intense. We won’t go into the
details of what each in this bouquet of packages does, except that each
of them is necessary for topic modelling. If you already have some of
these installed, just skip to the ones that you don’t have yet. Chances
are that you have tried our tutorial on document classification, and are
therefore already familiar with <code>quanteda</code> and
<code>readtext</code>.</p>
<p>If all of these look new, run the following lines of code:</p>
<pre class="r"><code>#install.packages(&quot;gutenbergr&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;readtext&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;quanteda&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;quanteda.textmodels&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;tidytext&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;stm&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;dplyr&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;tm&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;udpipe&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;data.table&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;future.apply&quot;, repos = &quot;http://cran.us.r-project.org&quot;)
#install.packages(&quot;flextable&quot;, repos = &quot;http://cran.us.r-project.org&quot;)</code></pre>
<p>This may take a minute or three. Installing packages is only
necessary once, so if you are working with this script, or your own, you
won’t need to run these installation commands more than once. In your
script, you can <em>mute</em> a command - basically telling R not to
execute it - by placing a #-symbol in front of it, like so:</p>
<pre class="r"><code>#install.packages</code></pre>
<p>In most cases, the installations will work without any issues. If you
should get an error message, we recommend taking a moment to read what
it says, and, if it does not make any sense to you, to google it. If an
issue comes up for you, chances are that this has already happened to
someone else - and, fortunately, the R community has a pretty good track
record of responding to questions about technical issues. Generally, it
is also a good idea to use a relatively new version of R. If you have
last used R two years ago, do update it.</p>
<p>Once you have installed the packages, you’ll need to load them in the
current session. This is done with the following lines of code:</p>
<pre class="r"><code>library(gutenbergr)
library(readtext)
library(quanteda) 
library(quanteda.textmodels)
library(tidytext)
library(stm)
library(dplyr)
library(tm)
library(udpipe)
library(data.table)
library(future.apply)
library(flextable)</code></pre>
</div>
<div id="installing-a-language-model" class="section level2"
number="1.5">
<h2><span class="header-section-number">1.5</span> Installing a language
model</h2>
<p>Now that all of the packages are loaded, we need to download and then
activate a language model so that we can part-of-speech tag the data.
Downloading the model only takes a single line of code:</p>
<pre class="r"><code>meng &lt;- udpipe::udpipe_download_model(language = &quot;english-ewt&quot;)</code></pre>
<p>Once the installation process is finished, we can initialize the
model which will allow R to use the language model. For this, we
use:</p>
<pre class="r"><code>m_eng &lt;- udpipe_load_model(file = here::here(&quot;udpipemodels&quot;, &quot;english-ewt-ud-2.5-191206.udpipe&quot;))</code></pre>
<p>With that, we have the computational prerequisites to generate topic
models in R. All we need now is data.</p>
</div>
<div id="research-questions" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Research
Questions</h2>
<p>For this, we turn to the literary vaults to dust off one of the
greats: Charles Dickens. Beyond and within Christmas fables, Dickens is
famous for his social criticism, especially the way he treated the topic
of poverty and developed visions for including the poor inside society
[see for example <span class="citation">Kailash (<a
href="#ref-kailash2012dickens">2012</a>)</span> or <span
class="citation">Mahlberg (<a
href="#ref-mahlberg2013corpus">2013</a>)</span>). Dickens is generally
considered exemplary for his literary realism, which he employed with no
small success to depict the plight of inequality and poverty. There is
more to Dickens than that, but it gives us a duplette of research
questions:</p>
<ol style="list-style-type: decimal">
<li><p>Can we use topic modelling to bring Dickens’ social criticism to
the fore, without the heavy lifting of actually reading his
books?</p></li>
<li><p>Can we use topic modelling to explore the rich imagery that
Dickens constructs with his literary realism?</p></li>
</ol>
<p>To explore these questions, we will construct a small corpus,
consisting of eight Dickens novels. These are:</p>
<ul>
<li>Christmas Carol<br />
</li>
<li>Tale of Two Cities<br />
</li>
<li>The Pickwick Papers<br />
</li>
<li>Oliver Twist<br />
</li>
<li>David Copperfield<br />
</li>
<li>Hard Times<br />
</li>
<li>Nicholas Nickleby<br />
</li>
<li>Great Expectations</li>
</ul>
</div>
</div>
<div id="data-gutenberg" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Data: Gutenberg</h1>
<p>Beyond the fact that his is a renowned style and perspective, Dickens
is convenient to work with because his work is old enough to be part of
the public domain. This means that the eight novels we are looking at
can be downloaded entirely legally from <a
href="https://www.gutenberg.org/">Project Gutenberg</a>. There is a <a
href="https://ladal.edu.au/gutenberg.html">specific tutorial</a> for
different ways of integrating Gutenberg into R, but we’ll walk you
through one approach anyway.</p>
<p>First, we can check out which of Dickens’ texts are available on
Gutenberg:</p>
<pre class="r"><code>dickens &lt;- gutenberg_works(author == &quot;Dickens, Charles&quot;)</code></pre>
<p>The command accesses a table of Gutenberg work metadata, in this case
specifically only for works authored by one <em>Dickens, Charles</em>.
We save this table to a variable called, tellingly, <em>dickens</em>.
Let’s take a look at it:</p>
<pre class="r"><code>dickens</code></pre>
<pre><code>## # A tibble: 54 × 8
##    gutenberg_id title    author gutenberg_author_id language gutenberg_bookshelf
##           &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;              
##  1           46 A Chris… Dicke…                  37 en       &quot;Children&#39;s Litera…
##  2          564 The Mys… Dicke…                  37 en       &quot;Mystery Fiction&quot;  
##  3          580 The Pic… Dicke…                  37 en       &quot;Best Books Ever L…
##  4          699 A Child… Dicke…                  37 en       &quot;Children&#39;s Histor…
##  5          700 The Old… Dicke…                  37 en       &quot;&quot;                 
##  6          730 Oliver … Dicke…                  37 en       &quot;&quot;                 
##  7          766 David C… Dicke…                  37 en       &quot;Harvard Classics&quot; 
##  8          821 Dombey … Dicke…                  37 en       &quot;&quot;                 
##  9          917 Barnaby… Dicke…                  37 en       &quot;Historical Fictio…
## 10          963 Little … Dicke…                  37 en       &quot;&quot;                 
## # ℹ 44 more rows
## # ℹ 2 more variables: rights &lt;chr&gt;, has_text &lt;lgl&gt;</code></pre>
<p>At first glance, we can see that there are 54 texts by Dickens on
Gutenberg, and that to each of these texts there is some metadate like
the Gutenberg ID, the language, the rights. This information is stored
in a tibble, an object that does not cram the console with its entire
length, but actually stops itself at ten rows. While this is helpful in
situations where you have millions of rows, here it is more hindrance
than help - we see some of the texts we’re looking for, but not all of
them. To display all of the rows and find our texts, we need the output
to display all 54 rows. This can be achieved like so:</p>
<pre class="r"><code>print(dickens, n=nrow(dickens)) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;All items on Project Gutenberg by Charles Dickens.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<pre><code>## # A tibble: 54 × 8
##    gutenberg_id title    author gutenberg_author_id language gutenberg_bookshelf
##           &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;              
##  1           46 &quot;A Chri… Dicke…                  37 en       &quot;Children&#39;s Litera…
##  2          564 &quot;The My… Dicke…                  37 en       &quot;Mystery Fiction&quot;  
##  3          580 &quot;The Pi… Dicke…                  37 en       &quot;Best Books Ever L…
##  4          699 &quot;A Chil… Dicke…                  37 en       &quot;Children&#39;s Histor…
##  5          700 &quot;The Ol… Dicke…                  37 en       &quot;&quot;                 
##  6          730 &quot;Oliver… Dicke…                  37 en       &quot;&quot;                 
##  7          766 &quot;David … Dicke…                  37 en       &quot;Harvard Classics&quot; 
##  8          821 &quot;Dombey… Dicke…                  37 en       &quot;&quot;                 
##  9          917 &quot;Barnab… Dicke…                  37 en       &quot;Historical Fictio…
## 10          963 &quot;Little… Dicke…                  37 en       &quot;&quot;                 
## 11          967 &quot;Nichol… Dicke…                  37 en       &quot;&quot;                 
## 12          968 &quot;Martin… Dicke…                  37 en       &quot;Best Books Ever L…
## 13         1023 &quot;Bleak … Dicke…                  37 en       &quot;&quot;                 
## 14         1392 &quot;The Se… Dicke…                  37 en       &quot;&quot;                 
## 15         1394 &quot;The Ho… Dicke…                  37 en       &quot;&quot;                 
## 16         1406 &quot;The Pe… Dicke…                  37 en       &quot;&quot;                 
## 17         1407 &quot;A Mess… Dicke…                  37 en       &quot;&quot;                 
## 18         1413 &quot;Tom Ti… Dicke…                  37 en       &quot;&quot;                 
## 19         1414 &quot;Somebo… Dicke…                  37 en       &quot;&quot;                 
## 20         1415 &quot;Doctor… Dicke…                  37 en       &quot;&quot;                 
## 21         1416 &quot;Mrs. L… Dicke…                  37 en       &quot;&quot;                 
## 22         1419 &quot;Mugby … Dicke…                  37 en       &quot;&quot;                 
## 23         1421 &quot;Mrs. L… Dicke…                  37 en       &quot;&quot;                 
## 24         1422 &quot;Going … Dicke…                  37 en       &quot;&quot;                 
## 25         1423 &quot;No Tho… Dicke…                  37 en       &quot;&quot;                 
## 26         1465 &quot;The Wr… Dicke…                  37 en       &quot;&quot;                 
## 27        15618 &quot;The Lo… Dicke…                  37 en       &quot;&quot;                 
## 28        19337 &quot;A Chri… Dicke…                  37 en       &quot;Children&#39;s Litera…
## 29        20795 &quot;The Cr… Dicke…                  37 en       &quot;Children&#39;s Litera…
## 30        23344 &quot;The Ma… Dicke…                  37 en       &quot;Children&#39;s Pictur…
## 31        23452 &quot;The Tr… Dicke…                  37 en       &quot;Children&#39;s Pictur…
## 32        23765 &quot;Captai… Dicke…                  37 en       &quot;Children&#39;s Pictur…
## 33        25852 &quot;The Le… Dicke…                  37 en       &quot;&quot;                 
## 34        25853 &quot;The Le… Dicke…                  37 en       &quot;&quot;                 
## 35        25854 &quot;The Le… Dicke…                  37 en       &quot;&quot;                 
## 36        25985 &quot;Bardel… Dicke…                  37 en       &quot;&quot;                 
## 37        30127 &quot;Tales … Dicke…                  37 en       &quot;&quot;                 
## 38        30368 &quot;A Chri… Dicke…                  37 en       &quot;&quot;                 
## 39        32241 &quot;Dicken… Dicke…                  37 en       &quot;&quot;                 
## 40        35536 &quot;The Po… Dicke…                  37 en       &quot;&quot;                 
## 41        37121 &quot;Charle… Dicke…                  37 en       &quot;&quot;                 
## 42        37581 &quot;The Cr… Dicke…                  37 en       &quot;&quot;                 
## 43        40723 &quot;The Ba… Dicke…                  37 en       &quot;&quot;                 
## 44        40729 &quot;\&quot;Old … Dicke…                  37 en       &quot;&quot;                 
## 45        41739 &quot;A Chri… Dicke…                  37 en       &quot;&quot;                 
## 46        41894 &quot;Christ… Dicke…                  37 en       &quot;&quot;                 
## 47        42232 &quot;A Chil… Dicke…                  37 en       &quot;&quot;                 
## 48        43111 &quot;The Pe… Dicke…                  37 en       &quot;&quot;                 
## 49        43207 &quot;Scenes… Dicke…                  37 en       &quot;&quot;                 
## 50        46675 &quot;Oliver… Dicke…                  37 en       &quot;&quot;                 
## 51        47534 &quot;The Po… Dicke…                  37 en       &quot;&quot;                 
## 52        47535 &quot;The Po… Dicke…                  37 en       &quot;&quot;                 
## 53        49125 &quot;Storie… Dicke…                  37 en       &quot;&quot;                 
## 54        52125 &quot;Nell a… Dicke…                  37 en       &quot;&quot;                 
## # ℹ 2 more variables: rights &lt;chr&gt;, has_text &lt;lgl&gt;</code></pre>
<div class="tabwid"><style>.cl-9f7edb44{table-layout:auto;width:95%;}.cl-9f737ea2{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f737ec0{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f777930{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f777944{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f7798d4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798de{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798e8{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798e9{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798f2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798f3{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f7798fc{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779906{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779907{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779908{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779910{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f77991a{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f77991b{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f77991c{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779924{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f779925{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-9f7edb44'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>All items on Project Gutenberg by Charles Dickens.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-9f7798d4"><p class="cl-9f777930"><span class="cl-9f737ea2">gutenberg_id</span></p></th><th class="cl-9f7798de"><p class="cl-9f777944"><span class="cl-9f737ea2">title</span></p></th><th class="cl-9f7798de"><p class="cl-9f777944"><span class="cl-9f737ea2">author</span></p></th><th class="cl-9f7798e8"><p class="cl-9f777930"><span class="cl-9f737ea2">gutenberg_author_id</span></p></th><th class="cl-9f7798de"><p class="cl-9f777944"><span class="cl-9f737ea2">language</span></p></th><th class="cl-9f7798de"><p class="cl-9f777944"><span class="cl-9f737ea2">gutenberg_bookshelf</span></p></th><th class="cl-9f7798de"><p class="cl-9f777944"><span class="cl-9f737ea2">rights</span></p></th><th class="cl-9f7798e9"><p class="cl-9f777930"><span class="cl-9f737ea2">has_text</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">46</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Literature/Christmas</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">564</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Mystery of Edwin Drood</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Mystery Fiction</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">580</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Pickwick Papers</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Best Books Ever Listings</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">699</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">A Child's History of England</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's History/United Kingdom</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">700</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Old Curiosity Shop</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">730</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Oliver Twist</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">766</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">David Copperfield</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Harvard Classics</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">821</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dombey and Son</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">917</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Barnaby Rudge: A Tale of the Riots of 'Eighty</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Historical Fiction</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">963</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Little Dorrit</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">967</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Nicholas Nickleby</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">968</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Martin Chuzzlewit</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Best Books Ever Listings</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,023</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Bleak House</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,392</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Seven Poor Travellers</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,394</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Holly-Tree</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,406</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Perils of Certain English Prisoners</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,407</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">A Message from the Sea</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,413</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Tom Tiddler's Ground</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,414</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Somebody's Luggage</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,415</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Doctor Marigold</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,416</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Mrs. Lirriper's Lodgings</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,419</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Mugby Junction</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,421</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Mrs. Lirriper's Legacy</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,422</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Going into Society</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">1,423</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">No Thoroughfare</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">1,465</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Wreck of the Golden Mary</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">15,618</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Loving Ballad of Lord Bateman</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">19,337</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">A Christmas Carol</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Literature/Christmas</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">20,795</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Cricket on the Hearth</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Literature</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">23,344</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Magic Fishbone</span><br><span class="cl-9f737ec0">A Holiday Romance from the Pen of Miss Alice Rainbird, Aged 7</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Picture Books</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">23,452</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Trial of William Tinkling</span><br><span class="cl-9f737ec0">Written by Himself at the Age of 8 Years</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Picture Books</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">23,765</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Captain Boldheart &amp; the Latin-Grammar Master</span><br><span class="cl-9f737ec0">A Holiday Romance from the Pen of Lieut-Col. Robin Redforth, aged 9</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Children's Picture Books</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">25,852</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Letters of Charles Dickens. Vol. 1, 1833-1856</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">25,853</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Letters of Charles Dickens. Vol. 2, 1857-1870</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">25,854</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Letters of Charles Dickens. Vol. 3, 1836-1870</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">25,985</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Bardell v. Pickwick</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">30,127</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Tales from Dickens</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">30,368</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">A Christmas Carol</span><br><span class="cl-9f737ec0">The original manuscript</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">32,241</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens' Stories About Children Every Child Can Read</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">35,536</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Poems and Verses of Charles Dickens</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">37,121</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Charles Dickens' Children Stories</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">37,581</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Cricket on the Hearth: A Fairy Tale of Home</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">40,723</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Battle of Life: A Love Story</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">40,729</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">"Old Scrooge": A Christmas Carol in Five Staves.</span><br><span class="cl-9f737ec0">Dramatized from Charles Dickens' Celebrated Christmas Story.</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">41,739</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">A Christmas Carol; Or, The Miser's Warning!</span><br><span class="cl-9f737ec0">(Adapted from Charles Dickens' Celebrated Work.)</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">41,894</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Christmas-Tide</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">42,232</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">A Child's Dream of a Star</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">43,111</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Personal History of David Copperfield</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">43,207</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Scenes and Characters from the Works of Charles Dickens</span><br><span class="cl-9f737ec0">Being Eight Hundred and Sixty-six Pictures Printed from the Original Wood Blocks</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">46,675</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Oliver Twist; or, The Parish Boy's Progress. Illustrated</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">47,534</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">The Posthumous Papers of the Pickwick Club, v. 1 (of 2)</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f779907"><p class="cl-9f777930"><span class="cl-9f737ec0">47,535</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">The Posthumous Papers of the Pickwick Club, v. 2 (of 2)</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779910"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f779908"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f77991a"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f7798f2"><p class="cl-9f777930"><span class="cl-9f737ec0">49,125</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Stories from Dickens</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f7798fc"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f7798f3"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779906"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9f77991b"><p class="cl-9f777930"><span class="cl-9f737ec0">52,125</span></p></td><td class="cl-9f77991c"><p class="cl-9f777944"><span class="cl-9f737ec0">Nell and Her Grandfather, Told from Charles Dickens's "The Old Curiosity Shop"</span></p></td><td class="cl-9f77991c"><p class="cl-9f777944"><span class="cl-9f737ec0">Dickens, Charles</span></p></td><td class="cl-9f779924"><p class="cl-9f777930"><span class="cl-9f737ec0">37</span></p></td><td class="cl-9f77991c"><p class="cl-9f777944"><span class="cl-9f737ec0">en</span></p></td><td class="cl-9f77991c"><p class="cl-9f777944"><span class="cl-9f737ec0"></span></p></td><td class="cl-9f77991c"><p class="cl-9f777944"><span class="cl-9f737ec0">Public domain in the USA.</span></p></td><td class="cl-9f779925"><p class="cl-9f777930"><span class="cl-9f737ec0">TRUE</span></p></td></tr></tbody></table></div>
<p>Now we have the complete output, we can go and identify the IDs of
the works we’re interested in. We find that:</p>
<ul>
<li>46 = A Christmas Carol<br />
</li>
<li>564 = The Mystery of Edwin Drood<br />
</li>
<li>580 = The Pickwick Papers<br />
</li>
<li>730 = Oliver Twist<br />
</li>
<li>766 = David Copperfield<br />
</li>
<li>821 = Dombey and Son<br />
</li>
<li>967 = Nicholas Nickleby<br />
</li>
<li>1023 = Bleak House</li>
</ul>
<p>We could either download each of the texts individually, but that
would be a hassle. Instead, we can save all of the ID numbers in a new
variable, which we’ll call <code>list_dickens</code>:</p>
<pre class="r"><code>list_dickens &lt;- c(46, 564, 580, 730, 766, 821, 967, 1023)</code></pre>
<p>This allows us to download all of the texts in one go (and clean it
by removing empty text elements using the <code>filter()</code> function
from the <code>dplyr</code> package):</p>
<pre class="r"><code># download data from Project Gutenberg
dickens_corpus &lt;- gutenberg_download(list_dickens, 
                                     meta_fields = &quot;title&quot;, 
                                     mirror = &quot;http://mirror.csclub.uwaterloo.ca/gutenberg&quot;) %&gt;%
  # remove empty rows
  dplyr::filter(text != &quot;&quot;)</code></pre>
<p>With this, we download the eight novels, saving them to a data frame
with one row per line per work, as well as the additional metadata of
the title of each work. If one were working with works by different
authors, it might make sense to include the author names - but since we
don’t, we won’t.</p>
<p>Taking a look at the <code>dickens_corpus</code> object is not yet
very meaningful:</p>
<pre class="r"><code>dickens_corpus %&gt;%
  head(10) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 10 lines of the Dickens data.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-abd22748{table-layout:auto;width:95%;}.cl-abc5d510{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-abc5d51a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-abca6fda{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-abca6fee{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-abca8d3a{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d44{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d4e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d4f{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d58{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d59{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d62{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d6c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d6d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d76{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d80{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-abca8d81{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-abd22748'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 10 lines of the Dickens data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-abca8d3a"><p class="cl-abca6fda"><span class="cl-abc5d510">gutenberg_id</span></p></th><th class="cl-abca8d44"><p class="cl-abca6fee"><span class="cl-abc5d510">text</span></p></th><th class="cl-abca8d4e"><p class="cl-abca6fee"><span class="cl-abc5d510">title</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-abca8d4f"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d58"><p class="cl-abca6fee"><span class="cl-abc5d51a">A CHRISTMAS CAROL</span></p></td><td class="cl-abca8d59"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d62"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d6c"><p class="cl-abca6fee"><span class="cl-abc5d51a">IN PROSE</span></p></td><td class="cl-abca8d6d"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d4f"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d58"><p class="cl-abca6fee"><span class="cl-abc5d51a">BEING</span></p></td><td class="cl-abca8d59"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d62"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d6c"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Ghost Story of Christmas</span></p></td><td class="cl-abca8d6d"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d4f"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d58"><p class="cl-abca6fee"><span class="cl-abc5d51a">by Charles Dickens</span></p></td><td class="cl-abca8d59"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d62"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d6c"><p class="cl-abca6fee"><span class="cl-abc5d51a">PREFACE</span></p></td><td class="cl-abca8d6d"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d4f"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d58"><p class="cl-abca6fee"><span class="cl-abc5d51a">I HAVE endeavoured in this Ghostly little book,</span></p></td><td class="cl-abca8d59"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d62"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d6c"><p class="cl-abca6fee"><span class="cl-abc5d51a">to raise the Ghost of an Idea, which shall not put my</span></p></td><td class="cl-abca8d6d"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d4f"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d58"><p class="cl-abca6fee"><span class="cl-abc5d51a">readers out of humour with themselves, with each other,</span></p></td><td class="cl-abca8d59"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-abca8d76"><p class="cl-abca6fda"><span class="cl-abc5d51a">46</span></p></td><td class="cl-abca8d80"><p class="cl-abca6fee"><span class="cl-abc5d51a">with the season, or with me.  May it haunt their houses</span></p></td><td class="cl-abca8d81"><p class="cl-abca6fee"><span class="cl-abc5d51a">A Christmas Carol in Prose; Being a Ghost Story of Christmas</span></p></td></tr></tbody></table></div>
<p>We can see the title of <em>The Mystery of Edwin Drood</em>, with one
line per row, and the table of contents included, but beyond that, not
yet too much. So let’s get to the data processing that will allow us to
do a bit of meaningful work with these texts.</p>
</div>
<div id="data-processing" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Data Processing</h1>
<p>Now that we have loaded the data, we need to prepare it for the
analysis (the topic modelling). The following section(s) describe and go
through the various data processing steps such as cleaning and
transformation.</p>
<div id="pre-processing-part-1" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Pre-Processing, Part
1</h2>
<p>The first step of the pre-processing requires us to transform the
texts we stored under <code>dickens_corpus</code>. First, we group the
data by title using <code>group_by()</code> (also a function from the
<code>dplyr</code> package) and we then we reframe the data so that each
row represents one sentence. During the reframing, we split the text
into sentences using the <code>tokenize_sentence</code> function from
the <code>quanteda</code> package. Then, we remove upper case sequences,
and we remove upper case letters except for capital <em>i</em> (I). This
should result in a table where each sentence represents one row.</p>
<pre class="r"><code>dickens_corpus %&gt;%
  dplyr::group_by(title) %&gt;%
  # combine text of each novel
  dplyr::reframe(text = paste0(text, collapse = &quot; &quot;),
                 # remove capitalized words
                 text = stringr::str_remove_all(text, &quot;[:upper:]{2,}&quot;),
                 # remove individual capitalized letters
                 text = stringr::str_replace_all(text, &quot; [A:H,J:Z] &quot;, &quot; &quot;),
                 text = unlist(quanteda::tokenize_sentence(text)),
                 text = stringr::str_squish(text)) -&gt; dickens_corpus</code></pre>
<p>To check if the splitting into sentences has worked, let’s have a
look at the transformed <code>dickens_corpus</code>:</p>
<pre class="r"><code>head(dickens_corpus$text, 10) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 10 lines of the data.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-acb841b0{table-layout:auto;width:95%;}.cl-acafdde0{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-acafddf4{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-acb2e3dc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-acb305f6{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-acb30600{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-acb30601{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-acb3060a{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-acb841b0'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 10 lines of the data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-acb305f6"><p class="cl-acb2e3dc"><span class="cl-acafdde0">.</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-acb30600"><p class="cl-acb2e3dc"><span class="cl-acafddf4">A Ghost Story of Christmas by Charles Dickens I endeavoured in this Ghostly little book, to raise the Ghost of an Idea, which shall not put my readers out of humour with themselves, with each other, with the season, or with me.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30601"><p class="cl-acb2e3dc"><span class="cl-acafddf4">May it haunt their houses pleasantly, and no one wish to lay it.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30600"><p class="cl-acb2e3dc"><span class="cl-acafddf4">Their faithful Friend and Servant, C.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30601"><p class="cl-acb2e3dc"><span class="cl-acafddf4">D.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30600"><p class="cl-acb2e3dc"><span class="cl-acafddf4">December, 1843.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30601"><p class="cl-acb2e3dc"><span class="cl-acafddf4">Stave I: Marley's Ghost Stave The First of the Three Spirits Stave The Second of the Three Spirits Stave The Last of the Spirits Stave V: The End of It I: 'S was dead: to begin with.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30600"><p class="cl-acb2e3dc"><span class="cl-acafddf4">There is no doubt whatever about that.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30601"><p class="cl-acb2e3dc"><span class="cl-acafddf4">The register of his burial was signed by the clergyman, the clerk, the undertaker, and the chief mourner.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb30600"><p class="cl-acb2e3dc"><span class="cl-acafddf4">Scrooge signed it: and Scrooge's name was good upon 'Change, for anything he chose to put his hand to.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-acb3060a"><p class="cl-acb2e3dc"><span class="cl-acafddf4">Old Marley was as dead as a door-nail.</span></p></td></tr></tbody></table></div>
<p>As we can see, we are left with each row representing one sentence.
Unfortunately, the sentence tokenisation has not worked perfectly as we
see that in the first row, the place of publication and the preface is
still part of the data.</p>
<p>To get a sense of the current structure of the corpus, we can take a
look at the titles, in the form of a table:</p>
<pre class="r"><code>table(dickens_corpus$title)</code></pre>
<pre><code>## 
## A Christmas Carol in Prose; Being a Ghost Story of Christmas 
##                                                         1916 
##                                                  Bleak House 
##                                                        20418 
##                                            David Copperfield 
##                                                        19360 
##                                               Dombey and Son 
##                                                        17821 
##                                            Nicholas Nickleby 
##                                                        16271 
##                                                 Oliver Twist 
##                                                         9104 
##                                   The Mystery of Edwin Drood 
##                                                         5605 
##                                          The Pickwick Papers 
##                                                        16151</code></pre>
<p>This command builds a contingency table, basically counting how many
documents in the corpus are associated with each title. This shows us,
on the one hand, how different in length the different novels are. On
the other hand, it allows us to see what we already caught a hint of
above: each sentence gets its own row in the corpus. While this is not
an issue for some approaches of text analysis, for topic modelling it
will present a problem - one that we’ll root out, but only at a later
stage of the pre-processing.</p>
</div>
<div id="parsing-the-corpus" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Parsing the
Corpus</h2>
<p>The next step is an essential, but also a computationally intense
one: we are going to parse the corpus. This is where we get the corpus
ready for topic modelling.</p>
<p>Before we go into the what and why of parsing, we suggest you
initiate the process - it can take a while (depending on how good your
device’s computing power is - it takes 1 hour and 6 seconds on my
laptop):</p>
<div class="warning"
style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
<strong>Because it takes so long, we suggest you do not execute the
following chunk but load the already processed data (as shown in the
<em>loading</em> chunk following the <em>parsing</em> chunk).</strong>
<br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<pre class="r"><code># parsing
dickens_corpus$text %&gt;%
  # pos-tagging
  udpipe::udpipe_annotate(m_eng, x = .) %&gt;%
  # convert into data frame
  as.data.frame() %&gt;%
  # remove sentence variable and save
  dplyr::select(-sentence) -&gt; dickens_parsed</code></pre>
<blockquote>
<p><strong>Execute the following chunk to load the already parsed
data!</strong></p>
</blockquote>
<pre class="r"><code># loading
# you can directly load the parsed dickens data by executing this chunk
dickens_parsed  &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/dickens_parsed.rda&quot;, &quot;rb&quot;))
# inspect data
dickens_parsed %&gt;%
  as.data.frame() %&gt;%
  head(10) %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 10 lines of the data.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-b30f521a{table-layout:auto;width:95%;}.cl-b2fd6492{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b2fd64b0{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b301d590{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b301d5b8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b30202cc{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b30202d6{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b30202ea{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b30202f4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b30202fe{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020308{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020312{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020313{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b302031c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020326{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020327{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020330{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020331{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b302033a{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b302033b{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3020344{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-b30f521a'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 10 lines of the data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-b30202cc"><p class="cl-b301d590"><span class="cl-b2fd6492">doc_id</span></p></th><th class="cl-b30202d6"><p class="cl-b301d5b8"><span class="cl-b2fd6492">paragraph_id</span></p></th><th class="cl-b30202d6"><p class="cl-b301d5b8"><span class="cl-b2fd6492">sentence_id</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">token_id</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">token</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">lemma</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">upos</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">xpos</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">feats</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">head_token_id</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">dep_rel</span></p></th><th class="cl-b30202ea"><p class="cl-b301d590"><span class="cl-b2fd6492">deps</span></p></th><th class="cl-b30202f4"><p class="cl-b301d590"><span class="cl-b2fd6492">misc</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-b30202fe"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">A</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">a</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">DET</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">DT</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">Definite=Ind|PronType=Art</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">0</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">root</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020313"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b302031c"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">By</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">by</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">ADP</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">IN</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">case</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020330"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b30202fe"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">New</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">New</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">PROPN</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">NNP</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">Number=Sing</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">compound</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020313"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b302031c"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">York</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">York</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">PROPN</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">NNP</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">Number=Sing</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">0</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">root</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020330"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b30202fe"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">4</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">&amp;</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">&amp;</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">CCONJ</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">CC</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">cc</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020313"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b302031c"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">5</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">.</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">.</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">PUNCT</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">.</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">punct</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020330"><p class="cl-b301d590"><span class="cl-b2fd64b0">SpacesAfter=\n</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b30202fe"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc2</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">_Copyright</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">_Copyright</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">INTJ</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">UH</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">discourse</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020313"><p class="cl-b301d590"><span class="cl-b2fd64b0">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b302031c"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc2</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020326"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">2</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">PUNCT</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0">punct</span></p></td><td class="cl-b3020327"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020330"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b30202fe"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc2</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020308"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">1905</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">1905</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">NUM</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">CD</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">NumType=Card</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">0</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0">root</span></p></td><td class="cl-b3020312"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020313"><p class="cl-b301d590"><span class="cl-b2fd64b0">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b3020331"><p class="cl-b301d590"><span class="cl-b2fd64b0">doc2</span></p></td><td class="cl-b302033a"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b302033a"><p class="cl-b301d5b8"><span class="cl-b2fd64b0">1</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">4</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">PUNCT</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">,</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">3</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0">punct</span></p></td><td class="cl-b302033b"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td><td class="cl-b3020344"><p class="cl-b301d590"><span class="cl-b2fd64b0"></span></p></td></tr></tbody></table></div>
<p>What the code chunk does is tokenize and tag the texts, returning a
data-table of the result. The corpus is thus transformed from an object
that has a sentence in each row, to one where each word has its own row.
More importantly, though, each word is assigned a part of speech tag.
Parsing text with <code>udpipe</code> also include lemmatization and
more complex tags like noun phrases, but for our purposes, part of
speech tags give enough information.</p>
<p>Once the parsing process is finished, we can take a look at the
structure of our new variable, <code>dickens_parsed</code>:</p>
<pre class="r"><code>str(dickens_parsed)</code></pre>
<pre><code>## &#39;data.frame&#39;:    2463083 obs. of  13 variables:
##  $ doc_id       : chr  &quot;doc1&quot; &quot;doc1&quot; &quot;doc1&quot; &quot;doc1&quot; ...
##  $ paragraph_id : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ sentence_id  : int  1 2 2 2 2 2 1 1 1 1 ...
##  $ token_id     : chr  &quot;1&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ...
##  $ token        : chr  &quot;A&quot; &quot;By&quot; &quot;New&quot; &quot;York&quot; ...
##  $ lemma        : chr  &quot;a&quot; &quot;by&quot; &quot;New&quot; &quot;York&quot; ...
##  $ upos         : chr  &quot;DET&quot; &quot;ADP&quot; &quot;PROPN&quot; &quot;PROPN&quot; ...
##  $ xpos         : chr  &quot;DT&quot; &quot;IN&quot; &quot;NNP&quot; &quot;NNP&quot; ...
##  $ feats        : chr  &quot;Definite=Ind|PronType=Art&quot; NA &quot;Number=Sing&quot; &quot;Number=Sing&quot; ...
##  $ head_token_id: chr  &quot;0&quot; &quot;3&quot; &quot;3&quot; &quot;0&quot; ...
##  $ dep_rel      : chr  &quot;root&quot; &quot;case&quot; &quot;compound&quot; &quot;root&quot; ...
##  $ deps         : chr  NA NA NA NA ...
##  $ misc         : chr  NA NA NA NA ...</code></pre>
<p>We are now dealing with a data frame that contains 2463083
observations (rows) of 13 variables (columns). Roughly two million words
for eight novels sounds about right. Of course, if we want to be sure
that we didn’t lose anything on the way thus far, we could go back to
the Gutenberg information to see whether we have the correct amount of
words. But we’ll carry on with the assumption that everything worked
fine so far.</p>
<p>The structure of the parsed corpus is very different from the
structure of the corpus as it was before. Among the columns, we find the
doc_id, sentence_id and token-ids, the tokens and their lemma, the part
of speech tag and the entity. Most of this, we will ignore for the
current purpose. What we need to get the corpus into processable form
are the part of speech tags.</p>
<p>So let’s look at the first few entries:</p>
<pre class="r"><code>head(dickens_parsed, n=15) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 15 lines of the parsed data.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-b353339a{table-layout:auto;width:95%;}.cl-b3404622{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b3404640{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b345d4ca{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b345d4de{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b345fa18{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa22{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa2c{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa36{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa40{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa4a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa4b{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa54{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa5e{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa68{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa69{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa72{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa73{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa7c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa7d{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b345fa86{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-b353339a'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 15 lines of the parsed data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-b345fa18"><p class="cl-b345d4ca"><span class="cl-b3404622">doc_id</span></p></th><th class="cl-b345fa22"><p class="cl-b345d4de"><span class="cl-b3404622">paragraph_id</span></p></th><th class="cl-b345fa22"><p class="cl-b345d4de"><span class="cl-b3404622">sentence_id</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">token_id</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">token</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">lemma</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">upos</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">xpos</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">feats</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">head_token_id</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">dep_rel</span></p></th><th class="cl-b345fa2c"><p class="cl-b345d4ca"><span class="cl-b3404622">deps</span></p></th><th class="cl-b345fa36"><p class="cl-b345d4ca"><span class="cl-b3404622">misc</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">A</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">a</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">DET</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">DT</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">Definite=Ind|PronType=Art</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">0</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">root</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">By</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">by</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">ADP</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">IN</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">case</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">New</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">New</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">PROPN</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">NNP</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">Number=Sing</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">compound</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">York</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">York</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">PROPN</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">NNP</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">Number=Sing</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">0</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">root</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">4</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">&amp;</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">&amp;</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">CCONJ</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">CC</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">cc</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">5</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">.</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">.</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">PUNCT</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">.</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">punct</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640">SpacesAfter=\n</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">_Copyright</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">_Copyright</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">INTJ</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">UH</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">discourse</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">2</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">PUNCT</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">punct</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">1905</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">1905</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">NUM</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">CD</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">NumType=Card</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">0</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">root</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">4</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">PUNCT</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">,</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">punct</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">5</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">by</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">by</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">ADP</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">IN</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">6</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">case</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">6</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">_</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">SYM</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">NFP</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">9</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">punct</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa40"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4a"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">7</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">&amp;</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">&amp;</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">CCONJ</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">CC</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">9</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640">cc</span></p></td><td class="cl-b345fa4b"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa54"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa5e"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa68"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">8</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">[</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">[</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">PUNCT</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">-LRB-</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">9</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640">punct</span></p></td><td class="cl-b345fa69"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa72"><p class="cl-b345d4ca"><span class="cl-b3404640">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b345fa73"><p class="cl-b345d4ca"><span class="cl-b3404640">doc2</span></p></td><td class="cl-b345fa7c"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa7c"><p class="cl-b345d4de"><span class="cl-b3404640">1</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">9</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">Illustration</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">Illustration</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">NOUN</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">NN</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">Number=Sing</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">3</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640">conj</span></p></td><td class="cl-b345fa7d"><p class="cl-b345d4ca"><span class="cl-b3404640"></span></p></td><td class="cl-b345fa86"><p class="cl-b345d4ca"><span class="cl-b3404640">SpaceAfter=No</span></p></td></tr></tbody></table></div>
<p>In these 15 rows we already see both the uses and the drawbacks of
what we are about to do. In rows 7 and 8 we find the words
<em>Charles</em> and <em>Dickens</em>, respectively. These get
identified correctly as proper nouns. Looking at rows 3 and 5, however,
we see that also <em>Christmas</em> and <em>Carol</em> get identified as
proper nouns (PROPN in the upos column). While Carol is a name, here it
clearly does not refer to a person, but to a type of music that was
typically sung around Christmas in the olden days. The reason for the
mislabelling of these words is rather, ahem, prosaic: as part of the
title, they are both spelt with capital letters, which to the parser
indicates that they are proper nouns. And the reason this presents a
problem is because we are going to remove all proper nouns.</p>
<p>If you respect the integrity of books (as we of course do too, under
most circumstances), you might be cringing at this point. Why would we
ruthlessly mangle texts like that?</p>
</div>
<div id="topic-modelling-and-the-purposes-of-parsing"
class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Topic Modelling and
the Purposes of Parsing</h2>
<p>The concept of topic modelling is based on the Firthian hypothesis
that “you shall know a word by the company it keeps” <span
class="citation">(<a href="#ref-firth1957ling">Firth 1957,
11</a>)</span>. When applying topic modelling to a corpus of text, we
exploit the fact that words which frequently occur in similar contexts
are representative of the same topic. One of the most common techniques
to construct topic models is the latent Dirichlet allocation (LDA). The
LDA</p>
<blockquote>
<p>derives word clusters using a generative statistical process that
begins by assuming that each document in a collection of documents is
constructed from a mix of some set of possible topics. The model then
assigns high probabilities to words and sets of words that tend to
co-occur in multiple contexts across the corpus. <span
class="citation">(<a href="#ref-jockers2013macroanalysis">Jockers 2013,
123</a>)</span></p>
</blockquote>
<p>The algorithm we will use in a minute is called STM, which stands for
Structural Topic Model. STM is very similar to LDA, but in addition to
what the LDA does, STM is capable of processing meta-information about
texts, such as the author or the date on which a document was produced.
More details about STM are available in <span class="citation">Roberts,
Stewart, and Tingley (<a
href="#ref-roberts2019stm">2019</a>)</span>.</p>
<p>The output of a topic modelling process most frequently comes as a
set of words that co-occur in multiple contexts across the corpus. This
understanding of the process reveals why, in this case, we choose to
remove the proper nouns: in the context of novels, proper nouns are
mostly names of characters and locations - and these names and locations
tend to co-occur mostly within novels. The upshot of which is that the
model latches onto these distinct proper nouns, which display a pattern
that is much more consistent than any other co-occurrence patterns in
the corpus, thus crowding out other patterns that are actually helpful
when it comes to answering our research questions on social criticism
and literary realism in Dickens.</p>
<p>Picking up where we left off with the pre-processing, there is
perhaps a question to be answered regarding the misidentification of
<em>Carol</em> as a proper noun. If we see something like that,
shouldn’t we make sure that we at least keep these terms in, since this
is obviously not the type of word we want to get rid of when we remove
the proper nouns from the corpus?</p>
<p>Well, no. For two reasons: firstly, when pre-processing large
quantities of text, there are always going to be some inaccuracies. The
relative merits of keeping in individual tokens that we see are
misidentified are, for all intents and purposes, irrelevant when we are
dealing with corpora that contain millions of words. Secondly, and
probably more importantly, going in and manually adjusting for
individual tokens make the process a lot less reproducible. Obviously,
it depends on the purpose of a project, but generally we don’t only want
to produce research, but produce it in such a way that anyone can
reproduce it (if they set their mind to it). Instead of going in and
fixing individual mislabellings, it’s a lot more useful to make sure
that each step of the research project is comprehensible to someone not
involved in the process.</p>
<p>That being said, if you end up with a topic model that is hard to
make sense of, and you have reason to believe that this is the result of
unsatisfactory pre-processing, it’s generally worthwhile to reflect on
each of the pre-processing steps, rather than going in and fixing
individual instances. We actually ended up doing some of the former for
this project, as we will detail below.</p>
</div>
<div id="pre-processing-part-2" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Pre-Processing, Part
2</h2>
<p>With the parsed corpus, as well as an understanding of how topic
modelling works, let’s proceed with the pre-processing.</p>
</div>
<div id="removing-proper-nouns" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Removing Proper
Nouns</h2>
<p>First off, we remove the proper nouns:</p>
<pre class="r"><code>no_prop_dickens &lt;- dickens_parsed %&gt;%
  dplyr::filter( upos != &quot;PROPN&quot;)</code></pre>
<p>We define a new variable, <code>no_prop_dickens</code>, and assign to
it the parsed Dickens corpus without the proper nouns. Specifically, we
assign all tokens which have not been tagged as proper nouns to the new
variable. The logical operator <code>!=</code> stands for
<code>not equal to</code>, thus allowing us to retain everything that is
not a proper noun.</p>
<p>Which, if we look at the number of rows the new variable contains,
turns out be most of the corpus:</p>
<pre class="r"><code>nrow(no_prop_dickens)</code></pre>
<pre><code>## [1] 2359427</code></pre>
<p>We get 1,916,359 rows, which means that only roughly 88,000 tokens
had been classified as proper nouns. While this sounds like a lot in
absolute terms, it only amounts to about 4.4% of the corpus. Considering
how much of an improvement this is for the final model, it’s an
absolutely acceptable price to pay.</p>
<p>It’s also worth checking briefly whether it was actually successful
at removing what we wanted to remove:</p>
<pre class="r"><code>head(no_prop_dickens, n=15) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 15 lines of the parsed data after removing proper nouns.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-b4211ae4{table-layout:auto;width:95%;}.cl-b40e1b92{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b40e1b9c{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b413c2d6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b413c2ea{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b413e36a{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e374{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e37e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e37f{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e388{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e392{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e393{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e39c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e39d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3a6{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3b0{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3ba{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3bb{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3c4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3ce{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b413e3cf{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-b4211ae4'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 15 lines of the parsed data after removing proper nouns.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-b413e36a"><p class="cl-b413c2d6"><span class="cl-b40e1b92">doc_id</span></p></th><th class="cl-b413e374"><p class="cl-b413c2ea"><span class="cl-b40e1b92">paragraph_id</span></p></th><th class="cl-b413e374"><p class="cl-b413c2ea"><span class="cl-b40e1b92">sentence_id</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">token_id</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">token</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">lemma</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">upos</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">xpos</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">feats</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">head_token_id</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">dep_rel</span></p></th><th class="cl-b413e37e"><p class="cl-b413c2d6"><span class="cl-b40e1b92">deps</span></p></th><th class="cl-b413e37f"><p class="cl-b413c2d6"><span class="cl-b40e1b92">misc</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">A</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">a</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">DET</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">DT</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">Definite=Ind|PronType=Art</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">0</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">root</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">2</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">By</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">by</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">ADP</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">IN</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">case</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">2</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">4</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">&amp;</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">&amp;</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">CCONJ</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">CC</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">cc</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">2</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">5</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">.</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">.</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">.</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpacesAfter=\n</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">_Copyright</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">_Copyright</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">INTJ</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">UH</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">discourse</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">2</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">1905</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">1905</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">NUM</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">CD</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">NumType=Card</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">0</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">root</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">4</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">,</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">5</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">by</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">by</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">ADP</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">IN</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">6</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">case</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">6</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">_</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SYM</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">NFP</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">9</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">7</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">&amp;</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">&amp;</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">CCONJ</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">CC</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">9</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">cc</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">8</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">[</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">[</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">-LRB-</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">9</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e388"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e392"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">9</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">Illustration</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">Illustration</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">NOUN</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">NN</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">Number=Sing</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">conj</span></p></td><td class="cl-b413e393"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e39c"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e39d"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3a6"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">10</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">:</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">:</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">:</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3b0"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ba"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b413e3bb"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">doc2</span></p></td><td class="cl-b413e3c4"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3c4"><p class="cl-b413c2ea"><span class="cl-b40e1b9c">1</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">11</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">"</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">"</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">PUNCT</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">``</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">3</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">punct</span></p></td><td class="cl-b413e3ce"><p class="cl-b413c2d6"><span class="cl-b40e1b9c"></span></p></td><td class="cl-b413e3cf"><p class="cl-b413c2d6"><span class="cl-b40e1b9c">SpaceAfter=No</span></p></td></tr></tbody></table></div>
<p>The first fifteen rows certainly indicate a success: gone is
<em>Christmas</em> and <em>Carol</em>, gone is <em>Charles</em> and
<em>Dickens</em>. Certain other features that are also not helpful for
interpreting the content of the corpus currently remain, most
prominently punctuation. Let’s take care of this.</p>
</div>
<div id="tokenizing-the-text" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Tokenizing the
Text</h2>
<p>The first step is tokenizing the <code>no_prop_dickens</code> and
removing punctuation and non-alphanumeric characters:</p>
<pre class="r"><code>no_prop_dickens %&gt;%
  dplyr::group_by(sentence_id) %&gt;%
  dplyr::summarise(sen = paste0(lemma, collapse = &quot; &quot;)) %&gt;%
  dplyr::pull(sen) %&gt;%
  #tokenisation
  quanteda::tokenize_sentence() %&gt;%
  unlist() %&gt;% 
  # remove non-word alpha-numeric characters
  stringr::str_remove_all(&quot;[^[:alnum:] ]&quot;) %&gt;%
  # remiove possessive s
  stringr::str_replace_all(&quot; s &quot;, &quot; &quot;) %&gt;%
  # convert to lower case 
  tolower() -&gt; toks</code></pre>
<p>We assign the contents of the <code>no_prop_dickens</code> object a
new variable <code>toks</code>, coercing the contents into a token
object. With this, we get rid of a lot of excess information that is not
relevant for the next steps. Let’s take a look:</p>
<pre class="r"><code>head(toks, n=10) %&gt;%
  as.data.frame() %&gt;%
  flextable() %&gt;%
  flextable::set_table_properties(width = .95, layout = &quot;autofit&quot;) %&gt;%
  flextable::theme_zebra() %&gt;%
  flextable::fontsize(size = 12) %&gt;%
  flextable::fontsize(size = 12, part = &quot;header&quot;) %&gt;%
  flextable::align_text_col(align = &quot;center&quot;) %&gt;%
  flextable::set_caption(caption = &quot;First 10 sentences of the cleaned data.&quot;)  %&gt;%
  flextable::border_outer()</code></pre>
<div class="tabwid"><style>.cl-b5cfb490{table-layout:auto;width:95%;}.cl-b5bfe36c{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b5bfe394{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b5c8367a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b5c85dda{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b5c85de4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b5c85dee{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b5c85df8{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-b5cfb490'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 10 sentences of the cleaned data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-b5c85dda"><p class="cl-b5c8367a"><span class="cl-b5bfe36c">.</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-b5c85de4"><p class="cl-b5c8367a"><span class="cl-b5bfe394">a copyright  1905  by na   illustration   he have be blood horse all the way from church    the combine qualitie of the realist and the idealist which possess to a remarkable degree  together with he naturally jovial attitude toward life in general  seem to have give he a remarkably happy feeling toward  though the privation and hardship of he boyhood could have allow he but little real experience with this day of day </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85dee"><p class="cl-b5c8367a"><span class="cl-b5bfe394">dickens give he first formal expression to he thought in he series of small book  the first of which be the famous    the one perfect chrysolite  the success of the book be immediate  write of it   who can listen to objection regard such a book as this </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85de4"><p class="cl-b5c8367a"><span class="cl-b5bfe394">it seem to i a national benefit  and to every man or woman who read it  a personal kindness   this volume be put forth in a very attractive manner  with illustration by  who be the first artist to make these character live  and he drawing be vari and spirite  there follow upon this four other   the    the cricket on the hearth    the of   and  the   with illustration on they first appearance by   and other  the five be know to  day as the    of they all the   be the best know and love  and  the cricket on the hearth   although third in the series  be perhaps next in point of popularity  and be especially familiar to through characterisation of </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85dee"><p class="cl-b5c8367a"><span class="cl-b5bfe394">dicken seem to have put he whole self into these glow little story  whoever see but a clever ghost story in the   miss its chief charm and lesson  for there be a different meaning in the movement of and he attendant spirit  no fog  no mist  clear  bright  jovial  stirr cold  cold  pipe for the blood to dance to  sun light  heavenly sky  sweet fresh air  merry bell  oh  glorious </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85de4"><p class="cl-b5c8367a"><span class="cl-b5bfe394">glorious </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85dee"><p class="cl-b5c8367a"><span class="cl-b5bfe394"> all this brightness have its attendant shadow  and deep from the childish heart come that true note of patho  the ever memorable toast of   god bless we  every one </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85de4"><p class="cl-b5c8367a"><span class="cl-b5bfe394">  the cricket on the hearth  strike a different note </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85dee"><p class="cl-b5c8367a"><span class="cl-b5bfe394">charmingly  poetically  the sweet chirping of the little cricket be associate with human feeling and action  and at the crisis of the story decide the fate and fortune of the carrier and he wife  greatest gift be characterization  and no english writer  save  have draw so many and so varied character  it would be as absurd to interpret all of these as caricature as to deny he great and varied power of creation </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85de4"><p class="cl-b5c8367a"><span class="cl-b5bfe394">dickens exaggerate many of he comic and satirical character  as be he right  for caricature and satire be very closely related  while exaggeration be the very essence of comedy  but there remain a host of character mark by humour and patho  yet the pictorial presentation of characters have ever tend toward the grotesque  the interpretation in this volume aim to eliminate the grosser phase of the caricature in favour of the more human  if the interpretation seem novel  if be not as he have be picture  it be because a more human scrooge be desire  a not wholly bad  a scrooge of a better heart  a scrooge to whom the resurrection describe in this story be possible  it have be the illustrator whole aim to make these people live in some form more fully consistent with they type </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-b5c85df8"><p class="cl-b5c8367a"><span class="cl-b5bfe394">na  na na save you </span></p></td></tr></tbody></table></div>
<p>The corpus now looks a lot like it did before we started with the
pre-processing: we see that again each sentence occupies one document.
The obvious difference is that all the proper nouns are gone - as we
intended.</p>
</div>
<div id="punctuation" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Punctuation</h2>
<p>Our next target is to transform the <code>toks</code> object into a
tokens object again (yes, it already is one), but this time we add
logical conditions which state <code>remove_punct = TRUE</code>,
<code>remove_symbols = TRUE</code>, and
<code>remove_numbers = TRUE</code>:</p>
<pre class="r"><code>toks &lt;- tokens(toks, remove_punct = TRUE, remove_symbols = TRUE, remove_numbers = TRUE)</code></pre>
<p>Again, a quick check to see if it worked:</p>
<pre class="r"><code>head(toks, n=15)</code></pre>
<pre><code>## Tokens consisting of 15 documents.
## text1 :
##  [1] &quot;a&quot;            &quot;copyright&quot;    &quot;by&quot;           &quot;na&quot;           &quot;illustration&quot;
##  [6] &quot;he&quot;           &quot;have&quot;         &quot;be&quot;           &quot;blood&quot;        &quot;horse&quot;       
## [11] &quot;all&quot;          &quot;the&quot;         
## [ ... and 59 more ]
## 
## text2 :
##  [1] &quot;dickens&quot;    &quot;give&quot;       &quot;he&quot;         &quot;first&quot;      &quot;formal&quot;    
##  [6] &quot;expression&quot; &quot;to&quot;         &quot;he&quot;         &quot;thought&quot;    &quot;in&quot;        
## [11] &quot;he&quot;         &quot;series&quot;    
## [ ... and 35 more ]
## 
## text3 :
##  [1] &quot;it&quot;       &quot;seem&quot;     &quot;to&quot;       &quot;i&quot;        &quot;a&quot;        &quot;national&quot;
##  [7] &quot;benefit&quot;  &quot;and&quot;      &quot;to&quot;       &quot;every&quot;    &quot;man&quot;      &quot;or&quot;      
## [ ... and 106 more ]
## 
## text4 :
##  [1] &quot;dicken&quot; &quot;seem&quot;   &quot;to&quot;     &quot;have&quot;   &quot;put&quot;    &quot;he&quot;     &quot;whole&quot;  &quot;self&quot;  
##  [9] &quot;into&quot;   &quot;these&quot;  &quot;glow&quot;   &quot;little&quot;
## [ ... and 58 more ]
## 
## text5 :
## [1] &quot;glorious&quot;
## 
## text6 :
##  [1] &quot;all&quot;        &quot;this&quot;       &quot;brightness&quot; &quot;have&quot;       &quot;its&quot;       
##  [6] &quot;attendant&quot;  &quot;shadow&quot;     &quot;and&quot;        &quot;deep&quot;       &quot;from&quot;      
## [11] &quot;the&quot;        &quot;childish&quot;  
## [ ... and 17 more ]
## 
## [ reached max_ndoc ... 9 more documents ]</code></pre>
<p>Comparing this latest output to the one preceding it, we find that
the comma, which was in the last position, has disappeared. We are
getting closer.</p>
</div>
<div id="stopwords" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> Stopwords</h2>
<p>The final of these smaller pre-processing steps, which are all
commonly applied with a lot of automated text analysis, is the removal
of stopwords. These are words which are very common, to a degree that
one can assume that they will show up on practically every page of a
book, thus making it harder for our model to identify more salient and
content-related co-occurrence patterns.</p>
<p>Stopwords are typically also words that have no little semantic
meaning on their own, for example <em>the</em>, <em>in</em>, etc. As
they rather regulate the relations between words, they are also called
function words (as opposed to content words, which we want to keep).
There is no universal list of stopwords - and some methods make do
without removing stopwords - but for our purposes, it makes sense to
just work with the default list supplied in the quanteda package. The
command is as follows:</p>
<pre class="r"><code>toks &lt;- toks %&gt;%
   # remove stopwords
  tokens_remove(pattern = stopwords(&quot;english&quot;)) </code></pre>
<p>Looking at the first few lines shows that this, too, worked:</p>
<pre class="r"><code>head(toks, n=15)</code></pre>
<pre><code>## Tokens consisting of 15 documents.
## text1 :
##  [1] &quot;copyright&quot;    &quot;na&quot;           &quot;illustration&quot; &quot;blood&quot;        &quot;horse&quot;       
##  [6] &quot;way&quot;          &quot;church&quot;       &quot;combine&quot;      &quot;qualitie&quot;     &quot;realist&quot;     
## [11] &quot;idealist&quot;     &quot;possess&quot;     
## [ ... and 25 more ]
## 
## text2 :
##  [1] &quot;dickens&quot;    &quot;give&quot;       &quot;first&quot;      &quot;formal&quot;     &quot;expression&quot;
##  [6] &quot;thought&quot;    &quot;series&quot;     &quot;small&quot;      &quot;book&quot;       &quot;first&quot;     
## [11] &quot;famous&quot;     &quot;one&quot;       
## [ ... and 11 more ]
## 
## text3 :
##  [1] &quot;seem&quot;     &quot;national&quot; &quot;benefit&quot;  &quot;every&quot;    &quot;man&quot;      &quot;woman&quot;   
##  [7] &quot;read&quot;     &quot;personal&quot; &quot;kindness&quot; &quot;volume&quot;   &quot;put&quot;      &quot;forth&quot;   
## [ ... and 37 more ]
## 
## text4 :
##  [1] &quot;dicken&quot;  &quot;seem&quot;    &quot;put&quot;     &quot;whole&quot;   &quot;self&quot;    &quot;glow&quot;    &quot;little&quot; 
##  [8] &quot;story&quot;   &quot;whoever&quot; &quot;see&quot;     &quot;clever&quot;  &quot;ghost&quot;  
## [ ... and 32 more ]
## 
## text5 :
## [1] &quot;glorious&quot;
## 
## text6 :
##  [1] &quot;brightness&quot; &quot;attendant&quot;  &quot;shadow&quot;     &quot;deep&quot;       &quot;childish&quot;  
##  [6] &quot;heart&quot;      &quot;come&quot;       &quot;true&quot;       &quot;note&quot;       &quot;patho&quot;     
## [11] &quot;ever&quot;       &quot;memorable&quot; 
## [ ... and 5 more ]
## 
## [ reached max_ndoc ... 9 more documents ]</code></pre>
<p>We are left with rather fewer words than before, but the ones that
remain are the ones which could be relevant for our research
question.</p>
</div>
<div id="chunks" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Chunks</h2>
<p>The next challenge is the structure in which Gutenberg supplies its
texts: each sentence occupies one row. In order to arrive at
interpretable results, we need to get chunks of text that are long
enough to contain co-occurrences of words, and we need to get enough of
them in order for the LDA to be able identify patterns of co-occurrences
throughout the corpus. Sentences are too short for this, and with only
eight novels, dividing the corpus into books would not yield good
results because there are not enough different texts in which to observe
co-occurrence patterns.</p>
<p>This leaves two options: dividing the corpus along chapters, or
simply creating chunks of a certain length. It is the latter approach we
are pursuing here, for three reasons: reconstructing the corpus along
chapters is technically somewhat more involved; on top of that, a
chapter may still be so long that the topic changes considerably for the
beginning of the chapter to the end; finally, you might be interested in
working with texts from a different source than Gutenberg, and the
approach to chunking that we use here will work for most textual data,
regardless of the source.</p>
<p>We begin by unraveling these documents into an object that contains a
single token per row. The command <code>unlist()</code> allows us to do
this, as it produces a vector which contains all the atomic components
that occur in an object.</p>
<pre class="r"><code>list_toks &lt;- unlist(toks, use.names = F)</code></pre>
<p>Now, we basically have Dickens novels as a long list of individual
words, without a proper name:</p>
<pre class="r"><code>head(list_toks, n=15) </code></pre>
<pre><code>##  [1] &quot;copyright&quot;    &quot;na&quot;           &quot;illustration&quot; &quot;blood&quot;        &quot;horse&quot;       
##  [6] &quot;way&quot;          &quot;church&quot;       &quot;combine&quot;      &quot;qualitie&quot;     &quot;realist&quot;     
## [11] &quot;idealist&quot;     &quot;possess&quot;      &quot;remarkable&quot;   &quot;degree&quot;       &quot;together&quot;</code></pre>
<p>Now, we are faced with choosing the size of the text chunks we want
to feed into our model. There is no best practice of how to choose the
chunk size, which means that there is some trial and error involved
here. Basically we want chunks that are large enough to allow for
meaningful co-occurrences to be observed, but small enough that
co-occurrences that get identified by the model are meaningful in some
way. One way to get there is to use paragraphs, as they are a meaningful
unit of discourse. But we do not have paragraphs in our corpus.</p>
<p>The heuristic we chose to start from is that two pages of a novel
should contain a bunch of words relating to a similar theme - thinking
for instance of descriptions of a space or person. As the average A5
page contains roughly 500 words, we started out with chunk sizes of
1,000 words.</p>
<p>However, it is very much a process of trial and error as to what
chunk size yields the best results. We played around with a bunch of
plausible sizes - plausible in the sense that, for instance, only half a
page is roughly the lower bound on which to expect co-occurrences. Thus,
we tried different versions between 250 and 5000 words, and we will
explore different chunk sizes in this range together in what
follows.</p>
<p>Once we decide on where to start, we simply define the chunk
size:</p>
<pre class="r"><code>chunk &lt;- 1000</code></pre>
<p>Next, we assign the length of our corpus to a new variable:</p>
<pre class="r"><code>n &lt;- length(list_toks)</code></pre>
<p>We now have two variables, <code>chunk</code> and <code>n</code>
which simply contain a number each. With these, we define a new
object:</p>
<pre class="r"><code>r &lt;- rep(1:ceiling(n/chunk), each = chunk)[1:n]</code></pre>
<p>This takes a bit of unpacking. The <code>rep()</code> function
replicates the values in the brackets. But what are we feeding it there?
The centerpiece is in the fraction <code>n/chunk</code>, a simple
calculation which states that, given the length (n) of our corpus, if we
want chunks of 1,000 words each, there will be 717 chunks. We set this
value (716.412, to be precise) as the ceiling. In effect, we are setting
a range between 1 and 717. The next element, <code>each = chunk</code>,
tells us how frequently each element in the range is to be repeated.
Finally, with the specifications in the square brackets, we say that
this process should be carried out for the whole length of our corpus.
Confused yet?</p>
<p>If we simply were to run this command, instead of assigning it to the
object <code>r</code>, as we do above, the output would be a list of
1,000 repetitions of <code>1</code>, followed by 1,000 repetitions of
<code>2</code> and so on, until we get to 1,000 repetitions of
<code>716</code> and finally some repetitions of <code>717</code>.</p>
<p>Have a look at the variable r, for instance with the table
function:</p>
<pre class="r"><code>table(r)</code></pre>
<pre><code>## r
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##   97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 
## 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 
##  849  850  851  852  853  854  855 
## 1000 1000 1000 1000 1000 1000  576</code></pre>
<p>The table shows you the number of repeated items. The number
corresponds to what we describe above. <code>1</code> is repeated 1,000
times, as is <code>2</code>, as is <code>3</code> and so on, until we
get to <code>702</code>, which is only repeated 412 times. The purpose
to this madness comes with the next command, where we split the corpus
in its current <code>list_toks</code> form into chunks of 1,000 words
each:</p>
<pre class="r"><code>chunky_dickens &lt;- split(list_toks, r)</code></pre>
<p>Basically, the first 1,000 words are assigned to the first
pseudo-document, simply labeled <code>1</code>, the second 1,000 words
are assigned to a second pseudo-document, labeled <code>2</code>, and so
on and so forth. If this does not seem to make heads or tails, the
description of the split function in R is actually quite clear.</p>
<pre class="r"><code>help(split)</code></pre>
<p>This tells us that the command <code>split(x, f)</code> divides the
data in the vector x into the groups defined by f. Which is how we end
up with 717 chunks, 716 of which contain 1,000 words and the last of
which contains the end of the tail, so to speak.</p>
<p>Before looking at the contents of the <code>chunky_dickens</code>
object, we can get an indication for whether the process was a success
by looking at the length of the object:</p>
<pre class="r"><code>length(chunky_dickens)</code></pre>
<pre><code>## [1] 855</code></pre>
<p>The length of 695, indicating 695 pseudo-documents in the corpus, is
already a good sign. We term these chunks pseudo-documents since they
are artificially constructed and not exactly representative of a
structure of the novels (the way chapters would be, for instance). Now,
let’s take a look at only the structure of our new object
<code>chunky_dickens</code>:</p>
<pre class="r"><code>str(chunky_dickens)</code></pre>
<pre><code>## List of 855
##  $ 1  : chr [1:1000] &quot;copyright&quot; &quot;na&quot; &quot;illustration&quot; &quot;blood&quot; ...
##  $ 2  : chr [1:1000] &quot;wonder&quot; &quot;go&quot; &quot;parliament&quot; &quot;angry&quot; ...
##  $ 3  : chr [1:1000] &quot;gruel&quot; &quot;cold&quot; &quot;head&quot; &quot;upon&quot; ...
##  $ 4  : chr [1:1000] &quot;bound&quot; &quot;round&quot; &quot;head&quot; &quot;know&quot; ...
##  $ 5  : chr [1:1000] &quot;fowls&quot; &quot;cluck&quot; &quot;strut&quot; &quot;stable&quot; ...
##  $ 6  : chr [1:1000] &quot;clock&quot; &quot;struck&quot; &quot;eleven&quot; &quot;domestic&quot; ...
##  $ 7  : chr [1:1000] &quot;quarter&quot; &quot;hour&quot; &quot;go&quot; &quot;yet&quot; ...
##  $ 8  : chr [1:1000] &quot;hearty&quot; &quot;nature&quot; &quot;sympathy&quot; &quot;poor&quot; ...
##  $ 9  : chr [1:1000] &quot;company&quot; &quot;pile&quot; &quot;fire&quot; &quot;half&quot; ...
##  $ 10 : chr [1:1000] &quot;quite&quot; &quot;loud&quot; &quot;often&quot; &quot;guess&quot; ...
##  $ 11 : chr [1:1000] &quot;change&quot; &quot;life&quot; &quot;think&quot; &quot;hope&quot; ...
##  $ 12 : chr [1:1000] &quot;say&quot; &quot;try&quot; &quot;see&quot; &quot;obtain&quot; ...
##  $ 13 : chr [1:1000] &quot;night&quot; &quot;can&quot; &quot;anything&quot; &quot;like&quot; ...
##  $ 14 : chr [1:1000] &quot;case&quot; &quot;next&quot; &quot;famous&quot; &quot;instance&quot; ...
##  $ 15 : chr [1:1000] &quot;anything&quot; &quot;else&quot; &quot;since&quot; &quot;leave&quot; ...
##  $ 16 : chr [1:1000] &quot;retainer&quot; &quot;like&quot; &quot;express&quot; &quot;steward&quot; ...
##  $ 17 : chr [1:1000] &quot;forgive&quot; &quot;face&quot; &quot;relent&quot; &quot;wrong&quot; ...
##  $ 18 : chr [1:1000] &quot;least&quot; &quot;see&quot; &quot;strange&quot; &quot;wrap&quot; ...
##  $ 19 : chr [1:1000] &quot;shall&quot; &quot;really&quot; &quot;see&quot; &quot;consideration&quot; ...
##  $ 20 : chr [1:1000] &quot;one&quot; &quot;poor&quot; &quot;little&quot; &quot;thing&quot; ...
##  $ 21 : chr [1:1000] &quot;time&quot; &quot;might&quot; &quot;heal&quot; &quot;wound&quot; ...
##  $ 22 : chr [1:1000] &quot;strange&quot; &quot;conductress&quot; &quot;inform&quot; &quot;time&quot; ...
##  $ 23 : chr [1:1000] &quot;appearance&quot; &quot;think&quot; &quot;look&quot; &quot;round&quot; ...
##  $ 24 : chr [1:1000] &quot;grant&quot; &quot;will&quot; &quot;relief&quot; &quot;possibly&quot; ...
##  $ 25 : chr [1:1000] &quot;age&quot; &quot;pretty&quot; &quot;young&quot; &quot;bride&quot; ...
##  $ 26 : chr [1:1000] &quot;winter&quot; &quot;perpetual&quot; &quot;summer&quot; &quot;age&quot; ...
##  $ 27 : chr [1:1000] &quot;break&quot; &quot;confidence&quot; &quot;submit&quot; &quot;better&quot; ...
##  $ 28 : chr [1:1000] &quot;artful&quot; &quot;contrivance&quot; &quot;hydraulic&quot; &quot;pressure&quot; ...
##  $ 29 : chr [1:1000] &quot;walk&quot; &quot;though&quot; &quot;grave&quot; &quot;will&quot; ...
##  $ 30 : chr [1:1000] &quot;shutter&quot; &quot;tumbl&quot; &quot;hinge&quot; &quot;fall&quot; ...
##  $ 31 : chr [1:1000] &quot;quite&quot; &quot;confused&quot; &quot;find&quot; &quot;think&quot; ...
##  $ 32 : chr [1:1000] &quot;child&quot; &quot;answer&quot; &quot;nothing&quot; &quot;sit&quot; ...
##  $ 33 : chr [1:1000] &quot;ogre&quot; &quot;say&quot; &quot;believe&quot; &quot;reputation&quot; ...
##  $ 34 : chr [1:1000] &quot;old&quot; &quot;people&quot; &quot;young&quot; &quot;invest&quot; ...
##  $ 35 : chr [1:1000] &quot;parasite&quot; &quot;quite&quot; &quot;overpower&quot; &quot;parent&quot; ...
##  $ 36 : chr [1:1000] &quot;variety&quot; &quot;expression&quot; &quot;save&quot; &quot;word&quot; ...
##  $ 37 : chr [1:1000] &quot;three&quot; &quot;hour&quot; &quot;time&quot; &quot;say&quot; ...
##  $ 38 : chr [1:1000] &quot;opium&quot; &quot;less&quot; &quot;nothing&quot; &quot;shining&quot; ...
##  $ 39 : chr [1:1000] &quot;like&quot; &quot;describe&quot; &quot;inquest&quot; &quot;recreative&quot; ...
##  $ 40 : chr [1:1000] &quot;come&quot; &quot;night&quot; &quot;drive&quot; &quot;park&quot; ...
##  $ 41 : chr [1:1000] &quot;dusk&quot; &quot;library&quot; &quot;every&quot; &quot;day&quot; ...
##  $ 42 : chr [1:1000] &quot;aboard&quot; &quot;ship&quot; &quot;submit&quot; &quot;leg&quot; ...
##  $ 43 : chr [1:1000] &quot;old&quot; &quot;crippler&quot; &quot;say&quot; &quot;shak&quot; ...
##  $ 44 : chr [1:1000] &quot;inform&quot; &quot;hand&quot; &quot;labour&quot; &quot;success&quot; ...
##  $ 45 : chr [1:1000] &quot;teach&quot; &quot;anything&quot; &quot;particular&quot; &quot;reply&quot; ...
##  $ 46 : chr [1:1000] &quot;weaver&quot; &quot;one&quot; &quot;might&quot; &quot;hope&quot; ...
##  $ 47 : chr [1:1000] &quot;servant&quot; &quot;sir&quot; &quot;know&quot; &quot;amost&quot; ...
##  $ 48 : chr [1:1000] &quot;thing&quot; &quot;car&quot; &quot;little&quot; &quot;anything&quot; ...
##  $ 49 : chr [1:1000] &quot;possibly&quot; &quot;continue&quot; &quot;really&quot; &quot;sir&quot; ...
##  $ 50 : chr [1:1000] &quot;stop&quot; &quot;outside&quot; &quot;house&quot; &quot;see&quot; ...
##  $ 51 : chr [1:1000] &quot;never&quot; &quot;turn&quot; &quot;head&quot; &quot;come&quot; ...
##  $ 52 : chr [1:1000] &quot;say&quot; &quot;get&quot; &quot;say&quot; &quot;always&quot; ...
##  $ 53 : chr [1:1000] &quot;gently&quot; &quot;kindly&quot; &quot;distinctly&quot; &quot;dear&quot; ...
##  $ 54 : chr [1:1000] &quot;busy&quot; &quot;make&quot; &quot;pleasant&quot; &quot;journey&quot; ...
##  $ 55 : chr [1:1000] &quot;accord&quot; &quot;common&quot; &quot;fate&quot; &quot;house&quot; ...
##  $ 56 : chr [1:1000] &quot;make&quot; &quot;radiant&quot; &quot;contrast&quot; &quot;shade&quot; ...
##  $ 57 : chr [1:1000] &quot;shade&quot; &quot;hottest&quot; &quot;long&quot; &quot;vacation&quot; ...
##  $ 58 : chr [1:1000] &quot;hear&quot; &quot;altercation&quot; &quot;appear&quot; &quot;upon&quot; ...
##  $ 59 : chr [1:1000] &quot;find&quot; &quot;nothing&quot; &quot;agree&quot; &quot;well&quot; ...
##  $ 60 : chr [1:1000] &quot;post&quot; &quot;trust&quot; &quot;thing&quot; &quot;come&quot; ...
##  $ 61 : chr [1:1000] &quot;say&quot; &quot;ah&quot; &quot;good&quot; &quot;room&quot; ...
##  $ 62 : chr [1:1000] &quot;water&quot; &quot;water&quot; &quot;water&quot; &quot;water&quot; ...
##  $ 63 : chr [1:1000] &quot;every&quot; &quot;stroke&quot; &quot;stroke&quot; &quot;document&quot; ...
##  $ 64 : chr [1:1000] &quot;massive&quot; &quot;kind&quot; &quot;swagger&quot; &quot;grave&quot; ...
##  $ 65 : chr [1:1000] &quot;real&quot; &quot;objection&quot; &quot;accompany&quot; &quot;place&quot; ...
##  $ 66 : chr [1:1000] &quot;breath&quot; &quot;square&quot; &quot;lad&quot; &quot;say&quot; ...
##  $ 67 : chr [1:1000] &quot;suit&quot; &quot;already&quot; &quot;pernicious&quot; &quot;cause&quot; ...
##  $ 68 : chr [1:1000] &quot;throw&quot; &quot;preceptor&quot; &quot;lesson&quot; &quot;last&quot; ...
##  $ 69 : chr [1:1000] &quot;say&quot; &quot;preoccupation&quot; &quot;mind&quot; &quot;hope&quot; ...
##  $ 70 : chr [1:1000] &quot;hard&quot; &quot;sir&quot; &quot;say&quot; &quot;harder&quot; ...
##  $ 71 : chr [1:1000] &quot;attraction&quot; &quot;also&quot; &quot;come&quot; &quot;speak&quot; ...
##  $ 72 : chr [1:1000] &quot;picture&quot; &quot;man&quot; &quot;speak&quot; &quot;inclin&quot; ...
##  $ 73 : chr [1:1000] &quot;condition&quot; &quot;touch&quot; &quot;nearly&quot; &quot;happen&quot; ...
##  $ 74 : chr [1:1000] &quot;gallery&quot; &quot;act&quot; &quot;sweep&quot; &quot;wink&quot; ...
##  $ 75 : chr [1:1000] &quot;retire&quot; &quot;dear&quot; &quot;say&quot; &quot;kind&quot; ...
##  $ 76 : chr [1:1000] &quot;always&quot; &quot;slide&quot; &quot;seat&quot; &quot;straw&quot; ...
##  $ 77 : chr [1:1000] &quot;little&quot; &quot;shop&quot; &quot;street&quot; &quot;musician&quot; ...
##  $ 78 : chr [1:1000] &quot;see&quot; &quot;clerk&quot; &quot;look&quot; &quot;mark&quot; ...
##  $ 79 : chr [1:1000] &quot;deserve&quot; &quot;say&quot; &quot;happy&quot; &quot;say&quot; ...
##  $ 80 : chr [1:1000] &quot;bear&quot; &quot;trace&quot; &quot;winter&quot; &quot;hothouse&quot; ...
##  $ 81 : chr [1:1000] &quot;whether&quot; &quot;possess&quot; &quot;single&quot; &quot;relative&quot; ...
##  $ 82 : chr [1:1000] &quot;know&quot; &quot;make&quot; &quot;part&quot; &quot;night&quot; ...
##  $ 83 : chr [1:1000] &quot;evening&quot; &quot;sit&quot; &quot;without&quot; &quot;coat&quot; ...
##  $ 84 : chr [1:1000] &quot;twist&quot; &quot;knot&quot; &quot;never&quot; &quot;mind&quot; ...
##  $ 85 : chr [1:1000] &quot;unconcerned&quot; &quot;may&quot; &quot;say&quot; &quot;strange&quot; ...
##  $ 86 : chr [1:1000] &quot;keep&quot; &quot;door&quot; &quot;wide&quot; &quot;open&quot; ...
##  $ 87 : chr [1:1000] &quot;sir&quot; &quot;notice&quot; &quot;queer&quot; &quot;kind&quot; ...
##  $ 88 : chr [1:1000] &quot;hand&quot; &quot;legal&quot; &quot;friend&quot; &quot;security&quot; ...
##  $ 89 : chr [1:1000] &quot;roll&quot; &quot;shirt&quot; &quot;sleeve&quot; &quot;tight&quot; ...
##  $ 90 : chr [1:1000] &quot;patriarch&quot; &quot;coachman&quot; &quot;fierce&quot; &quot;grin&quot; ...
##  $ 91 : chr [1:1000] &quot;young&quot; &quot;man&quot; &quot;name&quot; &quot;house&quot; ...
##  $ 92 : chr [1:1000] &quot;old&quot; &quot;store&quot; &quot;old&quot; &quot;girl&quot; ...
##  $ 93 : chr [1:1000] &quot;formerly&quot; &quot;think&quot; &quot;sure&quot; &quot;heart&quot; ...
##  $ 94 : chr [1:1000] &quot;come&quot; &quot;every&quot; &quot;day&quot; &quot;fully&quot; ...
##  $ 95 : chr [1:1000] &quot;power&quot; &quot;soothe&quot; &quot;calamity&quot; &quot;never&quot; ...
##  $ 96 : chr [1:1000] &quot;feel&quot; &quot;glow&quot; &quot;exultation&quot; &quot;renown&quot; ...
##  $ 97 : chr [1:1000] &quot;great&quot; &quot;consolation&quot; &quot;natural&quot; &quot;gentle&quot; ...
##  $ 98 : chr [1:1000] &quot;turret&quot; &quot;seem&quot; &quot;complete&quot; &quot;repose&quot; ...
##  $ 99 : chr [1:1000] &quot;candle&quot; &quot;light&quot; &quot;appear&quot; &quot;important&quot; ...
##   [list output truncated]</code></pre>
</div>
<div id="document-term-matrix" class="section level2" number="3.10">
<h2><span class="header-section-number">3.10</span> Document-Term
Matrix</h2>
<p>Now, the corpus is almost in the shape it needs to be in for the
topic modelling to proceed. What we require for the modelling process is
a document-term matrix (have a look at the tutorial on document
classification if you do not know what a document-term matrix is). This
is essentially a table which counts how often each word occurs in each
of the pseudo-documents. We’ll get into the structure of the
document-term matrix in a second. First, however, we need to turn it
into a tokens object, as the current object cannot be transformed into a
document-term matrix. The different types of objects that we use are
created with the quanteda library, which means you can find further
details on any of these objects in the documentation of quanteda
library.</p>
<pre class="r"><code>chunky_toks &lt;- tokens(chunky_dickens)</code></pre>
<p>The contents of the <code>chunky_dickens</code> object are
transformed into a tokens object and assigned to a new object,
<code>chunky_toks</code>. Looking at the new object, it displays a
different behavior:</p>
<pre class="r"><code>head(chunky_toks)</code></pre>
<pre><code>## Tokens consisting of 6 documents.
## 1 :
##  [1] &quot;copyright&quot;    &quot;na&quot;           &quot;illustration&quot; &quot;blood&quot;        &quot;horse&quot;       
##  [6] &quot;way&quot;          &quot;church&quot;       &quot;combine&quot;      &quot;qualitie&quot;     &quot;realist&quot;     
## [11] &quot;idealist&quot;     &quot;possess&quot;     
## [ ... and 988 more ]
## 
## 2 :
##  [1] &quot;wonder&quot;     &quot;go&quot;         &quot;parliament&quot; &quot;angry&quot;      &quot;uncle&quot;     
##  [6] &quot;come&quot;       &quot;dine&quot;       &quot;morrow&quot;     &quot;say&quot;        &quot;see&quot;       
## [11] &quot;yes&quot;        &quot;indeed&quot;    
## [ ... and 988 more ]
## 
## 3 :
##  [1] &quot;gruel&quot;    &quot;cold&quot;     &quot;head&quot;     &quot;upon&quot;     &quot;hob&quot;      &quot;nobody&quot;  
##  [7] &quot;bed&quot;      &quot;nobody&quot;   &quot;closet&quot;   &quot;nobody&quot;   &quot;dressing&quot; &quot;gow&quot;     
## [ ... and 988 more ]
## 
## 4 :
##  [1] &quot;bound&quot;    &quot;round&quot;    &quot;head&quot;     &quot;know&quot;     &quot;smart&quot;    &quot;sound&quot;   
##  [7] &quot;tooth&quot;    &quot;make&quot;     &quot;jaw&quot;      &quot;bring&quot;    &quot;together&quot; &quot;bandage&quot; 
## [ ... and 988 more ]
## 
## 5 :
##  [1] &quot;fowls&quot;     &quot;cluck&quot;     &quot;strut&quot;     &quot;stable&quot;    &quot;coach&quot;     &quot;house&quot;    
##  [7] &quot;shed&quot;      &quot;overrun&quot;   &quot;grass&quot;     &quot;retentive&quot; &quot;ancient&quot;   &quot;state&quot;    
## [ ... and 988 more ]
## 
## 6 :
##  [1] &quot;clock&quot;    &quot;struck&quot;   &quot;eleven&quot;   &quot;domestic&quot; &quot;ball&quot;     &quot;break&quot;   
##  [7] &quot;take&quot;     &quot;stations&quot; &quot;one&quot;      &quot;either&quot;   &quot;side&quot;     &quot;door&quot;    
## [ ... and 988 more ]</code></pre>
<p>The structure with pseudo-documents of 1,000 tokens remains, but now
the output doesn’t overflow as hard as it did before. Moreover, the
<code>chunky_toks</code> object can be turned into a document-term
matrix. For this, we use the command <code>dfm()</code>, which
transforms token (and other) objects into a sparse document-feature
matrix:</p>
<pre class="r"><code>dtm &lt;- dfm(chunky_toks)</code></pre>
<p>We create a new object <code>dtm</code>, to which we assign the
transformed contents of the <code>chunky_toks</code> object.</p>
<p>Taking a look at the <code>dtm</code> object gives a sense for its
structure:</p>
<pre class="r"><code>dtm</code></pre>
<pre><code>## Document-feature matrix of: 855 documents, 23,028 features (97.39% sparse) and 0 docvars.
##     features
## docs copyright na illustration blood horse way church combine qualitie realist
##    1         1 12            4     2     1   5      1       1        1       1
##    2         0  1            0     2     1   2      1       0        0       0
##    3         0  3            1     0     0   0      0       0        0       0
##    4         0  3            1     0     0   5      1       0        0       0
##    5         0  6            1     0     1   3      0       0        0       0
##    6         0  2            0     0     0   1      0       0        0       0
## [ reached max_ndoc ... 849 more documents, reached max_nfeat ... 23,018 more features ]</code></pre>
<p>The corpus is now structured as a table, and we see that for each of
the pseudo-documents, there is a count for how often each word occurs.
We also see that the <code>dtm</code> object retains the 717
pseudo-documents, and contains 27,695 features.</p>
</div>
</div>
<div id="exploring-the-data" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Exploring the Data</h1>
<div id="document-frequencies" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Document
Frequencies</h2>
<p>It makes sense to investigate the features some more before
proceeding to the topic modelling. Specifically, it’s worth looking at
the document frequency of the different features in the corpus:</p>
<pre class="r"><code>doc_freq = docfreq(dtm)</code></pre>
<p>The command <code>doc_freq()</code> by default simply counts how many
documents each feature occurs in. We assign this information to a new
variable, <code>doc_freq</code>. This is useful information for topic
modelling since it presents us with a chance to see which features are,
on the basis of their overall frequency, likely to co-occur with a lot
of other features. Also, like in document classification, it typically
makes sense to get rid of very rare features, which would lead to large
and overfitted models. It also gives us the opportunity to get a sense
for just how frequent the most frequent features are.</p>
<p>Let’s take a look at the first twenty features:</p>
<pre class="r"><code>head(doc_freq, n=20)</code></pre>
<pre><code>##    copyright           na illustration        blood        horse          way 
##            1          148           31          157          196          796 
##       church      combine     qualitie      realist     idealist      possess 
##          148           47           11            1            1          140 
##   remarkable       degree     together    naturally       jovial     attitude 
##          151          199          505          131           16          108 
##       toward         life 
##            6          674</code></pre>
<p>This already gives us a sense for the range: from <code>1843</code>
which occurs in only one of our pseudo-documents, whereas
<code>one</code> occurs in 715 pseudo-documents.</p>
<p>We can also take a look at the twenty five most common features. For
this, we sort the features in <code>doc_freq</code> in decreasing
order:</p>
<pre class="r"><code>head(sort(doc_freq, decreasing=T), n=25)</code></pre>
<pre><code>##    say   look    one   upon   take   know    see   make     go   time   come 
##    854    852    851    850    850    849    849    848    847    843    842 
##  think    now little   hand   will   good   much   head  great   like   well 
##    838    834    833    832    817    813    807    804    803    802    799 
##    way    man    eye 
##    796    795    795</code></pre>
<p>This list already gives a slight pointer towards Dickens style, if
not yet too much toward literary realism. The most common feature
<em>said</em>, which occurs in all but one of our pseudo-documents, as
well as its present equivalent <em>say</em>, which occurs in 667
pseudo-documents, indicate that there is a lot of speech and dialogue in
these novels. There are also several words related to time,
<em>time</em>, <em>now</em>, <em>never</em>, <em>first</em>, and in some
way also <em>old</em>, indicating that there is likely some development
of characters and states.</p>
<p>We are also seeing the rewards of our pre-processing: had we not
removed punctuation and stopwords, this list would be chock-full of
<em>the</em>, <em>a</em>, <em>I</em>, commas, fullstops and so on.</p>
<p>Moreover, we can see that the twenty fifth most frequent word,
<em>first</em>, has a document-frequency of 627, which is to say it
occurs in 87% of all pseudo-documents. This is still quite a lot and
would lead to many uninterpretable co-occurrences if we weren’t to trim
away the most frequent of the remaining features, as we will in a later
step.</p>
<p>But first, let’s take a brief look at the other end of the document
frequencies. Again, we sort the frequencies in decreasing order, but
this time we look at the twenty five entries with the lowest count,
using the <code>tail()</code> command:</p>
<pre class="r"><code>tail(sort(doc_freq, decreasing=T), n=25)</code></pre>
<pre><code>##         cripp     connectin  adwisability   conversable        seated 
##             1             1             1             1             1 
##       desists        cloggy        forger    showerbath     hearthrug 
##             1             1             1             1             1 
##     everbrown      contests     angerless     softeners          owor 
##             1             1             1             1             1 
##      stickler        seemly       duteous imaginatively       amplest 
##             1             1             1             1             1 
##     strenuous         dates     coverings  unappeasable     arguments 
##             1             1             1             1             1</code></pre>
<p>Unsurprisingly, we see only features that occur in one single
pseudo-document each. Some of these, specifically, all the ones which
include commas and dashes that stand between words without space, can be
attributed to erroneous processing. Others just seem to be rare words,
like <em>limes</em>, <em>pretender</em> or <em>schoolhouse</em>.</p>
<p>More interesting, and indicative of Dickens style and perspective,
are the words <em>stimilated</em> and <em>olesome</em>. Deriving from
<em>stimulated</em> and <em>wholesome</em>, both are clearly legible,
but clearly deviate from the standard spelling. These two words give us
a first flavour of Dickens’ literary realism, which entails the use of
non-standard spelling to render the dialogue of characters who speak
dialects other than the Queen’s English.</p>
<p>With a quick search, we can also identify <em>untoe</em> as an
alternate spelling of <em>unto</em>, as spoken by Pumblechook in Great
Expectations. Looking at the source material can certainly help to
identify features which are otherwise hardly legible. On that same page
as we find <em>untoe</em>, we also see that Pumblechook is the character
who utters <em>m’ria</em>, which turns out to be a contracted form of
the name <em>Maria</em>. A few sentences further, we also see that in
Pumblechook’s dialogue <em>are</em> is spelt as <em>air</em> - thus
showing that we won’t be able to identify all alternate spellings when
they are taken out of context, the way they are presented here.</p>
</div>
</div>
<div id="topic-modellings" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Topic Modellings</h1>
<p>After this substantial bit of pre-processing, we finally get to the
juicy bits. One last step of pre-processing remains, however. We are
going to trim the document-feature matrix, so as to remove the most
frequent words, as well as the rarest ones. The reason we include this
step as part of the topic modelling section rather than the
pre-processing is that this step is closer to fiddling with the
parameters of the model than most of the preceding steps were.</p>
<div id="trimming" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Trimming</h2>
<p>Trimming is used to return a document-feature matrix reduced in size
based on the document and term frequency. That is to say, we can set a
range for how many individual occurrences of a feature are acceptable,
and set a range for the percentage of documents a feature can occur in.
Although, the latter part we need to define specifically. Let’s take a
look at the command:</p>
<pre class="r"><code>dtm_trimmed &lt;- dfm_trim(dtm, min_termfreq=2, min_docfreq=0.0001, max_docfreq=0.15, docfreq_type=&quot;prop&quot;)</code></pre>
<p>We apply the command <code>dfm_trim()</code> to the <code>dtm</code>
object, and assign the output to a new object, <code>dtm_trimmed</code>.
We further specify:</p>
<p>*That the minimum term frequency should be 2. So only terms which
occur at least twice in the corpus are to be included in
<code>dtm_trimmed</code>. This makes sense if you consider that the
topic model is seeking co-occurrence patterns that appear throughout the
corpus. If a word appears only once, it will have some co-occurrences
with other words, but it will not yield an identifiable pattern, since,
well, it doesn’t occur in any other pseudo-documents.</p>
<p>*That the minimum document frequency should be 0.005. That is to say
that only features which appear in more than 0.5% of all
pseudo-documents are included in <code>dtm_trimmed</code>. So only
features which occur in more than three pseudo-documents are
included.</p>
<p>*That the maximum document frequency should be 0.25. That is to say
that only features which appear in less than a quarter, in less than
179, of all pseudo-documents are included in
<code>dtm_trimmed</code>.</p>
<p>*We define this with the specification
<code>docfreq_type="prop"</code>, which gives us a proportion by
dividing the document frequencies of all features by the total sum of
pseudo-documents.</p>
<p>If you are wondering why we went to the trouble of plucking out all
the stopwords and proper nouns, if we have this much simpler way of
cutting the corpus down in size, you have a point. The answer is as
straightforward as the question: topic modelling works better if you
have less features that are not interpretable (stopwords) or the mess up
the modelling process (proper nouns). If we simply relied on trimming to
get out the most frequent words, the chance of landing in the sweet spot
where meaningfully interpretable topics arise are a lot slimmer. Which
is why we do all of the pre-processing, and then still trim the corpus
down to an even more manageable size - which is where we are now.</p>
<p>So the pre-processed and trimmed version of the corpus,
<code>dtm_trimmed</code>, provides the basis for the first model. And
the first model is always a first model, since all of the parameters
will have to be tweaked later on, in order to arrive at better models
that are easier to interpret. But before we get into that, let’s create
the first model on the basis of the above parameters.</p>
</div>
<div id="first-model" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> First Model</h2>
<p>Actually creating a topic model is a question of a single line of
code, which looks like this:</p>
<pre class="r"><code>stmOut_1 &lt;- stm(documents=dtm_trimmed, K=10, max.em.its=200, verbose = F)</code></pre>
<p>Before checking out the results, let’s look at what this command
does. We create a new object, <code>stmOut_1</code> and assign a
structural topic model to it with the <code>stm()</code> command. We set
<code>dtm_trimmed</code> as the document term matrix we want modelled,
and tell the algorithm to create a model with 10 topics, which is
represented by <code>K=10</code>. The final specification,
<code>max.em.its=200</code> basically tells R to stop improving the
model after 200 iterations, even if it does not reach convergence. What
does this mean?</p>
<p>Basically, the model starts with the 10,000 most frequent words. From
these, it identifies some anchor words to build co-occurrence patterns
on, and then it begins iterating over the model. With each iteration,
the co-occurrences patterns are refined, with the new model being
compared to the preceding one. In the output, you can see the relative
change from model to model. Once the marginal improvements from further
iterations flattens out, the model is considered converged, i.e. as good
as it gets. So, with the parameter above, the improvement of the model
is terminated after 200 iterations even if there are still marginal
improvements to be had. For a more technical description of how this
works, we refer you to <span class="citation">Blei, Ng, and Jordan (<a
href="#ref-blei2003lda">2003</a>)</span>.</p>
<p>Let’s see what our latest object, <code>stmOut_1</code> holds:</p>
<pre class="r"><code>stmOut_1</code></pre>
<pre><code>## A topic model with 10 topics, 855 documents and a 15187 word dictionary.</code></pre>
<p>Not very informative yet, is it? For interpretable results, we want
to see the keywords of the ten topics in the model, which we can do by
plotting the contents of the model. For this, we use the
<code>plot()</code> command, feed it our model and tell it to display
the top ten keywords for each model:</p>
<pre class="r"><code>plot(stmOut_1, n=10, cex = .5, xlim = c(0, .8))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>If your model is anything like ours, this is not yet what you’d call
revelatory. There are some word pairs throughout the topics which go
well together. For instance, we get <em>prisoner</em> and
<em>prison</em> in one topic; <em>sea</em>, <em>river</em>, and
<em>ship</em> in another; <em>houses</em> and <em>windows</em>;
<em>dog</em> and <em>guardian</em>; <em>magistrate</em> and
<em>collector</em>.</p>
<p>Additionally, we get one topic with a lot of contractions: ’ll - ’em
- ’re - ’ve; and another one with alternate spellings like
<em>wery</em>, <em>wot</em>, <em>ai</em>, <em>wos</em>. The former
represents informal speech settings, and the latter points to dialogue
in dialect.</p>
<p>The topics showing up in your model will in all likelihood look
similar, but somewhat differently. This has to do with the fact that the
<code>stm()</code> function uses a random seed, which is to say that
each time you run the command it starts at a different point in the
corpus, leading to some variance in the results each time. There is, in
theory, the possibility of setting the seed, so as to guarantee that
with the same input, you will get the same results every time you run
the command. We refrain from doing so here, since the results are robust
enough that you will find ample similarities between our descriptions
and your own models.</p>
<p>With this disclaimer out of the way, let’s briefly recall the initial
research questions: 1. Can we use topic modelling to bring Dickens’
social criticism to the fore, without the heavy lifting of actually
reading his books? 2. Can we use topic modelling to explore the rich
imagery that Dickens constructs with his literary realism?</p>
<p>Despite this first model only showing hints of meaning, we can relate
the two distinct topics consisting of contractions and alternate
spellings to both research questions. On the one hand, the inclusion of
informal and dialectal language points towards Dickens’ literary
realism, which incorporates realistic depictions of spoken language. On
the other hand, Dickens’ choice to represent characters which speak a
dialect other than received pronunciation is clearly predicated on his
progressive attitudes towards poverty and the people living in it.</p>
<p>So we have some indication that the topic modelling is a) working, by
making visible non-standard speech, and b) that we can actually glean
some insights from it. However, it’s also clear that there is a lot of
room for improvement. The question is: where do we start?</p>
</div>
<div id="wild-goose-chase" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Wild Goose Chase</h2>
<p>There is a whole bunch of parameters that determine what the model
looks like. These are: * As part of the <code>stm()</code>
function:<br />
+ Number of topics<br />
+ Maximum number of iterations (fairly irrelevant in this case)<br />
* As part of the <code>dfm_trim()</code> function:<br />
+ Minimum term frequency<br />
+ Minimum document frequency<br />
+ Maximum document frequency<br />
* As part of the pre-processing:<br />
+ The chunk size</p>
<p>Getting from a first model to a good model is typically something of
a wild goose chase, involving a lot of trial and error. In the
following, we walk backwards through our options, starting with the
number of topics, tweaking as we go along.</p>
</div>
<div id="second-model-more-topics" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Second Model: More
Topics</h2>
<p>Sometimes, the number of topics is a constraint that prevents the
model from displaying its found co-occurrences in the level of
granularity that is required. To remedy this, we give it space for 20
topics instead of 10, and see where this takes us:</p>
<pre class="r"><code>stmOut_2 &lt;- stm(documents=dtm_trimmed, K=20, seed = 123, max.em.its=200, verbose = F)
plot(stmOut_2, n=10, cex = .5, xlim = c(0, .4))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<p>This already presents quite an improvement over the first model.
There is a degree of clarity to the topics that gives us more cause for
hope. One of the topics pertains to water, with words like
<em>boat</em>, <em>river</em>, <em>wind</em>, <em>tide</em>,
<em>sea</em> and <em>marshes</em>. Another topic reflects a young man’s
education, with the words like <em>boys</em>, <em>brothers</em>,
<em>school</em>, <em>schoolmaster</em>, <em>son</em> and <em>desk</em>.
Giving further indication of Dickens’ interests in justice, there is a
topic containing words like <em>prisoner</em>, <em>prison</em>,
<em>jury</em>, <em>court</em>, <em>citizen</em> and <em>witness</em>.
Closely related, there is a topic that reflects the institutional aspect
more strongly, featuring words like <em>magistrate</em>,
<em>office</em>, <em>clerk</em>, <em>attorney</em>, <em>officer</em> and
<em>judge</em>. Pointing towards an interest in death and the
otherworldly, there is a topic showing <em>beneath</em>, <em>grave</em>,
<em>goblin</em>, <em>churchyard</em>, <em>earth</em>, <em>church</em>
and <em>wind</em>. This also picks up on the ambiance Dickens is capable
of conjuring, as he for instance does at the beginning of Great
Expectations. Additionally, there are now several topics that capture
contractions and alternate spellings, as discussed above. Although you
won’t see the exact same topics, you should be able to see some
improvements in the model.</p>
<p>Despite this increase in meaningful topics, we also get several
topics that don’t have a clear line, which are somewhere between hard
and impossible to interpret. But overall, with this simple adjustment of
a single parameter, we have made a big step away from poking around in
tea-leaves, and towards an interpretable means of automated content
analysis.</p>
</div>
<div id="third-model-more-rare-words" class="section level2"
number="5.5">
<h2><span class="header-section-number">5.5</span> Third Model: More
Rare Words</h2>
<p>Taking a step back towards pre-processing, we can amplify the role
that rare words play, which might or might not lead us towards a more
interpretable model. To do this, we trim the <code>dtm</code> object in
such a way that only words that occur in no more than 15% of the
pseudo-documents are included:</p>
<pre class="r"><code>dtm_trimmed &lt;- dfm_trim(dtm, min_termfreq=2, min_docfreq=0.005, max_docfreq=0.15, docfreq_type=&quot;prop&quot;)</code></pre>
<p>And then we create a new model:</p>
<pre class="r"><code>stmOut_3 &lt;- stm(documents=dtm_trimmed, K=20, seed = 123, max.em.its=200, verbose = F)
stmOut_3</code></pre>
<pre><code>## A topic model with 20 topics, 855 documents and a 9048 word dictionary.</code></pre>
<pre class="r"><code>stmOut_1</code></pre>
<pre><code>## A topic model with 10 topics, 855 documents and a 15187 word dictionary.</code></pre>
<p>Comparing this new model <code>stmOut_3</code> to the first one,
<code>stmOut_1</code>, we see that the dictionary is smaller, as we
would expect, limiting the range of included words as we did. With the
latest trimming step, we lost some 397 words. Let’s see where that gets
us in terms of the model:</p>
<pre class="r"><code>plot(stmOut_3, n=10, cex = .5, xlim = c(0, .4))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>If your model is anything like ours, you will find some rather
intriguing new words in some of the topics, for instance <em>monks</em>
and a <em>lion</em> show up for us, but in general this does not seem to
have been an improvement. Indeed, we also get words like
<em>murdstone</em> and <em>peggotty</em>, which in addition to
<em>copperfield</em> and <em>squeers</em> that we already had before,
indicate that the removal of proper nouns in the pre-processing did not
capture all of the characters. Depending on how rigorous a research
project is intended to be, this might be the point at which to revisit
the pre-processing, and finding alternate means of identifying character
names. For the current purposes we continue working with this rather
imperfect data (although, for expectation management: your data is
likely to always have some flaws or quirks).</p>
</div>
<div id="fourth-model-more-common-words" class="section level2"
number="5.6">
<h2><span class="header-section-number">5.6</span> Fourth Model: More
Common Words</h2>
<p>We can also explore what happens when increasing the minimum document
frequency to 1%. This means that only words occurring in at least seven
pseudo-documents:</p>
<pre class="r"><code>dtm_trimmed &lt;- dfm_trim(dtm, min_termfreq=2, min_docfreq=0.01, max_docfreq=0.25, docfreq_type=&quot;prop&quot;)
stmOut_4 &lt;- stm(documents=dtm_trimmed, K=30, seed = 123, max.em.its=200, verbose = F)</code></pre>
<p>You’ll notice that we jumped directly to <code>K=30</code>, sparing
you at least one step between the previous model and this one. The
reason is that the model in between did not yield anything exciting. We
would very much encourage you to experiment with different parameters
here to get a sense for what changes when you shift a single parameter.
Or, to at the very least do so when you are working on a project of your
own. For better or worse, at this stage in its life cycle (and
improvements in the method are sure to come), topic modelling takes a
lot of tinkering.</p>
<p>Let’s see how the most recent adjustment, tightening the range of
document frequencies, changed our model:</p>
<pre class="r"><code>plot(stmOut_4, n=10, cex = .5, xlim = c(0, .3))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p>Again, if your model is anything like ours, there will be a remnant
of some of the clearest topics from the second model (we smell a vaguely
salty breeze from a somewhat diluted water-related topic and hear the
rustling of papers in court from another, less coherent legal topic),
but no overall improvement - which may be down to the fact that we need
to backtrack a bit further.</p>
</div>
<div id="fifth-model-smaller-chunks" class="section level2"
number="5.7">
<h2><span class="header-section-number">5.7</span> Fifth Model: Smaller
Chunks</h2>
<p>Since we already walked through each line of code step by step above,
we take the shortcut and copy the relevant steps here:</p>
<pre class="r"><code>chunk &lt;- 500</code></pre>
<p>We adjust the size of chunks downward, from 1,000 to 500 words. This
will by definition limit the number of co-occurrences each word has,
which should be especially relevant for rare and/or very scene-specific
words. Then we proceed:</p>
<pre class="r"><code>n &lt;- length(list_toks)
r &lt;- rep(1:ceiling(n/chunk), each = chunk)[1:n]
chunky_dickens &lt;- split(list_toks, r)
chunky_toks &lt;- tokens(chunky_dickens)
dtm &lt;- dfm(chunky_toks)</code></pre>
<p>For this first model derived from smaller chunks, we use the
specifications that have worked best thus far, namely the ones we had on
the second model:</p>
<pre class="r"><code>dtm_trimmed &lt;- dfm_trim(dtm, min_termfreq=2, min_docfreq=0.005, max_docfreq=0.25, docfreq_type=&quot;prop&quot;)
stmOut_5 &lt;- stm(documents=dtm_trimmed, K=25, seed = 123, max.em.its=200, verbose = F)</code></pre>
<p>Again, we opt to go for another number of topics, this time twenty
five, for identical reasons as above.</p>
<p>While the model is being constructed, we can quickly think through
how working with smaller chunks affects the other parameters. We still
simply select a number of topics, and since we do not process the
content of the corpus any further, the minimum term frequency will
remain the same. However, the minimum and maximum document frequency
will change. Since we are using relative document frequencies, and
increasing the number of documents, rare words that made the
trimming-cut before might now not be included anymore. Conversely, more
frequent words that made the cut before (because they appeared in, let’s
say, 23% of all documents) might not be included anymore, since they
might now be present in 26% of documents, or even more. Let’s see how
that changes our model:</p>
<pre class="r"><code>plot(stmOut_5, n=10, cex = .5, xlim = c(0, .3))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<p>This looks rather different than before, and the glimpses of Dickens’
literary realism and perspective on poverty that we saw in earlier
models are beginning to consolidate. The most salient topics in our
model are still the ones that capture informal language usage:
Considering that <em>said</em>’ was the term with the highest document
frequency, we have a good indication that there is a lot of dialogue -
and we could tell so even if we had never read a single un-processed
word of these novels. Now we see that seven out of twenty five topics
contain informal or dialectal language. This sheer presence of informal
language topics shows how much space Dickens is willing to give to
people who do not speak received pronunciation, which can be a marker
for rural and working class folks, as well as children - all of whom
have a high chance of living in poverty. So Dickens’ willingness to
represent people in poverty becomes even more salient than it was
before.</p>
<p>We also get some more distinct topics than we did before. One of them
points to graveyards, with words like <em>ground</em>, <em>cold</em>,
<em>beneath</em>, <em>lay</em>, <em>spot</em>, <em>earth</em> and
notably <em>grave</em>. Another one points to comfortable evenings, with
words including <em>evening</em>, <em>dinner</em>, <em>remember</em>,
<em>parlour</em>, <em>glad</em> and <em>sitting</em>. Two topics again
indicate an engagement with justice, one of them containing the likes of
<em>prisoner</em>, <em>prison</em> and <em>death</em>, while the other
harbors words like <em>case</em>, <em>question</em>, <em>judge</em>,
<em>clerk</em>, <em>jury</em> and <em>attorney</em>.</p>
<p>By decreasing the chunk size from 1,000 to 500, we are coming closer
to where we want to get, but there is still room for improvement. To
answer the question whether we should go even smaller, it’s perhaps
worthwhile to reflect on why 500 word chunks work better than 1,000 word
chunks: Basically, the whole process is intended to find a sweet spot
between words that are rare enough to be semantically representative of
a given topic, but frequent enough to not be singular or hyper-specific.
So, in order to arrive at a model that is meaningfully interpretable, we
need to find a chunk size that allows for thematically relevant
co-occurrence patterns to emerge, while shifting the thresholds for the
minimum and maximum document frequencies to a range that reveals the
thematically salient co-occurrence patterns.</p>
<p>A further factor is data sparseness versus topic development: if our
chunks are too short, only few words, that is features, remain. As a
result, the detection of topics, which typically hinges on several words
in collaboration, suffers. But if our chunks are too large, they cannot
detect changes in topics as they happen in the course of the development
of the document, and the resulting co-occurrence patterns become
impossible to interpret.</p>
<p>The direction that follows from the latest adjustment of the model is
clear: we should try smaller chunks to see whether they can even better
capture meaningful co-occurrence patterns.</p>
</div>
<div id="sixth-model-even-smaller-chunks" class="section level2"
number="5.8">
<h2><span class="header-section-number">5.8</span> Sixth Model: Even
Smaller Chunks</h2>
<p>For our next model, we will work with chunks of 200 words each, and
use the same specifications on the trimming as before:</p>
<pre class="r"><code>chunk &lt;- 200
n &lt;- length(list_toks)
r &lt;- rep(1:ceiling(n/chunk), each = chunk)[1:n]
chunky_dickens &lt;- split(list_toks, r)
chunky_toks &lt;- tokens(chunky_dickens)
dtm_3 &lt;- dfm(chunky_toks)
dtm_trimmed_3 &lt;- dfm_trim(dtm_3, min_termfreq=2, min_docfreq=0.005, max_docfreq=0.25, docfreq_type=&quot;prop&quot;)
stmOut_6 &lt;- stm(documents=dtm_trimmed_3, K=25, seed = 123, max.em.its=200, verbose = F)
plot(stmOut_6, n=10, cex = .5, xlim = c(0, .3))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>Decreasing the chunk size gets us much closer to where we want to
get. Across the twenty five topics, themes begin to emerge. Reliably
emerging - and since the very first model, too - are alternate spellings
and contractions, indicative of non-RP spoken language. In our version,
we get four different topics relating to this theme, with some distinct
flavors. One of them is reflective of dialects or sociolects -
containing <em>wery, </em>wot<em>, </em>ere<em>, </em>ai* - while
another one contains contractions like <em>’ll</em> and <em>n’t</em>
alongside words that detail interactions, like <em>asked</em>,
<em>hear</em> and <em>tell</em>. We have four topics of this kind, with
some variation and distinction but a lot of consistency.</p>
<p>Another set of topics more clearly points to Dickens literary
realism. One of them - displaying a high degree of internal consistency
- pertains to travel, with the words <em>coach</em>, <em>road</em>,
<em>horses</em>, <em>chaise</em> and <em>guard</em>. Another topic
captures descriptions of outdoor spaces, containing <em>light</em>,
<em>wind</em>, <em>people</em>, <em>water</em>, <em>windows</em>,
<em>dark</em>, <em>streets</em> and <em>sea</em>. The third one in this
group describes a comfortable social setting with <em>glass</em>,
<em>table</em>, <em>gentlemen</em>, <em>wine</em>, <em>company</em>,
<em>bottle</em>, <em>chair</em> and <em>water</em>. The fact that these
topics contain words which describe different spaces with high degree of
granularity reflects Dickens’ interest in including mundane-ish
experiences in some level of detail, which is pretty much the definition
of literary realism. This is also reflected in other topics, which
contain words like <em>hat</em> and <em>coat</em>. Although these are
less salient than the ones described above, they contain aspects of the
mundane and, thus, of literary realism.</p>
<p>A further theme that arises in various topics are positive emotions,
which could also be put under the label care. There are two topics that
reflect this theme in terms of family, with words like <em>child</em>,
<em>home</em>, <em>shall</em>, <em>happy</em>, <em>loved</em>,
<em>love</em> and <em>heart</em> in one, and <em>mother</em>,
<em>home</em>, <em>always</em>, <em>pretty</em>, <em>laughing</em>,
<em>remember</em> and <em>sure</em> in the other. In the third topic of
this theme, things get really interesting, as the scope opens up: we get
<em>heart</em>, <em>love</em>, <em>beautiful</em>, <em>happiness</em>,
<em>happy</em> and in addition we get <em>poor</em>, <em>people</em> and
<em>world</em>. Of course, we should not jump to conclusions based on
topic models alone, but this topic certainly gives us an indication that
Dickens’ might just have a broader conception of who is worthy of
happiness, beauty, and love, than some of his contemporaries.</p>
<p>Beyond these themes which are directly pertinent to our research
questions, there are some other topics worth mentioning. With the words
<em>father</em>, <em>business</em>, <em>money</em>, <em>brother</em>,
<em>tell</em> and <em>hope</em>, which refers to the prospects Dickens’
characters tend to have, before their lives get sidetracked by chance
and circumstance. There are also topics pertaining to remembrances -
with <em>saw</em>, <em>seen</em>, <em>sat</em>, <em>home</em>,
<em>knew</em>, <em>gone</em> and <em>left</em> - as well as loss:
<em>child</em>, <em>hands</em>, <em>let</em>, <em>heart</em>,
<em>cried</em>, <em>moment</em>, <em>arm</em>, <em>arms</em> and
<em>death</em>.</p>
<p>Finally, we get some topics that that we’ve seen in previous models,
related for example to school - <em>boys</em>, <em>school</em>,
<em>morning</em> - or jurisdiction, with <em>gentlemen</em>,
<em>case</em>, <em>name</em>, <em>shall</em>, <em>judge</em>,
<em>magistrate</em> and <em>court</em>. However, these are not as clear
cut as in some of our other models. Then of course, there remain some
topics which are barely interpretable, but that is really not
uncommon.</p>
<p>Still, we can see (and you should be able to as well, albeit with
slight differences in what arises exactly) that this model with smaller
chunks allows us to answer our research questions rather well.</p>
</div>
<div id="seventh-model-small-chunks-narrower-range"
class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> Seventh Model: Small
Chunks, Narrower Range</h2>
<p>Since the trajectory of smaller chunks has thus far led to
improvements with our results, we tried a model based on even smaller
chunks, but the results got worse. So instead of displaying that, we’ll
look at another model based on 200-word chunks, but this time we narrow
the range of included words by setting the maximum document frequency at
15%.</p>
<pre class="r"><code>dtm_trimmed_4 &lt;- dfm_trim(dtm_3, min_termfreq=2, min_docfreq=0.005, max_docfreq=0.15, docfreq_type=&quot;prop&quot;)
stmOut_7 &lt;- stm(documents=dtm_trimmed_4, K=25, seed = 123, max.em.its=200, verbose = F)
plot(stmOut_7, n=10, cex = .5, xlim = c(0, .3))</code></pre>
<p><img src="topmod_dickens_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>In comparison to the improvements between earlier models, these might
only be a few degrees, but some of them are worth getting into in a bit
of detail.</p>
<p>What is especially striking is that there are more topics containing
relatively fine-grained words indicative of literary realism. In
addition to the outdoor spaces described above, this model contains a
topic that more clearly details people’s appearance - with
<em>coat</em>, <em>black</em>, <em>hat</em>, <em>small</em>,
<em>white</em>, <em>large</em>, <em>pretty</em>, and, yes,
<em>appearance</em> - as well as one that describes social settings,
with words like <em>gentlemen</em>, <em>company</em>, <em>ladies</em>,
<em>fat</em>, <em>chair</em>, <em>party</em>, <em>honourable</em>,
<em>loud</em>, <em>men</em> and <em>crowd</em>. The topic of loss is
also complemented by more specific words like <em>bed</em>,
<em>fell</em>, <em>lay</em> and <em>hair</em>. In addition, there is a
topic that captures the passing of time in a very evocative but specific
way, containing words like <em>evening</em>, <em>often</em>,
<em>walked</em>, <em>quiet</em>, <em>hour</em>, <em>passed</em>,
<em>days</em>, <em>window</em>, <em>thoughts</em> and
<em>hours</em>.</p>
<p>The theme of the legal system also gains some specificity, with words
like <em>paper</em> and <em>read</em> finding their way into the same
topics as <em>case</em>, <em>prisoner</em>, <em>court</em> and
<em>judge</em>. Somewhat related, there is a topic that seems to capture
formal interactions in an institutional setting, with words like
<em>matter</em>, <em>beg</em>, <em>magistrate</em>, <em>fellow</em>,
<em>person</em>, <em>pray</em>, <em>certainly</em>, <em>ma’am</em>,
<em>immediately</em> and <em>inquired</em>.</p>
<p>We describe a topic on prospects above, which is present in this
model as well. In this model, there is a second topic that relates to
the prospects deriving from the family situation, with words like
<em>family</em>, <em>really</em>, <em>present</em>, <em>letter</em>,
<em>subject</em>, <em>opinion</em>, <em>state</em> and <em>find</em>.
This topic seems to capture the gap between the prospects that could be
expected, and the actual situation.</p>
<p>On the subject of family, there is again a topic on love - with
<em>love</em>, <em>child</em>, <em>happy</em>, <em>woman</em>,
<em>speak</em>, <em>tears</em>, <em>loved</em> and <em>feel</em> - and a
second one that captures heritage, with words like <em>mother</em>,
<em>gave</em>, <em>mine</em>, <em>remember</em>, <em>pretty</em>,
<em>wonder</em>, <em>father</em>, <em>suppose</em> and <em>baby</em>.
Especially the <em>wonder</em> and <em>suppose</em> bring in a quality
of speculation that could well refer to the orphan Pip in Great
Expectations. There are two more topics which reflect family relations,
one containing <em>uncle</em>, <em>ma’am</em>, <em>widow</em>,
<em>nephew</em>, <em>married</em>, <em>husband</em> and <em>wife</em>,
and the other containing <em>ladies</em>, <em>married</em>,
<em>papa</em>, <em>rejoined</em>, <em>children</em> and
<em>daughter</em>.</p>
<p>The obligatory topics containing contractions and alternate spellings
are represented again. The only thing to note here is that, because of
the different trimming, some words appear that were previously not
captured, with <em>coom</em> and <em>gen’l’m’n</em> standing out
particularly. Finally, there are still some topics that are challenging
to interpret.</p>
<p>An interesting sidenote is that the word <em>poor</em> no longer
appears, with this specification. This indicates that it occurs in
somewhere between 15- and 25% of all documents. As such, it is rather
frequent. Of course, the word <em>poor</em> is not necessarily related
to poverty per se, as it can express sympathy or pity for others, but
Dickens’ use of the word <em>poor</em> could be an interesting avenue
for more qualitative linguistic investigation.</p>
<p>As mentioned numerous times, there is of course going to be some
deviation between what we describe and what you see, since the models
are constructed with a random component. But you will certainly have
seen how tweaking the parameters can change the results, and also have
gotten a taste of how topic models can be interpreted. Which almost
brings this introduction to topic modelling to a close.</p>
</div>
</div>
<div id="final-comments" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Final Comments</h1>
<p>The biggest disclaimer is: many roads lead to Rome. This goes for
each step of the way, beginning with the choice of programming language
(there are dedicated tools for topic modelling, like MALLET, but also
ways of doing it in Python, for instance) and the packages, through the
pre-processing, to the precise specification and interpretation of the
models. There is no one-size fits all approach. The question is rather,
whether you find an approach that allows you to reach meaningful
results. Probably the best frame for thinking about topic modelling is
provided by <span class="citation">Tangherlini and Leonard (<a
href="#ref-tangherlini2013trawling">2013</a>)</span> who discuss topic
modelling in terms of a division of labour: “the computer algorithm is
given the task of doing what it does best: counting words and
calculating probabilities of term co-occurrence” and the *researcher is
given the task of doing what he or she does best: applying domain
expertise and experience for labelling and curating the topics” <span
class="citation">(<a href="#ref-tangherlini2013trawling">Tangherlini and
Leonard 2013, 728</a>)</span>. There is a vast literature on topic
modelling out there that will give more technical analyses, further
information on how to go from the results of your models back to the
text, different perspectives on the pros and cons of the method, and
more. However, after working through this humble course of ours, you
should be well equipped to get to decent topic models using R and be
able to begin investigating your own research questions. Let’s get on
it!</p>
<hr />
<p><a href="#introduction">Back to top</a></p>
<p><a href="https://ladal.edu.au">Back to HOME</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
entry-spacing="0">
<div id="ref-blei2003lda" class="csl-entry">
Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. <span>“Latent
Dirichlet Allocation.”</span> <em>Journal of Machine Learning
Research</em> 3 (3): 993–1022.
</div>
<div id="ref-firth1957ling" class="csl-entry">
Firth, John Rupert. 1957. <span>“Studies in Linguistic Analysis.”</span>
In <em>A Synopsis of Linguistic Theory 1930–1955</em>, edited by John
Rupert Firth, 1–32. Oxford: Blackwell.
</div>
<div id="ref-jockers2013macroanalysis" class="csl-entry">
Jockers, Matthew L. 2013. <em>Macroanalysis: Digital Methods and
Literary History</em>. Urbana, Chicago; Springfield: University of
Illinois Press.
</div>
<div id="ref-kailash2012dickens" class="csl-entry">
Kailash, Sudha. 2012. <span>“Charles Dickens as a Social Critic.”</span>
<em>International Journal of Research in Economics &amp; Social
Sciences</em> 2 (8): 1–51.
</div>
<div id="ref-mahlberg2013corpus" class="csl-entry">
Mahlberg, Michaela. 2013. <em>Corpus Stylistics and Dickens’s
Fiction</em>. Routledge.
</div>
<div id="ref-mohr2013introduction" class="csl-entry">
Mohr, John W, and Petko Bogdanov. 2013. <span>“Introduction—Topic
Models: What They Are and Why They Matter.”</span> <em>Poetics</em> 41
(6): 545–69.
</div>
<div id="ref-roberts2019stm" class="csl-entry">
Roberts, Margaret E, Brandon M Stewart, and Dustin Tingley. 2019.
<span>“Stm: An r Package for Structural Topic Models.”</span>
<em>Journal of Statistical Software</em> 91: 1–40.
</div>
<div id="ref-tangherlini2013trawling" class="csl-entry">
Tangherlini, Timothy R, and Peter Leonard. 2013. <span>“Trawling in the
Sea of the Great Unread: Sub-Corpus Topic Modeling and Humanities
Research.”</span> <em>Poetics</em> 41 (6): 725–49.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>If you want to render the R Notebook on your machine,
i.e. knitting the document to html or a pdf, you need to make sure that
you have R and RStudio installed and you also need to download the <a
href="https://slcladal.github.io/content/bibtex.bib"><strong>bibliography
file</strong></a> and store it in the same folder where you store the
Rmd file.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
