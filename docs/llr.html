<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2024-11-05" />

<title>Analyzing learner language using R</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="site_libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="site_libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="site_libs/wordcloud2-0.0.1/hover.js"></script>
<script src="site_libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>
<link rel="stylesheet" href="styles.css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VSGK4KYDQZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VSGK4KYDQZ');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="/content/ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="about.html">ABOUT</a>
</li>
<li>
  <a href="events.html">EVENTS</a>
</li>
<li>
  <a href="tutorials.html">TUTORIALS</a>
</li>
<li>
  <a href="tools.html">TOOLS</a>
</li>
<li>
  <a href="resources.html">RESOURCES</a>
</li>
<li>
  <a href="contact.html">CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Analyzing learner language using R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2024-11-05</h4>

</div>


<p><img src="https://slcladal.github.io/images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1 class="unnumbered">Introduction</h1>
<p>This tutorial focuses on learner language and how to analyze
differences between learners and L1 speakers of English using R. The aim
of this tutorial is to showcase how to extract information from essays
from learners and L1 speakers of English and how to analyze these
essays. The aim is not to provide a fully-fledged analysis but rather to
show and exemplify some common methods for data extraction, processing,
and analysis.</p>
<div class="warning"
style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
The entire R Notebook for the tutorial can be downloaded <a
href="https://slcladal.github.io/content/llr.Rmd"><strong>here</strong></a>.
If you want to render the R Notebook on your machine, i.e. knitting the
document to html or a pdf, you need to make sure that you have R and
RStudio installed and you also need to download the <a
href="https://slcladal.github.io/content/bibliography.bib"><strong>bibliography
file</strong></a> and store it in the same folder where you store the
Rmd file. <br><br> <a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Fllr_cb.ipynb%26branch%3Dmain"><img
src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a><br> <a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Fllr_cb.ipynb%26branch%3Dmain"><strong>Click
this link to open an interactive version of this tutorial on
MyBinder.org</strong></a>. <br> This interactive Jupyter notebook allows
you to execute code yourself and you can also change and edit the
notebook, e.g. you can change code and upload your own data. <br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Preparation and session set up</strong></p>
<p>This tutorial is based on R. If you have not installed R or are new
to it, you will find an introduction to and more information how to use
R <a href="https://slcladal.github.io/intror.html">here</a>. For this
tutorials, we need to install certain <em>packages</em> from an R
<em>library</em> so that the scripts shown below are executed without
errors. Before turning to the code below, please install the packages by
running the code below this paragraph. If you have already installed the
packages mentioned below, then you can skip ahead and ignore this
section. To install the necessary packages, simply run the following
code - it may take some time (between 1 and 5 minutes to install all of
the packages so you do not need to worry if it takes some time).</p>
<pre class="r"><code># install packages
install.packages(&quot;quanteda&quot;)
install.packages(&quot;flextable&quot;)
install.packages(&quot;quanteda.textstats&quot;)
install.packages(&quot;quanteda.textplots&quot;)
install.packages(&quot;tidyverse&quot;)
install.packages(&quot;tm&quot;)
install.packages(&quot;tidytext&quot;)
install.packages(&quot;tidyr&quot;)
install.packages(&quot;NLP&quot;)
install.packages(&quot;udpipe&quot;)
install.packages(&quot;koRpus&quot;)
install.packages(&quot;stringi&quot;)
install.packages(&quot;hunspell&quot;)
install.packages(&quot;wordcloud2&quot;)
install.packages(&quot;pacman&quot;)
# install the language support package
koRpus::install.koRpus.lang(&quot;en&quot;)
# install klippy for copy-to-clipboard button in code chunks
install.packages(&quot;remotes&quot;)
remotes::install_github(&quot;rlesur/klippy&quot;)</code></pre>
<p>Now that we have installed the packages, we can activate them as
shown below.</p>
<pre class="r"><code># set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=1000)
options(java.parameters = c(&quot;-XX:+UseConcMarkSweepGC&quot;, &quot;-Xmx8192m&quot;))
#gc()
# load packages
library(tidyverse)
library(flextable)
library(tm)
library(tidytext)
library(tidyr)
library(NLP)
library(udpipe)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
library(koRpus)
library(koRpus.lang.en)
library(stringi)
library(hunspell)
library(wordcloud2)
library(pacman)
pacman::p_load_gh(&quot;trinker/entity&quot;)
# activate klippy for copy-to-clipboard button
klippy::klippy()</code></pre>
<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<p>Once you have installed R and RStudio and once you have also
initiated the session by executing the code shown above, you are good to
go.</p>
<p><strong>Loading data</strong></p>
<p>We use 7 essays written by learners from the <a
href="https://uclouvain.be/en/research-institutes/ilc/cecl/icle.html"><em>International
Corpus of Learner English</em> (ICLE)</a> and two files containing
a-level essays written by L1-English British students from <a
href="https://uclouvain.be/en/research-institutes/ilc/cecl/locness.html"><em>The
Louvain Corpus of Native English Essays</em> (LOCNESS)</a> which was
compiled by the <em>Centre for English Corpus Linguistics</em> (CECL),
Université catholique de Louvain, Belgium. The code chunk below loads
the data from the LADAL repository on GitHub into R.</p>
<pre class="r"><code># load essays from l1 speakers
ns1 &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/ns1.rda&quot;, &quot;rb&quot;))
ns2 &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/ns2.rda&quot;, &quot;rb&quot;))
# load essays from l2 speakers
es &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/es.rda&quot;, &quot;rb&quot;))
de &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/de.rda&quot;, &quot;rb&quot;))
fr &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/fr.rda&quot;, &quot;rb&quot;))
it &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/it.rda&quot;, &quot;rb&quot;))
pl &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/pl.rda&quot;, &quot;rb&quot;))
ru &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/LCorpus/ru.rda&quot;, &quot;rb&quot;))
# inspect
ru %&gt;%
  # remove header
  stringr::str_remove(., &quot;&lt;[A-Z]{4,4}.*&quot;) %&gt;%
  # remove empty elements
  na_if(&quot;&quot;) %&gt;%
  na.omit %&gt;%
  #show first 3 elements
  head(3)</code></pre>
<pre><code>## [1] &quot;It is now a very wide spread opinion, that in the modern world there is no place for dreaming and imagination. Those who share this point of view usually say that at present we are so very much under the domination of science, industry, technology, ever-increasing tempo of our lives and so on, that neither dreaming nor imagination can possibly survive. Their usual argument is very simple - they suggest to their opponents to look at some samples of the modern art and to compare them to the masterpieces of the \&quot;Old Masters\&quot; of painting, music, literature.&quot;
## [2] &quot;As everything which is simple, the argument sounds very convincing. Of course, it is evident, that no modern writer, painter or musician can be compare to such names as Bach, Pushkin&lt; Byron, Mozart, Rembrandt, Raffael et cetera. Modern pictures, in the majority of cases, seem to be merely repetitions or combinations of the images and methods of painting, invented very long before. The same is also true to modern verses, novels and songs.&quot;                                                                                                                        
## [3] &quot;But, I think, those, who put forward this argument, play - if I may put it like this - not fair game with their opponents, because such an approach presupposes the firm conviction, that dreaming and imagination can deal only with Arts, moreover, only with this \&quot;well-established set\&quot; of Arts, which includes music, painting, architecture, sculpture and literature. That is, a person, who follows the above-mentioned point of view tries to make his opponent take for granted the statement, the evidence of which is, to say the least, doubtful.&quot;</code></pre>
<p>The data inspection shows the first 3 text elements from the essay
written a Russian learner of English to provide an idea of what the data
look like.</p>
<p>Now that we have loaded some data, we can go ahead and extract
information from the texts and process the data to analyze differences
between L1 speakers and learners of English.</p>
</div>
<div id="concordancing" class="section level1 unnumbered">
<h1 class="unnumbered">Concordancing</h1>
<p>Concordancing refers to the extraction of words or phrases from a
given text or texts <span class="citation">(<a
href="#ref-lindquist2009corpus">Lindquist 2009</a>)</span>. Commonly,
concordances are displayed in the form of key-word in contexts (KWIC)
where the search term is shown with some preceding and following
context. Thus, such displays are referred to as key word in context
concordances. A more elaborate tutorial on how to perform concordancing
with R is available <a
href="https://slcladal.github.io/kwics.html">here</a>.</p>
<p>Concordancing is helpful for seeing how a given term or phrased is
used in the data, for inspecting how often a given word occurs in a text
or a collection of texts, for extracting examples, and it also
represents a basic procedure, and often the first step, in more
sophisticated analyses.</p>
<p>We begin by creating KWIC displays of the term <em>problem</em> as
shown below. To extract the kwic concordances, we use the
<code>kwic</code> function from the <code>quanteda</code> package <span
class="citation">(cf. <a href="#ref-benoit2018quanteda">Benoit et al.
2018</a>)</span>.</p>
<pre class="r"><code># combine data from l1 speakers
l1 &lt;- c(ns1, ns2)
# combine data from learners
learner &lt;- c(de, es, fr, it, pl, ru)
# extract kwic for term &quot;problem&quot; in learner data
quanteda::kwic(quanteda::tokens(learner),     # the data in which to search
                       pattern = &quot;problem.*&quot;, # the pattern to look for
                       valuetype = &quot;regex&quot;,   # look for exact matches or patterns
                       window = 10) %&gt;%       # how much context to display (in elements) 
  # convert to table (called data.frame in R)
  as.data.frame() %&gt;%
  # remove superfluous columns
  dplyr::select(-to, -from, -pattern) -&gt; kwic
# inspect
head(kwic)</code></pre>
<pre><code>##   docname                                                     pre  keyword
## 1  text12                      Many of the drug addits have legal problems
## 2  text12     countries , like Spain , illegal . They have social problems
## 3  text30     In our society there is a growing concern about the  problem
## 4  text33 that once the availability of guns has been removed the  problem
## 5  text33    honest way and remove any causes that could worsen a  problem
## 6  text34       violence in our society . In order to analise the  problem
##                                                         post
## 1       because they steal money for buying the drug that is
## 2         too because people are afraid of them and the drug
## 3       of violent crime . In fact , particular attention is
## 4 of violence simply vanishes , but in this caotic situation
## 5                    which is already particularly serious .
## 6            in its complexity and allow people to live in a</code></pre>
<p>The output shows that the term <em>problem</em> occurs six times in
the learner data.</p>
<p>We can also arrange the output according to what comes before or
after the search term as shown below.</p>
<pre class="r"><code># take kwic
kwic %&gt;%
  # arrange kwic alphabetically by what comes after the key term
  dplyr::arrange(post)</code></pre>
<pre><code>##   docname                                                          pre  keyword
## 1  text12                           Many of the drug addits have legal problems
## 2  text39 , greatest ideas were produced and solutions to many serious problems
## 3  text34            violence in our society . In order to analise the  problem
## 4  text33      that once the availability of guns has been removed the  problem
## 5  text30          In our society there is a growing concern about the  problem
## 6  text12          countries , like Spain , illegal . They have social problems
## 7  text33         honest way and remove any causes that could worsen a  problem
##                                                          post
## 1        because they steal money for buying the drug that is
## 2 found . Most wonderful pieces of literature were created in
## 3             in its complexity and allow people to live in a
## 4  of violence simply vanishes , but in this caotic situation
## 5        of violent crime . In fact , particular attention is
## 6          too because people are afraid of them and the drug
## 7                     which is already particularly serious .</code></pre>
<pre class="r"><code># take quick
kwic %&gt;%
  # reverse the preceding context
  dplyr::mutate(prerev = stringi::stri_reverse(pre)) %&gt;%
  # arrange kwic alphabetically by reversed preceding context
  dplyr::arrange(prerev) %&gt;%
  # remove column with reversed preceding context
  dplyr::select(-prerev)</code></pre>
<pre><code>##   docname                                                          pre  keyword
## 1  text33         honest way and remove any causes that could worsen a  problem
## 2  text33      that once the availability of guns has been removed the  problem
## 3  text34            violence in our society . In order to analise the  problem
## 4  text30          In our society there is a growing concern about the  problem
## 5  text12                           Many of the drug addits have legal problems
## 6  text12          countries , like Spain , illegal . They have social problems
## 7  text39 , greatest ideas were produced and solutions to many serious problems
##                                                          post
## 1                     which is already particularly serious .
## 2  of violence simply vanishes , but in this caotic situation
## 3             in its complexity and allow people to live in a
## 4        of violent crime . In fact , particular attention is
## 5        because they steal money for buying the drug that is
## 6          too because people are afraid of them and the drug
## 7 found . Most wonderful pieces of literature were created in</code></pre>
<p>We can also combine concordancing with visualizations. For instance,
use the <code>textplot_xray</code> function from the
<code>quanteda.textplots</code> package to visualize where in some texts
the term <em>people</em> and the term <em>imagination</em> occurs.</p>
<pre class="r"><code># create kwics for people and imagination
kwic_people &lt;- quanteda::kwic(quanteda::tokens(learner), pattern = c(&quot;people&quot;, &quot;imagination&quot;))
# generate x-ray plot
quanteda.textplots::textplot_xray(kwic_people)</code></pre>
<p><img src="llr_files/figure-html/conc4-1.png" width="672" /></p>
<p>We can also search for phrases rather than individual words. To do
this, we need to use the <code>phrase</code> function in the
<code>pattern</code> argument as shown below. In the code chunk below,
we look for any combination of the word <em>very</em> and any following
word. It we would wish, we could of course also sort (or order) the
concordances as we have done above.</p>
<pre class="r"><code># generate kwic for phrases staring with very
kwic &lt;- quanteda::kwic(quanteda::tokens(learner),            # data
                       pattern = phrase(&quot;^very [a-z]{1,}&quot;),  # search pattern
                       valuetype = &quot;regex&quot;) %&gt;%              # type of pattern
  # convert into a data frame
  as.data.frame()</code></pre>
<div class="tabwid"><style>.cl-c851d618{table-layout:auto;width:75%;}.cl-c8468cea{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c8468cfe{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c84b4668{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c84b467c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c84b7ebc{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ed0{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7eda{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7edb{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ee4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ee5{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7eee{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7eef{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ef0{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ef8{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7ef9{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7f02{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7f0c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7f16{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7f17{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c84b7f18{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-c851d618'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 rows of the concordance for very + any other word in the learner data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-c84b7ebc"><p class="cl-c84b4668"><span class="cl-c8468cea">docname</span></p></th><th class="cl-c84b7ed0"><p class="cl-c84b467c"><span class="cl-c8468cea">from</span></p></th><th class="cl-c84b7ed0"><p class="cl-c84b467c"><span class="cl-c8468cea">to</span></p></th><th class="cl-c84b7eda"><p class="cl-c84b4668"><span class="cl-c8468cea">pre</span></p></th><th class="cl-c84b7eda"><p class="cl-c84b4668"><span class="cl-c8468cea">keyword</span></p></th><th class="cl-c84b7eda"><p class="cl-c84b4668"><span class="cl-c8468cea">post</span></p></th><th class="cl-c84b7edb"><p class="cl-c84b4668"><span class="cl-c8468cea">pattern</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-c84b7ee4"><p class="cl-c84b4668"><span class="cl-c8468cfe">text3</span></p></td><td class="cl-c84b7ee5"><p class="cl-c84b467c"><span class="cl-c8468cfe">193</span></p></td><td class="cl-c84b7ee5"><p class="cl-c84b467c"><span class="cl-c8468cfe">194</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">in black trousers and only</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">very seldom</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">in skirts , because she</span></p></td><td class="cl-c84b7eef"><p class="cl-c84b4668"><span class="cl-c8468cfe">^very [a-z]{1,}</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c84b7ef0"><p class="cl-c84b4668"><span class="cl-c8468cfe">text4</span></p></td><td class="cl-c84b7ef8"><p class="cl-c84b467c"><span class="cl-c8468cfe">9</span></p></td><td class="cl-c84b7ef8"><p class="cl-c84b467c"><span class="cl-c8468cfe">10</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">is admirable is that she's</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">very active</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">in doing sports and that</span></p></td><td class="cl-c84b7f02"><p class="cl-c84b4668"><span class="cl-c8468cfe">^very [a-z]{1,}</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c84b7ee4"><p class="cl-c84b4668"><span class="cl-c8468cfe">text4</span></p></td><td class="cl-c84b7ee5"><p class="cl-c84b467c"><span class="cl-c8468cfe">27</span></p></td><td class="cl-c84b7ee5"><p class="cl-c84b467c"><span class="cl-c8468cfe">28</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">managed by her in a</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">very simple</span></p></td><td class="cl-c84b7eee"><p class="cl-c84b4668"><span class="cl-c8468cfe">way . She's very interested</span></p></td><td class="cl-c84b7eef"><p class="cl-c84b4668"><span class="cl-c8468cfe">^very [a-z]{1,}</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c84b7ef0"><p class="cl-c84b4668"><span class="cl-c8468cfe">text4</span></p></td><td class="cl-c84b7ef8"><p class="cl-c84b467c"><span class="cl-c8468cfe">32</span></p></td><td class="cl-c84b7ef8"><p class="cl-c84b467c"><span class="cl-c8468cfe">33</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">very simple way . She's</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">very interested</span></p></td><td class="cl-c84b7ef9"><p class="cl-c84b4668"><span class="cl-c8468cfe">in cycling , swimming and</span></p></td><td class="cl-c84b7f02"><p class="cl-c84b4668"><span class="cl-c8468cfe">^very [a-z]{1,}</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c84b7f0c"><p class="cl-c84b4668"><span class="cl-c8468cfe">text5</span></p></td><td class="cl-c84b7f16"><p class="cl-c84b467c"><span class="cl-c8468cfe">3</span></p></td><td class="cl-c84b7f16"><p class="cl-c84b467c"><span class="cl-c8468cfe">4</span></p></td><td class="cl-c84b7f17"><p class="cl-c84b4668"><span class="cl-c8468cfe">She's also</span></p></td><td class="cl-c84b7f17"><p class="cl-c84b4668"><span class="cl-c8468cfe">very intelligent</span></p></td><td class="cl-c84b7f17"><p class="cl-c84b4668"><span class="cl-c8468cfe">and because of that she</span></p></td><td class="cl-c84b7f18"><p class="cl-c84b4668"><span class="cl-c8468cfe">^very [a-z]{1,}</span></p></td></tr></tbody></table></div>
</div>
<div id="frequency-lists" class="section level1 unnumbered">
<h1 class="unnumbered">Frequency lists</h1>
<p>A useful procedure when dealing with texts is to extract frequency
information. To exemplify how to extract frequency lists from texts, we
will do this here using the L1 data.</p>
<pre class="r"><code>ftb &lt;- c(ns1, ns2) %&gt;%
  # remove punctuation
  stringr::str_replace_all(., &quot;\\W&quot;, &quot; &quot;) %&gt;%
  # remove superfluous white spaces
  stringr::str_squish() %&gt;%
  # convert to lower case
  tolower() %&gt;%
  # split into words
  stringr::str_split(&quot; &quot;) %&gt;%
  # unlist
  unlist() %&gt;%
  # convert into table
  as.data.frame() %&gt;%
  # rename column
  dplyr::rename(word = 1) %&gt;%
  # remove empty rows
  dplyr::filter(word != &quot;&quot;) %&gt;%
  # count words
  dplyr::group_by(word) %&gt;%
  dplyr::summarise(freq = n()) %&gt;%
  # order by freq
  dplyr::arrange(-freq)
# inspect
head(ftb)</code></pre>
<pre><code>## # A tibble: 6 × 2
##   word   freq
##   &lt;chr&gt; &lt;int&gt;
## 1 the     650
## 2 to      373
## 3 of      320
## 4 and     283
## 5 is      186
## 6 a       176</code></pre>
<p>We can easily remove stop words (words without lexical content) using
the <code>anti_join</code> function as shown below.</p>
<pre class="r"><code>ftb_wosw &lt;- ftb %&gt;%
  # remove stop words
  dplyr::anti_join(stop_words)
# inspect
head(ftb_wosw)</code></pre>
<pre><code>## # A tibble: 6 × 2
##   word       freq
##   &lt;chr&gt;     &lt;int&gt;
## 1 transport    98
## 2 people       85
## 3 roads        80
## 4 cars         69
## 5 road         51
## 6 system       50</code></pre>
<p>We can then visualize the results as a bar chart as shown below.</p>
<pre class="r"><code>ftb_wosw %&gt;%
  # take 20 most frequent terms
  head(20) %&gt;%
  # generate a plot
  ggplot(aes(x = reorder(word, -freq), y = freq, label = freq)) +
  # define type of plot
  geom_bar(stat = &quot;identity&quot;) +
  # add labels
  geom_text(vjust=1.6, color = &quot;white&quot;) +
  # display in black-and-white theme
  theme_bw() +
  # adapt x-axis tick labels
  theme(axis.text.x = element_text(size=8, angle=90)) +
  # adapt axes labels
  labs(y = &quot;Frequnecy&quot;, x = &quot;Word&quot;)</code></pre>
<p><img src="llr_files/figure-html/fr5-1.png" width="672" /></p>
<p>Or we can visualize the data as a word cloud (see below).</p>
<pre class="r"><code># create wordcloud
wordcloud2(ftb_wosw[1:100,],    # define data to use
           # define shape
           shape = &quot;diamond&quot;,
           # define colors
           color = scales::viridis_pal()(8))</code></pre>
<div class="wordcloud2 html-widget html-fill-item" id="htmlwidget-c4597778eb353ad5d7c5" style="width:672px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-c4597778eb353ad5d7c5">{"x":{"word":["transport","people","roads","cars","road","system","rail","traffic","public","trains","car","government","travel","train","cities","major","britain","increasing","british","congestion","due","city","increase","bus","main","reduce","time","house","service","buses","lead","vehicles","world","country","motorways","services","increased","network","pollution","power","vote","amount","companies","party","tax","uk","change","democrasy","expensive","means","motorway","solution","times","building","cost","fares","jams","leads","money","political","recent","stations","systems","term","town","3","built","catch","centres","create","encourage","hours","industry","london","parties","past","railway","railways","short","votes","walk","2","build","bypass","bypasses","cycle","drive","efficient","electoral","environment","fair","greatly","heavy","journeys","lines","local","majority","modern","newbury","opposition"],"freq":[98,85,80,69,51,50,48,45,41,36,35,32,31,25,24,23,22,21,20,20,19,18,17,16,16,16,16,15,15,13,13,13,13,12,12,12,11,11,11,11,11,10,10,10,10,10,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6],"fontFamily":"Segoe UI","fontWeight":"bold","color":["#440154FF","#46337EFF","#365C8DFF","#277F8EFF","#1FA187FF","#4AC16DFF","#9FDA3AFF","#FDE725FF"],"minSize":0,"weightFactor":1.836734693877551,"backgroundColor":"white","gridSize":0,"minRotation":-0.7853981633974483,"maxRotation":0.7853981633974483,"shuffle":true,"rotateRatio":0.4,"shape":"diamond","ellipticity":0.65,"figBase64":null,"hover":null},"evals":[],"jsHooks":{"render":[{"code":"function(el,x){\n                        console.log(123);\n                        if(!iii){\n                          window.location.reload();\n                          iii = False;\n\n                        }\n  }","data":null}]}}</script>
</div>
<div id="splitting-texts-into-sentences"
class="section level1 unnumbered">
<h1 class="unnumbered">Splitting texts into sentences</h1>
<p>It can be every useful to split texts into individual sentences. This
can be done, e.g., to extract the average sentence length or simply to
inspect or annotate individual sentences. To split a text into
sentences, we clean the data by removing file identifiers and html tags
as well as quotation marks within sentences. As we are dealing with
several texts, we write a function that performs this task and that we
can then apply to the individual texts.</p>
<pre class="r"><code>cleanText &lt;- function(x,...){
  require(tokenizers)
  # paste text together
  x &lt;- paste0(x)
  # remove file identifiers
  x &lt;- stringr::str_remove_all(x, &quot;&lt;.*?&gt;&quot;)
  # remove quotation marks
  x &lt;- stringr::str_remove_all(x, fixed(&quot;\&quot;&quot;))
  # remove empty elements
  x &lt;- x[!x==&quot;&quot;]
  # split text into sentences
  x &lt;- tokenize_sentences(x)
  x &lt;- unlist(x)
}
# clean texts
ns1_sen &lt;- cleanText(ns1)
ns2_sen &lt;- cleanText(ns2)
de_sen &lt;- cleanText(de)
es_sen &lt;- cleanText(es)
fr_sen &lt;- cleanText(fr)
it_sen &lt;- cleanText(it)
pl_sen &lt;- cleanText(pl)
ru_sen &lt;- cleanText(ru)</code></pre>
<div class="tabwid"><style>.cl-c8ce351e{table-layout:auto;width:75%;}.cl-c8c581ee{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c8c581f8{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c8c8bd46{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c8c8d808{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8c8d809{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8c8d812{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8c8d81c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-c8ce351e'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 sentences of the Russian learner data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-c8c8d808"><p class="cl-c8c8bd46"><span class="cl-c8c581ee">.</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-c8c8d809"><p class="cl-c8c8bd46"><span class="cl-c8c581f8">It is now a very wide spread opinion, that in the modern world there is no place for dreaming and imagination.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8c8d812"><p class="cl-c8c8bd46"><span class="cl-c8c581f8">Those who share this point of view usually say that at present we are so very much under the domination of science, industry, technology, ever-increasing tempo of our lives and so on, that neither dreaming nor imagination can possibly survive.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8c8d809"><p class="cl-c8c8bd46"><span class="cl-c8c581f8">Their usual argument is very simple - they suggest to their opponents to look at some samples of the modern art and to compare them to the masterpieces of the Old Masters of painting, music, literature.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8c8d812"><p class="cl-c8c8bd46"><span class="cl-c8c581f8">As everything which is simple, the argument sounds very convincing.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8c8d81c"><p class="cl-c8c8bd46"><span class="cl-c8c581f8">Of course, it is evident, that no modern writer, painter or musician can be compare to such names as Bach, Pushkin&lt; Byron, Mozart, Rembrandt, Raffael et cetera.</span></p></td></tr></tbody></table></div>
<p>Now that we have split the texts into individual sentences, we can
easily extract and visualize the average sentence lengths of L1 speakers
and learners of English.</p>
</div>
<div id="sentence-length" class="section level1 unnumbered">
<h1 class="unnumbered">Sentence length</h1>
<p>The most basic complexity measure is average sentence length. In the
following, we will extract the average sentence length for L1-speakers
and learners of English with different language backgrounds.</p>
<p>We can use the <code>count_words</code> function from the
<code>tokenizers</code> package to count the words in each sentence. We
apply the function to all texts and generate a table (a data frame) of
the results and add the L1 of the speaker who produced the sentence.</p>
<pre class="r"><code># extract sentences lengths
ns1_sl &lt;- tokenizers::count_words(ns1_sen)
ns2_sl &lt;- tokenizers::count_words(ns2_sen)
de_sl &lt;- tokenizers::count_words(de_sen)
es_sl &lt;- tokenizers::count_words(es_sen)
fr_sl &lt;- tokenizers::count_words(fr_sen)
it_sl &lt;- tokenizers::count_words(it_sen)
pl_sl &lt;- tokenizers::count_words(pl_sen)
ru_sl &lt;- tokenizers::count_words(ru_sen)
# create a data frame from the results
sl_df &lt;- data.frame(c(ns1_sl, ns2_sl, de_sl, es_sl, fr_sl, it_sl, pl_sl, ru_sl)) %&gt;%
  dplyr::rename(sentenceLength = 1) %&gt;%
  dplyr::mutate(l1 = c(rep(&quot;en&quot;, length(ns1_sl)),
                       rep(&quot;en&quot;, length(ns2_sl)),
                       rep(&quot;de&quot;, length(de_sl)),
                       rep(&quot;es&quot;, length(es_sl)),
                       rep(&quot;fr&quot;, length(fr_sl)),
                       rep(&quot;it&quot;, length(it_sl)),
                       rep(&quot;pl&quot;, length(pl_sl)),
                       rep(&quot;ru&quot;, length(ru_sl))))</code></pre>
<div class="tabwid"><style>.cl-c8e74f68{table-layout:auto;width:75%;}.cl-c8deab10{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c8deab1a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c8e1f310{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c8e1f31a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c8e210b6{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210b7{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210c0{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210c1{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210ca{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210cb{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210d4{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c8e210d5{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-c8e74f68'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 rows of the table holding the sentences lengths and the L1 of the speakers that produced them.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-c8e210b6"><p class="cl-c8e1f310"><span class="cl-c8deab10">sentenceLength</span></p></th><th class="cl-c8e210b7"><p class="cl-c8e1f31a"><span class="cl-c8deab10">l1</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-c8e210c0"><p class="cl-c8e1f310"><span class="cl-c8deab1a">2</span></p></td><td class="cl-c8e210c1"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8e210ca"><p class="cl-c8e1f310"><span class="cl-c8deab1a">17</span></p></td><td class="cl-c8e210cb"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8e210c0"><p class="cl-c8e1f310"><span class="cl-c8deab1a">23</span></p></td><td class="cl-c8e210c1"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8e210ca"><p class="cl-c8e1f310"><span class="cl-c8deab1a">17</span></p></td><td class="cl-c8e210cb"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8e210c0"><p class="cl-c8e1f310"><span class="cl-c8deab1a">20</span></p></td><td class="cl-c8e210c1"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c8e210d4"><p class="cl-c8e1f310"><span class="cl-c8deab1a">34</span></p></td><td class="cl-c8e210d5"><p class="cl-c8e1f31a"><span class="cl-c8deab1a">en</span></p></td></tr></tbody></table></div>
<p>Now, we can use the resulting table to create a box plot showing the
results.</p>
<pre class="r"><code>sl_df %&gt;%
  ggplot(aes(x = reorder(l1, -sentenceLength, mean), y = sentenceLength, fill = l1)) +
  geom_boxplot() +
  # adapt y-axis labels
  labs(y = &quot;Sentence lenghts&quot;) +
  # adapt tick labels
  scale_x_discrete(&quot;L1 of learners&quot;, 
                   breaks = names(table(sl_df$l1)), 
                   labels = c(&quot;en&quot; = &quot;English&quot;,
                              &quot;de&quot; = &quot;German&quot;,
                              &quot;es&quot; = &quot;Spanish&quot;,
                              &quot;fr&quot; = &quot;French&quot;,
                              &quot;it&quot; = &quot;Italian&quot;,
                              &quot;pl&quot; = &quot;Polish&quot;,
                              &quot;ru&quot; = &quot;Russian&quot;)) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="llr_files/figure-html/senl8-1.png" width="672" /></p>
</div>
<div id="extracting-n-grams" class="section level1 unnumbered">
<h1 class="unnumbered">Extracting N-grams</h1>
<p>In a next step, we extract n-grams using the
<code>tokens_ngrams</code> function from the <code>quanteda</code>
package. In a first step, we take the sentence data, convert it to lower
case and remove punctuation. Then we apply the
<code>tokens_ngrams</code> function to extract the n-grams (in this case
2-grams).</p>
<pre class="r"><code>ns1_tok &lt;- ns1_sen %&gt;%
  tolower() %&gt;%
  quanteda::tokens(remove_punct = TRUE)
# extract n-grams
ns1_2gram &lt;- quanteda::tokens_ngrams(ns1_tok, n = 2)
# inspect
head(ns1_2gram[[2]], 10)</code></pre>
<pre><code>##  [1] &quot;the_basic&quot;        &quot;basic_dilema&quot;     &quot;dilema_facing&quot;    &quot;facing_the&quot;      
##  [5] &quot;the_uk&#39;s&quot;         &quot;uk&#39;s_rail&quot;        &quot;rail_and&quot;         &quot;and_road&quot;        
##  [9] &quot;road_transport&quot;   &quot;transport_system&quot;</code></pre>
<p>We can also extract tri-grams easily by changing the <code>n</code>
argument in the <code>tokens_ngrams</code> function.</p>
<pre class="r"><code># extract n-grams
ns1_3gram &lt;- quanteda::tokens_ngrams(ns1_tok, n = 3)
# inspect
head(ns1_3gram[[2]])</code></pre>
<pre><code>## [1] &quot;the_basic_dilema&quot;    &quot;basic_dilema_facing&quot; &quot;dilema_facing_the&quot;  
## [4] &quot;facing_the_uk&#39;s&quot;     &quot;the_uk&#39;s_rail&quot;       &quot;uk&#39;s_rail_and&quot;</code></pre>
<p>We now apply the same procedure to all texts as shown below.</p>
<pre class="r"><code>ns1_tok &lt;- ns1_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
ns2_tok &lt;- ns2_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
de_tok &lt;- de_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
es_tok &lt;- es_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
fr_tok &lt;- fr_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
it_tok &lt;- it_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
pl_tok &lt;- pl_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
ru_tok &lt;- ru_sen %&gt;% tolower() %&gt;% quanteda::tokens(remove_punct = TRUE)
# extract n-grams
ns1_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(ns1_tok, n = 2)))
ns2_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(ns2_tok, n = 2)))
de_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(de_tok, n = 2)))
es_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(es_tok, n = 2)))
fr_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(fr_tok, n = 2)))
it_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(it_tok, n = 2)))
pl_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(pl_tok, n = 2)))
ru_2gram &lt;- as.vector(unlist(quanteda::tokens_ngrams(ru_tok, n = 2)))</code></pre>
<p>Next, we generate a table with the ngrams and the L1 background of
the speaker that produced the bi-grams.</p>
<pre class="r"><code>ngram_df &lt;- c(ns1_2gram, ns2_2gram, de_2gram, es_2gram, 
              fr_2gram, it_2gram, pl_2gram, ru_2gram) %&gt;%
  as.data.frame() %&gt;%
  dplyr::rename(ngram = 1) %&gt;%
  dplyr::mutate(l1 = c(rep(&quot;en&quot;, length(ns1_2gram)),
                       rep(&quot;en&quot;, length(ns2_2gram)),
                       rep(&quot;de&quot;, length(de_2gram)),
                       rep(&quot;es&quot;, length(es_2gram)),
                       rep(&quot;fr&quot;, length(fr_2gram)),
                       rep(&quot;it&quot;, length(it_2gram)),
                       rep(&quot;pl&quot;, length(pl_2gram)),
                       rep(&quot;ru&quot;, length(ru_2gram))),
                learner = ifelse(l1 == &quot;en&quot;, &quot;no&quot;, &quot;yes&quot;))
# inspect
head(ngram_df)</code></pre>
<pre><code>##           ngram l1 learner
## 1  transport_01 en      no
## 2     the_basic en      no
## 3  basic_dilema en      no
## 4 dilema_facing en      no
## 5    facing_the en      no
## 6      the_uk&#39;s en      no</code></pre>
<p>Now, we process the table further to add frequency information, i.e.,
how often a given n-gram occurs in each the language of speakers with
distinct L1 backgrounds.</p>
<pre class="r"><code>ngram_fdf &lt;- ngram_df %&gt;%
  dplyr::group_by(ngram, learner) %&gt;%
  dplyr::summarise(freq = n()) %&gt;%
  dplyr::arrange(-freq)
# inspect
head(ngram_fdf)</code></pre>
<pre><code>## # A tibble: 6 × 3
## # Groups:   ngram [5]
##   ngram            learner  freq
##   &lt;chr&gt;            &lt;chr&gt;   &lt;int&gt;
## 1 of_the           no         72
## 2 to_the           no         40
## 3 in_the           no         39
## 4 public_transport no         35
## 5 of_the           yes        33
## 6 number_of        no         32</code></pre>
<p>As the word counts of the texts are quite different, we normalize the
frequencies to per-1,000-word frequencies which are comparable across
texts of different lengths.</p>
<pre class="r"><code>ngram_nfdf &lt;- ngram_fdf %&gt;%
  dplyr::group_by(ngram) %&gt;%
  dplyr::mutate(total_ngram = sum(freq)) %&gt;%
  dplyr::arrange(-total_ngram) %&gt;%
  # total by learner
  dplyr::group_by(learner) %&gt;%
  dplyr::mutate(total_learner = sum(freq),
                rfreq = freq/total_learner*1000)
# inspect
head(ngram_nfdf, 10)</code></pre>
<pre><code>## # A tibble: 10 × 6
## # Groups:   learner [2]
##    ngram            learner  freq total_ngram total_learner rfreq
##    &lt;chr&gt;            &lt;chr&gt;   &lt;int&gt;       &lt;int&gt;         &lt;int&gt; &lt;dbl&gt;
##  1 of_the           no         72         105          9452  7.62
##  2 of_the           yes        33         105          3395  9.72
##  3 in_the           no         39          49          9452  4.13
##  4 in_the           yes        10          49          3395  2.95
##  5 to_the           no         40          47          9452  4.23
##  6 to_the           yes         7          47          3395  2.06
##  7 it_is            no         23          44          9452  2.43
##  8 it_is            yes        21          44          3395  6.19
##  9 public_transport no         35          35          9452  3.70
## 10 number_of        no         32          35          9452  3.39</code></pre>
<p>We now reformat the table so that we have relative frequencies for
both learners and L1 speakers even if a particular n-gram does not occur
in the text produced by either a learner or a L1 speaker.</p>
<pre class="r"><code>ngram_rel &lt;- ngram_nfdf %&gt;%
  dplyr::select(ngram, learner, rfreq, total_ngram) %&gt;%
  tidyr::spread(learner, rfreq) %&gt;%
  dplyr::mutate(no = ifelse(is.na(no), 0, no),
                yes = ifelse(is.na(yes), 0, yes)) %&gt;%
  tidyr::gather(learner, rfreq, no:yes) %&gt;%
  dplyr::arrange(-total_ngram)
# inspect
head(ngram_rel)</code></pre>
<pre><code>## # A tibble: 6 × 4
##   ngram  total_ngram learner rfreq
##   &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1 of_the         105 no       7.62
## 2 of_the         105 yes      9.72
## 3 in_the          49 no       4.13
## 4 in_the          49 yes      2.95
## 5 to_the          47 no       4.23
## 6 to_the          47 yes      2.06</code></pre>
<p>Finally, we visualize the most frequent n-grams in the data in a bar
chart.</p>
<pre class="r"><code>ngram_rel %&gt;%
  head(20) %&gt;%
  ggplot(aes(y = rfreq, x = reorder(ngram, -total_ngram), group = learner, fill = learner)) +
  geom_bar(stat = &quot;identity&quot;, position = position_dodge()) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8, angle=90),
        legend.position = &quot;top&quot;) +
  labs(y = &quot;Relative frequnecy\n(per 1,000 words)&quot;, x = &quot;n-gram&quot;)</code></pre>
<p><img src="llr_files/figure-html/ng10-1.png" width="672" /></p>
<p>We can, of course also investigate only specific n-grams, e.g.,
n-grams containing a specific word such as <em>public</em> (below, we
only show the first 6 n-grams containing <em>public</em> by using the
<code>head</code> function).</p>
<pre class="r"><code>ngram_rel %&gt;%
  dplyr::filter(stringr::str_detect(ngram, &quot;public&quot;)) %&gt;%
  head()</code></pre>
<pre><code>## # A tibble: 6 × 4
##   ngram            total_ngram learner rfreq
##   &lt;chr&gt;                  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1 public_transport          35 no      3.70 
## 2 public_transport          35 yes     0    
## 3 use_public                10 no      1.06 
## 4 use_public                10 yes     0    
## 5 of_public                  6 no      0.635
## 6 of_public                  6 yes     0</code></pre>
<p>We can also specify the order by adding the underscore as shown
below.</p>
<pre class="r"><code>ngram_rel %&gt;%
  dplyr::filter(stringr::str_detect(ngram, &quot;public_&quot;)) %&gt;%
  head()</code></pre>
<pre><code>## # A tibble: 6 × 4
##   ngram             total_ngram learner rfreq
##   &lt;chr&gt;                   &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1 public_transport           35 no      3.70 
## 2 public_transport           35 yes     0    
## 3 public_action               1 no      0.106
## 4 public_and                  1 no      0.106
## 5 public_awareness            1 no      0.106
## 6 public_opposition           1 no      0.106</code></pre>
</div>
<div id="differences-in-ngram-use" class="section level1 unnumbered">
<h1 class="unnumbered">Differences in ngram use</h1>
<p>Next, we will set out to identify differences in n-gram frequencies
between learners and L1 speakers. In a first step, we transform the
table so that we have separate columns for learners and L1-speakers. In
addition, we also add columns containing all the information we need to
perform Fisher’s exact test to check if learners use certain n-grams
significantly more or less frequently compared to L1-speakers.</p>
<pre class="r"><code>sdif_ngram &lt;- ngram_fdf %&gt;%
  tidyr::spread(learner, freq) %&gt;%
  dplyr::mutate(no = ifelse(is.na(no), 0, no),
                yes = ifelse(is.na(yes), 0, yes)) %&gt;%
  dplyr::rename(l1speaker = no, 
                learner = yes) %&gt;%
  dplyr::mutate(total_ngram = l1speaker+learner) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(total_learner = sum(learner),
              total_l1 = sum(l1speaker)) %&gt;%
  dplyr::mutate(a = l1speaker,
                b = learner) %&gt;%
  dplyr::mutate(c = total_l1-a,
                d = total_learner-b)
# inspect
head(sdif_ngram)</code></pre>
<pre><code>## # A tibble: 6 × 10
##   ngram   l1speaker learner total_ngram total_learner total_l1     a     b     c
##   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 `_t             0       1           1          3395     9452     0     1  9452
## 2 £_1mil…         1       0           1          3395     9452     1     0  9451
## 3 £_bill…         1       0           1          3395     9452     1     0  9451
## 4 +_even          1       0           1          3395     9452     1     0  9451
## 5 +_peop…         1       0           1          3395     9452     1     0  9451
## 6 &lt;_byron         0       1           1          3395     9452     0     1  9452
## # ℹ 1 more variable: d &lt;dbl&gt;</code></pre>
<p>On this re-arranged data set, we can now apply the Fisher’s exact
tests. As we are performing many different tests, we need to correct for
multiple comparisons. To this end, we create a column which holds the
Bonferroni corrected critical value (.05). If a p-value is lower than
the corrected critical value, then the learners and L1-speakers differ
significantly in their use of that n-gram.</p>
<pre class="r"><code>sdif_ngram &lt;- sdif_ngram  %&gt;%
  # perform fishers exact test and extract estimate and p
  dplyr::rowwise() %&gt;%
  dplyr::mutate(fisher_p = fisher.test(matrix(c(a,c,b,d), nrow= 2))$p.value,
                oddsratio = fisher.test(matrix(c(a,c,b,d), nrow= 2))$estimate,
                # calculate bonferroni correction
                crit = .05/nrow(.),
                sig_corr = ifelse(fisher_p &lt; crit, &quot;p&lt;.05&quot;, &quot;n.s.&quot;)) %&gt;%
  dplyr::arrange(fisher_p) %&gt;%
  dplyr::select(-total_ngram, -total_learner, -total_l1, -a, -b, -c, -d, -crit)
# inspect
head(sdif_ngram)</code></pre>
<pre><code>## # A tibble: 6 × 6
## # Rowwise: 
##   ngram            l1speaker learner  fisher_p oddsratio sig_corr
##   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   
## 1 in_silence               0       8 0.0000236         0 n.s.    
## 2 public_transport        35       0 0.0000276       Inf n.s.    
## 3 silence_is               0       7 0.0000896         0 n.s.    
## 4 of_all                   0       6 0.000339          0 n.s.    
## 5 our_society              0       6 0.000339          0 n.s.    
## 6 in_our                   0       5 0.00129           0 n.s.</code></pre>
<p>In our case, there are no n-grams that differ significantly in their
use by learners and L1-speakers once we have corrected for repeated
testing as indicated by the <em>n.s.</em> (not significant) in the
column called <em>sig_corr</em>.</p>
</div>
<div id="finding-collocations" class="section level1 unnumbered">
<h1 class="unnumbered">Finding collocations</h1>
<p>There are various techniques for identifying collocations. To
identify collocations without having a pre-defined target term, we can
use the <code>textstat_collocations</code> function from the
<code>quanteda.textstats</code> package <span class="citation">(cf. <a
href="#ref-benoit2021package">Benoit et al. 2021</a>)</span>.</p>
<p>However, before we can apply that function and start identifying
collocations, we need to process the data to which we want to apply this
function. In the present case, we will apply that function to the
sentences in the L1 data which we extract in the code chunk below.</p>
<pre class="r"><code>ns_sen &lt;- c(ns1_sen, ns2_sen) %&gt;%
  tolower()</code></pre>
<div class="tabwid"><style>.cl-cfa05ef8{table-layout:auto;width:95%;}.cl-cf8f5a5e{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-cf8f5a7c{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-cf9714d8{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-cf973616{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cf973620{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cf973621{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cf97362a{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-cfa05ef8'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 sentences in L1 data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-cf973616"><p class="cl-cf9714d8"><span class="cl-cf8f5a5e">.</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-cf973620"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">transport 01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cf973621"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">the basic dilema facing the uk's rail and road transport system is the general rise in population.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cf973620"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">this leads to an increase in the number of commuters and transport users every year, consequently putting pressure on the uks transports network.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cf973621"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">the biggest worry to the system is the rapid rise of car users outside the major cities.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cf973620"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">most large cities have managed to incourage commuters to use public transport thus decreasing major conjestion in rush hour periods.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cf97362a"><p class="cl-cf9714d8"><span class="cl-cf8f5a7c">public transport is the obvious solution to to the increase in population if it is made cheep to commuters, clean, easy and efficient then it could take the strain of the overloaded british roads.</span></p></td></tr></tbody></table></div>
<p>From the output shown above, we also see that splitting texts did not
work perfectly as it produces some unwarranted artifacts like the
“sentences” that consist of headings (e.g., <em>transport 01</em>).
Fortunately, these errors do not really matter in the case of our
example.</p>
<p>Now that we have the L1 data split into sentences, we can tokenize
these sentences and apply the <code>textstat_collocations</code>
function which identifies collocations.</p>
<pre class="r"><code># create a token object
ns_tokens &lt;- quanteda::tokens(ns_sen, remove_punct = TRUE)# %&gt;%
#  tokens_remove(stopwords(&quot;english&quot;))
# extract collocations
ns_coll &lt;- quanteda.textstats::textstat_collocations(ns_tokens, size = 2, min_count = 20)</code></pre>
<div class="tabwid"><style>.cl-cfd11df4{table-layout:auto;width:50%;}.cl-cfc53a34{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-cfc53a48{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-cfc9d0e4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-cfc9d0f8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-cfc9fede{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9fef2{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9fefc{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9fefd{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff06{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff10{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff11{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff1a{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff24{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff25{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff26{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-cfc9ff2e{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-cfd11df4'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>Top 6 collocations in teh L1 data.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-cfc9fede"><p class="cl-cfc9d0e4"><span class="cl-cfc53a34">collocation</span></p></th><th class="cl-cfc9fef2"><p class="cl-cfc9d0f8"><span class="cl-cfc53a34">count</span></p></th><th class="cl-cfc9fef2"><p class="cl-cfc9d0f8"><span class="cl-cfc53a34">count_nested</span></p></th><th class="cl-cfc9fef2"><p class="cl-cfc9d0f8"><span class="cl-cfc53a34">length</span></p></th><th class="cl-cfc9fef2"><p class="cl-cfc9d0f8"><span class="cl-cfc53a34">lambda</span></p></th><th class="cl-cfc9fefc"><p class="cl-cfc9d0f8"><span class="cl-cfc53a34">z</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-cfc9fefd"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">public transport</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">35</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">7.170227</span></p></td><td class="cl-cfc9ff10"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">14.89924</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cfc9ff11"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">it is</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">23</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">3.119043</span></p></td><td class="cl-cfc9ff24"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">12.15265</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cfc9fefd"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">of the</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">72</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">1.617862</span></p></td><td class="cl-cfc9ff10"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">11.45624</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cfc9ff11"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">to use</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">21</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff1a"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">3.455653</span></p></td><td class="cl-cfc9ff24"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">10.58356</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cfc9fefd"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">number of</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">32</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff06"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">5.693830</span></p></td><td class="cl-cfc9ff10"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">10.06386</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-cfc9ff25"><p class="cl-cfc9d0e4"><span class="cl-cfc53a48">on the</span></p></td><td class="cl-cfc9ff26"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">31</span></p></td><td class="cl-cfc9ff26"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">0</span></p></td><td class="cl-cfc9ff26"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2</span></p></td><td class="cl-cfc9ff26"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">2.103127</span></p></td><td class="cl-cfc9ff2e"><p class="cl-cfc9d0f8"><span class="cl-cfc53a48">9.43355</span></p></td></tr></tbody></table></div>
<p>The resulting table shows collocations in L1 data descending by
collocation strength.</p>
<div id="visualizing-collocation-networks"
class="section level2 unnumbered">
<h2 class="unnumbered">Visualizing collocation networks</h2>
<p>Network graphs are a very useful and flexible tool for visualizing
relationships between elements such as words, personas, or authors. This
section shows how to generate a network graph for collocations of the
term <em>transport</em> using the <code>quanteda</code> package.</p>
<p>In a first step, we generate a document-feature matrix based on the
sentences in the L1 data. A document-feature matrix shows how often
elements (here these elements are the words that occur in the L1 data)
occur in a selection of documents (here these documents are the
sentences in the L1 data).</p>
<pre class="r"><code># create document-feature matrix
ns_dfm &lt;- quanteda::dfm(quanteda::tokens(ns_sen)) %&gt;%
  #quanteda::dfm_remove(remove_punct = TRUE) %&gt;%
    quanteda::dfm_remove(pattern = stopwords(&#39;english&#39;))</code></pre>
<div class="tabwid"><style>.cl-d0341e4a{table-layout:auto;width:50%;}.cl-d01f443e{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d01f4448{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d025b094{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d025b0b2{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d025f982{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9a0{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9b4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9be{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9c8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9d2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9dc{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9e6{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9e7{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9f0{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9fa{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d025f9fb{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-d0341e4a'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 rows and columns of the document-feature matrix.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-d025f982"><p class="cl-d025b094"><span class="cl-d01f443e">doc_id</span></p></th><th class="cl-d025f9a0"><p class="cl-d025b0b2"><span class="cl-d01f443e">transport</span></p></th><th class="cl-d025f9a0"><p class="cl-d025b0b2"><span class="cl-d01f443e">01</span></p></th><th class="cl-d025f9a0"><p class="cl-d025b0b2"><span class="cl-d01f443e">basic</span></p></th><th class="cl-d025f9a0"><p class="cl-d025b0b2"><span class="cl-d01f443e">dilema</span></p></th><th class="cl-d025f9b4"><p class="cl-d025b0b2"><span class="cl-d01f443e">facing</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-d025f9be"><p class="cl-d025b094"><span class="cl-d01f4448">text1</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9d2"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d025f9dc"><p class="cl-d025b094"><span class="cl-d01f4448">text2</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9e7"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d025f9be"><p class="cl-d025b094"><span class="cl-d01f4448">text3</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9d2"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d025f9dc"><p class="cl-d025b094"><span class="cl-d01f4448">text4</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9e6"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9e7"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d025f9be"><p class="cl-d025b094"><span class="cl-d01f4448">text5</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9c8"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9d2"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d025f9f0"><p class="cl-d025b094"><span class="cl-d01f4448">text6</span></p></td><td class="cl-d025f9fa"><p class="cl-d025b0b2"><span class="cl-d01f4448">1</span></p></td><td class="cl-d025f9fa"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9fa"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9fa"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td><td class="cl-d025f9fb"><p class="cl-d025b0b2"><span class="cl-d01f4448">0</span></p></td></tr></tbody></table></div>
<p>As we want to generate a network graph of words that collocate with
the term <em>organism</em>, we use the
<code>calculateCoocStatistics</code> function to determine which words
most strongly collocate with our target term (<em>organism</em>).</p>
<pre class="r"><code># load function for co-occurrence calculation
source(&quot;https://slcladal.github.io/rscripts/calculateCoocStatistics.R&quot;)
# define term
coocTerm &lt;- &quot;transport&quot;
# calculate co-occurrence statistics
coocs &lt;- calculateCoocStatistics(coocTerm, ns_dfm, measure=&quot;LOGLIK&quot;)
# inspect results
coocs[1:10]</code></pre>
<pre><code>##     public        use          .    traffic       rail     facing  commuters 
## 113.171974  19.437311  18.915658  10.508626   9.652830   9.382889   9.382889 
##    cheaper      roads       less 
##   9.382889   9.080648   8.067363</code></pre>
<p>We now reduce the document-feature matrix to contain only the top 20
collocates of <em>transport</em> (plus our target word
<em>transport</em>).</p>
<pre class="r"><code>redux_dfm &lt;- dfm_select(ns_dfm, 
                        pattern = c(names(coocs)[1:10], &quot;transport&quot;))</code></pre>
<div class="tabwid"><style>.cl-d0b8de1e{table-layout:auto;width:50%;}.cl-d0a94026{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d0a94030{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d0ae6416{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d0ae6420{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d0ae9d6e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9d78{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9d82{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9d8c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9d8d{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9da0{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9daa{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9dab{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9db4{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9db5{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9dbe{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0ae9dc8{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-d0b8de1e'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 rows and columns of the reduced feature co-occurrence matrix.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-d0ae9d6e"><p class="cl-d0ae6416"><span class="cl-d0a94026">doc_id</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">transport</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">facing</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">rail</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">.</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">commuters</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">use</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">public</span></p></th><th class="cl-d0ae9d78"><p class="cl-d0ae6420"><span class="cl-d0a94026">roads</span></p></th><th class="cl-d0ae9d82"><p class="cl-d0ae6420"><span class="cl-d0a94026">cheaper</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9d8c"><p class="cl-d0ae6416"><span class="cl-d0a94030">text1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9da0"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9daa"><p class="cl-d0ae6416"><span class="cl-d0a94030">text2</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9db4"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9d8c"><p class="cl-d0ae6416"><span class="cl-d0a94030">text3</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9da0"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9daa"><p class="cl-d0ae6416"><span class="cl-d0a94030">text4</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9db4"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9d8c"><p class="cl-d0ae6416"><span class="cl-d0a94030">text5</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9da0"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9daa"><p class="cl-d0ae6416"><span class="cl-d0a94030">text6</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9db4"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9d8c"><p class="cl-d0ae6416"><span class="cl-d0a94030">text7</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9da0"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9daa"><p class="cl-d0ae6416"><span class="cl-d0a94030">text8</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dab"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9db4"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9d8c"><p class="cl-d0ae6416"><span class="cl-d0a94030">text9</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9d8d"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9da0"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0ae9db5"><p class="cl-d0ae6416"><span class="cl-d0a94030">text10</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">1</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dbe"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td><td class="cl-d0ae9dc8"><p class="cl-d0ae6420"><span class="cl-d0a94030">0</span></p></td></tr></tbody></table></div>
<p>Now, we can transform the document-feature matrix into a
feature-co-occurrence matrix as shown below. A feature-co-occurrence
matrix shows how often each element in that matrix co-occurs with every
other element in that matrix.</p>
<pre class="r"><code>tag_fcm &lt;- fcm(redux_dfm)</code></pre>
<div class="tabwid"><style>.cl-d0e9413a{table-layout:auto;width:50%;}.cl-d0daace2{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d0daacec{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d0e0bbf0{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d0e0bc04{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d0e0e2ec{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e2f6{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e2f7{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e300{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e301{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e30a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e30b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e314{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e315{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e31e{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e328{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d0e0e329{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-d0e9413a'><caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span>First 6 rows and columns of the feature co-occurrence matrix.</span></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-d0e0e2ec"><p class="cl-d0e0bbf0"><span class="cl-d0daace2">doc_id</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">transport</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">facing</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">rail</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">.</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">commuters</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">use</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">public</span></p></th><th class="cl-d0e0e2f6"><p class="cl-d0e0bc04"><span class="cl-d0daace2">roads</span></p></th><th class="cl-d0e0e2f7"><p class="cl-d0e0bc04"><span class="cl-d0daace2">cheaper</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e300"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">transport</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">3</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">17</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">83</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">18</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">38</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td><td class="cl-d0e0e30a"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e30b"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">facing</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">2</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e315"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e300"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">rail</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">46</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">1</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">2</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td><td class="cl-d0e0e30a"><p class="cl-d0e0bc04"><span class="cl-d0daacec">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e30b"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">.</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">22</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">42</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">43</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">84</span></p></td><td class="cl-d0e0e315"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e300"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">commuters</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">1</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">2</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">1</span></p></td><td class="cl-d0e0e30a"><p class="cl-d0e0bc04"><span class="cl-d0daacec">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e30b"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">use</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">16</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">8</span></p></td><td class="cl-d0e0e315"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e300"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">public</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">1</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">5</span></p></td><td class="cl-d0e0e30a"><p class="cl-d0e0bc04"><span class="cl-d0daacec">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e30b"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">roads</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e314"><p class="cl-d0e0bc04"><span class="cl-d0daacec">4</span></p></td><td class="cl-d0e0e315"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e300"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">cheaper</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e301"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e30a"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-d0e0e31e"><p class="cl-d0e0bbf0"><span class="cl-d0daacec">traffic</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e328"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td><td class="cl-d0e0e329"><p class="cl-d0e0bc04"><span class="cl-d0daacec">0</span></p></td></tr></tbody></table></div>
<p>Using the feature-co-occurrence matrix, we can generate the network
graph which shows the terms that collocate with the target term
<em>transport</em> with the edges representing the co-occurrence
frequency. To generate this network graph, we use the
<code>textplot_network</code> function from the
<code>quanteda.textplots</code> package.</p>
<pre class="r"><code># generate network graph
quanteda.textplots::textplot_network(tag_fcm, 
                                     min_freq = 1, 
                                     edge_alpha = 0.3, 
                                     edge_size = 5,
                                     edge_color = &quot;gray80&quot;,
                                     vertex_labelsize = log(rowSums(tag_fcm)*15))</code></pre>
<p><img src="llr_files/figure-html/dfm8-1.png" width="672" /></p>
</div>
</div>
<div id="part-of-speech-tagging" class="section level1 unnumbered">
<h1 class="unnumbered">Part-of-speech tagging</h1>
<p>Part-of-speech tagging is a very useful procedure for many analyses.
Here, we automatically identify parts of speech (word classes) in the
text which, for a well-studied language like English, is approximately
95% accurate.</p>
<p>Here, we use the <code>udpipe</code> package to pos-tag text. We test
this by pos-tagging a simple sentence to see if the function does what
we want it to and to check the output format.</p>
<pre class="r"><code># generate test text
text &lt;- &quot;It is now a very wide spread opinion, that in the modern world there is no place for dreaming and imagination.&quot;
# download language model (for english) 
#m_eng   &lt;- udpipe::udpipe_download_model(language = &quot;english-ewt&quot;)
m_eng &lt;- udpipe_load_model(file = here::here(&quot;udpipemodels&quot;,  &quot;english-ewt-ud-2.5-191206.udpipe&quot;))
# pos-tag  text
tagged_text &lt;- udpipe::udpipe_annotate(m_eng, x = text) %&gt;%
  as.data.frame() %&gt;%
  dplyr::select(-sentence) 
# collapse into text
tagged_text &lt;- paste0(tagged_text$token, &quot;/&quot;, tagged_text$xpos, collapse = &quot; &quot;)
# inspect tagged text
tagged_text</code></pre>
<pre><code>## [1] &quot;It/PRP is/VBZ now/RB a/DT very/RB wide/JJ spread/NN opinion/NN ,/, that/DT in/IN the/DT modern/JJ world/NN there/EX is/VBZ no/DT place/NN for/IN dreaming/VBG and/CC imagination/NN ./.&quot;</code></pre>
<p>The tags are not always transparent, and this is very much the case
for the word class we will be looking at - the tag for an adjective is
<code>/JJ</code>!</p>
<p>The next step, we write a function that will clean our texts by
removing tags and quotation marks as well as superfluous white spaces.
In addition, we also pos-tag the texts.</p>
<pre class="r"><code>comText &lt;- function(x,...){
  # paste text together
  x &lt;- paste0(x)
  # remove file identifiers
  x &lt;- stringr::str_remove_all(x, &quot;&lt;.*?&gt;&quot;)
  # remove quotation marks
  x &lt;- stringr::str_remove_all(x, fixed(&quot;\&quot;&quot;))
  # remove superfluous white spaces
  x &lt;- stringr::str_squish(x)
  # remove empty elements
  x &lt;- x[!x==&quot;&quot;]
  # postag text
  x &lt;- udpipe::udpipe_annotate(m_eng, x) %&gt;%
  as.data.frame() %&gt;%
  dplyr::select(-sentence) 
  x &lt;- paste0(x$token, &quot;/&quot;, x$xpos, collapse = &quot; &quot;)
}</code></pre>
<p>Now we apply the text cleaning function to the texts.</p>
<pre class="r"><code># combine texts
ns1_pos &lt;- comText(ns1_sen)
ns2_pos &lt;- comText(ns2_sen)
de_pos &lt;- comText(de_sen)
es_pos &lt;- comText(es_sen)
fr_pos &lt;- comText(fr_sen)
it_pos &lt;- comText(it_sen)
pl_pos &lt;- comText(pl_sen)
ru_pos &lt;- comText(ru_sen)
# inspect
substr(ns1_pos, 1, 300)</code></pre>
<pre><code>## [1] &quot;Transport/NNP 01/CD The/DT basic/JJ dilema/NN facing/VBG the/DT UK/NNP &#39;s/POS rail/NN and/CC road/NN transport/NN system/NN is/VBZ the/DT general/JJ rise/NN in/IN population/NN ./. This/DT leads/VBZ to/IN an/DT increase/NN in/IN the/DT number/NN of/IN commuters/NNS and/CC transport/NN users/NNS ever&quot;</code></pre>
<p>We end up with pos-tagged texts where the pos-tags are added to each
word (or symbol).</p>
<p>In the following section, we will use these pos-tags to identify
potential differences between learners and L1-speakers of English.</p>
</div>
<div id="differences-in-pos-sequences"
class="section level1 unnumbered">
<h1 class="unnumbered">Differences in pos-sequences</h1>
<p>To analyze differences in part-of-speech sequences between
L1-speakers and learners of English,, we write a function that extracts
pos-tag bigrams from the tagged texts.</p>
<pre class="r"><code># tokenize and extract pos tags
posngram &lt;- function(x,...){
  x &lt;- x %&gt;%
    stringr::str_remove_all(&quot;\\w*/&quot;) %&gt;%
    quanteda::tokens(remove_punct = T) %&gt;%
    quanteda::tokens_ngrams(n = 2)
  return(x)
}</code></pre>
<p>We now apply the function to the pos-tagged texts.</p>
<pre class="r"><code># apply pos-tag function to data
ns1_posng &lt;- as.vector(unlist(posngram(ns1_pos)))
ns2_posng &lt;- as.vector(unlist(posngram(ns2_pos)))
de_posng &lt;- as.vector(unlist(posngram(de_pos)))
es_posng &lt;- as.vector(unlist(posngram(es_pos)))
fr_posng &lt;- as.vector(unlist(posngram(fr_pos)))
it_posng &lt;- as.vector(unlist(posngram(it_pos)))
pl_posng &lt;- as.vector(unlist(posngram(pl_pos)))
ru_posng &lt;- as.vector(unlist(posngram(ru_pos)))
# inspect
head(ns1_posng)</code></pre>
<pre><code>## [1] &quot;NNP_CD&quot; &quot;CD_DT&quot;  &quot;DT_JJ&quot;  &quot;JJ_NN&quot;  &quot;NN_VBG&quot; &quot;VBG_DT&quot;</code></pre>
<p>In a next step, we tabulate the results and add a column telling us
about the L1 background of the speakers who have produced the texts.</p>
<pre class="r"><code>posngram_df &lt;- c(ns1_posng, ns2_posng, de_posng, es_posng, fr_posng, 
                 it_posng, pl_posng, ru_posng) %&gt;%
  as.data.frame() %&gt;%
  # rename column
  dplyr::rename(ngram = 1) %&gt;%
  # add l1
  dplyr::mutate(l1 = c(rep(&quot;en&quot;, length(ns1_posng)),
                       rep(&quot;en&quot;, length(ns2_posng)),
                       rep(&quot;de&quot;, length(de_posng)),
                       rep(&quot;es&quot;, length(es_posng)),
                       rep(&quot;fr&quot;, length(fr_posng)),
                       rep(&quot;it&quot;, length(it_posng)),
                       rep(&quot;pl&quot;, length(pl_posng)),
                       rep(&quot;ru&quot;, length(ru_posng))),
                # add learner column
                learner = ifelse(l1 == &quot;en&quot;, &quot;no&quot;, &quot;yes&quot;)) %&gt;%
  # extract frequencies of ngrams
  dplyr::group_by(ngram, learner) %&gt;%
  dplyr::summarise(freq = n()) %&gt;%
  dplyr::arrange(-freq)
# inspect
head(posngram_df)</code></pre>
<pre><code>## # A tibble: 6 × 3
## # Groups:   ngram [6]
##   ngram learner  freq
##   &lt;chr&gt; &lt;chr&gt;   &lt;int&gt;
## 1 DT_NN no        520
## 2 IN_DT no        465
## 3 NN_IN no        464
## 4 JJ_NN no        332
## 5 IN_NN no        241
## 6 DT_JJ no        236</code></pre>
<p>Next, we transform the table and add all the information that we need
to perform the Fisher’s exact tests that we will use to determine if
there are significant differences between L1 speakers and learners of
English regarding their use of pos-sequences.</p>
<pre class="r"><code>posngram_df2 &lt;- posngram_df %&gt;%
  tidyr::spread(learner, freq) %&gt;%
  dplyr::mutate(no = ifelse(is.na(no), 0, no),
                yes = ifelse(is.na(yes), 0, yes)) %&gt;%
  dplyr::rename(l1speaker = no, 
                learner = yes) %&gt;%
  dplyr::mutate(total_ngram = l1speaker+learner) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(total_learner = sum(learner),
              total_l1 = sum(l1speaker)) %&gt;%
  dplyr::mutate(a = l1speaker,
                b = learner) %&gt;%
  dplyr::mutate(c = total_l1-a,
                d = total_learner-b)
# inspect
head(posngram_df2)</code></pre>
<pre><code>## # A tibble: 6 × 10
##   ngram l1speaker learner total_ngram total_learner total_l1     a     b     c
##   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 $_CC          0       1           1          3740    10247     0     1 10247
## 2 $_CD          1       0           1          3740    10247     1     0 10246
## 3 $_DT          2       0           2          3740    10247     2     0 10245
## 4 $_JJ         10       5          15          3740    10247    10     5 10237
## 5 $_JJR         1       0           1          3740    10247     1     0 10246
## 6 $_NFP         1       0           1          3740    10247     1     0 10246
## # ℹ 1 more variable: d &lt;dbl&gt;</code></pre>
<p>On this re-arranged data set, we can now apply the Fisher’s exact
tests. As we are performing many different tests, we need to correct for
multiple comparisons. To this end, we create a column which holds the
Bonferroni corrected critical value (.05). If a p-value is lower than
the corrected critical value, then the learners and L1-speakers differ
significantly in their use of that n-gram.</p>
<pre class="r"><code>sdif_posngram &lt;- posngram_df2  %&gt;%
  # perform fishers exact test and extract estimate and p
  dplyr::rowwise() %&gt;%
  dplyr::mutate(fisher_p = fisher.test(matrix(c(a,c,b,d), nrow= 2))$p.value,
                oddsratio = fisher.test(matrix(c(a,c,b,d), nrow= 2))$estimate,
                # calculate bonferroni correction
                crit = .05/nrow(.),
                sig_corr = ifelse(fisher_p &lt; crit, &quot;p&lt;.05&quot;, &quot;n.s.&quot;)) %&gt;%
  dplyr::arrange(fisher_p) %&gt;%
  dplyr::select(-total_ngram, -a, -b, -c, -d, -crit)
# inspect
head(sdif_posngram)</code></pre>
<pre><code>## # A tibble: 6 × 8
## # Rowwise: 
##   ngram   l1speaker learner total_learner total_l1   fisher_p oddsratio sig_corr
##   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   
## 1 PRP_VBZ        43      54          3740    10247    2.05e-9     0.288 p&lt;.05   
## 2 $_NN           32      41          3740    10247    1.48e-7     0.283 p&lt;.05   
## 3 NN_PRP         36      41          3740    10247    8.42e-7     0.318 p&lt;.05   
## 4 NN_NNS        152      21          3740    10247    3.64e-6     2.67  p&lt;.05   
## 5 IN_PRP         97      71          3740    10247    1.40e-5     0.494 p&lt;.05   
## 6 PRP_$          80      61          3740    10247    2.13e-5     0.475 p&lt;.05</code></pre>
<p>We can now check and compare the use of the the pos-tagged sequences
that differ significantly between learners and L1 speakers of English
using simple concordancing. We begin by checking the use in the
L1-data.</p>
<pre class="r"><code># combine l1 data
l1_pos &lt;- c(ns1_pos, ns2_pos)
# combine l2 data
l2_pos &lt;- c(de_pos, es_pos, fr_pos, it_pos, pl_pos, ru_pos)
# extract PRP_VBZ
PRP_VBZ_l1 &lt;-quanteda::kwic(quanteda::tokens(l1_pos), 
                            pattern = phrase(&quot;\\w* / PRP \\w* / VBZ&quot;), 
                            valuetype = &quot;regex&quot;,
                            window = 10) %&gt;%
  as.data.frame() %&gt;%
  # remove superfluous columns
  dplyr::select(-from, -to, -docname, -pattern)
# inspect results
head(PRP_VBZ_l1)</code></pre>
<pre><code>##                                      pre                keyword
## 1     NN in / IN population / NN if / IN      it / PRP is / VBZ
## 2  DT concrete / NN jungle / NN yet / CC      it / PRP is / VBZ
## 3 NN centres / NNS during / IN rush / NN ours / PRP comes / VBZ
## 4    IN various / JJ reasons / NNS . / . It / PRP removes / VBZ
## 5          JJR and / CC more / JJR . / .     It / PRP has / VBZ
## 6        DT price / NN though / RB . / .     It / PRP has / VBZ
##                                         post
## 1    made / VBN cheep / NN to / IN commuters
## 2        only / RB trying / VBG to / TO cope
## 3        to / IN a / DT near / JJ standstill
## 4 the / DT element / NN of / IN independence
## 5      given / VBN us / PRP the / DT freedom
## 6    reached / VBN the / DT stage / NN where</code></pre>
<p>We now turn to the learner data and also extract concordances for the
same pos-sequence.</p>
<pre class="r"><code># extract PRP_VBZ
PRP_VBZ_l2 &lt;-quanteda::kwic(quanteda::tokens(l2_pos), 
                            pattern = phrase(&quot;\\w* / PRP \\w* / VBZ&quot;), 
                            valuetype = &quot;regex&quot;, 
                            window = 10) %&gt;%
  as.data.frame() %&gt;%
  # remove superfluous columns
  dplyr::select(-from, -to, -docname, -pattern)
# inspect results
head(PRP_VBZ_l2)</code></pre>
<pre><code>##                                       pre               keyword
## 1       NN why / WRB I / PRP admire / VBP    her / PRP is / VBZ
## 2         NN - / HYPH lotions / NNS . / .   She / PRP has / VBZ
## 3 $ shoulders / NNS and / CC usually / RB she / PRP wears / VBZ
## 4             pony / NN - tail / NN . / .    She / PRP is / VBZ
## 5      IN skirts / NNS , / , because / IN she / PRP hates / VBZ
## 6       NN . / . Another / DT reason / NN    she / PRP is / VBZ
##                                         post
## 1              her / PRP $ beauty / NN . / .
## 2 glistening / VBG dark / JJ brown / JJ hair
## 3             a / DT hair / NN slide / NN or
## 4      always / RB well / RB dressed / VBN ,
## 5 wearing / VBG skirts / NNS and / CC tights
## 6      admirable / JJ is / VBZ that / IN she</code></pre>
</div>
<div id="lexical-diversity" class="section level1 unnumbered">
<h1 class="unnumbered">Lexical diversity</h1>
<p>Another common measure used to asses the development of language
learns is vocabulary size. Vocabulary size can be assessed with various
measures that represent lexical diversity. In the present case, we will
extract</p>
<ul>
<li><code>TTR</code>: <em>type-token ratio</em></li>
<li><code>C</code>: Herdan’s C (see <span class="citation">Tweedie and
Baayen (<a href="#ref-tweedie1988lexdiv">1998</a>)</span>; sometimes
referred to as LogTTR)</li>
<li><code>R</code>: Guiraud’s Root TTR (see <span
class="citation">Tweedie and Baayen (<a
href="#ref-tweedie1988lexdiv">1998</a>)</span>)</li>
<li><code>CTTR</code>: Carroll’s Corrected TTR</li>
<li><code>U</code>: Dugast’s Uber Index (see <span
class="citation">Tweedie and Baayen (<a
href="#ref-tweedie1988lexdiv">1998</a>)</span>)</li>
<li><code>S</code>: Summer’s index</li>
<li><code>Maas</code>: Maas’ indices</li>
</ul>
<p>The formulas showing how the lexical diversity measures are
calculated as well as additional information about the lexical diversity
measures can be found <a
href="https://quanteda.io/reference/textstat_lexdiv.html">here</a>.</p>
<p>While we will extract all of these scores, we will only visualize
Carroll’s Corrected TTR to keep things simple.</p>
<p><span class="math display">\[\begin{equation}
  CTTR =  \frac{N_{Types}}{\sqrt{2 N_{Tokens}}}
\end{equation}\]</span></p>
<p>However, before we extract the lexical diversity measures, we split
the data into individual essays.</p>
<pre class="r"><code>cleanEss &lt;- function(x){
  x %&gt;%
  paste0(collapse = &quot; &quot;) %&gt;%
  stringr::str_split(&quot;Transport [0-9]{1,2}&quot;) %&gt;%
  unlist() %&gt;%
  stringr::str_squish() %&gt;%
  .[. != &quot;&quot;]
}
# apply function
ns1_ess &lt;- cleanEss(ns1)
ns2_ess &lt;- cleanEss(ns2)
de_ess &lt;- cleanEss(de)
es_ess &lt;- cleanEss(es)
fr_ess &lt;- cleanEss(fr)
it_ess &lt;- cleanEss(it)
pl_ess &lt;- cleanEss(pl)
ru_ess &lt;- cleanEss(ru)
# inspect
head(ns1_ess, 1)</code></pre>
<pre><code>## [1] &quot;The basic dilema facing the UK&#39;s rail and road transport system is the general rise in population. This leads to an increase in the number of commuters and transport users every year, consequently putting pressure on the UKs transports network. The biggest worry to the system is the rapid rise of car users outside the major cities. Most large cities have managed to incourage commuters to use public transport thus decreasing major conjestion in Rush hour periods. Public transport is the obvious solution to to the increase in population if it is made cheep to commuters, clean, easy and efficient then it could take the strain of the overloaded British roads. For commuters who regularly travel long distances rail transport should be made more appealing, more comfortable and cheaper. Motorways and other transport links are constantly being extended, widened and slowly turning the country into a concrete jungle yet it is only trying to cope with the increase in traffic, we are our own enemy! Another major problem created by the mass of vehicle transport is the pollution emitted into the atmosphere damaging the ozone layer, creating smog and forming acid rain. Tourturing the Earth we are living on. In concluding I wish to propose clean, efficient comfortable and cheap public transport for the near future.&quot;</code></pre>
<p>In a next step, we can apply the <code>lex.div</code> function from
the <code>koRpus</code> package which calculates the different lexical
diversity measures for us.</p>
<pre class="r"><code># extract lex. div. measures
ns1_lds &lt;- lapply(ns1_ess, function(x){
  x &lt;- koRpus::lex.div(x, force.lang = &#39;en&#39;, # define language 
                       segment = 20,      # define segment width
                       window = 20,       # define window width
                       quiet = T,
                       # define lex div measures
                       measure=c(&quot;TTR&quot;, &quot;C&quot;, &quot;R&quot;, &quot;CTTR&quot;, &quot;U&quot;, &quot;Maas&quot;),
                       char=c(&quot;TTR&quot;, &quot;C&quot;, &quot;R&quot;, &quot;CTTR&quot;,&quot;U&quot;, &quot;Maas&quot;))
})
# inspect
ns1_lds[1]</code></pre>
<pre><code>## [[1]]
## 
## Total number of tokens: 217 
## Total number of types:  134
## 
## Type-Token Ratio
##                TTR: 0.62 
## 
## TTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.6140  0.6322  0.6429  0.6888  0.7129  0.9000 
##    SD
##  0.0852
## 
## 
## Herdan&#39;s C
##                  C: 0.91 
## 
## C characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.8614  0.9059  0.9131  0.9157  0.9164  0.9648 
##    SD
##  0.0186
## 
## 
## Guiraud&#39;s R
##                  R: 9.1 
## 
## R characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.789   5.459   6.484   6.596   8.158   9.080 
##    SD
##  1.8316
## 
## 
## Carroll&#39;s CTTR
##               CTTR: 6.43 
## 
## CTTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.265   3.860   4.585   4.664   5.769   6.420 
##    SD
##  1.2951
## 
## 
## Uber Index
##                  U: 26.08 
## 
## U characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   5.041  21.104  22.588  23.564  26.226  36.992 
##    SD
##  4.5831
## 
## 
## Maas&#39; Indices
##                  a: 0.2 
##               lgV0: 5.14 
##              lgeV0: 11.84 
## 
## Relative vocabulary growth (first half to full text)
##                  a: 0 
##               lgV0: 1.83 
##                 V&#39;: 0 (0 new types every 100 tokens)
## 
## Maas Indices characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1644  0.1953  0.2104  0.2112  0.2177  0.4454 
##    SD
##  0.0392
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.185   4.106   4.506   4.428   4.955   5.223 
##    SD
##  0.7145
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   2.729   9.455  10.376  10.196  11.410  12.026 
##    SD
##  1.6452</code></pre>
<p>We now go ahead and extract the lexical diversity scores for the
other essays.</p>
<pre class="r"><code>lexDiv &lt;- function(x){
  lapply(x, function(y){
    koRpus::lex.div(y, force.lang = &#39;en&#39;,  segment = 20, window = 20,  
                    quiet = T, measure=c(&quot;TTR&quot;, &quot;C&quot;, &quot;R&quot;, &quot;CTTR&quot;, &quot;U&quot;, &quot;Maas&quot;),
                    char=c(&quot;TTR&quot;, &quot;C&quot;, &quot;R&quot;, &quot;CTTR&quot;,&quot;U&quot;, &quot;Maas&quot;))
  })
}

# extract lex. div. measures
ns2_lds &lt;- lexDiv(ns2_ess)
de_lds &lt;- lexDiv(de_ess)
es_lds &lt;- lexDiv(es_ess)
fr_lds &lt;- lexDiv(fr_ess)
it_lds &lt;- lexDiv(it_ess)
pl_lds &lt;- lexDiv(pl_ess)
ru_lds &lt;- lexDiv(ru_ess)</code></pre>
<p>In a next step, we extract the CTTR values from L1-speakers and
learners and put the results into a table.</p>
<pre class="r"><code>cttr &lt;- data.frame(c(as.vector(sapply(ns1_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(ns2_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(de_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(es_lds, &#39;[&#39;, &quot;CTTR&quot;)),
                     as.vector(sapply(fr_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(it_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(pl_lds, &#39;[&#39;, &quot;CTTR&quot;)), 
                     as.vector(sapply(ru_lds, &#39;[&#39;, &quot;CTTR&quot;))),
          c(rep(&quot;en&quot;, length(as.vector(sapply(ns1_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;en&quot;, length(as.vector(sapply(ns2_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;de&quot;, length(as.vector(sapply(de_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;es&quot;, length(as.vector(sapply(es_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;fr&quot;, length(as.vector(sapply(fr_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;it&quot;, length(as.vector(sapply(it_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;pl&quot;, length(as.vector(sapply(pl_lds, &#39;[&#39;, &quot;CTTR&quot;)))),
            rep(&quot;ru&quot;, length(as.vector(sapply(ru_lds, &#39;[&#39;, &quot;CTTR&quot;)))))) %&gt;%
  dplyr::rename(CTTR = 1,
                l1 = 2)
# inspect
head(cttr)</code></pre>
<pre><code>##   CTTR l1
## 1 6.43 en
## 2 8.84 en
## 3 8.20 en
## 4 8.34 en
## 5 7.34 en
## 6 8.78 en</code></pre>
<p>We can now visualize the information in the table in the form of a
dot plot to inspect potential differences with respect to the
L1-background of speakers.</p>
<pre class="r"><code>cttr %&gt;%
  dplyr::group_by(l1) %&gt;%
  dplyr::summarise(CTTR = mean(CTTR)) %&gt;%
  ggplot(aes(x = reorder(l1, CTTR, mean), y = CTTR)) +
  geom_point() +
  # adapt y-axis labels
  labs(y = &quot;Lexical diversity (CTTR)&quot;) +
  # adapt tick labels
  scale_x_discrete(&quot;L1 of learners&quot;, 
                   breaks = names(table(cttr$l1)), 
                   labels = c(&quot;en&quot; = &quot;English&quot;,
                              &quot;de&quot; = &quot;German&quot;,
                              &quot;es&quot; = &quot;Spanish&quot;,
                              &quot;fr&quot; = &quot;French&quot;,
                              &quot;it&quot; = &quot;Italian&quot;,
                              &quot;pl&quot; = &quot;Polish&quot;,
                              &quot;ru&quot; = &quot;Russian&quot;)) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 15)) +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="llr_files/figure-html/ld7-1.png" width="672" /></p>
</div>
<div id="readability" class="section level1 unnumbered">
<h1 class="unnumbered">Readability</h1>
<p>Another measure to assess text quality or text complexity is
<em>readability</em>. As with lexical diversity scores, the
<code>textstat_readability</code> function from the
<code>quanteda.textstats</code> package provides a multitude of
different measures (see <a
href="https://quanteda.io/reference/textstat_readability.html">here</a>
for the entire list of readability scores that can be extracted). In the
following, we will focus on Flesch’s Reading Ease Score exclusively
<span class="citation">(cf. <a href="#ref-flesch1948new">Flesch
1948</a>)</span> (see below; ALS = average sentence length).</p>
<p><span class="math display">\[\begin{equation}
  Flesch =  206.835−(1.015 ASL)−(84.6 \frac{N_{Syllables}}{N_{Words}})
\end{equation}\]</span></p>
<p>In a first step, we extract the Flesch scores by applying the
<code>textstat_readability</code> to the essays.</p>
<pre class="r"><code>ns1_read &lt;- quanteda.textstats::textstat_readability(ns1_ess)
ns2_read &lt;- quanteda.textstats::textstat_readability(ns2_ess)
de_read &lt;- quanteda.textstats::textstat_readability(de_ess)
es_read &lt;- quanteda.textstats::textstat_readability(es_ess)
fr_read &lt;- quanteda.textstats::textstat_readability(fr_ess)
it_read &lt;- quanteda.textstats::textstat_readability(it_ess)
pl_read &lt;- quanteda.textstats::textstat_readability(pl_ess)
ru_read &lt;- quanteda.textstats::textstat_readability(ru_ess)
# inspect
ns1_read</code></pre>
<pre><code>##    document   Flesch
## 1     text1 43.12767
## 2     text2 62.34563
## 3     text3 63.16179
## 4     text4 62.90455
## 5     text5 53.53250
## 6     text6 56.92020
## 7     text7 53.89138
## 8     text8 59.28742
## 9     text9 62.26228
## 10   text10 53.60807
## 11   text11 58.24022
## 12   text12 58.36792
## 13   text13 55.85388
## 14   text14 48.55222
## 15   text15 55.41899
## 16   text16 62.98538</code></pre>
<p>Now, we generate a table with the results and the L1 of the speaker
that produced the essay.</p>
<pre class="r"><code>l1 &lt;- c(rep(&quot;en&quot;, nrow(ns1_read)), rep(&quot;en&quot;, nrow(ns2_read)),
        &quot;de&quot;, &quot;es&quot;, &quot;fr&quot;, &quot;it&quot;, &quot;pl&quot;, &quot;ru&quot;)
read_l1 &lt;- base::rbind(ns1_read, ns2_read, de_read, es_read, 
                    fr_read, it_read, pl_read, ru_read)
read_l1 &lt;- cbind(read_l1, l1) %&gt;%
  as.data.frame() %&gt;%
  dplyr::mutate(l1 = factor(l1, level = c(&quot;en&quot;, &quot;de&quot;, &quot;es&quot;, &quot;fr&quot;, &quot;it&quot;, &quot;pl&quot;, &quot;ru&quot;))) %&gt;%
  dplyr::group_by(l1) %&gt;%
  dplyr::summarise(Flesch = mean(Flesch))
# inspect
read_l1</code></pre>
<pre><code>## # A tibble: 7 × 2
##   l1    Flesch
##   &lt;fct&gt;  &lt;dbl&gt;
## 1 en      56.7
## 2 de      65.2
## 3 es      57.6
## 4 fr      66.4
## 5 it      55.4
## 6 pl      62.5
## 7 ru      43.8</code></pre>
<p>As before, we can visualize the results to check for potential
differences between L1-speakers and learners of English. In this case,
we use bar charts to visualize the results.</p>
<pre class="r"><code>read_l1 %&gt;%
  ggplot(aes(x = l1, y = Flesch, label = round(Flesch, 1))) +
  geom_bar(stat = &quot;identity&quot;) +
  geom_text(vjust=1.6, color = &quot;white&quot;)+
  # adapt tick labels
  scale_x_discrete(&quot;L1 of learners&quot;, 
                   breaks = names(table(read_l1$l1)), 
                   labels = c(&quot;en&quot; = &quot;English&quot;,
                              &quot;de&quot; = &quot;German&quot;,
                              &quot;es&quot; = &quot;Spanish&quot;,
                              &quot;fr&quot; = &quot;French&quot;,
                              &quot;it&quot; = &quot;Italian&quot;,
                              &quot;pl&quot; = &quot;Polish&quot;,
                              &quot;ru&quot; = &quot;Russian&quot;)) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 75)) +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="llr_files/figure-html/rd4-1.png" width="672" /></p>
</div>
<div id="spelling-errors" class="section level1 unnumbered">
<h1 class="unnumbered">Spelling errors</h1>
<p>We can also determine the number of spelling errors in L1 and learner
texts by checking if words in a given text occur in a dictionary or not.
To do this, we can use the <code>hunspell</code> function from the
<code>hunspell</code> package. We can choose between different
dictionaries (use <code>list_dictionaries()</code> to see which
dictionaries are available) and we can specify words to ignore via the
<code>ignore</code> argument.</p>
<pre class="r"><code># list words that are not in dict
hunspell(ns1_ess, 
         format = c(&quot;text&quot;),
         dict = dictionary(&quot;en_GB&quot;),
         ignore = en_stats) </code></pre>
<pre><code>## [[1]]
## [1] &quot;dilema&quot;     &quot;UKs&quot;        &quot;incourage&quot;  &quot;conjestion&quot; &quot;Tourturing&quot;
## 
## [[2]]
## [1] &quot;appealling&quot;
## 
## [[3]]
## [1] &quot;dependance&quot; &quot;recieve&quot;    &quot;travell&quot;   
## 
## [[4]]
## [1] &quot;ie&quot;          &quot;Improvent&quot;   &quot;maintanence&quot; &quot;theier&quot;      &quot;airplanes&quot;  
## [6] &quot;buisness&quot;    &quot;thier&quot;       &quot;ie&quot;          &quot;etc&quot;        
## 
## [[5]]
## [1] &quot;tendancy&quot;     &quot;etc&quot;          &quot;HGV&#39;s&quot;        &quot;Eurotunnel&quot;   &quot;Eurotunnel&#39;s&quot;
## 
## [[6]]
## [1] &quot;indaquacies&quot;      &quot;croweded&quot;         &quot;accomadating&quot;     &quot;roadsystem&quot;      
## [5] &quot;enviromentalists&quot; &quot;undergrouth&quot;      &quot;enviromentalists&quot; &quot;exponnentionally&quot;
## 
## [[7]]
## [1] &quot;taffic&quot;    &quot;taffic&quot;    &quot;percieved&quot;
## 
## [[8]]
## [1] &quot;notorously&quot; &quot;gars&quot;      
## 
## [[9]]
## [1] &quot;seperate&quot;    &quot;secondy&quot;     &quot;Dwyford&quot;     &quot;disastorous&quot; &quot;railtrak&quot;   
## [6] &quot;anymore&quot;     &quot;loocally&quot;    &quot;offes&quot;      
## 
## [[10]]
## [1] &quot;apparant&quot; &quot;persuede&quot; &quot;detere&quot;   &quot;overal&quot;  
## 
## [[11]]
## [1] &quot;Tarmat&quot;
## 
## [[12]]
##  [1] &quot;Britains&quot;      &quot;streches&quot;      &quot;improoved&quot;     &quot;ammount&quot;      
##  [5] &quot;soloution&quot;     &quot;privitisation&quot; &quot;bos&quot;           &quot;soloution&quot;    
##  [9] &quot;improove&quot;      &quot;liase&quot;        
## 
## [[13]]
## [1] &quot;abducters&quot; &quot;Bulger&quot;    &quot;enourmos&quot;  &quot;tyed&quot;      &quot;Britains&quot;  &quot;useage&quot;   
## [7] &quot;busses&quot;    &quot;useage&quot;   
## 
## [[14]]
##  [1] &quot;ment&quot;         &quot;accross&quot;      &quot;harmfull&quot;     &quot;byproducts&quot;   &quot;disel&quot;       
##  [6] &quot;traveling&quot;    &quot;likelyhood&quot;   &quot;adverage&quot;     &quot;collegue&quot;     &quot;effectivly&quot;  
## [11] &quot;controll&quot;     &quot;incrasing&quot;    &quot;restablished&quot; &quot;councills&quot;   
## 
## [[15]]
## [1] &quot;susstacial&quot; &quot;cataylitic&quot; &quot;alot&quot;       &quot;cataylitic&quot;
## 
## [[16]]
##  [1] &quot;ourselfs&quot;     &quot;ameander&quot;     &quot;illistrate&quot;   &quot;likly&quot;        &quot;firsty&quot;      
##  [6] &quot;mannor&quot;       &quot;greeny&quot;       &quot;tipee&#39;s&quot;      &quot;somthing&quot;     &quot;thent&quot;       
## [11] &quot;westeren&quot;     &quot;beause&quot;       &quot;earilene&quot;     &quot;shorly&quot;       &quot;disasterous&quot; 
## [16] &quot;nd&quot;           &quot;promblem&quot;     &quot;spiraling&quot;    &quot;intensifyed&quot;  &quot;privite&quot;     
## [21] &quot;companys&quot;     &quot;priviously&quot;   &quot;subsudised&quot;   &quot;privite&quot;      &quot;Unfortunatly&quot;
## [26] &quot;appethetic&quot;</code></pre>
<p>We can check how many spelling mistakes and words are in a text as
shown below.</p>
<pre class="r"><code>ns1_nerr &lt;- hunspell(ns1_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%
  unlist() %&gt;%
  length()
ns1_nw &lt;- sum(tokenizers::count_words(ns1_ess))
# inspect
ns1_nerr; ns1_nw</code></pre>
<pre><code>## [1] 111</code></pre>
<pre><code>## [1] 8499</code></pre>
<p>To check if L1 speakers and learners differ regrading the likelihood
of making spelling errors, we apply the <code>hunspell</code> function
to all texts and also extract the number of words for each text.</p>
<pre class="r"><code># ns1
ns1_nerr &lt;- hunspell(ns1_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
ns1_nw &lt;- sum(tokenizers::count_words(ns1_ess))
# ns2
ns2_nerr &lt;- hunspell(ns2_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
ns2_nw &lt;- sum(tokenizers::count_words(ns2_ess))
# de
de_nerr &lt;- hunspell(de_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
de_nw &lt;- sum(tokenizers::count_words(de_ess))
# es
es_nerr &lt;- hunspell(es_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
es_nw &lt;- sum(tokenizers::count_words(es_ess))
# fr
fr_nerr &lt;- hunspell(fr_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
fr_nw &lt;- sum(tokenizers::count_words(fr_ess))
# it
it_nerr &lt;- hunspell(it_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
it_nw &lt;- sum(tokenizers::count_words(it_ess))
# pl
pl_nerr &lt;- hunspell(pl_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
pl_nw &lt;- sum(tokenizers::count_words(pl_ess))
# ru
ru_nerr &lt;- hunspell(ru_ess, dict = dictionary(&quot;en_GB&quot;)) %&gt;%  unlist() %&gt;% length()
ru_nw &lt;- sum(tokenizers::count_words(ru_ess))</code></pre>
<p>Now, we generate a table from the results.</p>
<pre class="r"><code>err_tb &lt;- c(ns1_nerr, ns2_nerr, de_nerr, es_nerr, fr_nerr, it_nerr, pl_nerr, ru_nerr) %&gt;%
  as.data.frame() %&gt;%
  # rename column
  dplyr::rename(errors = 1) %&gt;%
  # add n of words
  dplyr::mutate(words = c(ns1_nw, ns2_nw, de_nw, es_nw, fr_nw, it_nw, pl_nw, ru_nw)) %&gt;%
  # add l1
  dplyr::mutate(l1 = c(&quot;en&quot;, &quot;en&quot;, &quot;de&quot;, &quot;es&quot;, &quot;fr&quot;, &quot;it&quot;, &quot;pl&quot;, &quot;ru&quot;)) %&gt;%
  # calculate rel freq
  dplyr::mutate(freq = round(errors/words*1000, 1)) %&gt;%
  # summarise
  dplyr::group_by(l1) %&gt;%
  dplyr::summarise(freq = mean(freq))
# inspect
head(err_tb)</code></pre>
<pre><code>## # A tibble: 6 × 2
##   l1     freq
##   &lt;chr&gt; &lt;dbl&gt;
## 1 de     23.4
## 2 en     17.0
## 3 es     27.6
## 4 fr     27.5
## 5 it      9  
## 6 pl      7.9</code></pre>
<p>We can now visualize the results.</p>
<pre class="r"><code>err_tb %&gt;%
  ggplot(aes(x = reorder(l1, -freq), y = freq, label = freq)) +
  geom_bar(stat = &quot;identity&quot;) +
  geom_text(vjust=1.6, color = &quot;white&quot;) +
  # adapt tick labels
  scale_x_discrete(&quot;L1 of learners&quot;, 
                   breaks = names(table(read_l1$l1)), 
                   labels = c(&quot;en&quot; = &quot;English&quot;,
                              &quot;de&quot; = &quot;German&quot;,
                              &quot;es&quot; = &quot;Spanish&quot;,
                              &quot;fr&quot; = &quot;French&quot;,
                              &quot;it&quot; = &quot;Italian&quot;,
                              &quot;pl&quot; = &quot;Polish&quot;,
                              &quot;ru&quot; = &quot;Russian&quot;)) +
  labs(y = &quot;Relative frequency\n(per 1,000 words)&quot;) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 40)) +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="llr_files/figure-html/sp7-1.png" width="672" /></p>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1 class="unnumbered">Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2024. <em>Analyzing learner language using
R</em>. Brisbane: The University of Queensland. url: <a
href="https://slcladal.github.io/llr.html"
class="uri">https://slcladal.github.io/llr.html</a> (Version
2024.11.05).</p>
<pre><code>@manual{schweinberger2024llr,
  author = {Schweinberger, Martin},
  title = {Analyzing learner language using R},
  note = {https://slcladal.github.io/pwr.html},
  year = {2024},
  organization = &quot;The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2024.11.05}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.4.1 (2024-06-14 ucrt)
## Platform: x86_64-w64-mingw32/x64
## Running under: Windows 11 x64 (build 22631)
## 
## Matrix products: default
## 
## 
## locale:
## [1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   
## [3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      
## [5] LC_TIME=English_Australia.utf8    
## 
## time zone: Australia/Brisbane
## tzcode source: internal
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] slam_0.1-54               Matrix_1.7-1             
##  [3] tokenizers_0.3.0          entity_0.1.0             
##  [5] pacman_0.5.1              wordcloud2_0.2.1         
##  [7] hunspell_3.0.5            stringi_1.8.4            
##  [9] koRpus.lang.en_0.1-4      koRpus_0.13-8            
## [11] sylly_0.1-6               quanteda.textplots_0.95  
## [13] quanteda.textstats_0.97.2 quanteda_4.1.0           
## [15] udpipe_0.8.11             tidytext_0.4.2           
## [17] tm_0.7-14                 NLP_0.3-0                
## [19] flextable_0.9.7           lubridate_1.9.3          
## [21] forcats_1.0.0             stringr_1.5.1            
## [23] dplyr_1.1.4               purrr_1.0.2              
## [25] readr_2.1.5               tidyr_1.3.1              
## [27] tibble_3.2.1              ggplot2_3.5.1            
## [29] tidyverse_2.0.0          
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.2.1        viridisLite_0.4.2       farver_2.1.2           
##  [4] fastmap_1.2.0           fontquiver_0.2.1        janeaustenr_1.0.0      
##  [7] digest_0.6.37           timechange_0.3.0        lifecycle_1.0.4        
## [10] magrittr_2.0.3          compiler_4.4.1          rlang_1.1.4            
## [13] sass_0.4.9              tools_4.4.1             utf8_1.2.4             
## [16] yaml_2.3.10             sna_2.8                 data.table_1.16.2      
## [19] knitr_1.48              labeling_0.4.3          askpass_1.2.1          
## [22] stopwords_2.3           htmlwidgets_1.6.4       here_1.0.1             
## [25] xml2_1.3.6              klippy_0.0.0.9500       withr_3.0.2            
## [28] grid_4.4.1              fansi_1.0.6             gdtools_0.4.0          
## [31] colorspace_2.1-1        scales_1.3.0            cli_3.6.3              
## [34] rmarkdown_2.28          ragg_1.3.3              generics_0.1.3         
## [37] rstudioapi_0.17.1       tzdb_0.4.0              cachem_1.1.0           
## [40] sylly.en_0.1-3          network_1.18.2          assertthat_0.2.1       
## [43] parallel_4.4.1          vctrs_0.6.5             jsonlite_1.8.9         
## [46] fontBitstreamVera_0.1.1 ISOcodes_2024.02.12     hms_1.1.3              
## [49] ggrepel_0.9.6           systemfonts_1.1.0       jquerylib_0.1.4        
## [52] glue_1.8.0              statnet.common_4.10.0   gtable_0.3.6           
## [55] munsell_0.5.1           pillar_1.9.0            htmltools_0.5.8.1      
## [58] openssl_2.2.2           R6_2.5.1                textshaping_0.4.0      
## [61] rprojroot_2.0.4         evaluate_1.0.1          lattice_0.22-6         
## [64] highr_0.11              SnowballC_0.7.1         fontLiberation_0.1.0   
## [67] bslib_0.8.0             Rcpp_1.0.13-1           zip_2.3.1              
## [70] uuid_1.2-1              fastmatch_1.1-4         coda_0.19-4.1          
## [73] nsyllable_1.0.1         officer_0.6.7           xfun_0.49              
## [76] pkgconfig_2.0.3</code></pre>
<hr />
<p><a href="#introduction">Back to top</a></p>
<p><a href="https://slcladal.github.io/index.html">Back to HOME</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
entry-spacing="0">
<div id="ref-benoit2021package" class="csl-entry">
Benoit, Kenneth, Kohei Watanabe, Haiyan Wang, Jiong Wei Lua, and Jouni
Kuha. 2021. <span>“Package <span>‘Quanteda. Textstats’</span>.”</span>
<em>Research Bulletin</em> 27 (2): 37–54.
</div>
<div id="ref-benoit2018quanteda" class="csl-entry">
Benoit, Kenneth, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng,
Stefan Müller, and Akitaka Matsuo. 2018. <span>“Quanteda: An r Package
for the Quantitative Analysis of Textual Data.”</span> <em>Journal of
Open Source Software</em> 3 (30): 774.
</div>
<div id="ref-flesch1948new" class="csl-entry">
Flesch, Rudolph. 1948. <span>“A New Readability Yardstick.”</span>
<em>Journal of Applied Psychology</em> 32 (3): 221–33.
</div>
<div id="ref-lindquist2009corpus" class="csl-entry">
Lindquist, Hans. 2009. <em>Corpus Linguistics and the Description of
English</em>. Edinburgh: Edinburgh University Press.
</div>
<div id="ref-tweedie1988lexdiv" class="csl-entry">
Tweedie, Fiona J., and R. Harald Baayen. 1998. <span>“How Variable May a
Constant Be? Measures of Lexical Richness in Perspective.”</span>
<em>Computers and the Humanities</em> 32: 323–52.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
