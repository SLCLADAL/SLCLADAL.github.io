<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />


<title>Introduction to Dimension Reduction Methods with R - AcqVA Aurora workshop</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>
<link rel="stylesheet" href="styles.css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VSGK4KYDQZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VSGK4KYDQZ');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="/content/ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    ABOUT LADAL
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="people.html">People | Collabs</a>
    </li>
    <li>
      <a href="news.html">News</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    EVENTS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="workshops.html">Workshops</a>
    </li>
    <li>
      <a href="compthinking.html">Computational Thinking in HASS</a>
    </li>
    <li>
      <a href="webinars2022.html">LADAL Webinar Series 2022</a>
    </li>
    <li>
      <a href="opening.html">LADAL Webinar Series 2021</a>
    </li>
    <li>
      <a href="atapevents.html">ATAP Events</a>
    </li>
  </ul>
</li>
<li>
  <a href="tutorials.html">TUTORIALS</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    RESOURCES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="links.html">Links</a>
    </li>
    <li>
      <a href="base.html">Tutorial stylesheet</a>
    </li>
  </ul>
</li>
<li>
  <a href="contact.html">CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Introduction to Dimension Reduction Methods
with R - AcqVA Aurora workshop</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">31 May, 2023</h4>

</div>


<p><img src="https://slcladal.github.io/images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1 class="unnumbered">Introduction</h1>
<p>This tutorial introduces dimension reduction methods with R with the
aim of showcasing how these methods work, how to prepare data and how to
implement selected dimension reduction methods (Principal Component
Analysis, Factor Analysis, and Multidimensional Scaling). Unfortunately,
we cannot deal with other, more complex dimension reduction methods such
as Uniform Manifold Approximation and Projection (UMAP) or t-Distributed
Stochastic Neighbor Embedding (t-SNE) in this tutorial (but we plan on
adding a separate tutorial for these methods in the future). The
reduction of multiple variables is useful for many things, e.g., for
visualization, noise reduction, and simplifying complex data sets.
However, it’s essential to note that interpretability of the principal
components may not always be straightforward, as they are linear
combinations of the original features.</p>
<p><img src="https://slcladal.github.io/images/gy_chili.jpg" width="15%" style="float:right; padding:10px" /></p>
<p>This tutorial is aimed at beginners and intermediate users of R. The
aim is not to provide a fully-fledged guide but rather to show and
exemplify some common dimension reduction methods with R.</p>
<div class="warning"
style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
The entire R Notebook for the tutorial can be downloaded <a
href="https://slcladal.github.io/content/dimred.Rmd"><strong>here</strong></a>.
If you want to render the R Notebook on your machine, i.e. knitting the
document to html or a pdf, you need to make sure that you have R and
RStudio installed and you also need to download the <a
href="https://slcladal.github.io/content/bibliography.bib"><strong>bibliography
file</strong></a> and store it in the same folder where you store the
Rproj file. <br><br> <strong><a
href="https://colab.research.google.com/drive/16VNNnRXAC6CFU9oBwLlQsoG_Xpub-CRl?usp=sharing">Here</a></strong>
is a <strong>link to an interactive version of this tutorial on
Binder</strong>. The interactive tutorial is based on a Jupyter notebook
of this tutorial. This interactive Jupyter notebook allows you to
execute code yourself and - if you copy the Jupyter notebook - you can
also change and edit the notebook, e.g. you can change code and upload
your own data.<br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<div class="warning"
style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
To be able to follow this tutorial, we suggest you check out and
familiarize yourself with the content of the following <strong>R
Basics</strong> tutorials:<br>
</p>
<p style="margin-top:1em; text-align:left">
<ul>
<li>
<a href="https://ladal.edu.au/introquant.html">Introduction to
Quantitative Reasoning</a>
</li>
<li>
<a href="https://ladal.edu.au/basicquant.html">Basic Concepts in
Quantitative Research</a>
</li>
<li>
<a href="https://ladal.edu.au/intror.html">Getting started with R</a>
</li>
<li>
<a href="https://ladal.edu.au/load.html">Loading, saving, and generating
data in R</a>
</li>
</ul>
</p>
<p style="margin-top:1em; text-align:center">
Click <a
href="https://ladal.edu.au/content/kwics.Rmd"><strong>here</strong></a><a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> to
download the <strong>entire R Notebook</strong> for this
tutorial.<br><br> <a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Fdimred_cb.ipynb%26branch%3Dmain"><img
src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a><br> Click
<a
href="https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Fdimred_cb.ipynb%26branch%3Dmain"><strong>here</strong></a>
to open an interactive Jupyter notebook that allows you to execute,
change, and edit the code as well as to upload your own data. <br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Preparation and session set up</strong></p>
<p>This tutorial is based on R. If you have not installed R or are new
to it, you will find an introduction to and more information how to use
R <a href="https://slcladal.github.io/intror.html">here</a>. For this
tutorials, we need to install certain <em>packages</em> from an R
<em>library</em> so that the scripts shown below are executed without
errors. Before turning to the code below, please install the packages by
running the code below this paragraph. If you have already installed the
packages mentioned below, then you can skip ahead and ignore this
section. To install the necessary packages, simply run the following
code - it may take some time (between 1 and 5 minutes to install all of
the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># install packages
install.packages(&quot;dplyr&quot;)
install.packages(&quot;stringr&quot;)
install.packages(&quot;writexl&quot;)
install.packages(&quot;here&quot;)
install.packages(&quot;flextable&quot;)
install.packages(&quot;tidyr&quot;)
install.packages(&quot;MASS&quot;)
install.packages(&quot;factoextra&quot;)
install.packages(&quot;ggplot2&quot;)
install.packages(&quot;report&quot;)
install.packages(&quot;psych&quot;)
install.packages(&quot;tufte&quot;)
# install klippy for copy-to-clipboard button in code chunks
install.packages(&quot;remotes&quot;)
remotes::install_github(&quot;rlesur/klippy&quot;)</code></pre>
<p>Now that we have installed the packages, we activate them as shown
below.</p>
<p>After installing these packages, we fetch them from the library to
activate the packages.</p>
<pre class="r"><code>options(scipen = 999) # supress math. notation
library(dplyr)
library(here)
library(flextable)
library(stringr)
library(tidyr)
library(MASS)
library(factoextra)
library(ggplot2)
library(report)
library(psych)
library(tufte)</code></pre>
</div>
<div id="what-are-dimension-reduction-methods"
class="section level1 unnumbered">
<h1 class="unnumbered">What are dimension reduction methods?</h1>
<p>Dimension reduction methods such as Principal Component Analysis
(PCA), Multidimensional Scaling (MDS), and Factor Analysis are
techniques used to <em>reduce the number of variables or dimensions in a
data set while preserving as much relevant information as
possible</em>.</p>
<p>The choice of method depends on the specific goals of the analysis
and the nature of the data being analyzed. Each method addresses
different aspects of dimension reduction:</p>
<ul>
<li><p>PCA emphasizes variance</p></li>
<li><p>MDS emphasizes pairwise distances</p></li>
<li><p>Factor Analysis emphasizes the underlying latent
factors.</p></li>
</ul>
<p>Below are brief explanations of the three commonly used dimension
reduction methods.</p>
<p><strong>Principal Component Analysis (PCA)</strong></p>
<p>Principal Component Analysis is a statistical technique that
transforms a data set into a new coordinate system where the variables
(features) are linearly uncorrelated.</p>
<p>It aims to find a set of orthogonal axes (principal components) in
such a way that the first principal component accounts for the maximum
variance in the data, the second principal component for the second
maximum variance, and so on. By selecting a subset of these principal
components, you can achieve dimension reduction while retaining the most
significant information in the data.</p>
<p>Unfortunately, PCA only works really well when the number of features
(or variables) isn’t too big and when the majority of the variance is
explained by 2 or 3 principal components. If you are dealing with a very
large data set with many features, UMAP is a better alternative.</p>
<p><strong>Multidimensional Scaling (MDS)</strong></p>
<p>Multidimensional Scaling is a method used to represent
high-dimensional data in a lower-dimensional space (usually 2D or 3D)
while maintaining pairwise distances or similarities between data
points. MDS attempts to preserve the relationships among data points as
much as possible. It’s often used in visualization to represent complex
data in a way that makes it easier to interpret or analyze.</p>
<p>Like PCA, MDS only works really well when the number of variables
isn’t too big and when the majority of the variance is explained by 2 or
3 dimensions.</p>
<p><strong>Factor Analysis</strong></p>
<p>Factor Analysis is a statistical technique that aims to uncover
underlying latent factors that contribute to the observed variables in a
data set. It’s particularly useful when dealing with data where
variables may be correlated, and you want to identify common factors
that explain the shared variance. Factor Analysis assumes that observed
variables are influenced by both the common factors and unique factors
specific to each variable.</p>
</div>
<div id="principal-component-analysis"
class="section level1 unnumbered">
<h1 class="unnumbered">Principal Component Analysis</h1>
<p>Principal Component Analysis (PCA) <span class="citation">(see, e.g.,
<a href="#ref-clark2011introduction">Clark and Ma’ayan 2011</a>)</span>
is used for dimensionality reduction and data compression while
preserving as much variance as possible in the data. It achieves this by
transforming the original data into a new coordinate system defined by a
set of orthogonal axes called <em>principal components</em>. The first
principal component captures the maximum variance in the data, the
second captures the second maximum variance, and so on.</p>
<blockquote>
<p>“Imagine you have just opened a cider shop. You have 50 varieties of
cider and you want to work out how to allocate them onto shelves, so
that similar-tasting ciders are put on the same shelf. There are lots of
different tastes and textures in cider - sweetness, tartness,
bitterness, yeastiness, fruitiness, clarity, fizziness etc etc. So what
you need to do to put the bottles into categories is answer two
questions:</p>
<ol style="list-style-type: decimal">
<li><p>What qualities are most important for identifying groups of
ciders? e.g. does classifying based on sweetness make it easier to
cluster your ciders into similar-tasting groups than classifying based
on fruitiness?</p></li>
<li><p>Can we reduce our list of variables by combining some of them?
e.g. is there actually a variable that is some combination of
“yeastiness and clarity and fizziness” and which makes a really good
scale for classifying varieties?</p></li>
</ol>
This is essentially what PCA does. Principal components are variables
that usefully explain variation in a data set - in this case, that
usefully differentiate between groups. Each principal component is one
of your original explanatory variables, or a combination of some of your
original explanatory variables.”
<footer>
Freya Harrison
</footer>
</blockquote>
<p>Let’s delve into an easy example to get a better understanding of the
theoretical underpinnings of PCA and to see how it works <span
class="citation">(this section is based on <a
href="#ref-stackpca3">Starmer 2018</a>)</span> and a very brief, nice,
and easy to understand explanation of PCA is available <a
href="https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/2700#2700">here</a>
<span class="citation">(<a href="#ref-stackpca4">Amoeba
2022</a>)</span>…</p>
<p><strong>Primer: Why should I use a PCA and what does PCA tell
us?</strong></p>
<p>Imagine we have a data set representing measurements of 4 features
across a sample of 6 languages. We now want to see if the languages from
groups based on the frequencies of these features.</p>
<div class="tabwid"><style>.cl-5f62f766{}.cl-5f5887b8{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5f5c98da{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5f5c98e4{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5f5cb752{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f5cb753{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f5cb75c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f5cb75d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f5cb75e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f5cb75f{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-5f62f766'><thead><tr style="overflow-wrap:break-word;"><th class="cl-5f5cb752"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Language</span></p></th><th class="cl-5f5cb753"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">Feat1</span></p></th><th class="cl-5f5cb753"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">Feat2</span></p></th><th class="cl-5f5cb753"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">Feat3</span></p></th><th class="cl-5f5cb753"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">Feat4</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75c"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang1</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">10</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">6.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">12.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75c"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang2</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">11</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">4.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">9.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75c"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang3</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">8</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">5.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">10.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75c"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang4</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">3</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">3.0</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">2.5</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75c"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang5</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">1</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">2.8</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">1.3</span></p></td><td class="cl-5f5cb75d"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-5f5cb75e"><p class="cl-5f5c98da"><span class="cl-5f5887b8">Lang6</span></p></td><td class="cl-5f5cb75f"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">2</span></p></td><td class="cl-5f5cb75f"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">1.0</span></p></td><td class="cl-5f5cb75f"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">2.0</span></p></td><td class="cl-5f5cb75f"><p class="cl-5f5c98e4"><span class="cl-5f5887b8">7</span></p></td></tr></tbody></table></div>
<p>To understand how PCA works, let us start by plotting the first
feature (Feat1).</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>When we check the visualization of the first feature, we see that
there appear to be two groups in our data!</p>
<p>We now add the second feature (Feat2) to check if the second feature
adds information and supports our hypothesis that there are two types of
languages in our data based on the features we collected.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>While adding the second feature has not added much information (in
that sense, Feat2 not as distinctive), there still appear to be two
groups. However, we continue by adding the third feature (Feat3) by
adding size as a way to show the third feature.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Feat3 supports the two group hypothesis as small dots have values
below 5 and big dots have values above 5 on the first feature scale.
Finally, we add the fourth feature (Feat4) and use color to visualize
this 4<sup>th</sup> dimension.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Like the second feature, Feat4 has not added much information.</p>
<p>Now, what would we use a PCA for in this context?</p>
<blockquote>
<p><strong>PCA can tell us if and how many groups there are in our data
and it can tell use what features are responsible for the division into
groups!</strong></p>
</blockquote>
<p>Let’s now go through a PCA step-by-step. Also, we only consider Feat1
and Feat2 to keep things very simple.</p>
<div class="tabwid"><style>.cl-6050f2d6{}.cl-6048345c{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-604b400c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-604b4016{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-604b5466{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-604b5467{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-604b5470{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-604b5471{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-604b547a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-604b547b{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-6050f2d6'><thead><tr style="overflow-wrap:break-word;"><th class="cl-604b5466"><p class="cl-604b400c"><span class="cl-6048345c">Language</span></p></th><th class="cl-604b5467"><p class="cl-604b4016"><span class="cl-6048345c">Feat1</span></p></th><th class="cl-604b5467"><p class="cl-604b4016"><span class="cl-6048345c">Feat2</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-604b5470"><p class="cl-604b400c"><span class="cl-6048345c">Lang1</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">10</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">6.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-604b5470"><p class="cl-604b400c"><span class="cl-6048345c">Lang2</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">11</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">4.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-604b5470"><p class="cl-604b400c"><span class="cl-6048345c">Lang3</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">8</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">5.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-604b5470"><p class="cl-604b400c"><span class="cl-6048345c">Lang4</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">3</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">3.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-604b5470"><p class="cl-604b400c"><span class="cl-6048345c">Lang5</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">1</span></p></td><td class="cl-604b5471"><p class="cl-604b4016"><span class="cl-6048345c">2.8</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-604b547a"><p class="cl-604b400c"><span class="cl-6048345c">Lang6</span></p></td><td class="cl-604b547b"><p class="cl-604b4016"><span class="cl-6048345c">2</span></p></td><td class="cl-604b547b"><p class="cl-604b4016"><span class="cl-6048345c">1.0</span></p></td></tr></tbody></table></div>
<p>We start by calculating the center of the data.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Next we scale and center the data so that the center is at (0,0).</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The relationship between data points is unchanged!</p>
<blockquote>
<p>Important: <strong>always center and scale your data</strong> as the
scales will impact the magnitude of variance! In other words, if you do
not center and scale, components can be deemed important simply because
the scale of the variables is bigger (not because they are more
important)!</p>
</blockquote>
<p>Now, we fit a line through the data.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="warning"
style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
<b>IMPORTANT!</b>
</p>
<p style="margin-left:1em;">
<p>But how do we arrive at this line and what is there always talk about
“orthogonal” when talking about PCA?</p>
Let’s have a look at simple the Ordinary Least Squared (OLS) procedure
that underlies regression:
</p>
<p style="margin-top:1em; text-align:center">
<img src="dimred_files/figure-html/unnamed-chunk-12-1.png" width="672" />
</p>
<p style="margin-left:1em;">
<p>In OLS, the lines that represent variance (or residuals) are
perpendicular to the x-axis.</p>
However, in PCA, the line are perpendicular to the regression line as
shown below!
</p>
<p style="margin-top:1em; text-align:center">
<p><img src="dimred_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</p>
<p></span></p>
</div>
<p>The line that minimizes variance is called <strong>Principal
Component 1</strong> (PC1) and it is different from a regression line.
The PC1 can be found by minimizing the orthogonal distances (blue lines
above) between data points and their projections (green points
above)!.</p>
<p>An alternative way to find PC1 is actually not to try and minimize
the distance between the data point and its projection but to maximize
the distance between the projection (the green points on the line) and
the origin (the center of the coordinate system). We can then square the
distances between projections and the origin and add these squared
distances, which gives us the <em>sum of squared distances</em> or
<em>SS(distances)</em>.</p>
<p>PC1 has a slope of 0.9411239 - this already shows us that the data is
spread much more along PC1 that along PC2!</p>
<p>We go about 1.0625593 units (1 / 0.9411) to the right and 1 unit
up.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Now, we find the value for a (square root of b<sup>2</sup> +
c<sup>2</sup>) = 1.4591204.</p>
<p>Next, we scale b and c so that a is 1.</p>
<p>a<sup>2</sup> = b<sup>2</sup> + c<sup>2</sup></p>
<p>b = 1.0625593 / 1.4591204 = 0.7282191</p>
<p>c = 1 / 1.4591204 = 0.6853444</p>
<p>To make PC1, we need 0.738 of Feat1 and 0.685 of Feat2.</p>
<p>This 1 unit long vector (a) is called the Eigenvector for PC1.</p>
<blockquote>
<p>Eigenvector and Eigenvalue are not the same! Eigenvector represent
the factor loadings for each observed variable on a specific factor.
Eigenvalue represents the amount of variance explained by an entire
factor.</p>
</blockquote>
<p>The proportions (0.738 and 0.685) are called the loading scores.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>PC2 is simply the perpendicular line to PC1 that goes through
0,0.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>As PC1 and PC2 are perpendicular, the Eigenvector of PC2 is -0.685 of
Feat1 and 0.728 of Feat2.</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We can (but have to) rotate the PC1 and make the points smaller (so
that our plot looks more like a proper PCA plot).</p>
<p><img src="dimred_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>To plot the results of a PCA, we simply rotate the plot so that the
PCs reflect the axes and we project the points onto the PCs.</p>
<pre class="r"><code># generate data
df &lt;- data.frame(pcadat$Feat1,
                 pcadat$Feat2)
colnames(df) &lt;- c(&quot;Feat1&quot;, &quot;Feat2&quot;)
# perform PCA
pcaex &lt;- prcomp(df, center = T, scale = T)
# visualize PCA results
fviz_pca_ind(pcaex, label =  &quot;&quot;) +
  coord_cartesian(xlim = c(-2, 2), ylim = c(-2, 2)) +
  ggtitle(&quot;PCA plot&quot;) +
  theme(aspect.ratio = 1)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Now we have an understanding of how we arrive at the visual
representation of a PCA. But how do we arrive at the explained
variance?</p>
<p>In the context of PCA, variance refers to summative variance or
overall/total variability.</p>
<p>To get a better grasp of what this means, let’s consider a covariance
matrix of some 3 variables (rather than just 2 variables as above).
Their variances are on the diagonal, and the sum of the 3 values (3.248)
is the overall variability.</p>
<div class="tabwid"><style>.cl-61f32528{}.cl-61eaec82{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-61ee2c4e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-61ee4152{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-61ee415c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-61ee415d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-61f32528'><thead><tr style="overflow-wrap:break-word;"><th class="cl-61ee4152"><p class="cl-61ee2c4e"><span class="cl-61eaec82">V1</span></p></th><th class="cl-61ee4152"><p class="cl-61ee2c4e"><span class="cl-61eaec82">V2</span></p></th><th class="cl-61ee4152"><p class="cl-61ee2c4e"><span class="cl-61eaec82">V3</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">1.3437305</span></p></td><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">-0.1601523</span></p></td><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">0.1864702</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">-0.1601523</span></p></td><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">0.6192056</span></p></td><td class="cl-61ee415c"><p class="cl-61ee2c4e"><span class="cl-61eaec82">-0.1266843</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-61ee415d"><p class="cl-61ee2c4e"><span class="cl-61eaec82">0.1864702</span></p></td><td class="cl-61ee415d"><p class="cl-61ee2c4e"><span class="cl-61eaec82">-0.1266843</span></p></td><td class="cl-61ee415d"><p class="cl-61ee2c4e"><span class="cl-61eaec82">1.4855496</span></p></td></tr></tbody></table></div>
<p>Now, PCA replaces original variables with new variables, called
principal components, which are orthogonal (i.e. they have zero
covariation!) and have variances (called eigenvalues) in decreasing
order. So, the covariance matrix between the principal components
extracted from the above data is this:</p>
<div class="tabwid"><style>.cl-6206400e{}.cl-61fd47ce{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-620073d6{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-620089b6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-620089c0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-620089c1{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-6206400e'><thead><tr style="overflow-wrap:break-word;"><th class="cl-620089b6"><p class="cl-620073d6"><span class="cl-61fd47ce">V1</span></p></th><th class="cl-620089b6"><p class="cl-620073d6"><span class="cl-61fd47ce">V2</span></p></th><th class="cl-620089b6"><p class="cl-620073d6"><span class="cl-61fd47ce">V3</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">1.651354</span></p></td><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">0.000000</span></p></td><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">0.0000000</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">0.000000</span></p></td><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">1.220288</span></p></td><td class="cl-620089c0"><p class="cl-620073d6"><span class="cl-61fd47ce">0.0000000</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-620089c1"><p class="cl-620073d6"><span class="cl-61fd47ce">0.000000</span></p></td><td class="cl-620089c1"><p class="cl-620073d6"><span class="cl-61fd47ce">0.000000</span></p></td><td class="cl-620089c1"><p class="cl-620073d6"><span class="cl-61fd47ce">0.5768431</span></p></td></tr></tbody></table></div>
<p>Note that the diagonal sum is still 3.448, which says that all 3
components account for all the multivariate variability. The PC1
accounts for or “explains” 1.651/3.448 = 47.9% of the overall
variability; the PC2 explains 1.220/3.448 = 35.4% of it; the 3rd one
explains .577/3.448 = 16.7% of it.</p>
<p>So, what do they mean when they say that PCA explains maximal
variance? That is not, of course, that it finds the largest variance
among three values 1.343730519 .619205620 1.485549631. PCA finds, in the
data space, the dimension (direction) with the largest variance out of
the overall variance 1.343730519+.619205620+1.485549631 = 3.448. That
largest variance would be 1.651354285. Then it finds the dimension of
the second largest variance, orthogonal to the first one, out of the
remaining 3.448-1.651354285 overall variance. That 2nd dimension would
be 1.220288343 variance. And so on. The last remaining dimension is
.576843142 variance.</p>
<p>For our example, we can extract the amount of variance accounted for
as shown below:</p>
<p>Step 1: get loading scores</p>
<pre class="r"><code>pcaex$x</code></pre>
<pre><code>##             PC1        PC2
## [1,] -1.6229306  0.2698980
## [2,] -0.9855078 -0.6922526
## [3,] -0.8983094  0.1947325
## [4,]  0.7132969  0.2067653
## [5,]  1.1180034  0.4515144
## [6,]  1.6754475 -0.4306576</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Step 2: calculate standard deviations of PC1 and PC2</p>
<pre class="r"><code>sdpc1 &lt;- sd(pcaex$x[,1])
sdpc2 &lt;- sd(pcaex$x[,2])
sdpc1; sdpc2</code></pre>
<pre><code>## [1] 1.339995</code></pre>
<pre><code>## [1] 0.45212</code></pre>
<p>Step 3: use standard deviations to calculate the amount of variance
explained by each component</p>
<pre class="r"><code># Proportion of Variance PC1 = sd PC1 squared / (sd PC1 squared + sd PC2 squared)
sdpc1^2 / (sdpc1^2 + sdpc2^2) </code></pre>
<pre><code>## [1] 0.8977938</code></pre>
<pre class="r"><code># Proportion of Variance PC2 = sd PC2 squared / (sd PC1 squared + sd PC2 squared)
sdpc2^2 / (sdpc1^2 + sdpc2^2) </code></pre>
<pre><code>## [1] 0.1022062</code></pre>
<p>According to our manual calculation, PC1 explains 0.8978 % of the
variation while PC2 explains 0.1022 % of the variation. To check if this
is correct, we check our results against the results provided by the
<code>prcomp</code> function.</p>
<pre><code>## Importance of components:
##                           PC1    PC2
## Standard deviation     1.3400 0.4521
## Proportion of Variance 0.8978 0.1022
## Cumulative Proportion  0.8978 1.0000</code></pre>
<p>But how do we arrive at the standard deviations of the PCs? The
standard deviations of the PCs are the covariance matrix values for the
respective PCs! So let’s have a look at the covariance matrices of the
raw data, the scales data, and the rotated, final data.</p>
<pre><code>##           Feat1    Feat2
## Feat1 18.966667 6.126667
## Feat2  6.126667 3.126667</code></pre>
<pre><code>##           Feat1     Feat2
## Feat1 1.0000000 0.7955875
## Feat2 0.7955875 1.0000000</code></pre>
<pre><code>##                          PC1                      PC2
## PC1 1.7955875066756534774726 0.0000000000000003981407
## PC2 0.0000000000000003981407 0.2044124933243466890609</code></pre>
<p>We see that the standard deviation of PC1 is equal to the sum of the
first row (or column) of the scaled covariance matrix. But more
importantly, we see that the <strong>squared standard deviations of the
PCs are equal to the variances (eigenvalues) of the PCs in the
covariance matrix</strong>.</p>
<pre class="r"><code>sdpc1^2 # sd of PC1 squared</code></pre>
<pre><code>## [1] 1.795588</code></pre>
<pre class="r"><code># which is equal to
sum(cov(pcaex$x)[1,])</code></pre>
<pre><code>## [1] 1.795588</code></pre>
<pre class="r"><code>sdpc2^2 # sd of PC2 squared</code></pre>
<pre><code>## [1] 0.2044125</code></pre>
<pre class="r"><code># which is equal to
sum(cov(pcaex$x)[2,])</code></pre>
<pre><code>## [1] 0.2044125</code></pre>
<p>Now that we have worked through one example of a PCA manually, we
turn to several examples to show how one can implement PCA in R to
showcase what PCA can be used for.</p>
<div id="example-1" class="section level3 unnumbered">
<h3 class="unnumbered">Example 1</h3>
<p>Here, we will show</p>
<ul>
<li><p>how to use the <code>prcomp()</code> function to perform
PCA</p></li>
<li><p>how to draw a PCA plot using ggplot2</p></li>
<li><p>how to determine how much variation each component accounts
for</p></li>
<li><p>how to examine the loading scores to determine what variables
have the largest effect on the graph</p></li>
</ul>
<p>In this example, the data is in a matrix called <code>pcadat</code>
where columns are individual samples (i.e. languages) and rows are
measurements taken for all the samples (i.e. features).</p>
<pre class="r"><code>pcadat &lt;- matrix(nrow=100, ncol=10)
colnames(pcadat) &lt;- c(
  paste(&quot;indoeu&quot;, 1:5, sep=&quot;&quot;), # Indo-European languages
  paste(&quot;austro&quot;, 1:5, sep=&quot;&quot;)) # Austronesian languages
rownames(pcadat) &lt;- paste(&quot;feature&quot;, 1:100, sep=&quot;&quot;)
for (i in 1:100) {
  indoeu.values &lt;- rpois(5, lambda=sample(x=10:1000, size=1))
  austro.values &lt;- rpois(5, lambda=sample(x=10:1000, size=1))
 
  pcadat[i,] &lt;- c(indoeu.values, austro.values)
}
# inspect data
head(pcadat); dim(pcadat)</code></pre>
<pre><code>##          indoeu1 indoeu2 indoeu3 indoeu4 indoeu5 austro1 austro2 austro3
## feature1    1058     996     985    1020     958     759     745     820
## feature2     601     639     628     666     591     657     702     662
## feature3     792     831     736     762     770     319     346     340
## feature4     321     363     340     371     351     102      97      96
## feature5     152     141     134     149     121     422     420     409
## feature6     380     407     406     409     417     871     930     895
##          austro4 austro5
## feature1     766     797
## feature2     625     692
## feature3     352     339
## feature4     127      95
## feature5     423     417
## feature6     887     817</code></pre>
<pre><code>## [1] 100  10</code></pre>
<p>We now implement the PCA using the <code>prcomp</code> function from
the <code>stats</code> package. In our case, we specify that we want to
transpose the data (using the <code>t</code> function) because
<strong>we need features to represent columns (not rows!)</strong> and
we set the argument <code>scale</code> to TRUE as the data has to be
normalised for a PCA to provide reliable results.</p>
<pre class="r"><code>pca &lt;- prcomp(t(pcadat), scale=TRUE) </code></pre>
<p>Now, we generate a scree plot to show how much variance is accounted
for by each component. We start by preparing the data.</p>
<pre class="r"><code># prepare data
pca.var &lt;- pca$sdev^2
# extract percentage of contribution
pca.var.per &lt;- round(pca.var/sum(pca.var)*100, 1)
# generate data frame for visualization
pcascreedat &lt;- data.frame(Component = paste0(&quot;PC&quot;, 1:10),
                          Percent = round(pca.var/sum(pca.var)*100, 2)) %&gt;%
  dplyr::mutate(Text = paste0(Percent, &quot;%&quot;),
                Component = factor(Component, 
                                    levels = c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;PC4&quot;, &quot;PC5&quot;, &quot;PC6&quot;, &quot;PC7&quot;, &quot;PC8&quot;, &quot;PC9&quot;, &quot;PC10&quot;)))
# inspect
pcascreedat</code></pre>
<pre><code>##    Component Percent   Text
## 1        PC1   92.48 92.48%
## 2        PC2    2.29  2.29%
## 3        PC3    1.43  1.43%
## 4        PC4    1.07  1.07%
## 5        PC5    0.79  0.79%
## 6        PC6    0.61  0.61%
## 7        PC7    0.57  0.57%
## 8        PC8    0.51  0.51%
## 9        PC9    0.24  0.24%
## 10      PC10    0.00     0%</code></pre>
<p>Now that the dtaa is formatted appropriately, we generate the scree
plot.</p>
<pre class="r"><code>ggplot(pcascreedat, aes(x = Component, y = Percent, label = Text)) +
  geom_bar(stat = &quot;identity&quot;) +
  geom_text(vjust=-1.6, size = 3) +
  ggtitle(&quot;Scree Plot&quot;) +
  labs(x=&quot;Principal Components&quot;, y=&quot;Percent Variation&quot;) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 100))</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>The scree plots shows that the PC1 accounts for 87.69% of the
variability while the PC2 only accounts for 3.52% of the variability.
This means that one component suffices to differentiate the data.</p>
<p>Now we make a fancy looking plot that shows the PCs and the
variation.</p>
<pre class="r"><code>data.frame(Sample=rownames(pca$x),
                       X=pca$x[,1],
                       Y=pca$x[,2]) %&gt;%
  ggplot(aes(x=X, y=Y, label=Sample)) +
  geom_text() +
  xlab(paste(&quot;PC1 (&quot;, pca.var.per[1], &quot;%)&quot;, sep=&quot;&quot;)) +
  ylab(paste(&quot;PC2 (&quot;, pca.var.per[2], &quot;%)&quot;, sep=&quot;&quot;)) +
  theme_bw() +
  ggtitle(&quot;PCA Graph&quot;) +
  coord_cartesian(xlim = c(-11, 11))</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Next, we get the names of the most important 5 features that
contribute most to PC1.</p>
<pre class="r"><code>loading_scores &lt;- pca$rotation[,1]
# extract the magnitudes of the scores
feature_scores &lt;- abs(loading_scores) 
# extract the 5 highest scores
feature_score_ranked &lt;- sort(feature_scores, decreasing=TRUE)
top_5_features &lt;- names(feature_score_ranked[1:5])
# show the names of the top 5 features 
top_5_features</code></pre>
<pre><code>## [1] &quot;feature24&quot; &quot;feature62&quot; &quot;feature58&quot; &quot;feature44&quot; &quot;feature29&quot;</code></pre>
<p>Now, we show the scores (and +/- sign)</p>
<pre class="r"><code>pca$rotation[top_5_features,1]</code></pre>
<pre><code>##  feature24  feature62  feature58  feature44  feature29 
##  0.1039671 -0.1039448 -0.1039315  0.1039010 -0.1039010</code></pre>
</div>
<div id="example-2" class="section level3 unnumbered">
<h3 class="unnumbered">Example 2</h3>
<p>In this example, we explore the use of PCA for survey data.
Specifically, we want to use PCA to check if 5 items reflect the
underlying factor appropriately or if one of the items needs to be
replaced.</p>
<pre class="r"><code>surveydata &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/sud.rda&quot;, &quot;rb&quot;))
# inspect
flextable::flextable(head(surveydata, 10))</code></pre>
<div class="tabwid"><style>.cl-62b8e43e{}.cl-62ad07fe{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-62b24f70{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-62b24f84{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-62b27694{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-62b2769e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-62b2769f{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-62b276a8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-62b276a9{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-62b276aa{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-62b8e43e'><thead><tr style="overflow-wrap:break-word;"><th class="cl-62b27694"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q01_Outgoing</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q02_Outgoing</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q03_Outgoing</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q04_Outgoing</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q05_Outgoing</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q06_Intelligence</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q07_Intelligence</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q08_Intelligence</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q09_Intelligence</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q10_Intelligence</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q11_Attitude</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q12_Attitude</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q13_Attitude</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q14_Attitude</span></p></th><th class="cl-62b2769e"><p class="cl-62b24f84"><span class="cl-62ad07fe">Q15_Attitude</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_01</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_02</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_03</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_04</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_05</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_06</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_07</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_08</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b2769f"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_09</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276a8"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-62b276a9"><p class="cl-62b24f70"><span class="cl-62ad07fe">Respondent_10</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">4</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">5</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">2</span></p></td><td class="cl-62b276aa"><p class="cl-62b24f84"><span class="cl-62ad07fe">1</span></p></td></tr></tbody></table></div>
<p>We now implement the PCA.</p>
<pre class="r"><code># entering raw data and extracting PCs  from the correlation matrix
pca_res2 &lt;- princomp(surveydata[c(&quot;Q01_Outgoing&quot;, 
                                  &quot;Q02_Outgoing&quot;,  
                                  &quot;Q03_Outgoing&quot;,  
                                  &quot;Q04_Outgoing&quot;,  
                                  &quot;Q05_Outgoing&quot;)])
# print variance accounted for
summary(pca_res2) </code></pre>
<pre><code>## Importance of components:
##                           Comp.1     Comp.2     Comp.3     Comp.4      Comp.5
## Standard deviation     3.2317383 0.62656643 0.50633614 0.44585671 0.332592305
## Proportion of Variance 0.9159511 0.03442977 0.02248422 0.01743374 0.009701174
## Cumulative Proportion  0.9159511 0.95038087 0.97286509 0.99029883 1.000000000</code></pre>
<p>The cumulative proportion of variance already shows that the five
items represent a single underlying factor as 91.5% of the variance is
explained by PC1 alone!</p>
<p>The loading scores for PC1 are very similar for all items and thus
show that none of the items under performs. In such a case, it might
make sense to remove items, not because they do not capture the
underlying concept but to reduce the items for participants.</p>
<pre class="r"><code># prepare data
pca2.var &lt;- pca_res2$sdev^2
# extract percentage of contribution
pca2.var.per &lt;- round(pca.var/sum(pca.var)*100, 1)
# generate data frame for visualization
data.frame(Component = paste0(&quot;PC&quot;, 1:5),
                          Percent = round(pca2.var/sum(pca2.var)*100, 2)) %&gt;%
  dplyr::mutate(Text = paste0(Percent, &quot;%&quot;),
                Component = factor(Component, 
                                    levels = c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;PC4&quot;, &quot;PC5&quot;))) %&gt;%
  ggplot(aes(x = Component, y = Percent, label = Text)) +
  geom_bar(stat = &quot;identity&quot;) +
  geom_text(vjust=-1.6, size = 3) +
  ggtitle(&quot;Scree Plot&quot;) +
  labs(x=&quot;Principal Components&quot;, y=&quot;Percent Variation&quot;) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 100))</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>We now plot the loading scores for each participant to see if we can
see groups among the participants based on outgoingness.</p>
<pre class="r"><code>pca_res2$scores %&gt;%
  as.data.frame() %&gt;%
  dplyr::rename(PC1 = 1,
                PC2 = 2,
                PC3 = 3,
                PC4 = 4,
                PC5 = 5) %&gt;%
  dplyr::mutate(Participants = paste0(&quot;P&quot;, 1:20),
                clr = ifelse(PC1 &gt; 0, 1, 0)) %&gt;%
  ggplot(aes(x = PC1, y = PC2, color = clr, label = Participants)) +
  geom_point(size=2) +
  geom_text(size = 3, nudge_x = -.2, check_overlap = T) +
  theme_bw() +
  scale_color_viridis_b() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>The figure shows that based on PC1, we can distinguish between
subjects who are very outgoign and subjects that are not very
outgoing.</p>
</div>
<div id="example-3" class="section level3 unnumbered">
<h3 class="unnumbered">Example 3</h3>
<p>In this example, we use the <code>biopsy</code> data to see what
variables can be used to predict malignant melanomas.</p>
<p>In a first step, we remove any data points with missing values and
add meaningful variable names.</p>
<pre class="r"><code>data(biopsy)
biopsy_nona &lt;- biopsy %&gt;%
  tidyr::drop_na() %&gt;%
  # add meaningful variable names
  dplyr::rename(ClumpSize = V1,
                CellSize = V2,
                CellShape = V3,
                Adhesion = V4,
                EpithelialSize = V5,
                Nuclei = V6,
                Chromatin = V7,
                Nucleoli = V8,
                Mitoses = V9)
# inspect data
flextable::flextable(head(biopsy_nona, 10))</code></pre>
<div class="tabwid"><style>.cl-632326dc{}.cl-6318f518{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-631d103a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-631d104e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-631d28d6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-631d28e0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-631d28e1{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-631d28e2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-631d28ea{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-631d28eb{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-632326dc'><thead><tr style="overflow-wrap:break-word;"><th class="cl-631d28d6"><p class="cl-631d103a"><span class="cl-6318f518">ID</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">ClumpSize</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">CellSize</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">CellShape</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">Adhesion</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">EpithelialSize</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">Nuclei</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">Chromatin</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">Nucleoli</span></p></th><th class="cl-631d28e0"><p class="cl-631d104e"><span class="cl-6318f518">Mitoses</span></p></th><th class="cl-631d28d6"><p class="cl-631d103a"><span class="cl-6318f518">class</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1000025</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">5</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1002945</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">5</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">4</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">4</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">5</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">7</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">10</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1015425</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1016277</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">6</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">8</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">8</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">4</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">7</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1017023</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">4</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1017122</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">8</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">10</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">10</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">8</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">7</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">10</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">9</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">7</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">malignant</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1018099</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">10</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1018561</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">3</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">1033078</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28e2"><p class="cl-631d104e"><span class="cl-6318f518">5</span></p></td><td class="cl-631d28e1"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-631d28ea"><p class="cl-631d103a"><span class="cl-6318f518">1033078</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">4</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">2</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28eb"><p class="cl-631d104e"><span class="cl-6318f518">1</span></p></td><td class="cl-631d28ea"><p class="cl-631d103a"><span class="cl-6318f518">benign</span></p></td></tr></tbody></table></div>
<p>Next, we remove non-numeric variables.</p>
<pre class="r"><code>biopsy_num &lt;- biopsy_nona %&gt;%
  dplyr::select_if(is.numeric)
# inspect data
flextable::flextable(head(biopsy_num, 10))</code></pre>
<div class="tabwid"><style>.cl-633f5bea{}.cl-6336241c{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6339a68c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6339bd98{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6339bda2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6339bda3{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-633f5bea'><thead><tr style="overflow-wrap:break-word;"><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">ClumpSize</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">CellSize</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">CellShape</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">Adhesion</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">EpithelialSize</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">Nuclei</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">Chromatin</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">Nucleoli</span></p></th><th class="cl-6339bd98"><p class="cl-6339a68c"><span class="cl-6336241c">Mitoses</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">5</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">5</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">4</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">4</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">5</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">7</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">10</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">6</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">8</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">8</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">4</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">7</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">4</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">8</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">10</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">10</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">8</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">7</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">10</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">9</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">7</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">10</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">3</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda2"><p class="cl-6339a68c"><span class="cl-6336241c">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">4</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">2</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td><td class="cl-6339bda3"><p class="cl-6339a68c"><span class="cl-6336241c">1</span></p></td></tr></tbody></table></div>
<p>We can perform the PCA.</p>
<pre class="r"><code>biopsy_pca &lt;- prcomp(biopsy_num,
                     scale = T)
# summary
summary(biopsy_pca)</code></pre>
<pre><code>## Importance of components:
##                           PC1     PC2     PC3     PC4     PC5     PC6     PC7
## Standard deviation     2.4289 0.88088 0.73434 0.67796 0.61667 0.54943 0.54259
## Proportion of Variance 0.6555 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271
## Cumulative Proportion  0.6555 0.74172 0.80163 0.85270 0.89496 0.92850 0.96121
##                            PC8     PC9
## Standard deviation     0.51062 0.29729
## Proportion of Variance 0.02897 0.00982
## Cumulative Proportion  0.99018 1.00000</code></pre>
<p>First, we create a scree plot of the variance captured by each
component.</p>
<pre class="r"><code>factoextra::fviz_eig(biopsy_pca,
                     addlabels = T,
                     ylim = c(0, 80),
                     barfill = &quot;gray50&quot;,
                     barcolor = &quot;gray20&quot;)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>We now create a pretty biplot to show the results of the PCA.</p>
<pre class="r"><code>fviz_pca_biplot(biopsy_pca,
                geom = &quot;point&quot;,
                # no data point labels
                label = &quot;var&quot;,
                # color by class
                habillage = biopsy_nona$class,
                # change variable color 
                col.var = &quot;black&quot;) + 
  # adapt data point color
  ggplot2::scale_color_manual(values = c(&quot;orange&quot;, &quot;purple&quot;)) +
  # add title
  ggtitle(&quot;A pretty biplot&quot;)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>The plot above is also known as variable correlation plot or biplot.
A biplot overlays a score plot with a loading plot and thus shows
individual data points as well as the relationships between all
variables (in the form of arrows). It can be interpreted as follow:</p>
<ul>
<li>Positively correlated variables are grouped together.<br />
</li>
<li>Negatively correlated variables would be positioned on opposite
sides of the plot origin (opposed quadrants).<br />
</li>
<li>The distance between variables and the origin measures the quality
of the variables on the factor map.<br />
</li>
<li>Variables that are away from the origin are well represented on the
factor map.</li>
</ul>
<p>But why are all variables cluster together?</p>
<p>Let’s have a look at the correlations between variables.</p>
<div class="tabwid"><style>.cl-63ce51a6{}.cl-63c5d238{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-63c8ec02{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-63c8ff9e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-63c8ffa8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-63c8ffa9{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-63ce51a6'><thead><tr style="overflow-wrap:break-word;"><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">ClumpSize</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">CellSize</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">CellShape</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">Adhesion</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">EpithelialSize</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">Nuclei</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">Chromatin</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">Nucleoli</span></p></th><th class="cl-63c8ff9e"><p class="cl-63c8ec02"><span class="cl-63c5d238">Mitoses</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6424815</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6534700</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4878287</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5235960</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5930914</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5537424</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5340659</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3509572</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6424815</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.9072282</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7069770</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7535440</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6917088</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7555592</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7193460</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4607547</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6534700</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.9072282</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6859481</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7224624</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7138775</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7353435</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7179634</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4412576</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4878287</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7069770</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6859481</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5945478</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6706483</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6685671</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6031211</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4188983</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5235960</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7535440</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7224624</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5945478</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5857161</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6181279</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6289264</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4805833</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5930914</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6917088</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7138775</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6706483</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5857161</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6806149</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5842802</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3392104</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5537424</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7555592</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7353435</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6685671</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6181279</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6806149</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6656015</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3460109</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5340659</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7193460</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.7179634</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6031211</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6289264</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.5842802</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.6656015</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td><td class="cl-63c8ffa8"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4337573</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3509572</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4607547</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4412576</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4188983</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4805833</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3392104</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.3460109</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">0.4337573</span></p></td><td class="cl-63c8ffa9"><p class="cl-63c8ec02"><span class="cl-63c5d238">1.0000000</span></p></td></tr></tbody></table></div>
<p>The correlation matrix shows that all variables are positively
correlated which explains why all variables cluster together. The low
correlations between the other variables and <em>Mitosis</em> explain
why it stands out.</p>
</div>
</div>
<div id="multidimensional-scaling" class="section level1 unnumbered">
<h1 class="unnumbered">Multidimensional Scaling</h1>
<p>Multidimensional Scaling (MDS, see <span class="citation">Davison (<a
href="#ref-davison1983introduction">1983</a>)</span> or <span
class="citation">Jacoby and Ciuk (<a
href="#ref-jacoby2018multidimensional">2018</a>)</span>) is used for
visualizing high-dimensional data in a lower-dimensional space
<strong>while preserving pairwise distances</strong> or similarities
between data points. MDS aims to represent the data in a way that
maintains the relationships among data points as much as possible.</p>
<p>There are two types of MDS:</p>
<ul>
<li><p><strong>metric or classical MDS</strong>: metric MDS aims to
represent the distances between objects in a way that preserves the
original dissimilarity/similarity relationships as accurately as
possible. It assumes that the input data reflects actual distances or
dissimilarities and it uses algorithms such as <em>Principal Coordinate
Analysis</em> (PCoA) to transform the data into a lower-dimensional
space while trying to maintain the original pairwise distances.</p></li>
<li><p><strong>non-metric MDS</strong>: non-metric MDS aims to represent
the rank order of the distances or dissimilarities between objects,
rather than the actual distances. It is more suitable when the input
data does not have a direct metric interpretation or when the distances
are only known in terms of ordinal rankings.</p></li>
</ul>
<p>MDS works exactly like PCA with one important difference:
<strong>while PCA starts off with correlations between variables (the
covariance matrix), MDS start of with distances (and thus relies on a
distance matrix)!</strong></p>
<div id="example-1-1" class="section level3 unnumbered">
<h3 class="unnumbered">Example 1</h3>
<p>We begin by loading data. This fictitious data set represents
responses to 15 items by 20 participants. The 15 items aim to assess 3
different psychological constructs:</p>
<ul>
<li><p>outgoingness (extroversion)</p></li>
<li><p>intelligence</p></li>
<li><p>attitude</p></li>
</ul>
<pre class="r"><code>surveydata &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/sud.rda&quot;, &quot;rb&quot;))
# inspect
report(surveydata)</code></pre>
<pre><code>## The data contains 20 observations of the following 16 variables:
## 
##   - Respondent: 20 entries, such as Respondent_01 (n = 1); Respondent_02 (n = 1);
## Respondent_03 (n = 1) and 17 others (0 missing)
##   - Q01_Outgoing: n = 20, Mean = 3.15, SD = 1.53, Median = 3.50, MAD = 2.22,
## range: [1, 5], Skewness = -0.18, Kurtosis = -1.52, 0 missing
##   - Q02_Outgoing: n = 20, Mean = 3.25, SD = 1.59, Median = 3.50, MAD = 2.22,
## range: [1, 5], Skewness = -0.10, Kurtosis = -1.73, 0 missing
##   - Q03_Outgoing: n = 20, Mean = 3.15, SD = 1.50, Median = 3.50, MAD = 2.22,
## range: [1, 5], Skewness = -0.07, Kurtosis = -1.58, 0 missing
##   - Q04_Outgoing: n = 20, Mean = 3.00, SD = 1.56, Median = 3.50, MAD = 2.22,
## range: [1, 5], Skewness = -0.09, Kurtosis = -1.64, 0 missing
##   - Q05_Outgoing: n = 20, Mean = 3.20, SD = 1.58, Median = 3.50, MAD = 2.22,
## range: [1, 5], Skewness = -0.19, Kurtosis = -1.59, 0 missing
##   - Q06_Intelligence: n = 20, Mean = 2.90, SD = 1.45, Median = 2.00, MAD = 1.48,
## range: [1, 5], Skewness = 0.31, Kurtosis = -1.43, 0 missing
##   - Q07_Intelligence: n = 20, Mean = 3.05, SD = 1.39, Median = 3.00, MAD = 1.48,
## range: [1, 5], Skewness = 0.03, Kurtosis = -1.24, 0 missing
##   - Q08_Intelligence: n = 20, Mean = 2.95, SD = 1.54, Median = 2.50, MAD = 2.22,
## range: [1, 5], Skewness = 0.19, Kurtosis = -1.54, 0 missing
##   - Q09_Intelligence: n = 20, Mean = 2.80, SD = 1.51, Median = 2.00, MAD = 1.48,
## range: [1, 5], Skewness = 0.38, Kurtosis = -1.48, 0 missing
##   - Q10_Intelligence: n = 20, Mean = 3.60, SD = 1.50, Median = 4.00, MAD = 1.48,
## range: [1, 5], Skewness = -0.58, Kurtosis = -1.33, 0 missing
##   - Q11_Attitude: n = 20, Mean = 2.75, SD = 1.62, Median = 2.50, MAD = 2.22,
## range: [1, 5], Skewness = 0.20, Kurtosis = -1.65, 0 missing
##   - Q12_Attitude: n = 20, Mean = 2.95, SD = 1.43, Median = 2.50, MAD = 2.22,
## range: [1, 5], Skewness = 0.22, Kurtosis = -1.40, 0 missing
##   - Q13_Attitude: n = 20, Mean = 2.75, SD = 1.65, Median = 2.00, MAD = 1.48,
## range: [1, 5], Skewness = 0.21, Kurtosis = -1.77, 0 missing
##   - Q14_Attitude: n = 20, Mean = 2.95, SD = 1.54, Median = 2.50, MAD = 2.22,
## range: [1, 5], Skewness = 0.19, Kurtosis = -1.54, 0 missing
##   - Q15_Attitude: n = 20, Mean = 2.95, SD = 1.70, Median = 2.50, MAD = 2.22,
## range: [1, 5], Skewness = 0.09, Kurtosis = -1.82, 0 missing</code></pre>
<p>As MDS, like PCA and FA, works only on numeric data, we remove
non-numeric variables from the data.</p>
<pre class="r"><code>surveydata &lt;- surveydata %&gt;% 
  dplyr::select(-Respondent)
# inspect
str(surveydata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    20 obs. of  15 variables:
##  $ Q01_Outgoing    : int  4 5 5 5 4 5 4 4 5 4 ...
##  $ Q02_Outgoing    : int  5 4 4 5 5 5 5 4 5 5 ...
##  $ Q03_Outgoing    : int  4 5 4 5 4 5 4 5 4 5 ...
##  $ Q04_Outgoing    : int  4 4 5 4 5 5 5 4 4 4 ...
##  $ Q05_Outgoing    : int  5 4 5 5 5 4 5 5 4 4 ...
##  $ Q06_Intelligence: int  2 2 2 1 2 5 4 5 5 4 ...
##  $ Q07_Intelligence: int  3 2 1 1 2 4 5 4 5 4 ...
##  $ Q08_Intelligence: int  3 2 1 1 1 5 4 5 4 5 ...
##  $ Q09_Intelligence: int  2 1 2 1 2 2 4 4 4 4 ...
##  $ Q10_Intelligence: int  2 2 2 1 1 2 5 5 5 5 ...
##  $ Q11_Attitude    : int  3 4 5 5 4 1 2 1 1 2 ...
##  $ Q12_Attitude    : int  3 4 4 4 5 2 1 2 2 1 ...
##  $ Q13_Attitude    : int  2 4 4 5 4 1 1 1 2 2 ...
##  $ Q14_Attitude    : int  3 5 4 5 5 2 2 1 1 2 ...
##  $ Q15_Attitude    : int  3 4 4 5 5 1 1 2 2 1 ...</code></pre>
<p>For MDS, we first calculate the distance matrix using the Euclidian
distance. Note that we are transposing, scaling and centering the data
just like for PCA.</p>
<pre class="r"><code>survey_dist &lt;- dist(scale(t(surveydata), center=TRUE, scale=TRUE),
  method=&quot;euclidean&quot;)</code></pre>
<p>Now, we generate an MDS object (this is basically eigenvalue
decomposition)</p>
<pre class="r"><code>mds.obj &lt;- cmdscale(survey_dist, 
                    eig=TRUE,   # adds a matrix of eignevalues to the mds object
                    x.ret=TRUE) # adds a symmetric distance matrix to the mds object</code></pre>
<p>Now, we calculate the percentage of variation that each MDS axis
accounts for…</p>
<pre class="r"><code>mds.var.per &lt;- round(mds.obj$eig/sum(mds.obj$eig)*100, 1)
# inspect
mds.var.per</code></pre>
<pre><code>##  [1] 54.8 29.0  4.8  2.7  2.1  1.7  1.5  1.0  0.9  0.6  0.4  0.3  0.1  0.0  0.0</code></pre>
<p>We make a fancy looking plot that shows the MDS axes and the
variation:</p>
<pre class="r"><code>mds.values &lt;- mds.obj$points
mds.data &lt;- data.frame(Sample=rownames(mds.values),
  X=mds.values[,1],
  Y=mds.values[,2])
# inspect
mds.data</code></pre>
<pre><code>##                            Sample          X          Y
## Q01_Outgoing         Q01_Outgoing  1.2441258 -2.9521948
## Q02_Outgoing         Q02_Outgoing  1.3832771 -3.2215742
## Q03_Outgoing         Q03_Outgoing  0.8464687 -2.8364303
## Q04_Outgoing         Q04_Outgoing  0.6884322 -3.1352690
## Q05_Outgoing         Q05_Outgoing  0.3742058 -3.2123840
## Q06_Intelligence Q06_Intelligence  3.7001253  1.1236968
## Q07_Intelligence Q07_Intelligence  3.4292730  1.8623706
## Q08_Intelligence Q08_Intelligence  4.0132660  1.5106590
## Q09_Intelligence Q09_Intelligence  3.8680562  2.5632774
## Q10_Intelligence Q10_Intelligence  1.5665476  3.9359300
## Q11_Attitude         Q11_Attitude -4.4171807  0.6011738
## Q12_Attitude         Q12_Attitude -3.8486419  1.2134235
## Q13_Attitude         Q13_Attitude -4.6650593  1.4927673
## Q14_Attitude         Q14_Attitude -3.8067797  0.1881540
## Q15_Attitude         Q15_Attitude -4.3761161  0.8663999</code></pre>
<pre class="r"><code>ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
  geom_text() +
  theme_bw() +
  xlab(paste(&quot;MDS1 - &quot;, mds.var.per[1], &quot;%&quot;, sep=&quot;&quot;)) +
  ylab(paste(&quot;MDS2 - &quot;, mds.var.per[2], &quot;%&quot;, sep=&quot;&quot;)) +
  ggtitle(&quot;MDS plot using Euclidean distance&quot;) +
  coord_cartesian(xlim = c(-7, 7), ylim = c(-4, 4))</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>The plot shows that we are dealing with 3 groups that are neatly
separated along 2 dimensions. We also see that Q10 behaves different
from the other items aiming to assess IQ. We could use this to optimize
the item set of our survey.</p>
</div>
</div>
<div id="factor-analysis" class="section level1 unnumbered">
<h1 class="unnumbered">Factor Analysis</h1>
<p>Factor Analysis is used to identify underlying latent factors that
explain the observed correlations among variables in a data set <span
class="citation">(<a href="#ref-kim1978introduction">Kim and Mueller
1978</a>; <a href="#ref-field2012discovering">Field, Miles, and Field
2012, 749–811</a>)</span>. It aims to reduce the complexity of
high-dimensional data by identifying a smaller number of factors (latent
variables) that contribute to the variance and covariance among
(observed) variables. Ideally those observed variables that represent an
underlying factor should be highly correlated with each other but not
correlated with (observed) variables that represent other factors
(underlying variables). Like PCA and MDS, we find factors by aiming to
reduce variability in the data but unlike PCA, which is based on a
co-variance matrix, or MDS, which is based on a distance matrix, EFA is
based on a correlation matrix.</p>
<p>There are two types of factor analysis:</p>
<ul>
<li><p>exploratory factor analysis (EFA)</p></li>
<li><p>confirmatory factor analysis (CFA)</p></li>
</ul>
<p>Here, we are only going to look at EFA which is used to identify how
many latent variables (factors) are present in a data set. In contrast
to CFA, EFA allows factors to be correlated with each other and it uses
a rotation step to transform the initial factor structure into a more
interpretable form. The rotation aims to maximize the loadings of
variables on only a single factor and it thereby maximizes the
separation between factors. Common rotation methods include
<em>Varimax</em>, <em>Oblimin</em>, and <em>Promax</em>. The
<em>Varimax</em> rotation is an orthogonal rotation and it is the most
common rotation method. It assumes that the factors are not correlated;
another type of rotation are <em>oblique</em> rotations, such as
<em>Oblimin</em> and <em>Promax</em>, which do not assume that the
factors are not correlated <span class="citation">(<a
href="#ref-field2012discovering">Field, Miles, and Field 2012,
755</a>)</span>.</p>
<p>CFA is used for hypothesis testing to confirm structures assumed to
be present in the data. In R, we can use the <code>sem</code> or
<code>lavaan</code> packages that implement Structural Equation Models
(SEM)) to implement CFA and test specific hypothesis about the existence
and interactions of latent factors.</p>
<div id="example-1-2" class="section level3 unnumbered">
<h3 class="unnumbered">Example 1</h3>
<p>We continue with the survey data set and we can now implement the EFA
using the <code>factanal</code> function from the base
<code>stats</code> package. Although <code>factanal</code> implements a
EFA, we need to provide it with the number of factors (latent variables)
it should look for (commonly, you need to vary this to find the optimal
number of factors).</p>
<p>As a first step, we generate a scree plot to assess how many factors
are in our data. There are different approaches to interpret the output:
(a) we choose the number of factors where there is a noticeable bend in
the eigenvalues of the factors or, if there is no noticeable bend (the
so-called <em>point of inflexion</em> <span class="citation">(<a
href="#ref-field2012discovering">Field, Miles, and Field 2012,
763</a>)</span>), (b) select the last value above 1 (following <span
class="citation">Kaiser (<a
href="#ref-kaiser1960application">1960</a>)</span> - however, <span
class="citation">Jolliffe (<a
href="#ref-jolliffe1987rotation">1987</a>)</span> suggests using .7 as 1
is too strict) <span class="citation">(see <a
href="#ref-field2012discovering">Field, Miles, and Field 2012, 763</a>
for more details on this discussion)</span>. Alternatively, we perform
the analysis with different numbers of factors and then check if the
<code>SS loadings</code> (the sum-of-squared loadings) of each factor
has a value greater than 1.</p>
<pre class="r"><code># extract eigenvalues
eigenvalues &lt;- eigen(cor(surveydata))
# inspect
#eigenvalues

# create scree plot
eigenvalues$values %&gt;%
  as.data.frame() %&gt;%
  dplyr::rename(Eigenvalues = 1) %&gt;%
  dplyr::mutate(Factors = 1:nrow(.)) %&gt;%
  ggplot(aes(x = Factors, y = Eigenvalues, label = round(Eigenvalues, 2))) +
  geom_bar(stat = &quot;identity&quot;, fill = &quot;lightgray&quot;) +
  geom_line(color = &quot;red&quot;, size = 1) +
  geom_point() +
  geom_text(vjust = -1.2) +
  geom_hline(yintercept = 1, color = &quot;blue&quot;, linetype = &quot;dotted&quot;) +
  theme_bw() +
  coord_cartesian(ylim = c(0, 10)) +
  ggtitle(&quot;Scree plot&quot;)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>As there is a noticeable bend in the Eigenvalues of the factors at 3
factors, we are justified by assuming that there are 3 factors (latent
or hidden variables) in our data. We can now perform the factor analysis
and set the number of expected factors to 3.</p>
<pre class="r"><code>factoranalysis &lt;- factanal(surveydata, # data
                           3) # number of factors
print(factoranalysis, 
      digits = 2,  # round to x decimals
      cutoff = .2, # do not show loadings smaller than .2
      sort = TRUE) # show items sorted</code></pre>
<pre><code>## 
## Call:
## factanal(x = surveydata, factors = 3)
## 
## Uniquenesses:
##     Q01_Outgoing     Q02_Outgoing     Q03_Outgoing     Q04_Outgoing 
##             0.09             0.06             0.12             0.07 
##     Q05_Outgoing Q06_Intelligence Q07_Intelligence Q08_Intelligence 
##             0.14             0.10             0.13             0.10 
## Q09_Intelligence Q10_Intelligence     Q11_Attitude     Q12_Attitude 
##             0.28             0.41             0.08             0.14 
##     Q13_Attitude     Q14_Attitude     Q15_Attitude 
##             0.04             0.09             0.06 
## 
## Loadings:
##                  Factor1 Factor2 Factor3
## Q06_Intelligence -0.82    0.25    0.41  
## Q07_Intelligence -0.80            0.47  
## Q08_Intelligence -0.85            0.42  
## Q09_Intelligence -0.79            0.29  
## Q11_Attitude      0.96                  
## Q12_Attitude      0.92                  
## Q13_Attitude      0.97                  
## Q14_Attitude      0.95                  
## Q15_Attitude      0.96                  
## Q01_Outgoing              0.94          
## Q02_Outgoing              0.96          
## Q03_Outgoing              0.93          
## Q04_Outgoing              0.96          
## Q05_Outgoing              0.92          
## Q10_Intelligence -0.22   -0.46    0.57  
## 
##                Factor1 Factor2 Factor3
## SS loadings       7.29    4.78    1.02
## Proportion Var    0.49    0.32    0.07
## Cumulative Var    0.49    0.80    0.87
## 
## Test of the hypothesis that 3 factors are sufficient.
## The chi square statistic is 62.79 on 63 degrees of freedom.
## The p-value is 0.484</code></pre>
<p>Let us examine the output.</p>
<p>We start with the <em>function call</em>, followed by
<em>uniqueness</em> scores. Uniqueness refers to the portion of the
variance in an observed variable that is not explained by the underlying
factors extracted from the data. It represents the variability in a
variable that is unique to that variable and cannot be accounted for by
the common factors identified in the analysis (uniqueness is the
variance that is unique to that variable whereas commonness is the
variance it shares with other variables or factors) <span
class="citation">(see <a href="#ref-field2012discovering">Field, Miles,
and Field 2012, 759</a>)</span>. This means that items that do not
capture or represent a latent variable well, will have high uniqueness
scores (see, e.g., <em>Q10_Intelligence</em>).</p>
<p>Next, the output shows a table with factor loadings.
<em>Loadings</em> are correlations between an observed variable and a
latent factor. Loadings indicate how strongly each observed variable is
associated with each extracted factor. They provide insights into which
factors influence the variation in each observed variable. Factor
loadings can be categorized as low (&lt;0.4), acceptable (0.4–0.6), or
high <span class="citation">(&gt;0.6 <a
href="#ref-stevens1992applied">Stevens 1992</a>; <a
href="#ref-tabachnick2007using">Tabachnick, Fidell, and Ullman 2007</a>;
<a href="#ref-kline2014easy">Kline 2014</a>)</span>. The fact that
Q10_Intelligence loads across factors shows that it does not represent
its intended factor (IQ) not very well.</p>
<p>We then get a table showing the sum-of-squares loadings with the
amount of variance explained by each latent variable which can help
identify the optimal or necessary number of latent variables (factors)
that we should or need to look for. As stated above, all factors should
have a value greater than 1 - if there is a value below 1 for the
<code>SS loadings</code>, then this could mean that at least one factor
could be removed.</p>
<p>The p-value should not be significant (if it is significant, then you
have missed factors). In our case, 2 factors would also report a non
significant result due to the low number of data points (but p is
highest for 3 factors). If this test is significant, then this suggests
that you may need more factors than you currently have in your PA (but
be careful: more factors can also lead to situations where you get
factors that are more difficult to interpret. So make sure that the
factors you include <em>make sense</em>).</p>
<p>We can now plot the results to see if and how the different items
group together. We start by created a data frame from the FA results
containing the information we need for the visualization.</p>
<pre class="r"><code>fadat &lt;- data.frame(Factor1 = factoranalysis$loadings[,1],
                    Factor2 = factoranalysis$loadings[,2],
                    Items = names(surveydata))
# inspect
head(fadat)</code></pre>
<pre><code>##                      Factor1   Factor2            Items
## Q01_Outgoing     -0.13793094 0.9411952     Q01_Outgoing
## Q02_Outgoing     -0.15957196 0.9560680     Q02_Outgoing
## Q03_Outgoing     -0.06826263 0.9334254     Q03_Outgoing
## Q04_Outgoing     -0.05828165 0.9619694     Q04_Outgoing
## Q05_Outgoing      0.07146568 0.9228791     Q05_Outgoing
## Q06_Intelligence -0.82137535 0.2535663 Q06_Intelligence</code></pre>
<p>Now, that the data is formatted appropriately, we can plot it.</p>
<pre class="r"><code>fadat %&gt;%
  ggplot(aes(x = Factor1, y = Factor2, label = Items, color = Factor1)) +
  geom_text() + 
  theme_bw() +
  coord_cartesian(xlim = c(-1.5, 1.5), ylim = c(-1, 1.5)) +
  scale_color_viridis_b() +
  labs(x = &quot;Factor 1 (49 %)&quot;, y = &quot;Factor 2 (32 %)&quot;)</code></pre>
<p><img src="dimred_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>As we can see, there are 3 groups (factors) with
<em>Q10_Intelligence</em> not aligning well with the other elements in
that group. This could suggest that <em>Q10_Intelligence</em> is not an
optimal item / variable for reflecting (or capturing) the latent
intelligence factor.</p>
<p>That’s all folks!</p>
</div>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1 class="unnumbered">Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2023. <em>Introduction to Dimension Reduction
Methods with R</em>. The University of Queensland, Australia. School of
Languages and Culture. url: www.ladal.edu.au/dimred.html (Version
2023.09.09).</p>
<pre><code>@manual{schweinberger2023dimred,
  author = {Schweinberger, Martin},
  title = {Introduction to Dimension Reduction Methods with R},
  note = {www.ladal.edu.au/dimred.html},
    year = {2023},
  organization = {The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2023.09.09}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   
## [3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      
## [5] LC_TIME=English_Australia.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tufte_0.13       psych_2.3.6      report_0.5.7     factoextra_1.0.7
##  [5] ggplot2_3.4.2    MASS_7.3-60      tidyr_1.3.0      stringr_1.5.0   
##  [9] flextable_0.9.1  here_1.0.1       dplyr_1.1.2     
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-163            fontquiver_0.2.1        insight_0.19.2         
##  [4] rprojroot_2.0.3         tools_4.2.2             backports_1.4.1        
##  [7] bslib_0.4.2             utf8_1.2.3              R6_2.5.1               
## [10] colorspace_2.1-0        withr_2.5.0             tidyselect_1.2.0       
## [13] mnormt_2.1.1            curl_5.0.0              compiler_4.2.2         
## [16] textshaping_0.3.6       cli_3.6.1               xml2_1.3.4             
## [19] officer_0.6.2           fontBitstreamVera_0.1.1 labeling_0.4.2         
## [22] sass_0.4.6              scales_1.2.1            askpass_1.1            
## [25] systemfonts_1.0.4       digest_0.6.31           rmarkdown_2.21         
## [28] gfonts_0.2.0            pkgconfig_2.0.3         htmltools_0.5.5        
## [31] fastmap_1.1.1           highr_0.10              rlang_1.1.1            
## [34] rstudioapi_0.14         httpcode_0.3.0          shiny_1.7.4            
## [37] jquerylib_0.1.4         farver_2.1.1            generics_0.1.3         
## [40] jsonlite_1.8.4          zip_2.3.0               car_3.1-2              
## [43] magrittr_2.0.3          Rcpp_1.0.10             munsell_0.5.0          
## [46] fansi_1.0.4             abind_1.4-5             gdtools_0.3.3          
## [49] lifecycle_1.0.3         stringi_1.7.12          yaml_2.3.7             
## [52] carData_3.0-5           grid_4.2.2              parallel_4.2.2         
## [55] promises_1.2.0.1        ggrepel_0.9.3           crayon_1.5.2           
## [58] lattice_0.21-8          knitr_1.43              pillar_1.9.0           
## [61] ggpubr_0.6.0            uuid_1.1-0              ggsignif_0.6.4         
## [64] crul_1.4.0              glue_1.6.2              evaluate_0.21          
## [67] fontLiberation_0.1.0    data.table_1.14.8       vctrs_0.6.2            
## [70] httpuv_1.6.11           gtable_0.3.3            openssl_2.0.6          
## [73] purrr_1.0.1             datawizard_0.7.1        cachem_1.0.8           
## [76] xfun_0.39               mime_0.12               xtable_1.8-4           
## [79] broom_1.0.4             rstatix_0.7.2           later_1.3.1            
## [82] ragg_1.2.5              viridisLite_0.4.2       tibble_3.2.1           
## [85] ellipsis_0.3.2</code></pre>
<hr />
<p><a href="#introduction">Back to top</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-stackpca4" class="csl-entry">
Amoeba. 2022. <span>“Making Sense of Principal Component Analysis,
Eigenvectors &amp;Amp; Eigenvalues.”</span> Cross Validated. <a
href="https://stats.stackexchange.com/q/140579">https://stats.stackexchange.com/q/140579</a>.
</div>
<div id="ref-clark2011introduction" class="csl-entry">
Clark, Neil R, and Avi Ma’ayan. 2011. <span>“Introduction to Statistical
Methods to Analyze Large Data Sets: Principal Components
Analysis.”</span> <em>Science Signaling</em> 4 (190): tr3–3.
</div>
<div id="ref-davison1983introduction" class="csl-entry">
Davison, Mark L. 1983. <span>“Introduction to Multidimensional Scaling
and Its Applications.”</span> <em>Applied Psychological
Measurement</em>. Sage Publications Sage CA: Thousand Oaks, CA.
</div>
<div id="ref-field2012discovering" class="csl-entry">
Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering
Statistics Using r</em>. Sage.
</div>
<div id="ref-jacoby2018multidimensional" class="csl-entry">
Jacoby, William G, and David J Ciuk. 2018. <span>“Multidimensional
Scaling: An Introduction.”</span> <em>The Wiley Handbook of Psychometric
Testing: A Multidisciplinary Reference on Survey, Scale and Test
Development</em>, 375–412.
</div>
<div id="ref-jolliffe1987rotation" class="csl-entry">
Jolliffe, Ian T. 1987. <span>“Rotation of Principal Components: Some
Comments.”</span> <em>Journal of Climatology</em> 7 (5): 507–10.
</div>
<div id="ref-kaiser1960application" class="csl-entry">
Kaiser, Henry F. 1960. <span>“The Application of Electronic Computers to
Factor Analysis.”</span> <em>Educational and Psychological
Measurement</em> 20 (1): 141–51.
</div>
<div id="ref-kim1978introduction" class="csl-entry">
Kim, Jae-On, and Charles W Mueller. 1978. <em>Introduction to Factor
Analysis: What It Is and How to Do It</em>. 13. Sage.
</div>
<div id="ref-kline2014easy" class="csl-entry">
Kline, Paul. 2014. <em>An Easy Guide to Factor Analysis</em>. Routledge.
</div>
<div id="ref-stackpca3" class="csl-entry">
Starmer, Josh. 2018. <span>“StatQuest: Principal Component Analysis
(PCA), Step-by-Step.”</span> YouTube. <a
href="https://www.youtube.com/watch?v=FgakZw6K1QQ">https://www.youtube.com/watch?v=FgakZw6K1QQ</a>.
</div>
<div id="ref-stevens1992applied" class="csl-entry">
Stevens, James. 1992. <em>Applied Statistics for the Social
Sciences</em>. Hillsdale, New Jersey: Lawrence Erlbaum Associates.
</div>
<div id="ref-tabachnick2007using" class="csl-entry">
Tabachnick, Barbara G, Linda S Fidell, and Jodie B Ullman. 2007.
<em>Using Multivariate Statistics</em>. 5th ed. Boston: Pearson.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>If you want to render the R Notebook on your machine,
i.e. knitting the document to html or a pdf, you need to make sure that
you have R and RStudio installed and you also need to download the <a
href="https://slcladal.github.io/content/bibliography.bib"><strong>bibliography
file</strong></a> and store it in the same folder where you store the
Rmd file.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
