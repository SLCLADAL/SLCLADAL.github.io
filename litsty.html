<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />
<link rel="icon" 
      type="image/x-icon" 
      href="favicon.ico" />


<meta name="author" content="Dattatreya Majumdar and Martin Schweinberger" />

<meta name="date" content="2021-02-04" />

<title>Computational Literary Stylistics with R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>


<!-- added by SKC for LADAL Style -->
<link rel="stylesheet" href="styles.css">
</head>

<body>


<div class="container-fluid main-container">





<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li>
  <a href="news.html">NEWS</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="comp.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="repro.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="intror.html">Getting started</a>
    </li>
    <li>
      <a href="string.html">String Processing</a>
    </li>
    <li>
      <a href="regex.html">Regular Expressions</a>
    </li>
    <li>
      <a href="table.html">Handling tables in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="dviz.html">Data Visualization with R</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="dstats.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="tree.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="clust.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="lexsim.html">Introduction to Lexical Similarity</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="net.html">Network Analysis</a>
    </li>
    <li>
      <a href="coll.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="vc.html">Phonetics: Creating Vowel Charts with Praat and R</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Useful How-To Tutorials</li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
    <li>
      <a href="gutenberg.html">Downloading Texts from Project Gutenberg</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES &amp; CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Computational Literary Stylistics with R</h1>
<h4 class="author">Dattatreya Majumdar and Martin Schweinberger</h4>
<h4 class="date">2021-02-04</h4>

</div>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130562131-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130562131-1');
</script>

<p><img src="https://slcladal.github.io/images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>This tutorial focuses on <strong>computational literary stylistics</strong> (also digital literary stylistics) and shows how fictional texts can be analyzed by using computational means. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/litsty.Rmd">here</a>.</p>
<p>Computational literary stylistics refers to analyses of the language of literary texts by computational means using linguistic concepts and categories, with the goal of finding patters among the literary texts and explaining how literary meaning/s is/are created by specific language choices. Computational literary stylistics has been linked with distant reading which aims to find patterns in large amounts of literary data that would not be detectable by traditional close reading techniques.</p>
<p>While this tutorial builds on <span class="citation">Silge and Robinson (<a href="#ref-silge2017text" role="doc-biblioref">2017</a>)</span> (see <a href="https://www.tidytextmining.com/">here</a>), it substantially expands <span class="citation">Silge and Robinson (<a href="#ref-silge2017text" role="doc-biblioref">2017</a>)</span> in terms of the range of methods that are presented and the data sources that are used.</p>
<div id="preparation-and-session-set-up" class="section level2 unnumbered">
<h2>Preparation and session set up</h2>
<p>This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R <a href="https://slcladal.github.io/IntroR_workshop.html">here</a>. For this tutorials, we need to install certain <em>packages</em> from an R <em>library</em> so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)
# install libraries
install.packages(c(&quot;tidytext&quot;,&quot;janeaustenr&quot;,&quot;tidyverse&quot;, &quot;quanteda&quot;, &quot;forcats&quot;, &quot;gutenbergr&quot;))</code></pre>
<p>Once you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.</p>
</div>
</div>
<div id="getting-started" class="section level1 unnumbered">
<h1>Getting started</h1>
<p>For this tutorial we will use several packages that contain functions that are particularly useful for computational literary stylistics. We will start by loading the required packages.</p>
<pre class="r"><code>library(tidyverse)
library(janeaustenr)
library(tidytext)
library(forcats)
library(quanteda)
library(gutenbergr)</code></pre>
<p>After loading the packages, we will download data from the Project Gutenberg. For this tutorial, we will download William Shakespeare’s <em>Romeo and Juliet</em>, Charles Darwin’s <em>On the Origin of Species</em>, Edgar Allan Poe’s <em>The Raven</em>, Jane Austen’s <em>Pride and Prejudice</em>, Athur Conan Doyle’s <em>The Adventures of Sherlock Holmes</em>, and Mark Twain’s <em>The Adventures of Tom Sawyer</em> (to see how to download data from Project Gutenberg, check out this <a href="https://slcladal.github.io/gutenberg.html">tutorial</a>).</p>
<p>The code below downloads the data from a server that mirrors the content of Project Gutenberg (which is more stable than the Project itself).</p>
<pre class="r"><code>shakespeare &lt;- gutenberg_works(gutenberg_id == &quot;1513&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
darwin &lt;- gutenberg_works(gutenberg_id == &quot;1228&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
twain &lt;- gutenberg_works(gutenberg_id == &quot;74&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
poe &lt;- gutenberg_works(gutenberg_id == &quot;1065&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
austen &lt;- gutenberg_works(gutenberg_id == &quot;1342&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
doyle &lt;- gutenberg_works(gutenberg_id == &quot;1661&quot;) %&gt;%
  gutenberg_download(mirror = &quot;http://mirrors.xmission.com/gutenberg/&quot;)
# inspect data
head(shakespeare, 15)</code></pre>
<pre><code>## # A tibble: 15 x 2
##    gutenberg_id text                             
##           &lt;int&gt; &lt;chr&gt;                            
##  1         1513 &quot;THE TRAGEDY OF ROMEO AND JULIET&quot;
##  2         1513 &quot;&quot;                               
##  3         1513 &quot;&quot;                               
##  4         1513 &quot;&quot;                               
##  5         1513 &quot;by William Shakespeare&quot;         
##  6         1513 &quot;&quot;                               
##  7         1513 &quot;&quot;                               
##  8         1513 &quot;&quot;                               
##  9         1513 &quot;&quot;                               
## 10         1513 &quot;&quot;                               
## 11         1513 &quot;&quot;                               
## 12         1513 &quot;Contents&quot;                       
## 13         1513 &quot;&quot;                               
## 14         1513 &quot;THE PROLOGUE.&quot;                  
## 15         1513 &quot;&quot;</code></pre>
<p>We can now begin to load and n a next step process the data.</p>
</div>
<div id="extracting-words" class="section level1 unnumbered">
<h1>Extracting words</h1>
<p>The most basic but also most common task is to extract instances of individual words and seeing how they are used in context. This is also called <em>concordancing</em>. When extracting words, they are typically displayed in context which is why their display is called a <em>keyword in context concordance</em> or kwic, for short.</p>
<p>The code below extracts the word <em>pride</em> from the novel <em>Pride and Prejudice</em> and displays the resulting instances of this keyword in a kwic.</p>
<pre class="r"><code># extract text
austen_text &lt;- austen %&gt;%
  dplyr::summarise(text = paste0(text, collapse = &quot; &quot;)) %&gt;%
  stringr::str_squish()
# give text a name
names(austen_text)  &lt;- &quot;Pride &amp; Prejudice&quot;
# extract instances of pride
pride &lt;- quanteda::kwic(austen_text, &quot;pride&quot;) %&gt;%
  as.data.frame()
# inspect data
head(pride)</code></pre>
<pre><code>##             docname from   to                          pre keyword
## 1 Pride &amp; Prejudice   19   19            [ # 42671 ] cover   Pride
## 2 Pride &amp; Prejudice 6214 6214            he is eat up with   pride
## 3 Pride &amp; Prejudice 6320 6320                him . &quot; &quot; His   pride
## 4 Pride &amp; Prejudice 6335 6335       offend _me_ so much as   pride
## 5 Pride &amp; Prejudice 6407 6407 I could easily forgive _his_   pride
## 6 Pride &amp; Prejudice 6418 6418       mortified _mine_ . &quot; &quot;   Pride
##                           post pattern
## 1 and Prejudice By Jane Austen   pride
## 2             , and I dare say   pride
## 3          , &quot; said Miss Lucas   pride
## 4   often does , because there   pride
## 5              , if he had not   pride
## 6          , &quot; observed Mary ,   pride</code></pre>
<p>The kwic display could now be processed further or could be inspected to see how the keyword in question (<em>pride</em>) is used in this novel.</p>
<p>We can also inspect the use of phrases, for example <em>natural selection</em>, expand the context window size, and clean the output (as shown below).</p>
<pre class="r"><code># extract text
darwin_text &lt;- darwin %&gt;%
  dplyr::summarise(text = paste0(text, collapse = &quot; &quot;)) %&gt;%
  stringr::str_squish()
# generate kwics
ns &lt;- quanteda::kwic(darwin_text, phrase(&quot;natural selection&quot;), window = 10) %&gt;%
  as.data.frame() %&gt;%
  dplyr::select(-docname, -from, -to, -pattern)
# inspect data
head(ns)</code></pre>
<pre><code>##                                                                  pre
## 1                         TOC ) On the Origin of Species BY MEANS OF
## 2                          NATURE . 3 . STRUGGLE FOR EXISTENCE . 4 .
## 3                    . CHAPTER 3 . STRUGGLE FOR EXISTENCE . Bears on
## 4                  the most important of all relations . CHAPTER 4 .
## 5                 of all relations . CHAPTER 4 . NATURAL SELECTION .
## 6 of the same species . Circumstances favourable and unfavourable to
##             keyword
## 1 NATURAL SELECTION
## 2 NATURAL SELECTION
## 3 natural selection
## 4 NATURAL SELECTION
## 5 Natural Selection
## 6 Natural Selection
##                                                            post
## 1       , OR THE PRESERVATION OF FAVOURED RACES IN THE STRUGGLE
## 2                    . 5 . LAWS OF VARIATION . 6 . DIFFICULTIES
## 3                 . The term used in a wide sense . Geometrical
## 4 . Natural Selection : its power compared with man&#39;s selection
## 5         : its power compared with man&#39;s selection , its power
## 6  , namely , intercrossing , isolation , number of individuals</code></pre>
</div>
<div id="identifying-keywords" class="section level1 unnumbered">
<h1>Identifying Keywords</h1>
<p>Another common task in literary stylistics is to extract terms that are particularly characteristic of a given text. The problem underlying the identification of keywords is to figure out the importance of words in each document. We can assign weights to words that are more characteristic for a text if these terms are used more frequently than expected in a given text. We can then show terms ordered by their relative weight. Using the <code>bind_tf_idf()</code> function from the <em>tidytext</em> package, we can extract the <em>term frequency - inverse document frequency</em>, or tf-idf, scores which represent these relative weights and we can also report other parameters such as number of occurrences of that word, total number of words and term frequency.</p>
<p>Before we continue, we need to define certain terms of concepts that are related to literary stylistics and that we will use repeatedly in this tutorials and that we need to define so that the analysis shown below makes sense.</p>
<p><em>Term Frequency</em> is the measure of importance of a word in a document or how frequently it appears in that document. However there are some words such as <em>the</em>,<em>is</em>, <em>of</em>, etc. which appear frequently even though they might not be important. An approach of using a list of stop-words and removing them before analysis can be useful but in case of some documents these words might be highly relevant.</p>
<p>The <em>Inverse Document Frequency</em> decreases the weight for most used words and increases the weight for words that are not much used in a collection of documents. This together with the Term Frequency can be used to calculate a term’s <em>tf-idf</em> (the multiplication of both the terms) which adjusts the frequency of the term based on how rarely it is used. Mathematically <em>idf</em> can be expressed as follows:</p>
<p><span class="math display">\[\begin{equation}
  idf_{(term)}=  ln (\frac{n_{documents}}{n_{documents\; containing\; term}})
\end{equation}\]</span></p>
<p>Before we calculate the <em>tf-idf</em>, we will collapse all the books into a single data frame though.</p>
<pre class="r"><code>books &lt;- rbind(shakespeare, darwin, twain, poe, austen, doyle)
# add names to books 
books$book &lt;- c(
  rep(&quot;Shakespeare&quot;, nrow(shakespeare)),
  rep(&quot;Darwin&quot;, nrow(darwin)),
  rep(&quot;Twain&quot;, nrow(twain)),
  rep(&quot;Poe&quot;, nrow(poe)),
  rep(&quot;Austen&quot;, nrow(austen)),
  rep(&quot;Doyle&quot;, nrow(doyle))
)
# clean data
books &lt;- books %&gt;%
  dplyr::filter(text != &quot;&quot;) %&gt;%
  dplyr::mutate(book = factor(book)) %&gt;%
  dplyr::select(-gutenberg_id)
# inspect data
head(books)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   text                            book       
##   &lt;chr&gt;                           &lt;fct&gt;      
## 1 THE TRAGEDY OF ROMEO AND JULIET Shakespeare
## 2 by William Shakespeare          Shakespeare
## 3 Contents                        Shakespeare
## 4 THE PROLOGUE.                   Shakespeare
## 5 ACT I                           Shakespeare
## 6 Scene I. A public place.        Shakespeare</code></pre>
<p>Now, we continue by calculating the <em>tf-idf</em> for eahc term in each of the books.</p>
<pre class="r"><code>book_words &lt;- books %&gt;%
  tidytext::unnest_tokens(word, text) %&gt;%
  dplyr::count(book, word, sort = TRUE) %&gt;% 
  dplyr::group_by(book) %&gt;% 
  dplyr::mutate(total = sum(n))
book_tf_idf &lt;- book_words %&gt;%
  tidytext::bind_tf_idf(word, book, n)
# inspect data
book_tf_idf</code></pre>
<pre><code>## # A tibble: 33,833 x 7
## # Groups:   book [6]
##    book   word      n  total     tf   idf tf_idf
##    &lt;fct&gt;  &lt;chr&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 Darwin the   10303 157049 0.0656     0      0
##  2 Darwin of     7865 157049 0.0501     0      0
##  3 Doyle  the    5630 105426 0.0534     0      0
##  4 Darwin and    4444 157049 0.0283     0      0
##  5 Austen the    4331 122343 0.0354     0      0
##  6 Austen to     4162 122343 0.0340     0      0
##  7 Darwin in     4019 157049 0.0256     0      0
##  8 Twain  the    3792  72201 0.0525     0      0
##  9 Darwin to     3613 157049 0.0230     0      0
## 10 Austen of     3611 122343 0.0295     0      0
## # ... with 33,823 more rows</code></pre>
<p>From the above table it is evident that the extremely common words have a very low inverse document frequency and thus a low tf-idf score. The inverse document frequency will be a higher number for words that occur in fewer documents in the collection of novels.</p>
<pre class="r"><code>book_tf_idf %&gt;%
  dplyr::select(-total) %&gt;%
  dplyr::arrange(desc(tf_idf))</code></pre>
<pre><code>## # A tibble: 33,833 x 6
## # Groups:   book [6]
##    book        word          n      tf   idf  tf_idf
##    &lt;fct&gt;       &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 Shakespeare romeo       300 0.0115   1.79 0.0206 
##  2 Poe         nevermore    11 0.0100   1.79 0.0180 
##  3 Twain       tom         722 0.0100   1.79 0.0179 
##  4 Darwin      species    1546 0.00984  1.79 0.0176 
##  5 Poe         lenore        8 0.00730  1.79 0.0131 
##  6 Shakespeare juliet      178 0.00681  1.79 0.0122 
##  7 Poe         raven        11 0.0100   1.10 0.0110 
##  8 Shakespeare capulet     141 0.00540  1.79 0.00967
##  9 Austen      elizabeth   597 0.00488  1.79 0.00874
## 10 Doyle       holmes      462 0.00438  1.79 0.00785
## # ... with 33,823 more rows</code></pre>
<p>Next, we plot the 15 words with the highest tf-idf scores for each novel to show which words are particularly charateristic of each of the novels.</p>
<pre class="r"><code>book_tf_idf %&gt;%
  dplyr::group_by(book) %&gt;%
  slice_max(tf_idf, n = 15) %&gt;%
  dplyr::ungroup() %&gt;%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = &quot;free&quot;) +
  labs(x = &quot;tf-idf&quot;, y = NULL)</code></pre>
<div class="figure">
<img src="litsty_files/figure-html/high_tf_idfplot-1.png" alt="Highest tf-idf words in each of Jane Austen's Novels" width="576" />
<p class="caption">
Highest tf-idf words in each of Jane Austen’s Novels
</p>
</div>
<p>As you can see, the method has indeed extracted words (and by extension concepts) that are characteristic of the texts.</p>
</div>
<div id="extracting-structural-features" class="section level1 unnumbered">
<h1>Extracting Structural Features</h1>
<p>Extracting structural features of texts is a very common and has a wide range of applications such as determining if texts belong to the same genre or if texts represent a real language or a made up nonsensical language, for example.</p>
<div id="word-frequency-distributions" class="section level2 unnumbered">
<h2>Word-Frequency Distributions</h2>
<p>Word-frequency distributions can be used to determine if a text represents natural language (or a simple replacement cipher, for example) or if the text does not represent natural language (or a more complex cipher). In the following, we will check if the language used in texts we have downloaded from Project Gutenberg aligns with distributions that we would expect when dealing with natural language. In a first step, we determine both the term-frequency and the idf.</p>
<pre class="r"><code>book_words &lt;- books %&gt;%
  tidytext::unnest_tokens(word, text) %&gt;%
  dplyr::count(book, word, sort = TRUE)  %&gt;% 
  dplyr::group_by(book) %&gt;% 
  dplyr::mutate(total = sum(n))
# inspect data
head(book_words)</code></pre>
<pre><code>## # A tibble: 6 x 4
## # Groups:   book [3]
##   book   word      n  total
##   &lt;fct&gt;  &lt;chr&gt; &lt;int&gt;  &lt;int&gt;
## 1 Darwin the   10303 157049
## 2 Darwin of     7865 157049
## 3 Doyle  the    5630 105426
## 4 Darwin and    4444 157049
## 5 Austen the    4331 122343
## 6 Austen to     4162 122343</code></pre>
<p>From the above table it is evident that the usual suspects <em>the</em>, <em>and</em>, <em>to</em> and so-forth are leading in terms of their usage frequencies in the novels. Now let us look at the distribution of <em>n/total</em> for each term in each of the novels (which represents the normalized term frequency).</p>
<pre class="r"><code>ggplot(book_words, aes(n/total, fill = book)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.005) +
  facet_wrap(~book, ncol = 2, scales = &quot;free_y&quot;)</code></pre>
<div class="figure">
<img src="litsty_files/figure-html/tfplot-1.png" alt="Term frequency distributions" width="576" />
<p class="caption">
Term frequency distributions
</p>
</div>
<p>From the plots it is clear that we are dealing with a negative exponential distribution and that many words occur only rarely and that only few words occur frequently. In other words, only few words occur frequently while most words occur rarely. This relationship represents a distribution that is captured by <em>Zipf’s law</em>.</p>
</div>
<div id="zipfs-law" class="section level2 unnumbered">
<h2>Zipf’s Law</h2>
<p>Zipf’s Law represents an empirical power law or power function that was established in the 1930s. Zipf’s law is one of the most fundamental laws in linguistics <span class="citation">(see Zipf <a href="#ref-george1935zipf" role="doc-biblioref">1935</a>)</span> and it states that the frequency of a word is inversely proportional to its rank in a text or collection of texts.</p>
<p>Let</p>
<ul>
<li><p>N be the number of elements in a text (or collection of texts);</p></li>
<li><p>k be their rank;</p></li>
<li><p>s be the value of the exponent characterizing the distribution.</p></li>
</ul>
<p>Zipf’s law then predicts that out of a population of N elements, the normalized frequency of the element of rank k, f(k;s,N), is:</p>
<p><span class="math display">\[\begin{equation}
f(k;s,N)={\frac {1/k^{s}}{\sum \limits _{n=1}^{N}(1/n^{s})}} 
\end{equation}\]</span></p>
<p>In the code chunk below, we check if Zipf’s Law applies to the words that occur in texts that we have downloaded from Project Gutenberg.</p>
<pre class="r"><code>freq_by_rank &lt;- book_words %&gt;% 
  dplyr::group_by(book) %&gt;% 
  dplyr::mutate(rank = row_number(), 
         `term frequency` = n/total) %&gt;%
  dplyr::ungroup()
# inspect data
freq_by_rank</code></pre>
<pre><code>## # A tibble: 33,833 x 6
##    book   word      n  total  rank `term frequency`
##    &lt;fct&gt;  &lt;chr&gt; &lt;int&gt;  &lt;int&gt; &lt;int&gt;            &lt;dbl&gt;
##  1 Darwin the   10303 157049     1           0.0656
##  2 Darwin of     7865 157049     2           0.0501
##  3 Doyle  the    5630 105426     1           0.0534
##  4 Darwin and    4444 157049     3           0.0283
##  5 Austen the    4331 122343     1           0.0354
##  6 Austen to     4162 122343     2           0.0340
##  7 Darwin in     4019 157049     4           0.0256
##  8 Twain  the    3792  72201     1           0.0525
##  9 Darwin to     3613 157049     5           0.0230
## 10 Austen of     3611 122343     3           0.0295
## # ... with 33,823 more rows</code></pre>
<p>To get a better understanding of Zipf’s law, let us visualize the distribution by plotting on the logged rank of elements on the x-axis and logged frequency of the terms on the y-axis. If Zipf’s law holds, then we should see more or less straight lines that go from top left to bottom right.</p>
<pre class="r"><code>freq_by_rank %&gt;% 
  ggplot(aes(rank, `term frequency`, color = book)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()</code></pre>
<div class="figure">
<img src="litsty_files/figure-html/fr-1.png" alt="Zipf's law for a sample of literary texts" width="480" />
<p class="caption">
Zipf’s law for a sample of literary texts
</p>
</div>
<p>We can see that the plot has a negative slope which corroborates the inverse relationship of rank with respect to term frequency which shows that the words in the texts from Project Gutenberg follow Zipf’s law. This would ascertain that we are dealing with natural language and not a made up nonsense language or a complex cipher.</p>
</div>
<div id="lexical-diversity" class="section level2 unnumbered">
<h2>Lexical Diversity</h2>
<p>Lexical diversity is a complexity measure that provides information about the lexicon size of a text, i.e. how many different words occur in a text given the size of the text. The Type-Token-Ratio (TTR) provides information about the number of word tokens (individual instances of a word) divided by the number of different word types (word forms). Let’s briefly elaborate on that and look a bit more closely at the terms <em>types</em> and <em>tokens</em>. The sentence <em>The dog chased the cat</em> contains five tokens but only 4 types because <em>the</em> occurs twice. Now, a text that is 100 words long and consist of 50 distinct words would have a TTR of .5 (50/100) while a text that is 100 words long but consist of 80 distinct words would have a TTR of .8 (80/100). Thus, typically, higher values indicate higher lexical diversity and more complex texts or more advanced learners of a language commonly have higher TTRs compared to simpler texts or less advanced language learners.</p>
<p>As such, we can use lexical diversity measures to analyze the complexity of the language in which a text is written which can be used to inspect the advances a language learner makes when acquiring a language: initially, the learner will have high TTR as they do not have a large vocabulary. The TTRs will increase as lexicon of the learner grows.</p>
<p>In the following example, we calculate the TTRs for the literary texts we have downloaded from Project Gutenberg. Ina first step, we tokenize the texts, i.e. we split the texts into individual words (tokens).</p>
<pre class="r"><code>books_texts &lt;- books %&gt;%
  dplyr::group_by(book) %&gt;%
  dplyr::summarise(text = paste(text, collapse = &quot; &quot;))
texts &lt;- books_texts %&gt;%
  dplyr::pull(text)
names(texts) &lt;- books_texts %&gt;%
  dplyr::pull(book)
tokens_texts &lt;- texts %&gt;%
  quanteda::corpus() %&gt;%
  quanteda::tokens()
# inspect data
head(tokens_texts)</code></pre>
<pre><code>## Tokens consisting of 6 documents.
## Austen :
##  [1] &quot;THERE&quot;       &quot;IS&quot;          &quot;AN&quot;          &quot;ILLUSTRATED&quot; &quot;EDITION&quot;    
##  [6] &quot;OF&quot;          &quot;THIS&quot;        &quot;TITLE&quot;       &quot;WHICH&quot;       &quot;MAY&quot;        
## [11] &quot;VIEWED&quot;      &quot;AT&quot;         
## [ ... and 143,958 more ]
## 
## Darwin :
##  [1] &quot;Click&quot;       &quot;on&quot;          &quot;any&quot;         &quot;of&quot;          &quot;the&quot;        
##  [6] &quot;filenumbers&quot; &quot;below&quot;       &quot;to&quot;          &quot;quickly&quot;     &quot;view&quot;       
## [11] &quot;each&quot;        &quot;ebook&quot;      
## [ ... and 177,217 more ]
## 
## Doyle :
##  [1] &quot;THE&quot;        &quot;ADVENTURES&quot; &quot;OF&quot;         &quot;SHERLOCK&quot;   &quot;HOLMES&quot;    
##  [6] &quot;by&quot;         &quot;SIR&quot;        &quot;ARTHUR&quot;     &quot;CONAN&quot;      &quot;DOYLE&quot;     
## [11] &quot;I&quot;          &quot;.&quot;         
## [ ... and 126,069 more ]
## 
## Poe :
##  [1] &quot;The&quot;      &quot;Raven&quot;    &quot;by&quot;       &quot;Edgar&quot;    &quot;Allan&quot;    &quot;Poe&quot;     
##  [7] &quot;Once&quot;     &quot;upon&quot;     &quot;a&quot;        &quot;midnight&quot; &quot;dreary&quot;   &quot;,&quot;       
## [ ... and 1,346 more ]
## 
## Shakespeare :
##  [1] &quot;THE&quot;         &quot;TRAGEDY&quot;     &quot;OF&quot;          &quot;ROMEO&quot;       &quot;AND&quot;        
##  [6] &quot;JULIET&quot;      &quot;by&quot;          &quot;William&quot;     &quot;Shakespeare&quot; &quot;Contents&quot;   
## [11] &quot;THE&quot;         &quot;PROLOGUE&quot;   
## [ ... and 32,888 more ]
## 
## Twain :
##  [1] &quot;THE&quot;        &quot;ADVENTURES&quot; &quot;OF&quot;         &quot;TOM&quot;        &quot;SAWYER&quot;    
##  [6] &quot;By&quot;         &quot;Mark&quot;       &quot;Twain&quot;      &quot;(&quot;          &quot;Samuel&quot;    
## [11] &quot;Langhorne&quot;  &quot;Clemens&quot;   
## [ ... and 86,823 more ]</code></pre>
<p>Next, we calculate the TTR using the <code>textstat_lexdiv</code> function from the <code>quanteda</code> package and visualize the resulting TTRs for the literary texts thta we have downloaded from Project Gutenberg.</p>
<pre class="r"><code>dfm(tokens_texts) %&gt;%
  quanteda::textstat_lexdiv(measure = &quot;TTR&quot;) %&gt;%
  ggplot(aes(x = TTR, y = reorder(document, TTR))) + 
  geom_point() +
  xlab(&quot;Type-Token-Ratio (TTR)&quot;) +
  ylab(&quot;&quot;)</code></pre>
<p><img src="litsty_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can see that Darwin’s <em>On the Origin of Species</em> has the lowest lexical diversity while Edgar Allan Poe’s <em>The Raven</em> has the highest. This would suggest that the language in <em>The Raven</em> is more complex than the language of <em>On the Origin of Species</em>. However, this is too simplistic and shows that simple Type-Token Ratios are severely affected by text length (as well as orthographic errors) and should only be used to compare texts</p>
<ul>
<li>that are comparatively long (at least 200 words)</li>
<li>that are approximately of the same length</li>
<li>that were error corrected so that orthographic errors do not confound the ratios</li>
</ul>
<div id="average-sentence-length" class="section level3 unnumbered">
<h3>Average Sentence Length</h3>
<p>The average sentence length (ASL) is another measure of textual complexity with more sophisticated language use being associated with longer and more complex sentences. As such, we can use the ASL as an alternative measure of the linguistic complexity of a text or texts.</p>
<pre class="r"><code>library(lexRankr)
books_sentences &lt;- books %&gt;%
  dplyr::group_by(book) %&gt;%
  dplyr::summarise(text = paste(text, collapse = &quot; &quot;)) %&gt;%
  lexRankr::unnest_sentences(sentence, text)
# inspect data
head(books_sentences)</code></pre>
<pre><code>##     book sent_id
## 1 Austen       1
## 2 Austen       2
## 3 Austen       3
## 4 Austen       4
## 5 Austen       5
## 6 Austen       6
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                sentence
## 1 THERE IS AN ILLUSTRATED EDITION OF THIS TITLE WHICH MAY VIEWED AT EBOOK [# 42671 ] cover       Pride and Prejudice       By Jane Austen         CONTENTS          Chapter 1          Chapter 2          Chapter 3          Chapter 4          Chapter 5          Chapter 6          Chapter 7          Chapter 8          Chapter 9          Chapter 10          Chapter 11          Chapter 12          Chapter 13          Chapter 14          Chapter 15          Chapter 16          Chapter 17          Chapter 18          Chapter 19          Chapter 20          Chapter 21          Chapter 22          Chapter 23          Chapter 24          Chapter 25          Chapter 26          Chapter 27          Chapter 28          Chapter 29          Chapter 30          Chapter 31          Chapter 32          Chapter 33          Chapter 34          Chapter 35          Chapter 36          Chapter 37          Chapter 38          Chapter 39          Chapter 40          Chapter 41          Chapter 42          Chapter 43          Chapter 44          Chapter 45          Chapter 46          Chapter 47          Chapter 48          Chapter 49          Chapter 50          Chapter 51          Chapter 52          Chapter 53          Chapter 54          Chapter 55          Chapter 56          Chapter 57          Chapter 58          Chapter 59          Chapter 60          Chapter 61       Chapter 1       It is a truth universally acknowledged, that a single man in       possession of a good fortune, must be in want of a wife.
## 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             However little known the feelings or views of such a man may be       on his first entering a neighbourhood, this truth is so well       fixed in the minds of the surrounding families, that he is       considered the rightful property of some one or other of their       daughters.
## 3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            “My dear Mr. Bennet,” said his lady to him one day, “have you       heard that Netherfield Park is let at last?”       Mr. Bennet replied that he had not.
## 4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  “But it is,” returned she; “for Mrs.
## 5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Long has just been here, and       she told me all about it.”       Mr. Bennet made no answer.
## 6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         “Do you not want to know who has taken it?” cried his wife       impatiently.</code></pre>
<p>Let’s now visualize the results for potential differences or trends.</p>
<pre class="r"><code>books_sentences %&gt;%
  dplyr::mutate(sentlength = stringr::str_count(sentence, &#39;\\w+&#39;)) %&gt;%
  ggplot(aes(x = sentlength, y = reorder(book, sentlength, mean), group = book)) +
  stat_summary(fun = mean, geom = &quot;point&quot;)   +          
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  xlab(&quot;Average Sentence Length (ASL)&quot;) +
  ylab(&quot;&quot;)</code></pre>
<p><img src="litsty_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>We can see that that <em>The Raven</em> (which does not contain any punctuation) is (unsurprisingly) the text with the longest ASL while Shakespeare’s play <em>Romeo and Juliet</em> (which contains a lost of dialogues) is deemed the work with the shortest ASL. With the exception of Poe’s <em>The Raven</em>, the ALS results reflect text complexity with Darwin’s <em>On the Origin of Species</em> being more complex or written like than the other texts with <em>Romeo and Juliet</em> being the most similar to spoken dialogue.</p>
</div>
</div>
<div id="similarity-among-literary-texts" class="section level2 unnumbered">
<h2>Similarity among literary texts</h2>
<p>We will now explore how similar the language of literary works is. This approach can, of course, be extended to syntactic features or, for instance, to determine if certain texts belong to a certain literary genre or were written by a certain author. When extending this approach to syntactic features, one would naturally use features like the ALS, TTRs, or the frequency of adjectives as the basis for determining similarity. Regarding authorship, things like bigrams, spacing or punctuation methods would be relevant features.</p>
<p>To assess the similarity of literary works (based on the words that occur in the texts), we first create a feature list, i.e. a matrix with word frequencies. In teh present case, we remove stop words as well as symbols (it can be useful to retain thse but this is depends on the task at hand).</p>
<pre class="r"><code>feature_mat &lt;- books %&gt;%
  dplyr::group_by(book) %&gt;%
  dplyr::sample_n(100) %&gt;%
  dplyr::summarise(text = paste0(text, collapse = &quot; &quot;)) %&gt;%
  dplyr::ungroup() %&gt;%
  quanteda::corpus(text_field = &quot;text&quot;, docid_field = &quot;book&quot;) %&gt;%
  quanteda::dfm(remove_punct = TRUE, remove_symbols = TRUE) %&gt;% 
  quanteda::dfm_remove(pattern = stopwords(&quot;en&quot;))
# inspect data
feature_mat[1:6, 1:6]</code></pre>
<pre><code>## Document-feature matrix of: 6 documents, 6 features (63.9% sparse).
##              features
## docs          ah said mrs bennet shaking head
##   Austen       1    5   3      4       1    1
##   Darwin       0    0   0      0       0    0
##   Doyle        1    6   0      0       0    0
##   Poe          1    6   0      0       0    1
##   Shakespeare  0    0   0      0       0    0
##   Twain        0    5   2      0       0    0</code></pre>
<p>We see that the texts are represented as the row names and the terms the column names. The content of the matrix consists of the term frequencies.</p>
<p>We can now perform agglomerative hierarchical clustering and visualize the results in a dendrogram to assess the similarity of texts.</p>
<pre class="r"><code>books_dist &lt;- as.dist(textstat_dist(feature_mat))
books_clust &lt;- hclust(books_dist)
plot(books_clust)</code></pre>
<p><img src="litsty_files/figure-html/sim03-1.png" width="672" /></p>
<p>According to the dendrogram, Conan Doyle’s <em>The Adventures of Sherlock Holmes</em> and Shakespeare’s <em>Romeo and Juliet</em> are the most similar texts. Edgar Allen Poe’s <em>The Raven</em> is the most idiosyncratic texts as it is on a branch by its own and is amalgamated with the other texts only as a very last step at the root of the tree.</p>
</div>
<div id="networks-of-personas" class="section level2 unnumbered">
<h2>Networks of Personas</h2>
<p>A final procedure we will perform is a network analysis of the personas in Shakespeare’s <em>Romeo and Juliet</em>. We directly load a co-occurrence matrix which provides information about how often character’s in that play have been in the same scene (as the extraction of this information is a bit cumbersome, I have done that for you and you can simply load the matrix into R).</p>
<pre class="r"><code># load data
romeo &lt;- read.delim(&quot;https://slcladal.github.io/data/romeo.txt&quot;, sep = &quot;\t&quot;)
# convert into feature co-occurrence matrix
romeo_fcm &lt;- as.fcm(as.matrix(romeo))
# inspect data
romeo_fcm</code></pre>
<pre><code>## Feature co-occurrence matrix of: 23 by 23 features.
##                features
## features        Abraham Benvolio LordCapulet Gregory LadyCapulet LadyMontague
##   Abraham             1        1           1       1           1            1
##   Benvolio            1        7           3       1           2            1
##   LordCapulet         1        3           9       1           7            1
##   Gregory             1        1           1       1           1            1
##   LadyCapulet         1        2           7       1          10            1
##   LadyMontague        1        1           1       1           1            1
##   LordMontague        1        2           2       1           3            1
##   PrinceEscalus       1        2           2       1           3            1
##   Romeo               1        7           5       1           4            1
##   Sampson             1        1           1       1           1            1
##                features
## features        LordMontague PrinceEscalus Romeo Sampson
##   Abraham                  1             1     1       1
##   Benvolio                 2             2     7       1
##   LordCapulet              2             2     5       1
##   Gregory                  1             1     1       1
##   LadyCapulet              3             3     4       1
##   LadyMontague             1             1     1       1
##   LordMontague             3             3     3       1
##   PrinceEscalus            3             3     3       1
##   Romeo                    3             3    14       1
##   Sampson                  1             1     1       1
## [ reached max_feat ... 13 more features, reached max_nfeat ... 13 more features ]</code></pre>
<p>As the <code>quanteda</code> package has a very neat and easy to use function (<code>textplot_network</code>) for generating network graphs, we make use this function and can directly generate the network.</p>
<pre class="r"><code>textplot_network(romeo_fcm, min_freq = 0.1, edge_alpha = 0.1, edge_size = 5)</code></pre>
<p><img src="litsty_files/figure-html/net_05-1.png" width="672" /></p>
<p>The thickness of the lines indicates how often characters have co-occurred. We could now generate different network graphs for the personas in different plays to see how these plays and personas differ or we could apply the network analysis to other types of information such as co-occurrences of words.</p>
<p>We have reached the end of this tutorial. Please feel free to explore more of our content at <a href="https://slcladal.github.io/index.html" class="uri">https://slcladal.github.io/index.html</a> - for computational literary stylistics, especially the tutorials on <a href="https://slcladal.github.io/tagging.html">part-of-speech tagging and syntactic parsing</a> as well as on <a href="https://slcladal.github.io/lex.html">lexicography with R</a> provide relevant additional information.</p>
</div>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Majumdar, Dattatreya and Martin Schweinberger. 2021. <em>Literary Stylistics with R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/litsty.html" class="uri">https://slcladal.github.io/litsty.html</a> (Version 2021.02.04).</p>
<pre><code>@manual{Majumdar2021ta,
  author = {Majumdar, Dattatreya and Martin Schweinberger},
  title = {Literary Stylistics with R},
  note = {https://slcladal.github.io/litsty.html},
  year = {2021},
  organization = &quot;The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2021.02.04}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.3 (2020-10-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19041)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] lexRankr_0.5.2    gutenbergr_0.2.0  quanteda_2.1.2    tidytext_0.2.6   
##  [5] janeaustenr_0.1.5 forcats_0.5.0     stringr_1.4.0     dplyr_1.0.2      
##  [9] purrr_0.3.4       readr_1.4.0       tidyr_1.1.2       tibble_3.0.4     
## [13] ggplot2_3.3.2     tidyverse_1.3.0  
## 
## loaded via a namespace (and not attached):
##  [1] fs_1.5.0             usethis_1.6.3        lubridate_1.7.9     
##  [4] RColorBrewer_1.1-2   httr_1.4.2           SnowballC_0.7.0     
##  [7] tools_4.0.3          backports_1.1.10     utf8_1.1.4          
## [10] R6_2.5.0             rpart_4.1-15         Hmisc_4.4-1         
## [13] DBI_1.1.0            lazyeval_0.2.2       colorspace_1.4-1    
## [16] nnet_7.3-14          withr_2.3.0          tidyselect_1.1.0    
## [19] gridExtra_2.3        proxyC_0.1.5         compiler_4.0.3      
## [22] cli_2.1.0            rvest_0.3.6          htmlTable_2.1.0     
## [25] network_1.16.1       xml2_1.3.2           labeling_0.4.2      
## [28] checkmate_2.0.0      scales_1.1.1         digest_0.6.27       
## [31] foreign_0.8-80       rmarkdown_2.5        base64enc_0.1-3     
## [34] jpeg_0.1-8.1         pkgconfig_2.0.3      htmltools_0.5.0     
## [37] dbplyr_2.0.0         highr_0.8            htmlwidgets_1.5.2   
## [40] rlang_0.4.8          readxl_1.3.1         rstudioapi_0.11     
## [43] farver_2.0.3         generics_0.1.0       jsonlite_1.7.1      
## [46] statnet.common_4.4.1 tokenizers_0.2.1     magrittr_1.5        
## [49] Formula_1.2-4        Matrix_1.2-18        Rcpp_1.0.5          
## [52] munsell_0.5.0        fansi_0.4.1          lifecycle_0.2.0     
## [55] stringi_1.5.3        yaml_2.2.1           grid_4.0.3          
## [58] ggrepel_0.8.2        crayon_1.3.4         lattice_0.20-41     
## [61] haven_2.3.1          splines_4.0.3        hms_0.5.3           
## [64] sna_2.6              knitr_1.30           pillar_1.4.6        
## [67] stopwords_2.0        rle_0.9.2            fastmatch_1.1-0     
## [70] reprex_0.3.0         glue_1.4.2           evaluate_0.14       
## [73] latticeExtra_0.6-29  data.table_1.13.2    RcppParallel_5.0.2  
## [76] modelr_0.1.8         vctrs_0.3.4          png_0.1-7           
## [79] cellranger_1.1.0     gtable_0.3.0         assertthat_0.2.1    
## [82] xfun_0.19            broom_0.7.2          coda_0.19-4         
## [85] survival_3.2-7       cluster_2.1.0        ellipsis_0.3.1</code></pre>
<hr />
<p><a href="#introduction">Back to top</a></p>
<p><a href="https://slcladal.github.io/index.html">Back to HOME</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-silge2017text">
<p>Silge, Julia, and David Robinson. 2017. <em>Text Mining with R: A Tidy Approach</em>. " O’Reilly Media, Inc.".</p>
</div>
<div id="ref-george1935zipf">
<p>Zipf, K, George. 1935. <em>The Psychobiology of Language</em>. Houghton-Mifflin.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>
</html>
