---
title: "Corpus Linguistics with R: Swearing in Irish English"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
bibliography: bibliography.bib
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction{-}

This section presents different case studies or use cases that highlight how the the content shown in the tutorials can be put into practice. The case studies thus merely exemplify ways in which R can be used in language-based research rather than providing models of how to do research. The R markdown document of this case study can be downloaded [here](https://slcladal.github.io/rscripts/corplingr.Rmd).

## Preparation and session set up{-}

This case study is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/IntroR_workshop.html). For this case study, we need to install certain *packages* from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).

```{r prep1, echo=T, eval = F, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options("scipen" = 100, "digits" = 4) # supress math annotation
# manual installation
install.packages("devtools")
# load devtools and install development version of data.table
library(devtools)
install_github("Rdatatable/data.table", build_vignettes = FALSE)
```

Once you have installed R-Studio and initiated the session by executing the code shown above, you are good to go.

# Getting started{-}

This case study aims to answer if swearing differs across age groups and genders, i.e. whether old or young or men or women swear more, in a small subsample of the Irish component of the [International Corpus of English (ICE)](https://www.ice-corpora.uzh.ch/en.html) using R. The case study represents a simplified version of the analysis of [paper](https://www.sciencedirect.com/science/article/pii/S0024384117304357) [@schweinberger2018swearing].

In a first step, we load the load the data into R. The way that the corpus data is loaded in this example is somewhat awkward because the data is in a server directory rather than on a hard drive on a simple PC. If the corpus data is not stored in a directory of a server, then you should not use the code shown immediately below but code in the window following the code immediately below.  

```{r sw0, eval = F, echo=F}
# load txt tidyr style
tbl <- list.files(pattern = "*.txt") %>% 
        map_chr(~ read_file(.)) %>% 
        data_frame(text = .)
```

```{r sw1, eval = T, echo=T}
# define path to corpus
corpuspath <- "https://slcladal.github.io/data/ICEIrelandSample/"
# define corpusfiles
files <- paste(corpuspath, "S1A-00", 1:20, ".txt", sep = "")
files <- gsub("[0-9]([0-9][0-9][0-9])", "\\1", files)
# load corpus files
corpus <- sapply(files, function(x){
  x <- readLines(x)
  x <- paste(x, collapse = " ")
  x <- tolower(x)
})
# inspect corpus
str(corpus)
```

If the corpus data is stored on your own computer (on not on a serves as is the case in the present example), you should use the following code (you need to adapt the path though as the code below only works on my computer):

```{r sw2, eval = F, echo=T}
# define path to corpus
# WARNING: you need to include your own path!
corpuspath <- "D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io\\data\\ICEIrelandSample"
# define corpusfiles
files <- list.paste(corpuspath, all.names = T)
# load corpus files
corpus <- sapply(files, function(x){
  x <- scan(x, what = "char", sep = "", quote = "", skipNul = T)
  x <- paste(x, sep = " ", collapse = " ")
  x <- tolower(x)
})
# inspect corpus
str(corpus)
```

Now that the corpus data is loaded, we can prepare the searches by defining the search patterns. We will use regular expressions to retrieve all variants of the swear words. The sequence `\\b` denotes word boundaries while the sequence `[a-z]{0,3}` means that the sequences *ass* can be followed by a string consisting of any character symbol that is maximally three characters long (so that the search would also retrieve *asses*). We separate the search patters by `|` as this means *or*.

```{r sw3, eval = T, echo=T, message=FALSE, warning=FALSE}
searchpatterns <- c("\\bass[ingedholes]{0,6}\\b|\\bbitch[a-z]{0,3}\\b|\\b[a-z]{0,}fuck[a-z]{0,3}\\b|\\bshit[a-z]{0,3}\\b|\\bcock[a-z]{0,3}\\b|\\bwanker[a-z]{0,3}\\b|\\bboll[io]{1,1}[a-z]{0,3}\\b|\\bcrap[a-z]{0,3}\\b|\\bbugger[a-z]{0,3}\\b|\\bcunt[a-z]{0,3}\\b")
```

After defining the search pattern(s), we extract the kwics (keyword(s) in context) of the swear words. 

```{r sw4, eval = T, echo=T, message=FALSE, warning=FALSE}
# activate package
library(quanteda)
# extarct kwic
kwicswears <- kwic(corpus, searchpatterns,window = 10, valuetype = "regex")
# inspect results
head(kwicswears)
```
We now clean the kwic so that it is easier to see the relevant information.

```{r sw5, eval = T, echo=T, message=FALSE, warning=FALSE}
kwicswearsdf <- as.data.frame(kwicswears)
colnames(kwicswearsdf) <- c("File", "StartPosition", "EndPosition", "PreviousContext", "Token", "FollowingContext", "SearchPattern")
library(dplyr)
library(stringr)
kwicswearsclean <- kwicswearsdf %>%
  select(-StartPosition, -EndPosition, -SearchPattern) %>%
  mutate(File = str_remove_all(File, ".*/"),
         File = str_remove_all(File, ".txt"))
# inspect results
head(kwicswearsclean)
```
We now create another kwic but with much more context because we want to extract the speaker that has uttered the swear word. To this end, we remove everything that proceeds the `$` symbol as the speakers are identified by characters that follow the `$` symbol, remove everything that follows the `>` symbol which end the speaker identification sequence, remove remaining white spaces, and convert the remaining character to upper case. 

```{r sw6, eval = T, echo=T, message=FALSE, warning=FALSE}
# extract kwic
kwiclong <- kwic(corpus, searchpatterns,window = 1000, valuetype = "regex")
kwiclong <- as.data.frame(kwiclong)
colnames(kwiclong) <- c("File", "StartPosition", "EndPosition", "PreviousContext", "Token", "FollowingContext", "SearchPattern")
kwiclong <- kwiclong %>%
  select(-StartPosition, -EndPosition, -SearchPattern) %>%
  mutate(File = str_remove_all(File, ".*/"),
         File = str_remove_all(File, ".txt"),
         Speaker = str_remove_all(PreviousContext, ".*\\$"),
         Speaker = str_remove_all(Speaker, ">.*"),
         Speaker = str_squish(Speaker),
         Speaker = toupper(Speaker)) %>%
  select(Speaker)
# inspect results
head(kwiclong)
```


We now add the Speaker to our initial kwic. This way, we combine the swear word kwic with the speaker and as we already have the file, we can use the file plus speaker idenification to check if the speaker was a man or a woman.

```{r sw7, eval = T, echo=T, message=FALSE, warning=FALSE}
swire <- cbind(kwicswearsclean, kwiclong)
# inspect data
head(swire)
```


Now, we inspect the extracted swear word tokens to check if our search strings have indeed captured swear words. 

```{r sw8, eval = T, echo=T, message=FALSE, warning=FALSE}
# convert tokens to lower case
swire$Token <- tolower(swire$Token)
# inspect tokens
table(swire$Token)
```
FUCK and its variants is by far the most common swear word in our corpus. However, we do not need the type of swear word to answer our research question and we thus summarize the table to show which speaker in which files has used how many swear words.

```{r sw9, eval = T, echo=T, message=FALSE, warning=FALSE}
swire <- swire %>%
  group_by(File, Speaker) %>%
  summarise(Swearwords = n())
# inspect data
head(swire)
```

Now that we extract how many swear words the speakers in the corpus have used, we can load the biodata of the speakers.

```{r sw10, eval = T, echo=T, message=FALSE, warning=FALSE}
# load bio data
bio <- read.table("https://slcladal.github.io/data/data01.txt", header = T, sep = "\t")
# oinspect data
head(bio)
```


```{r sw11, eval = T, echo=T, message=FALSE, warning=FALSE}
bio <- bio %>%
  rename(File = text.id, 
         Speaker = spk.ref,
         Gender = sex,
         Age = age,
         Words = word.count) %>%
  select(File, Speaker, Gender, Age, Words)
# inspect data
head(bio)
```

 In a next step, we combine the table with the speaker information with the table showing the swear word use.

```{r sw12, eval = T, echo=T, message=FALSE, warning=FALSE}
# combine frequencies and biodata
swire <- dplyr::left_join(bio, swire, by = c("File", "Speaker"))
# replave NA with 0
swire$Swearwords <- ifelse(is.na(swire$Swearwords), 0, swire$Swearwords)
# inspect data
head(swire)
```

We now clean the table by removing speakers for which we do not have any information on their age and gender. Also, we summarize the table to extract the mean frequencies of swear words (per 1,000 words) by age and gender.

```{r sw13, eval = T, echo=T, message=FALSE, warning=FALSE}
# clean data
swire <- swire %>%
  filter(is.na(Gender) == F,
         is.na(Age) == F) %>%
  group_by(Age, Gender) %>%
  summarise(SumWords = sum(Words),
         SumSwearwords = sum(Swearwords),
         FrequencySwearwords = round(SumSwearwords/SumWords*1000, 3)) 
# inspect data
head(swire)
```

The summary table shows that speakers between the gaes of 0 and 18 are so rare that we will exclude them from the analysis.

```{r sw14, eval = T, echo=T, message=FALSE, warning=FALSE}
swire <- swire %>%
  filter(Age != "0-18")
# inspect data
head(swire)
```


Now that we have prepared our data, we can plot swear word use by gender. 

```{r sw15, eval = T, echo=T, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(swire, aes(x = Age, y = FrequencySwearwords, group = Gender, color = Gender)) +
  geom_line() +
  theme_bw() +
  scale_color_manual(values = c("orange", "darkgrey"))
```

The graph suggests that the genders do not differ in their use of swear words except for the age bracket from 26 to 41: men swear more among speakers aged between 26 and 33 while women swear more between 34 and 41 years of age. 

We could now perform a statistical test, e.g. a (Hierarchical) Configural Frequency Analysis (HCFA) or a Linear Regression to check if age and gender correlate significantly with the frequency of swear word use but for this case study, the simple visualization shall suffice.

It has to be borne in mind, though, that this is merely a case study and that a more fine-grained analysis on a substantially larger data set were necessary to get a more reliable impression.

# Citation & Session Info {-}

Schweinberger, Martin. 2020. *Corpus Linguistics with R: Swearing in Irish English*. Brisbane: The University of Queensland. url: https://slcladal.github.io/corplingr.html (Version 2020.09.29).


```
@manual{schweinberger2020cl,
  author = {Schweinberger, Martin},
  title = {Corpus Linguistics with R: Swearing in Irish English},
  note = {https://slcladal.github.io/corplingr.html},
  year = {2020},
  organization = "The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/09/29}
}
```

```{r fin}
sessionInfo()
```

***

[Main page](https://slcladal.github.io/index.html)

***

# References {-}

