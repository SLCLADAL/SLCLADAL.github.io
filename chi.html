<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-01-21" />

<title>Basic Inferential Statistics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="hypotheses.html">Hypotheses</a>
    </li>
    <li>
      <a href="significance.html">Significance</a>
    </li>
    <li>
      <a href="errors.html">Errors</a>
    </li>
    <li>
      <a href="researchdesigns.html">Research Designs</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics</a>
    </li>
    <li>
      <a href="intror.html">Getting started with R</a>
    </li>
    <li>
      <a href="loading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="page-b.html">Web Crawling</a>
    </li>
    <li>
      <a href="tabulating.html">Tabulating data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization Techniques</a>
    </li>
    <li>
      <a href="advancedgraphs.html">Advanced Visualization Techniques</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptives.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="chi.html">Basic Interential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Advanced Interential Statistics</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis/Corpus Linguistics</li>
    <li>
      <a href="page-c.html">Network Analysis</a>
    </li>
    <li>
      <a href="page-c.html">Topic Modeling</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="page-c.html">Available Software</a>
    </li>
    <li>
      <a href="antconcexcel.html">Corpus Linguistics with AntConc, TextPad and Excel</a>
    </li>
    <li>
      <a href="page-c.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Basic Inferential Statistics</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-01-21</em></h4>

</div>


<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces basic statistical techniques from inferential statistics for hypothesis testing. The first part of this section focuses on basic non-parametric tests such as the chi-square family of tests while the second part introduces simple regression models and discusses their underlying logic.</p>
</div>
<div id="non-parateric-tests" class="section level1">
<h1><span class="header-section-number">2</span> Non-Parateric Tests</h1>
<p>This section focuses on test that do not require the data to be distributed normally. Tests that do not rewuire normal data are referred to as <em>non-parametric tests</em> (test that require the data to be distributed normally are analogously called <em>parametric tests</em>). We focus on non-parametric tests first as this family of test in frequently used in linguistics. In the later part of this section, we will focus on regression modelling where assumptions of about the data become more important.</p>
<div id="chi-square-tests" class="section level2">
<h2><span class="header-section-number">2.1</span> Chi-Square Tests</h2>
<p>To explore how chi-square (or chi-squared or simply <span class="math inline">\(\chi^{2}\)</span>) tests work, we will test whether speakers of American English (AmE) and speakers of British English (BrE) differ in their use of the near-synonyms <em>sort of</em> and <em>kind of</em> as in “<em>He’s sort of stupid</em>” and “<em>He’s kind of stupid</em>”. As a first step, we formulate the hypothesis that we want to test (H<span class="math inline">\(_{1}\)</span>) and its Nullhypothesis (H<span class="math inline">\(_{0}\)</span>). The Alternativ- or Testhypothesis reads:</p>
<p><span class="math inline">\(H_{1}\)</span>: Speakers of AmE and BrE differ with respect to their preference for <em>sort of</em> und <em>kind of</em>.</p>
<p>while the Nullhypothesis (H<span class="math inline">\(_{0}\)</span>) states</p>
<p><span class="math inline">\(H_{0}\)</span> Speakers of AmE and BrE do not differ with respect to their preference for <em>sort of</em> und <em>kind of</em>.</p>
<p>The H<span class="math inline">\(_{0}\)</span> claims the non-existence of something (which is the more conservative position) and in our example the non-existence of a correlation between variety of English and the use of <em>sort of</em> und <em>kind of</em>. The question now arises what has to be the case in order to reject the H<span class="math inline">\(_{0}\)</span> in favor of the H<span class="math inline">\(_{1}\)</span>.</p>
<p>To answer this question, we require information about the probability of error, i.e. the probability that the H<span class="math inline">\(_{0}\)</span> does indeed hold for the entire population. Before performing the chi-square test, we follow the convetion that the required significance level is 5 percent. In other words, we will reject the H<span class="math inline">\(_{0}\)</span> if the likelyhood for the H<span class="math inline">\(_{0}\)</span> being true is less than 5 percent given the distribution of the data. In that case, i.e. in case that the likelihood for the H<span class="math inline">\(_{0}\)</span> being true is less than 5 percent, we consider the result of the chi-square test as statistically significant. This means that the observed distribution makes it very unlikey that there is no correlation between the variety of English and the use of <em>sort of</em> and <em>kind of</em>.</p>
<p>Let us now assume that we have performed a search for <em>sort of</em> and <em>kind of</em> in two corpora representing American and British English and that we have obtained the following freqeuncies:</p>
<table>
<caption>Observed frequencies of <em>sort of</em> and <em>kind of</em> in American and British English</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">BrE</th>
<th align="right">AmE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>kindof</td>
<td align="right">181</td>
<td align="right">177</td>
</tr>
<tr class="even">
<td>sortof</td>
<td align="right">655</td>
<td align="right">67</td>
</tr>
</tbody>
</table>
<p>In a first step, we now have to caluculate the row and column sums of our table.</p>
<p>I had the same question. I have tried all solutions provided above and none of them worked… But I have found a solution that works for me, and hopefully for others too.</p>
<table>
<caption>Observed frequencies of <em>sort of</em> and <em>kind of</em> in American and British English with row and column totals</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">BrE</th>
<th align="right">AmE</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>kindof</td>
<td align="right">181</td>
<td align="right">655</td>
<td align="right">836</td>
</tr>
<tr class="even">
<td>sortof</td>
<td align="right">177</td>
<td align="right">67</td>
<td align="right">244</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right">358</td>
<td align="right">722</td>
<td align="right">1080</td>
</tr>
</tbody>
</table>
<p>Next, we calculate, the values that would have expected if there was no correlation between variety of English and the use of <em>sort of</em> and <em>kind of</em>. In order to get these “expected” freqeuncies, we apply the equation below to all cells in our table.</p>
<p><span class="math inline">\(\frac{Column total*Row total}{Overall total}\)</span></p>
<p>In our example this means that for the cell with [+]BrE [+]kindof we get:</p>
<p><span class="math inline">\(\frac{836*358}{1080} = \frac{299288}{1080} = 277.1185\)</span></p>
<p>For the entire table this means we get the following expected values:</p>
<table>
<caption>Expected frequencies of <em>sort of</em> and <em>kind of</em> in American and British English with row and column totals</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">BrE</th>
<th align="right">AmE</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>kindof</td>
<td align="right">277.11850</td>
<td align="right">558.8815</td>
<td align="right">836</td>
</tr>
<tr class="even">
<td>sortof</td>
<td align="right">80.88148</td>
<td align="right">163.1185</td>
<td align="right">244</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right">358.00000</td>
<td align="right">722.0000</td>
<td align="right">1080</td>
</tr>
</tbody>
</table>
<p>In a next step, we calculate the contribution of each cell to the overall <span class="math inline">\(\chi^{2}\)</span> value (<span class="math inline">\(\chi^{2}\)</span> contribution). To get <span class="math inline">\(\chi^{2}\)</span> contribution for each cell, we apply the equation below to each cell.</p>
<p><span class="math inline">\(\frac{(observed – expected)^{2}}{expected}\)</span></p>
<p>In our example this means that for the cell with [+]BrE [+]kindof we get:</p>
<p><span class="math inline">\(\frac{(181 – 277.1185)^{2}}{277.1185} = \frac{-96.1185^{2}}{277.1185} = \frac{9238.766}{277.1185} = 33.33868\)</span></p>
<p>For the entire table this means we get the following <span class="math inline">\(\chi^{2}\)</span> values:</p>
<table>
<caption>Chi values of <em>sort of</em> and <em>kind of</em> in American and British English with row and column totals</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">BrE</th>
<th align="right">AmE</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>kindof</td>
<td align="right">33.33869</td>
<td align="right">16.53082</td>
<td align="right">49.86951</td>
</tr>
<tr class="even">
<td>sortof</td>
<td align="right">114.22602</td>
<td align="right">56.63839</td>
<td align="right">170.86440</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right">147.56470</td>
<td align="right">73.16921</td>
<td align="right">220.73390</td>
</tr>
</tbody>
</table>
<p>The sum of <span class="math inline">\(\chi^{2}\)</span> contributions in our example is 220.7339. To see if this value is staistically significant, we need to calculate the degrees of freedom because the <span class="math inline">\(\chi\)</span> distribution differes across degrees of freedom. Degrees of freedom are calculated accroding to the equation below.</p>
<p><span class="math inline">\(DF = (rows -1) * (columns – 1) = (2-1) * (2-1) = 1 * 1 = 1\)</span></p>
<p>In a last step, we check whether the <span class="math inline">\(\chi^{2}\)</span> value that we have calculated is higher thana critical value (in which case the correlation in our table is significant). Degrees of freedom are relevcvenat here because the critical values is dependent upon the degrees of freedom: the more degrees of freedom, the higher the critical value, i.e. the harder it is to breach ethe level of significance.</p>
<p>Since theer is only 1 degree of freedom in our case, we need to consider only the first column in the table of critical values below.</p>
<table>
<caption>Critical chi values for 1 to 5 degrees of freedom</caption>
<thead>
<tr class="header">
<th align="right">DF</th>
<th align="right">p&lt;.05</th>
<th align="right">p&lt;.01</th>
<th align="right">p&lt;.001</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">3.84</td>
<td align="right">6.64</td>
<td align="right">10.83</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5.99</td>
<td align="right">9.21</td>
<td align="right">13.82</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">7.82</td>
<td align="right">11.35</td>
<td align="right">16.27</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">9.49</td>
<td align="right">13.28</td>
<td align="right">18.47</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">11.07</td>
<td align="right">15.09</td>
<td align="right">20.52</td>
</tr>
</tbody>
</table>
<p>Since the <span class="math inline">\(\chi^{2}\)</span> value that we have calculated is much higher than the critical value provided for p&lt;.05, we can reject the <span class="math inline">\(H_{0}\)</span> and may now claim that speakers of AmE and BrE differ with respect to their preference for <em>sort of</em> und <em>kind of</em>.</p>
<p>Before we summarize the results, we will calculate the effect size which is a measure for how strong the correleations are.</p>
<div id="effect-sizes-in-chi-square" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Effect Sizes in Chi-Square</h3>
<p>Effect sizes are important because they correlations may be highly significant but the effect between variables can be extremely weak. The effect size is therefore a measure how strong the correlation or the explanatory and predictive power between variables is.</p>
<p>The effect size measure for <span class="math inline">\(\chi^{2}\)</span> tests can be either the <span class="math inline">\(\phi\)</span>-coeffizient (phi-coeffizient) or Cramer’s <span class="math inline">\(\phi\)</span> (Cramer’s phi). The <span class="math inline">\(\phi\)</span>-coeffizient is used when dealing with 2x2 tables while Cramer’s <span class="math inline">\(\phi\)</span> is used when dealing with tables with more than 4 cells. The <span class="math inline">\(\phi\)</span> coeffizient can be calculated by using the equation below (N = overall sample size).</p>
<p><span class="math inline">\(\phi = \sqrt{\frac{\chi^{2}}{N}}\)</span></p>
<p>In our case, this means:</p>
<p><span class="math inline">\(\phi = \sqrt{\frac{220.7339}{1080}} = \sqrt{0.2043832} = 0.4520876\)</span></p>
<p>The <span class="math inline">\(\phi\)</span> coefficient varies between 0 (no effect) and 1 (perfect correlation). Für die Einteilung in schwache, moderate und starke Effekte kann man der Einteilung für <span class="math inline">\(\omega\)</span> (kleines Omega) folgen, sodass man bei Werten von .1 von schwacher, um einen Wert bei 0.3 von moderater und ab .5 von einer starken Effektstärke sprechen kann . Wir haben es in diesem Beispiel also mit einem mittleren Effekt oder Zusammenhang zu tun.</p>
</div>
<div id="chi-square-in-r" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Chi-Square in R</h3>
<p>Bevor wir dazu kommen, wie die Ergebnisse zusammengefasst werden, werden wir im Folgenden den <span class="math inline">\(\chi^{2}\)</span> test in <code>R</code>! rechnen. Zusätzlich zu den Schritten, die wir oben durchlaufen sind, werden wir die Daten graphisch darstellen.</p>
<p>Im ersten Schritt laden wir die Daten ein:</p>
<pre class="r"><code># load data
chidata &lt;- read.table(&quot;http://martinschweinberger.de/docs/data/dt001.txt&quot;, header = F, sep = &quot;\t&quot;, quote = &quot;&quot;, comment.char = &quot;&quot;)
# ad column and row names
colnames(chidata) &lt;- c(&quot;BrE&quot;, &quot;AmE&quot;)
rownames(chidata) &lt;- c(&quot;kindof&quot;, &quot;sortof&quot;)
# inspect data
chidata</code></pre>
<pre><code>##        BrE AmE
## kindof 181 177
## sortof 655  67</code></pre>
<p>We will now visualize the data with an association and a mosaic plot.</p>
<p><img src="chi_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Die Farbe des Mosaikplots (rechts) deutet auf einen signifikanten Unterschied hin. Auch der Assoziationsplot (links) deutet dies an indem die Verteilung der Balken in den beiden Panels gespiegelt ist. Im nächsten Schritt werden wir direkt den Test durchführen.</p>
<pre class="r"><code># run chi square test
chisq.results &lt;- chisq.test(chidata, corr = F)
# inspect results
chisq.results</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  chidata
## X-squared = 220.73, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>Wir sehen, dass die Ergebnisse, die <code>R</code> uns berichtet dieselben sind, wie die, die wir vorher ausgerechnet haben. Im nächsten Schritt werden wir die Effektstärke berechnen.</p>
<pre class="r"><code># calculate effect size
phi.coefficient = sqrt(chisq.results$statistic / sum(chidata) * (min(dim(chidata))-1))
# inspect effect size
phi.coefficient</code></pre>
<pre><code>## X-squared 
## 0.4520877</code></pre>
<p>Nach der Visualisierung der Daten, dem Testen und der Berechnung der Effektstärke können wir nun dazu übergehen uns damit zu beschäftigen, wie unsere Ergebnisse zusammengefasst werden sollten.</p>
</div>
<div id="summarizing-chi-square-results" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Summarizing Chi-Square Results</h3>
<p>Man kann das Ergebnis unseres Beispiels wie folgt zusammenfassen: Ein <span class="math inline">\(\chi\)</span>^{2}-Test bestätigt einen hoch signifikanten Zusammenhang mittlerer Stärke zwischen der Varietät des Englischen und der Verwendung der Heckenausdrücke  und  (<span class="math inline">\(\chi\)</span>^{2} = 220.73, df = 1, p <span class="math inline">\(&lt;\)</span> .001***, <span class="math inline">\(\phi\)</span> = .452).</p>
</div>
<div id="requirements-of-chi-square" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Requirements of Chi-Square</h3>
<p>To provide reliable results, 80 percent of cells in a table to which the chi-square test is applied have to have expected values of 5 or higher and at most 20 percent of expected values can be smaller than 5 (vgl.<span class="citation">[@bortz1990verteilungsfreie]</span> 98). In addition, none of the expected values can be smaller than 1 (vgl. <span class="citation">[@bortz1990verteilungsfreie]</span> 136) because then, the estimation, which relies on the <span class="math inline">\(\chi\)</span>^{2}-distribution, becomes too imprecise to allow meaningful inferences <span class="citation">[@cochran1954somemethods]</span>.</p>
<p>If these requierments are violated, then the <em>Fisher’s Exact Test</em> is more reliable and offers the additional advantage that these tests can also be applied to data that represent very small sample sizes. When applying the Fisher’s Exact Test, the probabilities for all possibles outcomes are calculated and the summed probability for the observed or more extreme results are determined. If this sum of probabilities exceeds five percent, then the result is deemed statistically significant.</p>
</div>
</div>
<div id="extensions-of-chi-square" class="section level2">
<h2><span class="header-section-number">2.2</span> Extensions of Chi-Square</h2>
<p>In the following, we will have a look at tests and methods that can be used if the requirements for ordinary (Pearson’s) chi-square tests are violated and their use would be inaapropriate</p>
<div id="the-yates-correction" class="section level3">
<h3><span class="header-section-number">2.2.1</span> The Yates-Correction</h3>
<p>If all requirements for ordinary chi-square tests are acceptable and only the sample size is the issue, then applying a so-called <em>Yates-correction</em> may be appropriate. This type of correction is used in cases where the overall sample size lies inbetween 60 and 15 cases (<span class="citation">[@bortz1990verteilungsfreie]</span> 91). The difference between the ordinary chi-square and a Yates-corrected chi-square lies in the fact that the Yates-corrected chi-square is calculated according to equation XXX below.</p>
<p><span class="math inline">\(\frac{(|observed – expected|-0.5)^{2}}{expected}\)</span></p>
<p>Damit würde sich für unser Beispiel anstatt Tabelle ({) die folgende Tabelle () führen. Es ist hierbei zu bedenken, dass in unserem Fall keine Yates-Korrektur angebracht wäre, da unsere Stichprobe den Wert von 60 Fällen stark überschreitet.</p>
<table>
<caption>Corrected chi-square values for sort of and kind of in BrE and AmE</caption>
<thead>
<tr class="header">
<th align="left">Variant</th>
<th align="left">BrE</th>
<th align="left">AmE</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">kind of</td>
<td align="left">32.9927</td>
<td align="left">113.0407</td>
<td align="left">146.0335</td>
</tr>
<tr class="even">
<td align="left">sort of</td>
<td align="left">16.3593</td>
<td align="left">56.0507</td>
<td align="left">72.41</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="left">49.352</td>
<td align="left">169.0914</td>
<td align="left">218.4434</td>
</tr>
</tbody>
</table>
<p>Es zeigt sich, dass die Yates-Korrektur zu einem etwas geringerem <span class="math inline">\(\chi\)</span>^{2}-Wert führt und sie somit zu konservativeren Ergebnissen führt, als es nach Pearson der Fall wäre.</p>
</div>
<div id="chi-square-within-2k-tables" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Chi-Square within 2*k Tables</h3>
<p>Obwohl der <span class="math inline">\(\chi\)</span>^{2}-Test weit verbreitet ist und insgesamt sehr robust ist, wird er doch häufig falsch verwendet. Dies geschieht insbesondere dann, wenn man den Test auf Tabellen anwendet, die mehr als zwei Spalten oder Zeilen haben. Es ist sehr wichtig festzuhalten, dass man für Untersuchungen, in denen man Teiltabellen auf Signifikanz testen möchte nicht den gewöhnlichen <span class="math inline">\(\chi\)</span>^{2}-Test, sondern abgewandelte Varianten nutzen muss. Im Folgenden sollen zwei Beispiele darstellen, wie man in solchen Fällen vorgehen sollte.</p>
<p>Im ersten Fall handelt es sich um eine Tabelle mit 2 Spalten aber mehreren Zeilen, einer sogenannten 2*k-Tabelle. Um zu testen, ob eine der Ausprägungen in den Zeilen signifikant häufiger ist als eine andere sollte man die Formel, die von  dargelegt wird, implementieren.</p>
<p>In diesem Beispiel geht es darum, ob weiche Röntgenstrahlen sich von harten Röntgenstrahlen im Hinblick auf das Erreichen bzw. Nicht-Erreichen des Mitosestadiums bei Heuschreckenneuroblasten unterscheiden. Die zugrundeliegende Datentabelle sieht wie folgt aus.</p>
<table>
<caption>Data adapted from Bortz (1990: 126)</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Mitosis not reached</th>
<th align="left">Mitosis reached</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>X-ray soft</td>
<td align="left">21</td>
<td align="left">14</td>
<td align="left">35</td>
</tr>
<tr class="even">
<td>X-ray hard</td>
<td align="left">18</td>
<td align="left">13</td>
<td align="left">31</td>
</tr>
<tr class="odd">
<td>Beta-rays</td>
<td align="left">24</td>
<td align="left">12</td>
<td align="left">36</td>
</tr>
<tr class="even">
<td>Light</td>
<td align="left">13</td>
<td align="left">30</td>
<td align="left">43</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="left">76</td>
<td align="left">69</td>
<td align="left">145</td>
</tr>
</tbody>
</table>
<p>Würde man einen einfachen <span class="math inline">\(\chi\)</span>^{2}-Test rechnen, so würde man unterschlagen, dass die Daten in Zusammenhang mit anderen Daten erhoben wurden und somit nicht unabhängig sind. Wir werden zunächst einen einfachen (falschen) <span class="math inline">\(\chi^{2}\)</span>-Test rechnen, um dann die korrekte Variante zu berechnen, und die Ergebnisse zu vergleichen.</p>
<pre class="r"><code># load function
source(&quot;http://martinschweinberger.de/docs/scripts/x2.2k.r&quot;)
# create table generieren
chitb2 &lt;- matrix(c(21, 14, 18, 13, 24, 12, 13, 30), byrow = T, nrow = 4)
colnames(chitb2) &lt;- c(&quot;erreicht&quot;, &quot;nichterreicht&quot;)
rownames(chitb2) &lt;- c(&quot;rweich&quot;, &quot;rhart&quot;, &quot;beta&quot;, &quot;licht&quot;)
# extract subtable
chitb3 &lt;- matrix(c(21, 14, 18, 13), byrow = T, nrow = 2)
colnames(chitb3) &lt;- c(&quot;erreicht&quot;, &quot;nichterreicht&quot;)
rownames(chitb3) &lt;- c(&quot;rweich&quot;, &quot;rhart&quot;)
# simple x2-test
chisq.test(chitb3, corr = F)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  chitb3
## X-squared = 0.025476, df = 1, p-value = 0.8732</code></pre>
<pre class="r"><code>x2.2k(chitb2, 1, 2)</code></pre>
<pre><code>## $Description
## [1] &quot;rweich  against  rhart  by  erreicht  vs  nichterreicht&quot;
## 
## $`Chi-Squared`
## [1] 0.025
## 
## $df
## [1] 1
## 
## $`p-value`
## [1] 0.8744
## 
## $Phi
## [1] 0.013
## 
## $Report
## [1] &quot;Conclusion: the null hypothesis cannot be rejected! Results are not significant!&quot;</code></pre>
<p>Hier die Ergebnisse in tabellarischer Form.</p>
<table>
<caption>Table adapted from Bortz (1990: 126)</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">chi-square</th>
<th align="left">chi-square in 2*k-tables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>chi-squared</td>
<td align="left">0.0255</td>
<td align="left">0.025</td>
</tr>
<tr class="even">
<td>p-value</td>
<td align="left">0.8732</td>
<td align="left">0.8744</td>
</tr>
</tbody>
</table>
<p>Wie sich zeigt, kommen zwar beide Tests zu den gleichen Ergebnissen, jedoch unterscheiden sich die Resultate minimal. Dies ist nicht immer der Fall, da die Ergebnisse stark variieren können!</p>
</div>
<div id="chi-square-within-zk-tables" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Chi-Square within z*k Tables</h3>
<p>Eine weitere Anwendung, bei der der <span class="math inline">\(\chi\)</span>^{2}-Test häufig inkorrekter Weise verwendet wird, ist das Testen von Teilen von Tabellen mit mehr als zwei Zeilen und mehr als zwei Spalten, d.h. z*k-Tabellen (z: Zeile, k: Kolumne). Ein Beispiel wird in  besprochen, der auch das -Skript für die korrekte Version des <span class="math inline">\(\chi^{2}\)</span>-Test erstellt hat.</p>
<p>Laden wir zuerst die Daten, die in dem Beispiel von  besprochen werden, in dem es darum geht, ob sich nicht nur Register und EMOTION-Metaphern unterscheiden, sondern auch darum, ob sich gesprochene Konversationen von Fiktion im Gebrach von EMOTION IST LICHT und EMOTION IST EINE NATURKRAFT unterscheiden.</p>
<pre class="r"><code># create table
x &lt;- matrix(c(8, 31, 44, 36, 5, 14, 25, 38, 4, 22, 17, 12, 8, 11, 16, 24), ncol=4)
attr(x, &quot;dimnames&quot;)&lt;-list(Register=c(&quot;acad&quot;, &quot;spoken&quot;, &quot;fiction&quot;, &quot;new&quot;),
Metaphor = c(&quot;Heated fluid&quot;, &quot;Light&quot;, &quot;NatForce&quot;, &quot;Other&quot;))</code></pre>
<p>Es ergibt sich aus diesen Daten Tabelle ().</p>
<table>
<caption>Table adapted from Gries (2014: 9)</caption>
<thead>
<tr class="header">
<th align="left">Register</th>
<th align="left">Heated fluid</th>
<th align="left">Light</th>
<th align="left">NatForce</th>
<th align="left">Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">acad</td>
<td align="left">8</td>
<td align="left">5</td>
<td align="left">4</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">spoken</td>
<td align="left">31</td>
<td align="left">14</td>
<td align="left">22</td>
<td align="left">11</td>
</tr>
<tr class="odd">
<td align="left">fiction</td>
<td align="left">44</td>
<td align="left">25</td>
<td align="left">17</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td align="left">new</td>
<td align="left">36</td>
<td align="left">38</td>
<td align="left">12</td>
<td align="left">24</td>
</tr>
</tbody>
</table>
<p>Würden wir einen normalen (hier inkorrekten) <span class="math inline">\(\chi\)</span>^{2}-Test verwenden, so würde sich ergeben, dass sich gesprochene Konversationen nicht signifikant von Fiktion im Gebrach von EMOTION IST LICHT und EMOTION IST EINE NATURKRAFT unterscheiden (<span class="math inline">\(\chi^{2}\)</span>=3.3016, df=1, p<span class="math inline">\(=\)</span>.069, <span class="math inline">\(\phi\)</span> = .2057).</p>
<pre class="r"><code># create table
subtable &lt;- matrix(c(14, 25, 22, 17), ncol=2)
chisq.results &lt;- chisq.test(subtable, correct=FALSE) # WRONG!
phi.coefficient = sqrt(chisq.results$statistic / sum(subtable) * (min(dim(subtable))-1))
chisq.results</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  subtable
## X-squared = 3.3016, df = 1, p-value = 0.06921</code></pre>
<pre class="r"><code>phi.coefficient</code></pre>
<pre><code>## X-squared 
## 0.2057378</code></pre>
<p>Die korrekte Analyse berücksichtigt hierbei, dass es sich um eine Untertabelle handelt, die nicht unabhängig von der Gesamttabelle ist. Dies bedeutet, dass die korrekte Analyse die gesamte Anzahl der Fälle, sowie die Gesamtzeilen- und Gesamtspaltensummen zu berücksichtigen sind .</p>
<p>Um die korrekte Analyse durchführen zu können, muss die Analyse von Funktion von  implementiert oder direkt die Funktion von Gries eingelesen und auf die Teiltabelle angewandt werden.</p>
<pre class="r"><code># load function for chi square test for subtables
source(&quot;http://martinschweinberger.de/docs/scripts/sub.table.r&quot;) 
# apply test
results &lt;- sub.table(x, 2:3, 2:3, out=&quot;short&quot;)
# inspect results
results</code></pre>
<pre><code>## $`Whole table`
##          Metaphor
## Register  Heated fluid Light NatForce Other Sum
##   acad               8     5        4     8  25
##   spoken            31    14       22    11  78
##   fiction           44    25       17    16 102
##   new               36    38       12    24 110
##   Sum              119    82       55    59 315
## 
## $`Sub-table`
##          Metaphor
## Register  Light NatForce Sum
##   spoken     14       22  36
##   fiction    25       17  42
##   Sum        39       39  78
## 
## $`Chi-square tests`
##                                   Chi-square Df    p-value
## Cells of sub-table to whole table  7.2682190  3 0.06382273
## Rows (within sub-table)            0.2526975  1 0.61518204
## Columns (within sub-table)         3.1519956  1 0.07583417
## Contingency (within sub-table)     3.8635259  1 0.04934652</code></pre>
<p>The results show that the difference is, in fact, statistically significant (<span class="math inline">\(\chi^{2}\)</span>=3.864, df=1, p=.049*).</p>
</div>
<div id="chi-square-excercises" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Chi-Square Excercises</h3>
<p>1.Sie sind interessiert daran, ob junge oder alte Sprecher häufiger sprachlich auf sich selbst verweisen, da Sie die Hypothese haben, dass – im Gegensatz zur weitläufig gängigen Ansicht – ältere Menschen eher narzisstisch sind als jüngere Menschen. Sie extrahieren aus einem Korpus folgende Verteilung.</p>
<table>
<caption>Table adapted from Gries (2014: 9)</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">1SGPN</th>
<th align="left">PN without 1SG</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jung</td>
<td align="left">61</td>
<td align="left">43</td>
<td align="left">104</td>
</tr>
<tr class="even">
<td>Alt</td>
<td align="left">42</td>
<td align="left">36</td>
<td align="left">78</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="left">103</td>
<td align="left">79</td>
<td align="left">182</td>
</tr>
</tbody>
</table>
<p>Rechnen Sie nun einen <span class="math inline">\(\chi^{2}\)</span> test und fassen Sie Ihre Ergebnisse korrekt zusammen.</p>
<ol start="2" style="list-style-type: decimal">
<li>Sie sind nun daran interessiert, ob junge Männer oder junge Frauen häufiger das Wort <em>whatever</em> verwenden, da Sie davon ausgehen, dass entgegen einiger früherer Beobachtungen junge Männer häufiger <em>whatever</em> nutzen als junge Frauen. Sie extrahieren aus einem Korpus folgende Verteilung.</li>
</ol>
<table>
<caption>Observed frequency with row- and column totals for the use of <em>whatever</em> by male and female speakers.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">YoungMales</th>
<th align="left">YoungFemales</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>whatever</td>
<td align="left">17</td>
<td align="left">55</td>
<td align="left">71</td>
</tr>
<tr class="even">
<td>other words</td>
<td align="left">345128</td>
<td align="left">916552</td>
<td align="left">1261680</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="left">345145</td>
<td align="left">916607</td>
<td align="left">1261752</td>
</tr>
</tbody>
</table>
<p>Rechnen Sie nun einen <span class="math inline">\(\chi^{2}\)</span> test und fassen Sie Ihre Ergebnisse korrekt zusammen.</p>
<ol start="3" style="list-style-type: decimal">
<li>Suchen Sie sich einen Partner und diskutieren das Verhältnis von Signifikanzwert und Effektstärke. Suchen Sie sich nun einen anderen Partner und sprechen Sie über potentielle Probleme, die entstehen, wenn man die Häufigkeit von Wörtern gegenüber allen anderen Wörtern testet.</li>
</ol>
</div>
</div>
<div id="other-non-parametric-tests" class="section level2">
<h2><span class="header-section-number">2.3</span> Other Non-Parametric Tests</h2>
<p>%Wenn die vorliegende abhängige Variable nicht nominal oder kategorial, sondern ordinal ist, d.h. wenn die abhängige Variable Rangdaten darstellt, dann ist der <span class="math inline">\(\chi\)</span>^{2}-Test nicht anzuwenden. In solchen Fällen sollte man auf Tests zurückgreifen, die für ordinale Variablen ausgelegt sind. Im Folgenden werden die wichtigsten bi-variaten Tests für Rangdaten dargestellt.</p>
<div id="mann-whitney-u-test" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Mann-Whitney U Test</h3>
<p>%Häufig kommt es vor, dass numerische abhängige Variablen entweder in Rangdaten transformiert werden müssen (bspw. da die Verteilung der Residuen/Fehler keine einfache lineare Regression oder einfache Varianzanalyse zulässt) oder die abhängige Variable von vornherein nach Rängen gestuft ist. In solchen Fällen kann kein <span class="math inline">\(\chi\)</span>^{2}-Test gerechnet werden, da dieser von nominalen oder kategorialen Variablen ausgeht und nicht auf Rangdaten angepasst werden darf. Man nutzt in solche Fällen den Mann-Whitney U Test, der sowohl in Fällen anwendbar ist, wo es sich um abhängige (dieselben Versuchspersonen werden unter mindestens zwei Bedingungen getestet), wie auch unabhängige Gruppen handelt (unterschiedliche Versuchspersonen werden unter mindestens zwei Bedingungen getestet). Wenn man es mit unabhängigen Gruppen, d.h. unterschiedlichen Versuchspersonen in den Gruppen zu tun hat, und die abhängige Variable eine Rangfolge darstellt, nutzt man folgenden Code, um den Mann-Whitney U Test in  zu implementieren.</p>
<pre class="r"><code># y ist aV und numerisch, x ist uV und ein binaerer faktor
#wilcox.test(y ~ x)

# y1 ist aV, y2 ist uV und beide sind numerisch
#wilcox.test(y1, y2)</code></pre>
<p>%Hat man es mit abhängigen Gruppen zu tun, muss man das Argument  gleich  setzen (siehe unten).</p>
<pre class="r"><code># dependent 2-group Wilcoxon Signed Rank Test
#wilcox.test(y1,y2,paired=TRUE) # where y1 and y2 are numeric</code></pre>
</div>
<div id="kruskal-wallis-test" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Kruskal Wallis Test</h3>
<p>%Bei dem Kruskal Wallis Test handelt es sich um eine einfache Varianzanalyse, die anstatt auf numerische Werte auf die Rangdaten angewandt wird.</p>
<pre class="r"><code>#y &lt;- c(15, 13, 10, 8, 37, 23, 31, 52, 11, 17)
#x &lt;- c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;)
# Kruskal Wallis Test One Way Anova by Ranks
#kruskal.test(y~x) # where y1 is numeric and x is a factor</code></pre>
</div>
<div id="excercises-for-other-non-parametric-tests" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Excercises for other non-parametric tests</h3>
</div>
</div>
</div>
<div id="simple-linear-regression" class="section level1">
<h1><span class="header-section-number">3</span> Simple Linear Regression</h1>
<p>This chapter focuses on a very widely used statistical method which is called regression. Regressions are used when we try to understand how independent variables correlate with a dependent or outcome variable. So if you want to investigate how certain criteria affect an outcome, then a regression is the way to go. We will have a look at two simple examples to understand what the concepts underlying a regression mean and how a regression works. After that, we will turn to a more compley case and we will implement a multiple linear regression. The <code>R</code>-Code, that we will use, is based on <span class="citation">[@field2012discovering]</span>.</p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>Although the basic logic underlying regressions is identical to the conceptual underpinnings of analysis of variance (ANOVA), a related method, sociolinguistists have traditionally favoured regression analysis in their studes while ANOVAs have been the method of choice in psycholinguistics. The preference for either method is grounded in historical happenstances and the culture of these subdisciplines rather than in methodological reasoning.</p>
<p>A minor difference between regressions and ANOVA lies in the fact that regressions are based on the <span class="math inline">\(t\)</span>-distribution while ANOVAs use the <span class="math inline">\(F\)</span>-distribution (however, the <span class="math inline">\(F\)</span>-value is merely t<sup>2</sup>). Both <span class="math inline">\(t\)</span>- and <span class="math inline">\(F\)</span>-values report on the ratio between explained and unexplained variance.</p>
<p>The idea behind regression analysis is expressed formaly in <a href="#eq:slm">equation</a> and can best be described graphically: Imagine drawing a line through points in a scatterplot (Grafik  left panel).</p>
<p><span class="math inline">\(f_{(x)} = \alpha + \beta_{1}x_{i} + \epsilon\)</span> {#eq:slm}</p>
<p>Regressions aim to find that line which has the minimal summed distance between points and the line (Grafik  center panel). Technically speaking, the aim of a regression is to find the line with the minimal deviance or the line with the minimal sum of residuals (variance) (Grafik  right panel). This means that the sum of the length of the lines between the points and the lines should be minimal. The slope of the line is called <em>coefficient</em> and the point where the line crosses the y-axis is called the <em>intercept</em>.</p>
<div class="figure">
<img src="chi_files/figure-html/unnamed-chunk-16-1.png" alt="Scatterplots mit Regressionsgeraden (mitte) und Residuen (rechts)" width="960" />
<p class="caption">
Scatterplots mit Regressionsgeraden (mitte) und Residuen (rechts)
</p>
</div>
<p>A word about standard errors (SE) is in order here because most commonly used statistics programs will provide SE values when reportigng regression models. The SE is a measure that tells us how much the coefficients were to vary if the same regression were applied to many samples from the same population. A relatively small SE value therefore indicates that the coefficients will ermain very stable if the same regression model is fitted to many different samples with identical parameters. In contrast, a large SE tells you that the model is volatile and not very stable or reliable as the coefficients vary substantially if the model is applied to many samples.</p>
</div>
<div id="example-1-preposition-use-across-real-time" class="section level2">
<h2><span class="header-section-number">3.2</span> Example 1: Preposition Use across Real-Time</h2>
<p>We will now turn to our first example. In this example, we will investiagte whether the frequency of prepositions has changed from Middle English to Late Modern English. The reasoning behind this example is that Old English was highly sythetic compared with Present-Day English which comparatively analytic. In other words, while Old English speakers used case to indicate syntactic relations, speakers of Present-Day English use word order and prepositions to indicate syntactic relationships. This means that the loss of case had to be compensated by different strategies and maybe these strategies continued to develop and incerase in frequency even after the change from synthetic to analytic had been mostly accomplished. And this prolonged change in compensatory strategies is what this example will focus on.</p>
<p>The analysis is based on data extrcted from the <em>Penn Corpora of Historical English</em> (see <a href="http://www.ling.upenn.edu/hist-corpora/" class="uri">http://www.ling.upenn.edu/hist-corpora/</a>), that consistss of 603 texts written between 1125 and 1900. In preparation of this example, all elements that were part-of-speech tagged as prepositions were extracted from the PennCorpora.</p>
<p>Then, the relative frequencies (per 1,000 words) of prepositions per text were calculated. This frequency of prepositions per 1,000 words represents our dependent variable. In a next step, the date when each letter had been written was extracted. The resulting two vectors were combined into a table which thus contained for each text, when it was written (independent variable) and its relative freqeuncy of prepositions (dependent or outcome variable).</p>
<p>A regression analysis will follow the steps described below: Die folgende Ablauf ist typisch für Regressionsanalysen.</p>
<ol style="list-style-type: decimal">
<li>Extraction and processing of the data</li>
<li>Data visualization</li>
<li>Applying the regression analysis to the data</li>
<li>Diagnosing the regression model and checking whether or not basic model assumptions have been violated.</li>
</ol>
<div id="simple-linear-regression-in-r" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Simple Linear Regression in <code>R</code></h3>
<p>In a first step, we prepare our session by cleaning the work space, installing libraries that we need for the analysis, and loading the libraries and fucntions.</p>
<pre class="r"><code># clean workspace
rm(list=ls(all=T))
# installing neccessary or helpful packages/libraries (if you have not sone so previously)
# (remove the # sign to activate the code)
#install.packages(&quot;QuantPsyc&quot;)
#install.packages(&quot;car&quot;)
# initialise packages/libraries
library(QuantPsyc)
library(car)
library(ggplot2)
# function which allows us to plot several plots in one window
source(&quot;http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r&quot;)
# function for summarizing simple linear regression models
source(&quot;http://martinschweinberger.de/docs/scripts/slr.summary.tb.r&quot;) </code></pre>
<p>After perparing our session, we can now load and inspect the data to get a first implression of its properties.</p>
<pre class="r"><code># load data
slr.data &lt;- read.delim(&quot;http://martinschweinberger.de/docs/data/slr.data.txt&quot;, header = TRUE)
# attach data
attach(slr.data)
# unnoetige spalten entfernen
slr.data &lt;- as.data.frame(cbind(slr.data$datems, slr.data$P.ptw))
# spaltennamen hinzufuegen
colnames(slr.data) &lt;- c(&quot;year&quot;, &quot;prep.ptw&quot;)
# entfernen unvollstaendiger datenpunkte
slr.data &lt;- slr.data[!is.na(slr.data$year) == T, ]
# erste zeilen des datensatzes betrachten
head(slr.data)</code></pre>
<pre><code>##   year prep.ptw
## 1 1736   166.01
## 2 1711   139.86
## 3 1808   130.78
## 4 1878   151.29
## 5 1743   145.72
## 6 1807   152.59</code></pre>
<pre class="r"><code># struktur des datensatzes betrachten
str(slr.data)</code></pre>
<pre><code>## &#39;data.frame&#39;:    603 obs. of  2 variables:
##  $ year    : num  1736 1711 1808 1878 1743 ...
##  $ prep.ptw: num  166 140 131 151 146 ...</code></pre>
<pre class="r"><code># eigenschaften des datensatzes betrachten
summary(slr.data)</code></pre>
<pre><code>##       year         prep.ptw     
##  Min.   :1125   Min.   : 63.97  
##  1st Qu.:1545   1st Qu.:115.66  
##  Median :1615   Median :130.78  
##  Mean   :1619   Mean   :129.81  
##  3rd Qu.:1687   3rd Qu.:144.08  
##  Max.   :1913   Max.   :195.86</code></pre>
<p>Inspecting the data is very important because it can happen that a data set may not load completely or that variables which should be numeric have been converted in charater variables. If unchecked, then such hidden data issues could go unnoticed and cause much trouble once you realize that the data you have been working with is different from what you had in mind.</p>
<p>We will now plot the data to get a more thorough impression of the structure of the data.</p>
<pre class="r"><code># visualisieren der daten
p2 &lt;- ggplot(slr.data, aes(year, prep.ptw)) +
geom_point() +
labs(x = &quot;Year&quot;) +
labs(y = &quot;Prepositions per 1,000 words&quot;) +
geom_smooth()

p3 &lt;- ggplot(slr.data, aes(year, prep.ptw)) +
geom_point() +
labs(x = &quot;Year&quot;) +
labs(y = &quot;Prepositions per 1,000 words&quot;) +
geom_smooth(method = &quot;lm&quot;) # with linear model smoothing!

multiplot(p2, p3, cols = 2)</code></pre>
<pre><code>## Loading required package: grid</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="chi_files/figure-html/plotting-1.png" width="672" /></p>
<p>Bevor wir mit der Regression beginnen, werden wir die Jahreszahlen skalieren, d.h. wir ziehen vom jeweiligen Wert der Jahreszahl den Mittelwert der Jahreszahlen ab. Bei numerischen Variablen kann dies sehr hilfreich bei der Interpretation sein, denn wenn beispielsweise die numerische Variable  nicht skaliert werden würde, würde die Regression die Effekte im Jahr 0 angeben(!). Wenn eine Variable hingegen skaliert ist, dann werden die anderen Variablen nicht relativ zum Nullwert der Variable, sondern zu deren Mittelwert ins Verhältnis gesetzt, d.h. wir erhalten den Effekt der anderen Variablen, wenn die Variable  ihren Mittelwert annimmt.</p>
<pre class="r"><code># scaling date
slr.data$prep.ptw &lt;- slr.data$prep.ptw - mean(slr.data$prep.ptw)</code></pre>
<p>Wir beginnen nun mit der Regression, indem wir eine erste Regression rechnen und anschließend deren Ergebnisse und diagnostische Plots betrachten.</p>
<pre class="r"><code># create initial model
prep.lm &lt;- lm(prep.ptw ~ year, data = slr.data)
# inspect results
summary(prep.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = prep.ptw ~ year, data = slr.data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -66.842 -13.523   1.183  14.086  65.117 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -27.723706  10.863978  -2.552   0.0110 *
## year          0.017128   0.006691   2.560   0.0107 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.11 on 601 degrees of freedom
## Multiple R-squared:  0.01079,    Adjusted R-squared:  0.00914 
## F-statistic: 6.553 on 1 and 601 DF,  p-value: 0.01071</code></pre>
<pre class="r"><code># plot model: 3 plots per row in one window
par(mfrow = c(1, 3))
plot(resid(prep.lm))
plot(rstandard(prep.lm))
plot(rstudent(prep.lm))</code></pre>
<p><img src="chi_files/figure-html/initialmodel-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1)) # restroe default parameters</code></pre>
<p>Die linke Grafik zeigt die Residuen des Modells (d.h. die Unterscheide zwischen den beobachteten und den durch das Modell vorhergesagten Werten). Das Problem bei diesem Plot ist, dass die Residuen nicht standardisiert sind und man sie so nicht mit den Residuen anderer Modelle vergleichen kann. Um diesen Mangel zu beheben standardisiert man die Residuen, indem man die Residuen durch deren Standartabweichung dividiert, und plottet sie gegen die beobachteten Werte (mittlerer Plot). Auf diese Weise erhält man nicht nur standardisierte Residuen, sondern die Werte der Residuen sind nun zu z-Werten geworden und man kann die z-Verteilung nutzen, um problematische Punkte zu finden. Es gibt drei Daumenregeln bezüglich des Findens problematischer Datenpunkte aufgrund von Residuen :</p>
<ol style="list-style-type: decimal">
<li>Punkte mit extremen Werten, d.h. Werten <span class="math inline">\(\ge\)</span> 3 (um genau zu sein, Werten <span class="math inline">\(\ge\)</span> 3.29), sollten aus den Daten entfernt werden.</li>
<li>Falls mehr als 1% der Datenpunkte Werte <span class="math inline">\(\ge\)</span> 2.5 haben (2.58 um genau zu sein), dann sind die Fehler unseres Models zu groß.</li>
<li>Falls mehr als 5% der Datenpunkte Werte <span class="math inline">\(\ge\)</span> 2 haben (1.96 um genau zu sein), dann sind die Fehler unseres Models ebenfalls zu groß.</li>
</ol>
<p>Die rechte Grafik zeigt die <em>studentized Residuen</em>, d.h. die angepassten vorhergesagten Werte jedes Datenpunkts werden durch den Standardfehler der Residuen dividiert. Auf diesem Weg ist es möglich die Student’s t-Verteilung zu nutzen, um unser Model zu diagnostizieren.</p>
<p>Angepasste vorhergesagte Werte sind ebenfalls Residuen, aber einer besonderen Art: Das Model wird ohne einen Datenpunkt gerechnet und dann genutzt um diesen Datenpunkt vorherzusagen. Der Unterschied zwischen dem beobachteten Datenpunkt und dem vorhergesagten Datenpunkt wird dann angepasster vorhergesagter Wert genannt. Zusammenfassend kann gesagt werden, dass studentized Residuen sehr nützlich dahingehend sind, dass Sie einflussreiche Datenpunkte erkennen lassen.</p>
<p>Die Plots zeigen, dass es zwei potentiell problematische Datenpunkte gibt (die Punkte ganz oben und ganz unten). diese zwei Punkte setzten sich deutlich von den anderen Punkten ab und können demnach Ausreißer (outlier) darstellen. Wir werden später testen, ob diese punkte entfernt werden müssen.</p>
<p>Wir werden nun weitere modelldiagnostische Grafiken generieren.</p>
<pre class="r"><code># generiere eine 2x2 matrize diagnostischer grafiken
par(mfrow = c(2, 2))
plot(prep.lm)</code></pre>
<p><img src="chi_files/figure-html/diagnosticplots-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>Die diagnostischen Grafiken sehen sehr gut aus und wir werden im Folgenden erklären warum. Die Grafik im oberen linken Panel ist nützlich, um (a) Oulier zu finden oder (b) die Korrelation zwischen Residuen und vorhergesagten Werten zu bestimmen: Wenn ein Trend in der Linie oder den Punkten sichtbar wird (bspw. ein aufsteigender Trend oder eine Zickzacklinie), dann hätte unser Model ein Problem und wir müssten wahrscheinlich Datenpunkte entfernen.</p>
<p>Die Grafik im oberen rechten Panel zeigt an, ob die Residuen normal verteilt sind (was wünschenswert ist), ober ob die Residuen nicht einer Normalverteilung folgen. Liegen die Punkte auf der Linie, so folgen die Residuen einer Normalverteilung. Wenn die Punkte beispielsweise am oberen und unteren Ende nicht auf der Linie liegen, so zeigt dies, dass das Model kleine und große Werte nicht gut vorhersagt und daher nicht gut auf die Daten angepasst ist.</p>
<p>Die Grafik im unteren linken Panel gibt Aufschluss über Homoskedastizität. Homoskedastizität bedeutet, dass die Varianz der Residuen konstant bleibt und nicht mit dem Wert der unabhängigen Variable korrelieren. In unproblematischen Fällen zeigt die Grafik eine flache Linie. Liegt eine Trend in der Linie vor, so haben wir es mit Heteroskedastizität, also mit einer Korrelation zwischen unabhängigen Variablen und den Residuen, zu tun, die für Regressionen sehr problematisch ist.</p>
<p>Die Grafik im unteren rechten Panel zeigt problematische einflussreiche Datenpunkte, die die Regression überproportional beeinflussen (dies sollte nicht der Fall sein). Falls solche einflussreichen Datenpunkte vorliegen, so sollten diese entweder (a) gewichtet werden (robuste Regression) oder (b) entfernt werden. Die Grafik zeigt die Cookdistanz, welche zeigt, wie sich die Regression verändert, wenn ein Model ohne diesen Datenpunkt gerechnet wird. Die Cookdistanz zeigt also, welchen Einfluss ein Datenpunkt auf die Regression als ganzes hat. Datenpunkte, die eine Cookdistanz <span class="math inline">\(\ge\)</span> 1 haben sind problematisch .</p>
<p>Die sogenannte Leverage ist ebenso ein Maß, das anzeigt, wie stark ein Datenpunkt die Genauigkeit der Regression beeinflusst. Leveragewerte liegen zwischen 0 (kein Einfluss) und 1 (starker Einfluss: suboptimal!). Um zu testen, ob ein spezifischer Datenpunkt einen hohen Leveragewert besitzt, muss man einen Cut-Off-Punkt berechnen, der anzeigt, ob die Leverage zu stark oder noch akzeptabel ist. Folgende zwei Formeln werden hierzu genutzt:</p>
<p><span class="math inline">\(\frac{3(k + 1)}{n}\)</span></p>
<p>oder</p>
<p><span class="math inline">\(\frac{2(k + 1)}{n}\)</span></p>
<p>Wir werden im Kontext der multiplen linearen regression genauer auf Leverage eingehen und nun nur noch eine Überblicktabelle der Ergebnisse der Regression generieren.</p>
<pre class="r"><code># tabulate results
slr.summary(prep.lm)</code></pre>
<pre><code>##                                   Estimate Std. Beta Pearson&#39;s r
## (Intercept)                         -27.72                      
## year                                  0.02    0.1039         0.1
## Model statistics                                                
## Number of cases in model                                        
## Residual standard error on 601 DF                               
## Multiple R-squared                                              
## Adjusted R-squared                                              
## F-statistic (1, 601)                                            
## Model p-value                                                   
##                                   Std. Error t value Pr(&gt;|t|) P-value sig.
## (Intercept)                            10.86   -2.55    0.011     p &lt; .05*
## year                                    0.01    2.56   0.0107     p &lt; .05*
## Model statistics                                                     Value
## Number of cases in model                                               603
## Residual standard error on 601 DF                                    21.11
## Multiple R-squared                                                  0.0108
## Adjusted R-squared                                                  0.0091
## F-statistic (1, 601)                                                  6.55
## Model p-value                                                       0.0107</code></pre>
<p>Typischer weise werden die Ergebnisse von Regressionen in solchen Tabellen wiedergegeben, da diese aller wichtigen Kennzahlen der Modellgüte und die Signifikanz wie auch die Stärke der Effekte beinhalten. Die Tabelle ist hier noch einmal abgebildet.</p>

<p>Zusätzlich sollten die Ergebnisse von einfachen linearen Regressionen schriftlich in etwa wie folgt zusammengefasst werden:\[.2cm]</p>
<p>Eine einfache lineare Regression wurde auf die Daten angepasst. Eine visuelle Begutachtung der modelldiagostischen Grafiken zeigten keine problematischen Datenpunkte (Ausreißer) oder überproportional einflussreiche Datenpunkte an und wiesen auf einen guten Modellfit hin. Das finale lineare Regressionsmodell basiert auf 603 Datenpunkten und korreliert hoch signifikant mit den Daten (<span class="math inline">\(R^{2}\)</span>: 0.0108, F-Statistik (1, 601): 6.553, p-Wert: 0.0107*) und bestätigt eine signifikante positive Korrelation zwischen dem Jahr in dem der Text geschrieben wurde und der relativen Häufigkeit von Präpositionen in den Texten nach (Koeffizient: .02, Std. <span class="math inline">\(\beta\)</span>: 0.1039, SE: 0.01, t-Wert: 2.560, p-Wert: .0107*).</p>
</div>
</div>
<div id="example-2-teaching-styles" class="section level2">
<h2><span class="header-section-number">3.3</span> Example 2: Teaching Styles</h2>
<p>Im vorhergehenden Beispiel haben wir es mit zwei numerischen Variablen zu tun gehabt, während es sich in dem folgenden Beispiel um eine kategoriale und eine numerische abhängige Variable handelt. Die Eigenschaft, dass Regressionen mit sehr verschiedenen Variablenarten umgehen können, macht Regressionen zu einer weit verbreiteten und robusten Analysemethode.</p>
<p>In diesem Beispiel haben wir es mit zwei Gruppen von Schülern zu tun, die zufällig einer Gruppe zugewiesen wurden und unterschiedlichen Lehrmethoden ausgesetzt waren. Beide Gruppen unterziehen sich im Anschluss an die Lehreinheit einem Sprachlerntest mit einer Höchstpunktzahl von 20 Punkten. Die Schüler der ersten Gruppen haben folgende Punktzahlen erreicht:</p>
<ul>
<li>Gruppe A: 15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14 (mean: 14,93)</li>
</ul>
<p>Die Schüler der zweiten Gruppe haben diese Punktzahlen erreicht.</p>
<ul>
<li>Gruppe B: 11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7 (mean: 11,77)</li>
</ul>
<p>Unsere Frage ist nun, ob Gruppe A wirklich besser ist oder ob das Ergebnis Zufall ist?</p>
<p>Gehen wir nun dazu über, die Regression in <code>R</code> zu implementieren. Wie im vorherigen Beispiel leeren wir den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.</p>
<pre class="r"><code># entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages(&quot;QuantPsyc&quot;)
#install.packages(&quot;car&quot;)
# pakete initialisieren
library(QuantPsyc)
library(car)
library(ggplot2)
source(&quot;http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r&quot;) # mehrere ggplots in einem fenster
source(&quot;http://martinschweinberger.de/docs/scripts/slr.summary.tb.r&quot;) # funktion zum erstellen von summary tabellen</code></pre>
<p>Nachdem die notwendigen Spezifikationen durchgeführt wurden, werden wir nun unser Datenset generieren und es anschließend betrachten.</p>
<pre class="r"><code># einladen der daten
g1 &lt;- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)
g2 &lt;- c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)
g &lt;- c(rep(&quot;A&quot;, length(g1)), rep(&quot;B&quot;, length(g2)))
sprtestdata &lt;- data.frame(g, c(g1, g2))
# spaltennamen hinzufuegen
colnames(sprtestdata) &lt;- c(&quot;gruppe&quot;, &quot;punkte&quot;)
# erste zeilen des datensatzes betrachten
head(sprtestdata)</code></pre>
<pre><code>##   gruppe punkte
## 1      A     15
## 2      A     12
## 3      A     11
## 4      A     18
## 5      A     15
## 6      A     15</code></pre>
<pre class="r"><code># struktur des datensatzes betrachten
str(sprtestdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    60 obs. of  2 variables:
##  $ gruppe: Factor w/ 2 levels &quot;A&quot;,&quot;B&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ punkte: num  15 12 11 18 15 15 9 19 14 13 ...</code></pre>
<pre class="r"><code># eigenschaften des datensatzes betrachten
summary(sprtestdata)</code></pre>
<pre><code>##  gruppe     punkte     
##  A:30   Min.   : 5.00  
##  B:30   1st Qu.:11.75  
##         Median :14.00  
##         Mean   :13.35  
##         3rd Qu.:16.00  
##         Max.   :19.00</code></pre>
<p>Nun stellen wir die Daten grafisch dar. In diesem Fall bietet sich ein Boxplot zur Visualisierung an.</p>
<pre class="r"><code># erstelle boxplot
boxplot(punkte ~ gruppe,
data = sprtestdata, # the data we want to display
main = &quot;&quot;, # you could specify a title here
ylab = &quot;Punkte&quot;, # titel der y-achse
ylim = c(0, 20), # grenzen der y-achse festlegen
xlab = c(&quot;Gruppen&quot;), # titel der x-achse
notch = T, # notches einfuegen
col = c(&quot;lightgreen&quot;, &quot;lightblue&quot;)) # box einfaerben
# text darstellen
text(1:2,
c(4.0, 4.0),
cex = 0.85,
labels = paste(&quot;mean\n&quot;,
c(round(as.vector(by(sprtestdata$punkte, sprtestdata$gruppe, mean))[1], 2),
round(as.vector(by(sprtestdata$punkte, sprtestdata$gruppe, mean))[2], 2),
sep = &quot;&quot;)))
rug(jitter(sprtestdata$punkte),
side=4)
grid()
box()</code></pre>
<div class="figure">
<img src="chi_files/figure-html/boxplot-1.png" alt="Darstellung der Sprachtestdaten" width="672" />
<p class="caption">
Darstellung der Sprachtestdaten
</p>
</div>
<p>Die Daten weisen darauf hin, dass Gruppe A signifikant besser abgeschnitten hat als Gruppe B. Wir werden diesen Eindruck dadurch testen, dass wir im nächsten Schritt das Regressionsmodell und erstellen die modelldiagnostischen Grafiken generieren.</p>
<pre class="r"><code># Simples Lineares Regressionsmodel erstellen
sprtest.lm &lt;- lm(punkte ~ gruppe, data = sprtestdata)
# ergebnisse betrachten
summary(sprtest.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = punkte ~ gruppe, data = sprtestdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.767 -1.933  0.150  2.067  6.233 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  14.9333     0.5346  27.935  &lt; 2e-16 ***
## gruppeB      -3.1667     0.7560  -4.189 9.67e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.928 on 58 degrees of freedom
## Multiple R-squared:  0.2322, Adjusted R-squared:  0.219 
## F-statistic: 17.55 on 1 and 58 DF,  p-value: 9.669e-05</code></pre>
<pre class="r"><code># graphik parameter setzen: 3 plots in einer reihe
par(mfrow = c(1, 3))
plot(resid(sprtest.lm))
plot(rstandard(sprtest.lm))
plot(rstudent(sprtest.lm))</code></pre>
<p><img src="chi_files/figure-html/create%20simple%20model-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1)) # wiederherstellen der originalparameter</code></pre>

<p>Die Grafiken weisen nicht auf Ausreißer oder andere Probleme hin und wir können daher mit weiteren diagnostischen Grafiken fortfahren.</p>
<pre class="r"><code># generiere eine 2x2 matrize diagnostischer grafiken
par(mfrow = c(2, 2))
plot(sprtest.lm)</code></pre>
<p><img src="chi_files/figure-html/diagnostic%20plots-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>

<p>Auch diese Grafiken weisen auf keine Probleme hin. In diesem Fall können die Daten im nächsten Schritt zusammengefasst werden.</p>
<pre class="r"><code># ergebnisse tabellieren
slr.summary(sprtest.lm)</code></pre>
<pre><code>## Warning in var(if (is.vector(x) || is.factor(x)) x else as.double(x), na.rm = na.rm): Calling var(x) on a factor x is deprecated and will become an error.
##   Use something like &#39;all(duplicated(x)[-1L])&#39; to test for a constant vector.</code></pre>
<pre><code>##                                  Estimate Std. Beta Pearson&#39;s r Std. Error
## (Intercept)                         14.93                             0.53
## gruppeB                             -3.17   -0.4819        0.48       0.76
## Model statistics                                                          
## Number of cases in model                                                  
## Residual standard error on 58 DF                                          
## Multiple R-squared                                                        
## Adjusted R-squared                                                        
## F-statistic (1, 58)                                                       
## Model p-value                                                             
##                                  t value Pr(&gt;|t|) P-value sig.
## (Intercept)                        27.94        0  p &lt; .001***
## gruppeB                            -4.19    1e-04  p &lt; .001***
## Model statistics                                         Value
## Number of cases in model                                    60
## Residual standard error on 58 DF                          2.93
## Multiple R-squared                                      0.2322
## Adjusted R-squared                                       0.219
## F-statistic (1, 58)                                      17.55
## Model p-value                                            1e-04</code></pre>

<p>Die Ergebnisse dieser einfachen linearen Regressionen können wie folgt zusammengefasst werden:\[.2cm]</p>
<p>Eine einfache lineare Regression wurde auf die Daten angepasst. Eine visuelle Begutachtung der modelldiagostischen Grafiken zeigten keine problematischen Datenpunkte (Ausreißer) oder überproportional einflussreiche Datenpunkte an und wiesen auf einen guten Modellfit hin. Das finale lineare Regressionsmodell basiert auf 60 Datenpunkten und korreliert hoch signifikant mit den Daten (<span class="math inline">\(R^{2}\)</span>: 0.2322, <span class="math inline">\(F\)</span>-Statistik (1, 58): 2.93, p-Wert <span class="math inline">\(&lt;\)</span>.001<strong><em>) und bestätigt, dass Gruppe A signifikant besser bei dem Sprachlerntest abgeschnitten hat als Gruppe B (Koeffizient: -3.17, Std. <span class="math inline">\(\beta\)</span>: -0.4819, SE: 0.48, t-Wert: -4.19, p-Wert <span class="math inline">\(&lt;\)</span>.001</em></strong>).</p>
</div>
</div>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">4</span> (Multiple) Linear Regression</h1>
<p>Im Gegensatz zu der einfachen linearen Regression, die den Zusammenhang zwischen einer unabhängigen und einer abhängigen Variable testet, kann eine multiple lineare Regression den Einfluss mehrerer unterschiedlicher unabhängiger Variablen und deren Interaktionen auf die abhängige Variable bestimmen (vgl. Formel ()). Eine einfache lineare Regression kann somit nicht gleichzeitig den Einfluss mehrerer Variablen oder derer Interaktionen bestimmen.</p>
<p><span class="math inline">\(f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon\)</span></p>
<p>Es gibt ausgiebige Fachliteratur zu multiplen Regressionen und den zugrundeliegenden Konzepten. Insbesondere seien hier , , , ,  (mein persönlicher Favorit!), und  zu nennen. Sehr gute Einführungen dazu, wie Regressionen in <code>R</code> implementiert werden können, finden sich u.a. in ,  oder .</p>
<p>Eine weitere Anmerkung vorweg: Die modelldiagnostischen Verfahren werden teilweise identisch sein mit denen, die im Kapitel zur einfachen linearen Regression besprochen wurden und sie werden daher nur dann ausgiebiger erläutert, insofern dies nicht bereits geschehen ist.</p>
<p>Eine letzte Anmerkung betrifft die Stichprobengröße, die notwendig ist um eine Regression zu rechnen. Obwohl die Angabe, dass 25 Datenpunkte pro Gruppe ausreichen weit verbreitet ist, ist diese Angabe nicht korrekt, da sich die benötigte Stichprobengröße nach der Größe des Effekts, der bestimmt werden soll, und nach der Anzahl der untersuchten Variablen richtet. Gehen viele unabhängige Variablen in die Regression ein und die Effektstärke der zu testenden Variable(n) ist sehr klein, dann kann man von einer Mindestgröße der Stichprobe von 600 Datenpunkten ausgehen.  geben zur Mindestgröße der benötigten Stichprobe Daumenregeln an die Hand (k = Anzahl der Prädikatoren; kategorische Prädikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):</p>
<ul>
<li>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</li>
<li>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</li>
<li>Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen. \end{itemize}</li>
</ul>
<p>%Grafik  einfügen. XXX</p>
<p>Sie werden im -code sehen, dass hierzu eine Funktion existiert, die testet, ob die Stichprobe für die Untersuchung angemessen war.</p>
<p>Hinsichtlich der Modellanpassung wird nur auf step-wise step-down Prozeduren, die auf dem AIC (Akaike information criterion) beruhen, eingegangen werden. Es gibt eine Vielzahl von möglichen Prozeduren, die genutzt werden können forced entry, stepwise, hierarchical) und innerhalb dieser Prozeduren gibt es Unterklassen, sodass eine Diskussion den Rahmen dieser Sektion sprengen würde.</p>
<div id="example-1-expenditures-for-presents" class="section level2">
<h2><span class="header-section-number">4.1</span> Example 1: Expenditures for Presents</h2>
<p>In diesem Beispiel werden wir untersuchen, ob der Geldbetrag, den Männer für Geschenke ausgeben, mit der Attraktivität und dem Beziehungsstatus der Frauen, für die Geschenke gekauft wurden, korreliert. Das Beispiel ist  entnommen. Wir werden nun das Beispiel in  implementieren und leeren dazu, wie üblich, den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.</p>
<pre class="r"><code># entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages(&quot;rms&quot;)
#install.packages(&quot;glmulti&quot;)
#install.packages(&quot;lmtest&quot;)
#install.packages(&quot;MASS&quot;)
#install.packages(&quot;QuantPsyc&quot;)
#install.packages(&quot;car&quot;)
#install.packages(&quot;ggplot2&quot;)
# pakete initialisieren
#library(rms)
#library(glmulti)
#library(lmtest)
#library(MASS)
library(car)
library(QuantPsyc)
library(boot)
library(ggplot2)
source(&quot;http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r&quot;)
source(&quot;http://martinschweinberger.de/docs/scripts/mlinr.summary.r&quot;)
source(&quot;http://martinschweinberger.de/docs/scripts/SampleSizeMLR.r&quot;)
source(&quot;http://martinschweinberger.de/docs/scripts/ExpR.r&quot;)
# optionen festlegen
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)</code></pre>
<p>Nachdem wir die notwendigen Pakete usw. in  eingelesen haben, können wir nun die Daten laden und uns einen ersten Eindruck über deren Struktur und Eigenschaften verschaffen.</p>
<pre class="r"><code># daten laden
mlrdata &lt;- read.delim(&quot;http://martinschweinberger.de/docs/data/mlrdata.txt&quot;, header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code># struktur der daten betrachten
str(mlrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code># zusammenfassung der daten betrachten
summary(mlrdata)</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p>Wir haben nun den Datensatz eingelesen und seine Struktur betrachtet. Im nächsten Schritt werden wir die Daten visualisieren, um einen Eindruck der Daten und der Verteilungen der Variablen zu gewinnen. Wir werden vier Grafiken erstellen und diese dann in einem Fenster darstellen.</p>
<pre class="r"><code>p1 &lt;- ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = T, aes(fill = factor(status))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Status&quot;)
p2 &lt;- ggplot(mlrdata, aes(attraction, money)) +
geom_boxplot(notch = T, aes(fill = factor(attraction))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Attraction&quot;)
p3 &lt;- ggplot(mlrdata, aes(x = money)) +
geom_histogram(aes(y=..density..),
binwidth = 10,
colour = &quot;black&quot;, fill = &quot;white&quot;) +
geom_density(alpha=.2, fill = &quot;#FF6666&quot;) # Overlay with transparent density plot
p4 &lt;- ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = F, aes(fill = factor(status))) +
scale_fill_brewer(palette=&quot;Paired&quot;) +
facet_wrap(~ attraction, nrow = 1) +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE)
# Plot the plots
multiplot(p1, p3, p2, p4, cols = 2)</code></pre>
<p><img src="chi_files/figure-html/plot%20data-1.png" width="672" /></p>

<p>Die Grafik im oberen linken Panel scheint anzudeuten, dass Männer mehr Geld für Frauen ausgeben, die Single sind, allerdings relativiert sich dieser Eindruck, denn die Grafik im unteren rechten Panel deutet darauf hin, dass Männer nur dann mehr Geld für ein Geschenk ausgeben, wenn die Frau Single ist UND sie an ihr interessiert sind. Den der Beziehungsstatus hat keinen Einfluss auf das Geld für Geschenke für Frauen, an denen Männer nicht interessiert sind. Die Grafik im oberen rechten Panel weist darauf hin, dass Männer substantiell mehr Geld für Geschenke für Frauen ausgeben, an denen sie interessiert sind.</p>
<p>Gehen wir nun dazu über mit der Regression zu beginnen. Im ersten Schritt erzeugen wir vier Baselinemodelle: Zwei minimale Modelle, die nur den Gesamtmittelwert (Intercept) als Prädiktor beinhalten und zwei gesättigte Modelle (saturated models), die alle möglichen Prädikatoren und Interaktionen beinhalten.</p>
<pre class="r"><code># generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m0.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -87.45 -38.54  -6.65  33.20 112.61 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 48.6 on 99 degrees of freedom</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m0.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -87.45  -38.54   -6.65   33.20  112.61  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2359)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance: 233562  on 99  degrees of freedom
## AIC: 1063
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -45.08  -14.26    0.46   11.93   44.14  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 360)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance:  34558  on 96  degrees of freedom
## AIC: 878.3
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Nachdem wir die Baselinemodelle generiert haben, werden wir nun mit dem Modellanpassung (model fitting)beginnen. Modellanpassung bezeichnet den Prozess mit dem man zu demjenigen Modell gelangt, dass das Maximum an Varianz mit einem Minimum an Variablen erklärt. Das zugrunde liegende Prinzip ist daher das  oder , welches im Englischen häufig als Ockham’s Rasiermesser bezeichnet wird.</p>
<p>Wir werden einen automatischen step-wise step-down Prozess bei der Modellanpassung nutzen, der dasjenige Modell mit dem niedrigsten AIC (Akaike information criterion) Wert sucht. Das AIC berechnet sich nach Formel () und ist ein Maß der Sparsamkeit, dass einen Wert dafür bildet, wie viel Varianz mit wie vielen Variablen erklärt werden kann <span class="citation">[cf. @field2012discovering 318]</span>. Um so niedriger der AIC-Wert, umso besser die Balance zwischen erklärter Varianz und der Anzahl der dafür nötigen Variablen. Die AIC-Werte können nun zwischen Modellen verglichen werden, die auf die selben Datenpunkte angepasst sind (<span class="math inline">\(LL\)</span> steht für LogLikelihood und <span class="math inline">\(k\)</span> für die Anzahl der unabhängigen Variablen im Modell).</p>
<p><span class="math inline">\(-2LL + 2k\)</span>  \end{equation}</p>
<p>Beginnen wir nun mit der Modellanpassung.</p>
<pre class="r"><code># automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<pre class="r"><code># minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassugn der modellergebnisse betrachten
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<p>Basierend auf dem Modell mit dem kleinsten AIC-Wert haben wir das minimale adäquate Modell (minimal adequate model) generiert und anschließend haben wir die Zusammenfassung der Ergebnisse des Modells auswerfen lassen. Im Folgenden werden wir den Output, d.h. die Zusammenfassung der Ergebnisse des minimalen adäquaten Modells beleuchten und die verschiedenen Konzepte erläutern.</p>
<p>Das erste Objekt, was die Zusammenfassung berichtet ist der , d.h. die Formel des des minimalen adäquaten Modells. Daran anschließend wird die Verteilung der Residuen, also der Unterschiede zwischen den vorhergesagten und beobachteten Werten, berichtet. Dann folgt das wichtigste Element der Modellzusammenfassung: Die Tabelle mit den Koeffizienten der Prädikatoren des Modells (dies sind die Koeffizienten der Fixed Effects). Wir werden uns mit dieser Tabelle später genauer beschäftigen. Nach der Tabelle folgen die Modellstatistiken, die Aufschluss darüber geben, wie gut das Modell die Daten modelliert, d.h. wie gut das Modell den beobachteten Daten entspricht. Der Unterschied zwischen diesen Werten und der Tabelle mit den Koeffizienten besteht darin, dass die Modellstatistiken über die Gesamtgüte des Modells berichten, während die Tabelle mit den Koeffizienten nur etwas über die individuellen Faktoren aussagt.</p>
<p>Der multiple <span class="math inline">\(R^{2}\)</span>-Wert gibt an, wie viel Varianz das Modell erklärt. Ein Wert von 0 würde bedeuten, dass das Modell gar keine Varianz erklärt, während ein Wert von 1 bedeuten würde, dass das Modell 100% der Varianz erklärt und somit die Vorhersage des Modells genau den beobachteten Daten entspricht. Dies bedeutet, dass, wenn man den <span class="math inline">\(R^{2}\)</span>-Wert mit 100 multipliziert, man den Prozentwert der Varianz erhält, den das Modell erklärt. In unserem Fall sagt der multiple <span class="math inline">\(R^{2}\)</span>-Wert von 0.852 also aus, dass unser minimales adäquates Modell 85.2% der Varianz erklärt. Modelle, die einen multiplen <span class="math inline">\(R^{2}\)</span>-Wert von <span class="math inline">\(ge\)</span>.05 haben, gelten als substantiell signifikant (substantially significant) . Manche gehen soweit zu sagen, dass Modelle mindestens einen <span class="math inline">\(R^{2}\)</span>-Wert von <span class="math inline">\(\ge\)</span>.05 haben müssen, aber dies ist problematisch, da es durchaus vorkommen kann, dass man an sehr schwachen (aber signifikanten) Effekten interessiert ist, die aber zu einem sehr kleinen <span class="math inline">\(R^{2}\)</span>-Wert führen. Wichtiger ist, dass das Modell insgesamt signifikant ist, da dies aussagt, dass das Modell zu signifikant besseren Vorhersagen kommt, als es durch Zufall der Fall wäre.</p>
<p>Der angepasste <span class="math inline">\(R^{2}\)</span>-Wert (adjusted <span class="math inline">\(R^{2}\)</span>) berücksichtigt die Anzahl der Prädikatoren. Darüber hinaus gibt der angepasste <span class="math inline">\(R^{2}\)</span>-Wert darüber Aufschluss, wie gut sich das Modell eignet, um Aussagen über die Population (und nicht nur über die Stichprobe) zu tätigen. Wenn der Unterschied zwischen dem multiplen <span class="math inline">\(R^{2}\)</span>-Wert und dem angepassten <span class="math inline">\(R^{2}\)</span>-Wert sehr gering ist, dann bedeutet dies, dass sich das Modell dazu eignet Aussagen über die Population als Ganzes zu machen. Wenn der Unterschied allerdings relativ groß ist, dann bedeutet dies, dass das Modell instabil ist und die Datenstruktur, auf die das Modell angepasst wurde, eine suboptimale Verteilung aufweist, z.B. wegen Ausreißern. In anderen Worten bedeutet der Unterschied, dass wenn die Regression auf die Population anstatt der Stichprobe angewandt worden wäre, dann würde sie .5% weniger Varianz (85.2-84.7) erklären.</p>
<p>Kommen wir nun zu der Tabelle mit den Koeffizienten zurück. Alle Haupteffekte und eine Interaktion zwischen  und  sind signifikant. Eine Interaktion besteht dann, wenn die Korrelation zwischen einer unabhängigen und der abhängigen variable von einer anderen unabhängigen variable beeinflusst wird. In unserem Szenario geben Männer nur dann mehr Geld für ein Geschenk für eine Frau aus, wenn sie an ihr (a) interessiert sind und (b) sie Single ist. Die Korrelation zwischen  und  wird also von einer anderen Variable  beeinflusst. Wir haben es also mit einer Interaktion zwischen  und  zu tun.</p>
<p>Hinsichtlich der Interpretation dieser Ergebnisse ist festzuhalten, dass man Haupteffekte, die an Interaktionen beteiligt sind, nicht interpretieren sollte, da nicht klar ist, wie sich der Anteil an erklärter Varianz zwischen dem Haupteffekten und den Interaktionen aufteilt. Zusätzlich ist festzuhalten, dass, insofern nur Haupteffekte signifikant sind, die Koeffizienten die Korrelation zwischen der abhängigen und der unabhängigen Variable abbilden, wenn die anderen Variablen einen Wert von 0 oder das jeweilige Baseline-Level annehmen.</p>
<p>Bevor wir die Tabelle mit den Koeffizienten weiter interpretieren, werden wir noch die Konfidenzintervalle berechnen und das Baselinemodell mit dem minimalen adäquaten Modell vergleichen, um zu schauen, ob das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell.</p>
<pre class="r"><code># konfidenzintervalle der koeffizineten
confint(m2.mlr)</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre class="r"><code># vergleich zwiscehn dem baseline-modell und dem minimal adequate model
anova(m0.mlr, m2.mlr)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;)</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Vergleich der Modelle zeigt eindeutig, dass das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell. Wir werden nun mit der Modelldiagnose fortfahren, indem wir schauen, ob Datenpunkte entfernt werden sollten, da sie die Passgenauigkeit des Modells (modelfit) überproportional verschlechtern.</p>
<pre class="r"><code># suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;)</code></pre>
<pre><code>## [1] 52 83</code></pre>
<pre class="r"><code># Cooks D plot
# D-werte &gt; 4/(n-k-1) sind problematisch
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)</code></pre>
<p><img src="chi_files/figure-html/finding%20outliers-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>

<p>Die Grafiken deuten darauf hin, dass drei Datenpunkte potentiell problematisch sind (Datenpunkte 52, 64, 83). Wir werden nun diesen Eindruck statistisch evaluieren und die Datenpunkte, falls nötig entfernen.</p>
<pre class="r"><code># entfernen zu einflussreicher datenpunkte
# um dies zu tun extrahieren wir diagnostische
# werte zu allen datenpunkten und addieren die
# spalten mit diesen werten zu unserem
# datensatz hinzu
infl &lt;- influence.measures(m2.mlr)

# addieren der einflussstatistiken zu dem datensatz
mydata &lt;- data.frame(mlrdata, infl[[1]], infl[[2]])
head(mydata)</code></pre>
<pre><code>##         status    attraction money                  dfb.1_
## 1 Relationship NotInterested 86.33  0.00000000000000236805
## 2 Relationship NotInterested 45.58  0.00000000000000022805
## 3 Relationship NotInterested 68.43 -0.00000000000000091891
## 4 Relationship NotInterested 52.93 -0.00000000000000016896
## 5 Relationship NotInterested 61.86  0.00000000000000011789
## 6 Relationship NotInterested 48.47 -0.00000000000000004889
##                   dfb.sttS dfb.atNI  dfb.sS.N    dffit  cov.r     cook.d
## 1 -0.000000000000001067658  0.27414 -0.193850  0.38770 0.9358 0.03658407
## 2 -0.000000000000000396634 -0.04569  0.032306 -0.06461 1.0817 0.00105355
## 3  0.000000000000001134168  0.13140 -0.092911  0.18582 1.0491 0.00864788
## 4  0.000000000000000269812  0.01111 -0.007854  0.01571 1.0860 0.00006233
## 5 -0.000000000000000001814  0.08021 -0.056718  0.11344 1.0722 0.00324023
## 6  0.000000000000000015629 -0.02334  0.016507 -0.03301 1.0850 0.00027528
##    hat dfb.1_.1 dfb.sttS.1 dfb.atNI.1 dfb.sS.N.1 dffit.1 cov.r.1 cook.d.1
## 1 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 2 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 3 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 4 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 5 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 6 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
##   hat.1
## 1 FALSE
## 2 FALSE
## 3 FALSE
## 4 FALSE
## 5 FALSE
## 6 FALSE</code></pre>
<pre class="r"><code># zu einflussreiche datenpunkte erkennen
remove &lt;- apply(infl$is.inf, 1, function(x) {
ifelse(x == TRUE, return(&quot;remove&quot;), return(&quot;keep&quot;)) } )

# informationen zu den zu einflussreichen datenpunkten
# zum datensatz hinzuaddieren
mlrdata &lt;- data.frame(mlrdata, remove)

# zeilenzahl des alten datensatzes anzeigen
nrow(mydata)</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>mlrdata &lt;- mlrdata[mlrdata$remove == &quot;keep&quot;, ]

# zeilenzahl des neuen datensatzes anzeigen
nrow(mlrdata)</code></pre>
<pre><code>## [1] 98</code></pre>
<p>Die Zeilenzahl weist darauf hin, dass zwei potentielle Problemfälle entfernt wurden, da deren Werte inakzeptabel waren, während einer der Punkte im Modell verbleiben durfte. Da wir es nun mit einem veränderten Datensatz zu tun haben, müssen wir die bisherigen Schritte wiederholen. Die einzelnen wiederholten Schritte werden nun nicht weiter erläutert, insofern die Erläuterungen mit den bereits oben ausgeführten weitgehend identisch wäre.</p>
<pre class="r"><code># generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m0.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -76.00 -38.05  -6.39  33.15 105.66 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 46.9 on 97 degrees of freedom</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m0.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -76.00  -38.05   -6.39   33.15  105.66  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2198)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance: 213227  on 97  degrees of freedom
## AIC: 1035
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -35.76  -13.51   -0.99   10.60   38.77  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 323.5)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance:  30411  on 94  degrees of freedom
## AIC: 850.4
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>#############################
# automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre class="r"><code># minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassung der modellergebnisse betrachten
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># konfidenzintervalle der koeffizineten
confint(m2.mlr)</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre class="r"><code># vergleich zwiscehn dem baseline-modell und dem minimal adequate model
anova(m0.mlr, m2.mlr)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;)</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;)</code></pre>
<pre><code>## 84 88 
## 82 86</code></pre>
<pre class="r"><code># Cooks D plot
# D-werte &gt; 4/(n-k-1) sind problematisch
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)</code></pre>
<p><img src="chi_files/figure-html/generate%20new%20minimal%20model-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>

<p>Die diagnostischen Grafiken zeigen nun zwar weitere potentiell problematische Datenpunkte an, allerdings weichen diese Punkte weitaus weniger vom allgemeinen Trend ab, als dies bei den entfernten Punkten der Fall war. Wir berechnen dennoch diagnostische Statistiken und fügen diese zum Datensatz hinzu, um sicher zu gehen, dass nun alle Datenpunkte akzeptabel sind.</p>
<pre class="r"><code># addieren von modelldiagnostiken zum datasatz
mlrdata$residuals &lt;- resid(m2.mlr)
mlrdata$standardized.residuals &lt;- rstandard(m2.mlr)
mlrdata$studentized.residuals &lt;- rstudent(m2.mlr)
mlrdata$cooks.distance &lt;- cooks.distance(m2.mlr)
mlrdata$dffit &lt;- dffits(m2.mlr)
mlrdata$leverage &lt;- hatvalues(m2.mlr)
mlrdata$covariance.ratios &lt;- covratio(m2.mlr)
mlrdata$fitted &lt;- m2.mlr$fitted.values</code></pre>
<p>Wir nutzen nun die hinzugefügten Diagnosewerte um neue diagnostische Grafiken zu erstellen.</p>
<pre class="r"><code># erstellen diagnostischer grafiken
# (drei grafiken in einem fenster)
p1 &lt;- histogram&lt;-ggplot(mlrdata, aes(studentized.residuals)) +
theme(legend.position = &quot;none&quot;) +
geom_histogram(aes(y=..density..),
binwidth = 1,
colour=&quot;black&quot;,
fill=&quot;white&quot;) +
labs(x = &quot;Studentized Residual&quot;, y = &quot;Density&quot;)
p2 &lt;- histogram + stat_function(fun = dnorm, args = list(mean = mean(mlrdata$studentized.residuals, na.rm = TRUE), sd = sd(mlrdata$studentized.residuals, na.rm = TRUE)), colour = &quot;red&quot;, size = 1)
p3 &lt;- scatter &lt;- ggplot(mlrdata, aes(fitted, studentized.residuals))
p4 &lt;- scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;)+ labs(x = &quot;Fitted Values&quot;, y = &quot;Studentized Residual&quot;)
p5 &lt;- qqplot.resid &lt;- qplot(sample = mlrdata$studentized.residuals, stat=&quot;qq&quot;) + labs(x = &quot;Theoretical Values&quot;, y = &quot;Observed Values&quot;)</code></pre>
<pre><code>## Warning: `stat` is deprecated</code></pre>
<pre class="r"><code>p6 &lt;- qqplot.resid
multiplot(p2, p4, p6, cols=3)</code></pre>
<p><img src="chi_files/figure-html/generate%20new%20diagnostic%20plots-1.png" width="672" /></p>

<p>Die Grafiken zeigen keine auffälligen Ausreißer. Wir überprüfen diesen Eindruck dennoch statistisch. Hierzu lässt sich folgendes sagen:</p>
<ul>
<li><p>Datenpunkte mit standardisierten Residuenwerten &gt; 3.29 sollten entfernt werden <span class="citation">[@field2012discovering 269]</span></p></li>
<li><p>Wenn mehr als 1% der Datenpunkte standardisierte Residuenwerte <span class="math inline">\(\ge\)</span> 2.58, so ist der Fehleranteil des Modells inakzeptabel <span class="citation">[@field2012discovering 269]</span></p></li>
</ul>
<p>*Wenn mehr als 5% der Datenpunkte standardisierte Residuenwerte <span class="math inline">\(\ge\)</span> 1.96 haben, so ist der Fehleranteil des Modells inakzeptabel <span class="citation">[@field2012discovering 269]</span></p>
<ul>
<li><p>Zusätzlich sollten Datenpunkte mit Cooks D-Werten <span class="math inline">\(\ge\)</span> 1 entfernt werden</p></li>
<li><p>Schließlich sollten Leveragewerte <span class="math inline">\(3(k + 1)/n\)</span> (k = Anzahl der Prädikatoren, N = Anzahl der Datenpunkte) nicht überschreiten </p></li>
<li><p>Es sollte keine Autokorrelation innerhalb der unabhängigen Variablen vorliegen, d.h. eine Variable darf nicht mit sich selbst korrelieren (ist dies der Fall muss ein Repeated Measures Design oder ein hierarchisches Regressionsmodell genutzt werden)</p></li>
<li><p>Unabhängige Variablen dürfen untereinander nicht stark korrelieren (Multikollinearität). Daher gilt, dass Datenpunkte mit Varianzinflationsfaktorenwerten (VIF) <span class="math inline">\(\ge\)</span> 10 entfernt werden sollten <span class="citation">[@myers1990classical]</span>. Es können aber bereits Werte von 2.5 problematisch sein <span class="citation">[@szmrecsanyi2006morphosyntactic 215]</span>!</p></li>
<li><p>Datenpunkte mit 1/VIF Werten <span class="math inline">\(&lt;\)</span> .1 müssen entfernt werden (ab .2 gelten die Datenpunkte als problematisch) <span class="citation">[@menard1995applied]</span></p></li>
<li><p>Der Mittelwert der VIFs sollte <span class="math inline">\(&lt;\)</span> 1 sein <span class="citation">[@bowerman1990linear]</span></p></li>
</ul>
<pre class="r"><code># 1: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$standardized.residuals &gt; 3.29)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 2: optimal = 1
# (aufgelistete datenpunkte sollten entfernt werden)
stdres_258 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 2.58, 1, 0) } ))
(sum(stdres_258) / length(stdres_258)) * 100</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># 3: optimal = 5
# (aufgelistete datenpunkte sollten entfernt werden)
stdres_196 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 1.96, 1, 0) } ))
(sum(stdres_196) / length(stdres_196)) * 100</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre class="r"><code># 4: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$cooks.distance &gt; 1)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 5: optimal = 0
# (datenpunkte sollten entfernt werden, wenn cooks distanz nahe 1 ist)
which(mlrdata$leverage &gt;= (3*mean(mlrdata$leverage)))</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 6: checking autocorrelation:
# Durbin-Watson test (optimal: grosser p-wert)
dwt(m2.mlr)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968   0.668
##  Alternative hypothesis: rho != 0</code></pre>
<pre class="r"><code># 7: multicolliniaritaet testen 1
vif(m2.mlr)</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre class="r"><code># 8: multicolliniaritaet testen 2
1/vif(m2.mlr)</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre class="r"><code># 9: mittlerer vif wert sollte nicht groesser als 1 sein
mean(vif(m2.mlr))</code></pre>
<pre><code>## [1] 2.307</code></pre>
<p>Bis auf den Mittelwert der VIFs, der <span class="math inline">\(&lt;\)</span> 1 sein sollte, tatsächlich aber 2.307 beträgt, sind alle diagnostischen Werte völlig akzeptabel. Wir werden nun testen, ob die Stichprobengröße in unserer Untersuchung ausreicht. Basierend auf <span class="citation">[@green1991many]</span> geben <span class="citation">[@field2012discovering 273-274]</span> zur Mindestgröße der benötigten Stichprobe Daumenregeln an die Hand (k = Anzahl der Prädikatoren; kategorische Prädikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):</p>
<ul>
<li><p>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</p></li>
<li><p>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</p></li>
<li><p>Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen.</p></li>
</ul>
<p>Zusätzlich werden wir prüfen, wie groß der Wert für <code>R</code> basierend auf einer Zufallsstichprobe wäre, um abschätzen zu können, wie groß die Wahrscheinlichkeit eines <span class="math inline">\(\beta\)</span>-Fehlers bei der vorliegenden Stichprobengröße ist <span class="citation">[vgl. @field2012discovering 274]</span>. Bei <span class="math inline">\(\beta\)</span>-Fehlern handelt es sich um die Annahme, ein Prädikator ist nicht signifikant, obwohl er tatsächlich einen signifikanten Einfluss hat (siehe Sektion ). Die Prüfgröße schwankt zwischen 0 und 1. Umso kleiner der Wert ist, umso besser. Wenn der Wert <span class="math inline">\(\ge\)</span> 1 liegt, dann gibt es Grund zur Sorge und es sollte eine größere Stichprobe gezogen werden.</p>
<pre class="r"><code># ist die stichprobe ausreichend gross
smplesz(m2.mlr)</code></pre>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre class="r"><code># gefahr von beta-fehlern
expR(m2.mlr)</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<p>Die Funktion <code>smplesz</code> teilt mit, dass die Stichprobengröße nicht optimal ist und 9 Datenpunkte fehlen, um der Anforderung von <span class="citation">[@green1991many]</span> zu genügen. Die Wahrscheinlichkeit einen <span class="math inline">\(\beta\)</span>-Fehler zu begehen ist hingegen sehr klein (0.0309). Als letzten Schritt tabellarisieren wir die Ergebnisse und fassen diese anschließend in Textform zusammen.</p>
<pre class="r"><code># ergebnisse der mlr betrachten
mlr.summary(m2.mlr, m2.glm, ia = T)</code></pre>
<pre><code>## Waiting for profiling to be done...
## Waiting for profiling to be done...</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%) CI(97.5%)
## (Intercept)                             99.15          92.1    106.21
## statusSingle                            55.85    2    45.78     65.93
## attractionNotInterested                -47.66 1.96   -57.63    -37.69
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71    -45.21
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                                                          
##                                               Std. Error      t value
## (Intercept)                                          3.6        27.56
## statusSingle                                        5.14        10.87
## attractionNotInterested                             5.09        -9.37
## statusSingle:attractionNotInterested                7.27        -8.18
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                          F-statistic: 188.36 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>

<p>Zusätzlich werden die Ergebnisse von multiplen linearen Regressionen schriftlich wie folgt zusammengefasst:</p>
<p>(Falls signifikante Interaktionen vorliegen, sollten die Haupteffekte der Prädikatoren, die an der/n Interaktion/en beteiligt sind, nicht interpretiert werden. Sie werden hier dennoch interpretiert, um zu verdeutlichen, wie die Ergebnisse einer multiplen linearen Regression verschriftlicht werden können.)</p>
<p>Eine multiple lineare Regression wurde mit AIC-basierter (Akaike’s Information Criterion) step-wise step-down Prozedur auf die Daten angepasst, um zum finalen minimalen adäquaten Modell zu gelangen. Während der Modelldiagnose wurden zwei Datenpunkte als Ausreißer ermittelt und aus dem Datensatz entfernt. Weitere modelldiagnostischen Grafiken und zusätzliche statistische Modelldiagnosen ergaben nach dem Entfernen der Ausreißer keine weiteren Auffälligkeiten.</p>
<p>Das finale minimale adäquate Modell basiert auf 98 Datenpunkten und korreliert hoch signifikant mit dem Datensatz (Multipler <span class="math inline">\(R^{2}\)</span>: .857, Angepasster <span class="math inline">\(R^{2}\)</span>: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p<span class="math inline">\(&lt;.001***\)</span>). Das finale minimale adäquate Modell enthält sowohl  und  als signifikante Haupteffekte. Der Status von Geschenk-empfängern korreliert hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.14, <span class="math inline">\(t\)</span>-Wert: 10.87, p<span class="math inline">\(&lt;.001***\)</span>). Dies zeigt, dass wenn eine Person single ist, ihr Geschenk {55,85} mehr wert ist, verglichen mit dem Fall, dass sie in einer Beziehung ist (in diesem Fall ist das Geschenk {99.15}, wenn der Schenker nicht an der Beschenkten interessiert ist. Der Faktor  korreliert ebenfalls hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.09, <span class="math inline">\(t\)</span>-Wert: -9.37, p<span class="math inline">\(&lt;.001***\)</span>). Falls der Schenkende nicht an der Beschenkten interessiert ist, dann gibt er {-47.66} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er sie attraktiv findet (vorausgesetzt die Beschenkte ist in einer Beziehung). Schließlich weist das finale minimale adäquate Modell eine hoch signifikante Interaktion zwischen  und  nach (SE: 7.27, <span class="math inline">\(t\)</span>-Wert: -8.18, p<span class="math inline">\(&lt;\)</span>.001***): Wenn die Beschenkte ein Single ist, aber der Schenker nicht an ihr interessiert ist, dann gibt der Schenker {59,46} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er an der Beschenkten interessiert ist (vgl. Figure ).</p>
</div>
<div id="regression-excersies" class="section level2">
<h2><span class="header-section-number">4.2</span> Regression Excersies</h2>
<ol style="list-style-type: decimal">
<li>Laden sich sich den Datensatz  herunter von \ und wenden Sie das Gelernte an, indem Sie eine multiple lineare Regression durchführen, um herauszufinden, ob sich Bewegung (move) und Essgewohnheiten (food) auf das Gewicht auswirkt (weight). \end{enumerate}</li>
</ol>
</div>
</div>
<div id="outlook-mixed-effects-models" class="section level1">
<h1><span class="header-section-number">5</span> Outlook: Mixed-Effects Models </h1>
<p>Ohne es genauer zu spezifizieren haben wir bisher nur mit Fixed-Effects gearbeitet, d.h. alle Datenpunkte werden so betrachtet, als ob sie auf der gleichen Hierarchieebene liegen. Häufig ist es aber so, dass Datenpunkte keine flache, sondern eine hierarchische Struktur haben, da beispielsweise mehrere Datenpunkte von demselben Sprecher stammen. Um der hierarchischen Struktur Rechnung zu tragen, muss man diese auch modellieren, was mit Hilfe von  geschehen kann.</p>

<p> haben zwei Ausprägungen:  (rechtes Panel Grafik ) und  (mittleres Panel Grafik ). Wir werden uns im Folgenden auf  konzentrieren, da dies die weitaus gebräuchlichere Variante ist. Um zu beschreiben, worum es sich bei  handelt, fokussieren wir uns auf Grafik .</p>

<p>Im mittleren Panel von Grafik  wird genau eine Regressionsgrade genutzt, um Werte vorherzusagen. Wenn wir  für die drei Gruppen einführen, so entsteht für jede Ausprägung des , d.h. für jede Gruppe, eine eigene Regressionsgerade.</p>
<p>Nachdem Random Slopes eingeführt sind, werden, wie bei der multiplen Regression, Prädiktoren (Ffixed Effekte) hinzugefügt, d.h. Mixed-Effects Modelle werden Mixed-Effects Modelle genannt, weil Sie sowohl Random Effekte (meistens Random Intercepts) und einfache Prädiktoren (Fixed Effekte) beinhalten.</p>
<p>Was die Vorgehensweise betrifft, so lässt sich sagen, dass zuerst die Random Effektstruktur eingebaut und evaluiert wird und erst im Anschluß die Fixed Effekte in das Model aufgenommen werden . Man testet, ob das Einfügen von Random Effekten berechtigt ist, indem man ein Model, das nur den Intercept als Prädiktoren hat gegen ein Model, welches nur die Random Intercepts als Prädiktoren hat. Ist die Varianz bei dem Random Effects Modell geringer, so war das Einfügen der Random Intercepts berechtigt.</p>
%

<p>% %Nachdem die Sitzung nun vorbereitet ist, kann mit dem Einlesen der Daten begonnen werden. Es ist allerdings unbedingt zu bedenken, dass, um de folgenden Code nutzen zu können, eine aktive Internetverbindung benötigt wird und, dass die %Pfade auf den eigenen Rechner angepasst werden müssen!</p>
%

%Wie bereits bei edr einfachen linearen Regression werden wir die numerischen Variablen skalieren. Skalieren bedeutet, dass der Mittelwert der numerischen Variable von jedem Wert dieser Variable abgezogen wird. % %

</div>
<div id="references" class="section level1">
<h1><span class="header-section-number">6</span> References</h1>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
