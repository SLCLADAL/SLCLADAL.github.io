<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-09-29" />

<title>Descriptive Statistics with R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    NEWS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="news.html">News &amp; Announcements</a>
    </li>
    <li>
      <a href="conferences.html">Events &amp; Presentations</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="introcomputer.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="reproducibility.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="IntroR_workshop.html">Getting started</a>
    </li>
    <li>
      <a href="stringprocessing.html">String Processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular Expressions</a>
    </li>
    <li>
      <a href="introtables.html">Working with Tables</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="basicgraphs.html">Common Visualization Types</a>
    </li>
    <li>
      <a href="basicgraphs.html">Advanced Visualization Methods</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
    <li>
      <a href="vc.html">Creating Vowel Charts with Praat and R</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES &amp; CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Descriptive Statistics with R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-09-29</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial focuses on how to describe and summarize data <span class="citation">(see e.g. Bickel and Lehmann <a href="#ref-bickel2012descriptive" role="doc-biblioref">2012</a>; Thompson <a href="#ref-thompson2009descriptive" role="doc-biblioref">2009</a>)</span>. The entire R markdown document for this tutorial can be downloaded <a href="https://slcladal.github.io/descriptivestatz.Rdm">here</a>.</p>
<p>To show why data summaries are useful, think of the following: you are teaching two different classes in the same school, in the same grade, and at the same level. Both classes take the same exam and, after correcting and grading the exams, someone asks you which class performed better. You could of course say something along the lines of “Well, class A had 5 Bs, 10 Cs, 12 Ds, and 2 Fs while class B had 2 As, 8 Bs, 10 Ds, and 4 Fs” but this answer is not really satisfying. Descriptive statistics enable you to summarize complex data sets in very few words and using only very basic, and easy to understand, concepts. And this is what we will be dealing with in the following.</p>
<p>Before delving deeper into what descriptive statistics is, it is useful to have a general idea of how it can be contextualized. Thus, on a more general note, we will be dealing only with one particular subbranch of statistics. Statistics in general can be defined as a branch of mathematics that deals with data collection, organization, analysis, interpretation, and presentation. As such, statistics can be subdivided into two main areas. <em>Descriptive statistics</em> deals with the description of data and their visualization, while <em>inferential statistics</em> deals with data analysis and interpretation. Typically, this means testing assumptions about correlations between variables (see for example <a href="https://slcladal.github.io/basicstatzregression.html">here</a>). As stated above, here, we will be dealing with the description of data, especially with <em>measures of central tendency</em>, <em>measures of variability</em> and <em>confidence intervals</em>.</p>
<p><strong>Preparation and session set up</strong></p>
<p>As all calculations and visualizations in this tutorial rely on “R”, it is necessary to install “R” and “RStudio”. If these programs (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the libraries by running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)
# install packages
install.packages(c(&quot;boot&quot;, &quot;DescTools&quot;, &quot;dplyr&quot;, &quot;knitr&quot;, &quot;psych&quot;, 
                   &quot;Rmisc&quot;, &quot;stringr&quot;))</code></pre>
<p>After having installed the packages, we have to activate them by running the code below.</p>
<pre class="r"><code># activate packages
library(boot)
library(DescTools)
library(dplyr)
library(knitr)
library(psych)
library(Rmisc)
library(stringr)</code></pre>
<p>Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="measures-of-centrality" class="section level1">
<h1><span class="header-section-number">2</span> Measures of Centrality</h1>
<p>In linguistics three measures of centrality or measures of central tendency are of particular relevance: the <em>mean</em>, the <em>median</em> and the <em>mode</em> <span class="citation">(Gaddis and Gaddis <a href="#ref-gaddis1990introduction" role="doc-biblioref">1990</a>)</span>. In addition, there are two more measures of central tendency, the geometric and the harmonic mean which we will only briefly discuss as they are not that relevant for language research. What measure is appropriate depends on the type of variable scaling, the distribution of the data, and what is the intended aim of the data summary.</p>
<table>
<caption>Measures of central tendency and their use.</caption>
<colgroup>
<col width="23%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Means</th>
<th align="left">Use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Arithmetic) mean (average)</td>
<td align="left">Description of normally distributed numeric variables (most common measure of central tendency)</td>
</tr>
<tr class="even">
<td align="left">Median (middle value)</td>
<td align="left">Description of non-normal numeric variables or ordinal variables (skewed data or influential outliers)</td>
</tr>
<tr class="odd">
<td align="left">Mode (most frequent value)</td>
<td align="left">Description of nominal and categorical variables</td>
</tr>
<tr class="even">
<td align="left">Geometric mean (average factor)</td>
<td align="left">Description of dynamic processes such as growth rates</td>
</tr>
<tr class="odd">
<td align="left">Harmonic mean (average rate)</td>
<td align="left">Description of dynamic processes such as velocities</td>
</tr>
</tbody>
</table>
<p>In the following we will go over these types of measures of central tendencies, exemplify their use, describe their strengths and weaknesses, and show how to calculate them in R.</p>
<div id="mean" class="section level2">
<h2><span class="header-section-number">2.1</span> Mean</h2>
<p>The mean is used when the data is numeric and normally distributed. The mean is calculated by applying the formula shown below.</p>
<p><span class="math display">\[\begin{equation}
  \bar{x}=\frac{1}{n} \sum_{i=1}^n x_i = \frac{x_{1}+x_{2}+ \dots + x_{n}}{n}
\end{equation}\]</span></p>
<p>To calculate the mean, sum up all values and divide by the number of values. See the example below for clarification.</p>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Consider, we are interested in the mean length of sentences in a short text, then the first thing we could do would be to list the sentences and their length in a table.</p>
<table>
<caption>Sentences of the first paragraph of Herman Melville’s <em>Moby Dick</em> and the number of words in each sentence.</caption>
<colgroup>
<col width="98%" />
<col width="1%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Sentences</th>
<th align="right">Words</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Call me Ishmael</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Some years ago – never mind how long precisely – having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.</td>
<td align="right">40</td>
</tr>
<tr class="odd">
<td align="left">It is a way I have of driving off the spleen, and regulating the circulation.</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left">Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people’s hats off–then, I account it high time to get to sea as soon as I can.</td>
<td align="right">87</td>
</tr>
</tbody>
</table>
<p>To calculate the mean, we need to divide the sum of the number of words per sentence (145) by the number of sentences (7) (see the equation below).</p>
<p><span class="math display">\[\begin{equation}
\frac{3+40+15+87}{4} = \frac{145}{4} = 36.25
\label{eq:mittel2}
\end{equation}\]</span></p>
<p>The mean sentences length in our example is 36.25 words</p>
<p>In R, the <em>mean</em> is calculated as follows.</p>
<pre class="r"><code># create numeric vector
frequencies &lt;- c(3, 40, 15, 87)
# calculate mean
mean(frequencies)</code></pre>
<pre><code>## [1] 36.25</code></pre>
</div>
<div id="median" class="section level2">
<h2><span class="header-section-number">2.2</span> Median</h2>
<p>The median is typically used when dealing with ordinal variables, i.e. variables that are ordered but not truly numeric. The median is the central value in a de- or increasing ordering of values in a vector. In other words, 50 percent of values are above and 50 percent of values are below the median in a given vector.</p>
<p>If the vector contains an even number of elements, then the two central values are summed up and divided by 2. If the vector contains an uneven number of elements, the median represents the central value.</p>
<p><span class="math display">\[\begin{equation}
median_{x}=
\begin{cases}
x_{\frac{n+1}{2}} &amp; n\text{ uneven} \\
\frac{1}{2}\bigl(x_{\frac{n}{2}}+x_{\frac{n+1}{2}}\bigr) &amp; n\text{ even}
\end{cases}
\label{eq:median}
\end{equation}\]</span></p>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Let’s have a look at an example. Consider you are interested in the age stratification of speakers in the private dialogue section of the Irish component of the <em>International Corpus of English</em> (ICE). When tabulating and plotting the age variable you get the following table and graph.</p>
<table>
<caption>Number of speakers across age groups in the private dialogue section of the Irish component of the <em>International Corpus of English</em> (ICE)</caption>
<thead>
<tr class="header">
<th align="left">Age</th>
<th align="right">Counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0-10</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left">19-25</td>
<td align="right">160</td>
</tr>
<tr class="odd">
<td align="left">26-33</td>
<td align="right">70</td>
</tr>
<tr class="even">
<td align="left">34-41</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="left">42-49</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left">50+</td>
<td align="right">57</td>
</tr>
</tbody>
</table>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The age groups represent an order factor which means that there are categories with a natural order (here from old to young or vice versa). If we order speakers according to their age from young to old, we get a vector of length 320. If we then take the central value, i.e. the value of the 160<sup>th</sup> speaker, we get the median age in the private dialogue section of the Irish component of the <em>International Corpus of English</em> (ICE).</p>
<p>In R, the <em>median</em> is calculated as shown below.</p>
<pre class="r"><code># create a vector consisting out of ranks
ranks &lt;- c(rep(1, 9), rep(2, 160), rep(3, 70), rep(4, 15), rep(5, 9), rep(6, 57))
# calculate median
median(ranks)</code></pre>
<pre><code>## [1] 2</code></pre>
<p>In our case, the median age is <em>19-25</em> because the 160<sup>th</sup> speaker belongs to the 2<sup>nd</sup> age group, i.e. the age group with speakers between 19 and 25 years old.</p>
</div>
<div id="mode" class="section level2">
<h2><span class="header-section-number">2.3</span> Mode</h2>
<p>The mode is typically used when dealing with categorical variables and it reports which level of a factor or a categorical variable is the most frequent.</p>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Here is an example to illustrate the mode. Consider you are interested where most speakers in the private dialogue section of the Irish component of the <em>International Corpus of English</em> are currently residing and you get the following distribution.</p>
<table>
<caption>Number of speakers across counties of current residency in the private dialogue section of the Irish component of the <em>International Corpus of English</em> (ICE)</caption>
<thead>
<tr class="header">
<th align="left">CurrentResidence</th>
<th align="right">Speakers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Belfast</td>
<td align="right">98</td>
</tr>
<tr class="even">
<td align="left">Down</td>
<td align="right">20</td>
</tr>
<tr class="odd">
<td align="left">Dublin (city)</td>
<td align="right">110</td>
</tr>
<tr class="even">
<td align="left">Limerick</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="left">Tipperary</td>
<td align="right">19</td>
</tr>
</tbody>
</table>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The tabulated and visualized data show that the mode is <em>“Dublin (City)”</em>, because the largest group (110 speakers) of speakers in the corpus are speakers from the city of Dublin. This means that the “average” speaker in in the private dialogue section of the Irish component of the <em>International Corpus of English</em> (ICE) is from Dublin city.</p>
<p>In R the <em>mode</em> is calculated as shown below:</p>
<pre class="r"><code># create a factor with the current residence of speakers
CurrentResidence &lt;- c(rep(&quot;Belfast&quot;, 98),         # repeat &quot;Belfast&quot; 98 times
                      rep(&quot;Down&quot;, 20),            # repeat &quot;Down&quot; 20 times
                      rep(&quot;Dublin (city)&quot;, 110),  # repeat &quot;Dublin (city)&quot; 110 times
                      rep(&quot;Limerick&quot;, 13),        # repeat &quot;Limerick&quot; 13 times
                      rep(&quot;Tipperary&quot;, 19))       # repeat &quot;Tipperary&quot; 19 times
# calculate mode
names(which.max(table(CurrentResidence)))         # extract which level occurs most frequently</code></pre>
<pre><code>## [1] &quot;Dublin (city)&quot;</code></pre>
<p>A word of warning is in order here as only the first(!) maximal value is provided by R even if several categories have the same frequency.</p>
</div>
<div id="geometric-mean" class="section level2">
<h2><span class="header-section-number">2.4</span> Geometric mean</h2>
<p>The geometric mean represents a measure of central tendency that is used when dealing with dynamic processes where the later elements are dependent on the previous elements. The geometric mean is calculated according to the equation below.</p>
<p><span class="math display">\[\begin{equation}
\bar{x}_{geometric} = \sqrt[n]{x_1 \times x_{i+1} \times \dots \times x_n}
\end{equation}\]</span></p>
<p>Imagine you have the option to buy two different stock packages and you have to buy one of them. Which one would you buy?</p>
<table>
<caption>Performance of two stock packages.</caption>
<thead>
<tr class="header">
<th align="left">Year</th>
<th align="left">Package1</th>
<th align="left">Package2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Year 1</td>
<td align="left">+5%</td>
<td align="left">+20%</td>
</tr>
<tr class="even">
<td align="left">Year 2</td>
<td align="left">-5%</td>
<td align="left">-20%</td>
</tr>
<tr class="odd">
<td align="left">Year 3</td>
<td align="left">+5%</td>
<td align="left">+20%</td>
</tr>
<tr class="even">
<td align="left">Year 4</td>
<td align="left">-5%</td>
<td align="left">-20%</td>
</tr>
</tbody>
</table>
<p>Is one package better than the other? Did one package perform better than the other?</p>
<ul>
<li>Package 1:
<ul>
<li>Return: <span class="math inline">\(1.05 \times .95 \times 1.05 \times .95 = .995\)</span> (0.5% loss)</li>
<li>Year-over-year average: <span class="math inline">\(.995^{1/4}\)</span> = ~0.125% loss per year</li>
</ul></li>
<li>Package 2:
<ul>
<li>Return: <span class="math inline">\(1.2 \times .8 \times 1.2 \times .8 = 0.9216\)</span> (7.84% loss)</li>
<li>Year-over-year average: <span class="math inline">\(.9216^{1/4}\)</span> = ~2% loss per year.</li>
</ul></li>
</ul>
<p>Package 2 performs substantially worse because here, the changes in growth depend on the previous growth rates.</p>
</div>
<div id="harmonic-mean" class="section level2">
<h2><span class="header-section-number">2.5</span> Harmonic mean</h2>
<p>The harmonic mean is a measure of central tendency that provides us with the average rate and is used when dealing with dynamic processes that involve velocities and distances. The harmonic mean is calculated according to the equation below.</p>
<p><span class="math display">\[\begin{equation}
\bar{x}_{harmonic} = 
\frac{n}{\frac{1}{x_i} + \frac{1}{x_{i+1}} + \frac{1}{x_{i+\dots}} + \frac{1}{x_n}}
\end{equation}\]</span></p>
<p>Let’s use an example to see what the harmonic mean describes. Imagine you assign group projects to students and you are interested in the average time it takes them to finalize the projects. The cruial thing is that the end state is the same: the finished project.</p>
<p>Let us say there are two groups, group A and group B. It takes group A 30 hours and group B 60 hours to finish their project. What is the average rate at which these two groups have finished their projects? If we used the arithmetic mean, we would say it takes them on average 45 hours to finish their projects but this is not appropriate in the present case.</p>
<p><span class="math display">\[\begin{equation}
\bar{x}_{harmonic} = 
\frac{2}{\frac{1}{30} + \frac{1}{60}} = \frac{2}{\frac{2}{60} + \frac{1}{60}} = \frac{2}{\frac{3}{60}} = \frac{2}{1} \times \frac{60}{3} = \frac{120}{3} = 40
\end{equation}\]</span></p>
<p>The harmonic mean is used when two rates contribute to the same workload (for instance when we download a file). Each instalment is in a relay race and contributes the same amount to the issue. For example, we make a round trip to work and back. The way to work is 60 kilometres. On the way to work, we can only travel at 30 kph while we can go 60 kph on the way back. The distance is the same. Half of the results (distance travelled) comes from the first rate (30 kilometres per hour) and the other half from the second rate (60 kilometres per hour). The result is that is takes us 3 hours to get to work and back.</p>
<p>The reason why using the arithmetic mean is inappropriate in such cases is the following: The idea behind the arithmetic mean is that we calculate a single value that can replace all values in a given distribution and the sum of the mean values is identical to the sum of the observed values. So, the average is a single element that replaces each element. In our example, we have to drive at 40 kilometres per hour (instead of 30) to work and 40 kilometres per hour (instead of 60) to get back from work in the same amount of time. If we went with 45 kilometres pe hour, then the result would not be 3 hours but 2 hours and 40 minutes so that the result would not be the same.</p>
</div>
<div id="notes-on-measures-of-centrality" class="section level2">
<h2><span class="header-section-number">2.6</span> Notes on Measures of Centrality</h2>
<p>You may ask yourself why there are three different types to calculate the central tendency of a why this is necessary. To answer these questions, consider the following example: Imagine you are interested whether the use of discourse particles differs across two corpora that represent the speech of the same five speakers but different registers. In a first step, you calculate the relative frequency of discourse particle use and both corpora have a mean of 13.4 particles per 1,000 words. Given the mean, the two corpora do not seem to differ. However, when tabulating and plotting the use of particles by speaker across these two corpora we will become immediately aware of the fact that the mean is not the appropriate measure of the central tendency in situations where distributions are very dissimilar.</p>
<table>
<caption>Relative frequencies of discourse particles per speaker in two corpora</caption>
<thead>
<tr class="header">
<th align="left">Corpus</th>
<th align="left">Speaker</th>
<th align="right">Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C1</td>
<td align="left">A</td>
<td align="right">5.2</td>
</tr>
<tr class="even">
<td align="left">C1</td>
<td align="left">B</td>
<td align="right">11.4</td>
</tr>
<tr class="odd">
<td align="left">C1</td>
<td align="left">C</td>
<td align="right">27.1</td>
</tr>
<tr class="even">
<td align="left">C1</td>
<td align="left">D</td>
<td align="right">13.7</td>
</tr>
<tr class="odd">
<td align="left">C1</td>
<td align="left">E</td>
<td align="right">9.6</td>
</tr>
<tr class="even">
<td align="left">C2</td>
<td align="left">A</td>
<td align="right">0.2</td>
</tr>
<tr class="odd">
<td align="left">C2</td>
<td align="left">B</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">C2</td>
<td align="left">C</td>
<td align="right">1.1</td>
</tr>
<tr class="odd">
<td align="left">C2</td>
<td align="left">D</td>
<td align="right">93.7</td>
</tr>
<tr class="even">
<td align="left">C2</td>
<td align="left">E</td>
<td align="right">0.4</td>
</tr>
</tbody>
</table>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>The Figure above shows that the use of discourse particles is distributed rather evenly across speakers in Corpus 1 while 4 out of 5 speakers use almost no discourse particles in Corpus 2 - only speaker D makes extensive use of discourse particles in corpus 2. The high usage frequency of discourse particles by speaker D in corpus 2 causes the mean of corpus 2 to be identical to the mean reported for corpus 1 although the distribution of usage rates differs drastically. This means that reporting the median in addition to the mean can be useful even for numeric variables if the distribution of values is very dissimilar.</p>
<p>To exemplify, we will summarize the distribution of discourse particles in the two corpora: The use of discourse particles in corpus 1 (mean = 13.7, median = 11.4) is substantially different from the use of discourse particles in corpus 2 (mean = 13.7, median = 0.4).</p>
<p>It is important to keep in mind that - similar to variable scales - measures of central tendency are downward compatible but not upward compatible. This means that one may report the median and mode for numeric variables but the mean may only be used for numeric variables but not for categorical variables. In the following, we have a look at another, more common, way to describe the differences in the distribution between the two corpora, namely, measures of variability.</p>
</div>
</div>
<div id="measures-of-variability" class="section level1">
<h1><span class="header-section-number">3</span> Measures of Variability</h1>
<p>Measures of variability provide information about the distribution of values such as whether the data are distributed evenly and do not differ substantially or whether the data are rather heterogeneous and are distributed very unevenly <span class="citation">(Thompson <a href="#ref-thompson2009descriptive" role="doc-biblioref">2009</a>)</span>. In the following, we will have a look at the <em>variance</em> and the <em>standard deviation</em>.</p>
<p>As before, we will use a practical example to see the usefulness of applying measures of variability. Imagine you dealing with two cities that have the same mean temperature per year. However, the variability of temperatures varies differs dramatically between the two cities.</p>
<table>
<caption>Average temperature in two cities by month</caption>
<thead>
<tr class="header">
<th align="left">Month</th>
<th align="right">CityA</th>
<th align="right">CityB</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">January</td>
<td align="right">-5.00</td>
<td align="right">7.00</td>
</tr>
<tr class="even">
<td align="left">February</td>
<td align="right">-12.00</td>
<td align="right">7.00</td>
</tr>
<tr class="odd">
<td align="left">March</td>
<td align="right">5.00</td>
<td align="right">8.00</td>
</tr>
<tr class="even">
<td align="left">April</td>
<td align="right">12.00</td>
<td align="right">9.00</td>
</tr>
<tr class="odd">
<td align="left">May</td>
<td align="right">15.00</td>
<td align="right">10.00</td>
</tr>
<tr class="even">
<td align="left">June</td>
<td align="right">18.00</td>
<td align="right">13.00</td>
</tr>
<tr class="odd">
<td align="left">July</td>
<td align="right">22.00</td>
<td align="right">15.00</td>
</tr>
<tr class="even">
<td align="left">August</td>
<td align="right">23.00</td>
<td align="right">15.00</td>
</tr>
<tr class="odd">
<td align="left">September</td>
<td align="right">20.00</td>
<td align="right">13.00</td>
</tr>
<tr class="even">
<td align="left">October</td>
<td align="right">16.00</td>
<td align="right">11.00</td>
</tr>
<tr class="odd">
<td align="left">November</td>
<td align="right">8.00</td>
<td align="right">8.00</td>
</tr>
<tr class="even">
<td align="left">December</td>
<td align="right">1.00</td>
<td align="right">7.00</td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="right">10.25</td>
<td align="right">10.25</td>
</tr>
</tbody>
</table>
<p><img src="descriptivestatz_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>In the following, we will discuss and calculate different measures of variability for the two cities.</p>
<div id="range" class="section level2">
<h2><span class="header-section-number">3.1</span> Range</h2>
<p>The range is the simples measure of variability and reports the lowest and highest value of a distribution. That is, the range provides minimum and maximum of a vector to show the span of values within a distribution.</p>
<p>In R, the <em>range</em> is extracted as shown below.</p>
<pre class="r"><code># create a numeric vector
cityA &lt;- c(-5, -12, 5, 12, 15, 18, 22, 23, 20, 16, 8, 1)
min(cityA); max(cityA) # extract range</code></pre>
<pre><code>## [1] -12</code></pre>
<pre><code>## [1] 23</code></pre>
<p>The lowest temperature value for city A is -12 degrees Celsius and the highest value is 23 degrees Celsius. The range thus spans from -12 to 23.</p>
</div>
<div id="interquartile-range-iqr" class="section level2">
<h2><span class="header-section-number">3.2</span> Interquartile range (IQR)</h2>
<p>The interquartile range (IQR) informs about how values are distributed and it denotes the range that encompasses 50 percent of data points. This means that the IQR spans from the first quantile that encompasses 25 percent of the data to the third quartile that encompasses 75 percent of the data.</p>
<p>The easiest way to extract the IQR in R is to apply the “summary” function to a vector as shown below.</p>
<pre class="r"><code>summary(cityA) # extract IQR</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -12.00    4.00   13.50   10.25   18.50   23.00</code></pre>
<p>The “summary” function reports that 25 percent of the data fall within -12 and 4 degrees Celsius. The second IQR ranges between 4 and 13.5 degrees Celsius (the median), the third IQR range between 13.5 and 18.5 degrees Celsius, while the fourth IQR ranges between 18.5 and the highest value in the data (23 degrees Celsius). The IQR represent identical width only if the data is distributed normally. Therefore, when dealing with non-normal data, the best option to provide a summary of the distribution is to report the IQRs</p>
</div>
<div id="variance" class="section level2">
<h2><span class="header-section-number">3.3</span> Variance</h2>
<p>The variance is calculated according to the formula below. To calculate the variance, each value is subtracted from the mean and the result is squared. The squared values are then added and the resulting sum is divided by the number of values minus 1.</p>
<p><span class="math inline">\(s = \sigma^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^{2}\)</span></p>
<p>For our example, the variance of temperatures for city A is 123.6591 and 9.477273 for city B.</p>
<p>In R, the <em>variance</em> is calculated as shown below.</p>
<pre class="r"><code>sd(cityA)^2</code></pre>
<pre><code>## [1] 123.6591</code></pre>
</div>
<div id="standard-deviation" class="section level2">
<h2><span class="header-section-number">3.4</span> Standard deviation</h2>
<p>The standard deviation (abbreviated with capital <span class="math inline">\(sigma\)</span> <span class="math inline">\(\sigma\)</span>) is calculated according to first equation shown below or, alternatively, according to second equation shown below and it is the square root of the squared variance.</p>
<p><span class="math inline">\(\sigma = \sqrt{s} = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}\)</span></p>
<p><span class="math inline">\(\sigma = \sqrt{\frac{ \sum_{i=1}^{n} (x_i - \bar{x})^2}{n-1}}\)</span></p>
<p>For our example, the first equation shown above provides a standard deviation of 11.12 for city A and a standard deviation of 3.08 for city B.</p>
<p>In R, the <em>standard deviation</em> is calculated as shown below.</p>
<pre class="r"><code>sd(CityA) # calculate standard deviation</code></pre>
<pre><code>## [1] 10.64679</code></pre>
<p>The standard deviation of temperature values of city A is 11.12.</p>
<blockquote>
<p>Exercises</p>
<p>Calculate the mean, median, and mode as well as the standard deviation for the following two vectors (A: 1, 3, 6, 2, 1, 1, 6, 8, 4, 2, 3, 5, 0, 0, 2, 1, 2, 1, 0; B: 3, 2, 5, 1, 1, 4, 0, 0, 2, 3, 0, 3, 0, 5, 4, 5, 3, 3, 4).</p>
<p>Find a partner and discuss which measure of central tendency is appropriate when dealing with grades. Then, find another partner and see whether they have come to the same conclusion or discuss why if not. Finally, discuss the advantages and disadvantages of calculating the mean when dealing with grades.</p>
<p>Where are mean, median, and mode when dealing with normal data?</p>
<p>You are investigating differences between boys and girls and their respective use of discourse particles in three different locations. In the first location, you find that the variance in discourse particle use is almost identical for boys and girls but the means differ substantially. In the second location, they have almost identical means but drastically different variances, and in the third location you find that the means and variances differ substantially. How do you interpret the findings for the three locations?</p>
<p>Go and find a partner. Please discuss what it means - on a conceptual level rather than on a statistical/mathematical level - that two groups have different ranges for a certain feature (be careful, this is not as trivial as it may seem!).</p>
</blockquote>
</div>
<div id="standard-error" class="section level2">
<h2><span class="header-section-number">3.5</span> Standard Error</h2>
<p>The standard error is a measure of variability in the sense that it reports the average distance from some parameters (most often from the mean). It is calculated as the standard deviation of the residuals of the parameter in question. To exemplify the standard error, we will extract and tabulate the most frequent 20 words in the Irish component of the <em>International Corpus of English</em> (ICE Ireland 1.2.2)</p>
<table>
<caption>20 most frequent words in the sample corpus of ICE Ireland.</caption>
<thead>
<tr class="header">
<th align="left">WordType</th>
<th align="left">POS</th>
<th align="right">Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">i</td>
<td align="left">PPR</td>
<td align="right">1063</td>
</tr>
<tr class="even">
<td align="left">the</td>
<td align="left">ART</td>
<td align="right">1015</td>
</tr>
<tr class="odd">
<td align="left">you</td>
<td align="left">PPR</td>
<td align="right">953</td>
</tr>
<tr class="even">
<td align="left">and</td>
<td align="left">CON</td>
<td align="right">907</td>
</tr>
<tr class="odd">
<td align="left">’s</td>
<td align="left">OTH</td>
<td align="right">643</td>
</tr>
<tr class="even">
<td align="left">it</td>
<td align="left">PPR</td>
<td align="right">632</td>
</tr>
<tr class="odd">
<td align="left">to</td>
<td align="left">OTH</td>
<td align="right">610</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">ART</td>
<td align="right">580</td>
</tr>
<tr class="odd">
<td align="left">was</td>
<td align="left">V</td>
<td align="right">521</td>
</tr>
<tr class="even">
<td align="left">that</td>
<td align="left">DPR</td>
<td align="right">515</td>
</tr>
<tr class="odd">
<td align="left">of</td>
<td align="left">PRP</td>
<td align="right">430</td>
</tr>
<tr class="even">
<td align="left">in</td>
<td align="left">PRP</td>
<td align="right">421</td>
</tr>
<tr class="odd">
<td align="left">he</td>
<td align="left">PPR</td>
<td align="right">373</td>
</tr>
<tr class="even">
<td align="left">know</td>
<td align="left">V</td>
<td align="right">328</td>
</tr>
<tr class="odd">
<td align="left">like</td>
<td align="left">V</td>
<td align="right">289</td>
</tr>
<tr class="even">
<td align="left">they</td>
<td align="left">PPR</td>
<td align="right">267</td>
</tr>
<tr class="odd">
<td align="left">she</td>
<td align="left">PPR</td>
<td align="right">253</td>
</tr>
<tr class="even">
<td align="left">but</td>
<td align="left">CON</td>
<td align="right">222</td>
</tr>
<tr class="odd">
<td align="left">there</td>
<td align="left">DPR</td>
<td align="right">214</td>
</tr>
<tr class="even">
<td align="left">on</td>
<td align="left">ART</td>
<td align="right">195</td>
</tr>
</tbody>
</table>
<p>The standard error of the mean is calculated using the equation below.</p>
<p><span class="math display">\[\begin{equation}
\sigma~{\bar{x}}~ =\frac{\sigma}{\sqrt{n}} 
\end{equation}\]</span></p>
<p>The standard error can be calculated manually (see below) by implementing the equation from above.</p>
<pre class="r"><code>sd(wordstb$Frequency, na.rm=TRUE) /  
   sqrt(length(wordstb$Frequency[!is.na(wordstb$Frequency)]))  </code></pre>
<pre><code>## [1] 62.18777</code></pre>
<p>An easier way to extract standard errors is to use the “describe” function from the “psych” package (see below)</p>
<pre class="r"><code># decsribe data
describe(wordstb$Frequency,  # vector to be described
               type=2)       # determine of skew and kurtosis</code></pre>
<pre><code>##    vars  n   mean     sd median trimmed    mad min  max range skew kurtosis
## X1    1 20 521.55 278.11  472.5   496.5 262.42 195 1063   868 0.73    -0.58
##       se
## X1 62.19</code></pre>
</div>
</div>
<div id="confidence-intervals" class="section level1">
<h1><span class="header-section-number">4</span> Confidence Intervals</h1>
<p>Confidence intervals provide an estimation of in-between which values the reported value would lie in the population with a confidence of 95 percent. There are several ways to extract that information and to exemplify how to extract confidence intervals for values, we will look at the frequency of the 20 most frequent words in a sample of the Irish component of the <em>International Corpus of English</em> (ICE Ireland 1.2.2). Below you see a table showing the data we will be working with here.</p>
<div id="confidence-intervals-for-simple-vectors" class="section level2">
<h2><span class="header-section-number">4.1</span> Confidence Intervals for Simple Vectors</h2>
<table>
<caption>20 most frequent words in the sample corpus of ICE Ireland.</caption>
<thead>
<tr class="header">
<th align="left">WordType</th>
<th align="left">POS</th>
<th align="right">Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">i</td>
<td align="left">PPR</td>
<td align="right">1063</td>
</tr>
<tr class="even">
<td align="left">the</td>
<td align="left">ART</td>
<td align="right">1015</td>
</tr>
<tr class="odd">
<td align="left">you</td>
<td align="left">PPR</td>
<td align="right">953</td>
</tr>
<tr class="even">
<td align="left">and</td>
<td align="left">CON</td>
<td align="right">907</td>
</tr>
<tr class="odd">
<td align="left">’s</td>
<td align="left">OTH</td>
<td align="right">643</td>
</tr>
<tr class="even">
<td align="left">it</td>
<td align="left">PPR</td>
<td align="right">632</td>
</tr>
<tr class="odd">
<td align="left">to</td>
<td align="left">OTH</td>
<td align="right">610</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">ART</td>
<td align="right">580</td>
</tr>
<tr class="odd">
<td align="left">was</td>
<td align="left">V</td>
<td align="right">521</td>
</tr>
<tr class="even">
<td align="left">that</td>
<td align="left">DPR</td>
<td align="right">515</td>
</tr>
<tr class="odd">
<td align="left">of</td>
<td align="left">PRP</td>
<td align="right">430</td>
</tr>
<tr class="even">
<td align="left">in</td>
<td align="left">PRP</td>
<td align="right">421</td>
</tr>
<tr class="odd">
<td align="left">he</td>
<td align="left">PPR</td>
<td align="right">373</td>
</tr>
<tr class="even">
<td align="left">know</td>
<td align="left">V</td>
<td align="right">328</td>
</tr>
<tr class="odd">
<td align="left">like</td>
<td align="left">V</td>
<td align="right">289</td>
</tr>
<tr class="even">
<td align="left">they</td>
<td align="left">PPR</td>
<td align="right">267</td>
</tr>
<tr class="odd">
<td align="left">she</td>
<td align="left">PPR</td>
<td align="right">253</td>
</tr>
<tr class="even">
<td align="left">but</td>
<td align="left">CON</td>
<td align="right">222</td>
</tr>
<tr class="odd">
<td align="left">there</td>
<td align="left">DPR</td>
<td align="right">214</td>
</tr>
<tr class="even">
<td align="left">on</td>
<td align="left">ART</td>
<td align="right">195</td>
</tr>
</tbody>
</table>
<p>One easy method for extracting confidence intervals is to apply the “t.test” function.</p>
<pre class="r"><code>t.test(wordstb$Frequency, conf.level=0.95)  # extract mean and confidence intervals</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  wordstb$Frequency
## t = 8.3867, df = 19, p-value = 8.255e-08
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  391.3895 651.7105
## sample estimates:
## mean of x 
##    521.55</code></pre>
<p>The “t.test” function provides the mean frequency of the 20 most frequent words in the corpus (521.55) and the 95 percent confidence band: With 95 percent confidence, the mean frequency of the top twenty word types across corpora of the same size and similar register will have a mean between 391.4 and 651.7 words.</p>
<p>Another way to extract the mean and its confidence intervals is by using the “CI” function from the “Rmisc” package.</p>
<pre class="r"><code># extract mean and confidence intervals
CI(wordstb$Frequency, ci=0.95)   </code></pre>
<pre><code>##    upper     mean    lower 
## 651.7105 521.5500 391.3895</code></pre>
<p>The next way to extract the mean and its confidence intervals we will exemplify here is by using the “MeanCI” function from the “DescTools” package.</p>
<pre class="r"><code># extract mean and confidence intervals
MeanCI(wordstb$Frequency, conf.level=0.95)   </code></pre>
<pre><code>##     mean   lwr.ci   upr.ci 
## 521.5500 391.3895 651.7105</code></pre>
<p>The last way to calculate the mean and its confidence intervals is by bootstrapping or resampling the data and calculating confidence intervals based on the distribution of the resamples data. This is also done via the “MeanCI” function from the “DescTools” package.</p>
<pre class="r"><code># extract mean CIs
MeanCI(wordstb$Frequency, method=&quot;boot&quot;, type=&quot;norm&quot;, R=1000)</code></pre>
<pre><code>##     mean   lwr.ci   upr.ci 
## 521.5500 401.2803 638.9128</code></pre>
<p>Because this is a data-driven approach, the results will vary, depending on the characteristics of the resampled data. To illustrate, compare the values provided above to the values generated below.</p>
<pre class="r"><code># extract mean CIs
MeanCI(wordstb$Frequency, method=&quot;boot&quot;, type=&quot;norm&quot;, R=1000)</code></pre>
<pre><code>##     mean   lwr.ci   upr.ci 
## 521.5500 402.9187 640.2781</code></pre>
</div>
<div id="confidence-intervals-for-grouped-data" class="section level2">
<h2><span class="header-section-number">4.2</span> Confidence Intervals for Grouped Data</h2>
<p>To extract the confidence intervals for grouped data, we can sue the “summarySE” function from the “Rmisc” package.</p>
<pre class="r"><code># apply summarySE function to data
summarySE(data=wordstb,           
          # define variable representing frequencies
          measurevar=&quot;Frequency&quot;, 
          # define grouping variabel
          groupvars=&quot;POS&quot;,        
          # extract standard deviation, standard error, 
          # and confidence intervals
          conf.interval = 0.95)   </code></pre>
<pre><code>##   POS N Frequency         sd        se         ci
## 1 ART 3  596.6667 410.253986 236.86025 1019.12740
## 2 CON 2  564.5000 484.368145 342.50000 4351.87512
## 3 DPR 2  364.5000 212.839141 150.50000 1912.28381
## 4 OTH 2  626.5000  23.334524  16.50000  209.65238
## 5 PPR 6  590.1667 352.774385 144.01954  370.21401
## 6 PRP 2  425.5000   6.363961   4.50000   57.17792
## 7   V 3  379.3333 124.226943  71.72246  308.59683</code></pre>
<p>Confidence intervals for mean by bootstrap with boot package</p>
<pre class="r"><code># function to extract values
BootFunction = function(x, index) {                        
                  return(c(mean(x[index]),
                           var(x[index]) / length(index)))
}
# apply function to data
Bootstrapped = boot(data=wordstb$Frequency,                
            statistic=BootFunction,
            R=1000)
# extract values
mean(Bootstrapped$t[,1])                                   </code></pre>
<pre><code>## [1] 523.7682</code></pre>
<pre class="r"><code># alternative to extract values
boot.ci(Bootstrapped, conf=0.95)                           </code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = Bootstrapped, conf = 0.95)
## 
## Intervals : 
## Level      Normal              Basic             Studentized     
## 95%   (397.8, 640.9 )   (392.1, 639.0 )   (402.2, 679.0 )  
## 
## Level     Percentile            BCa          
## 95%   (404.1, 651.0 )   (411.3, 655.3 )  
## Calculations and Intervals on Original Scale</code></pre>
<p>The advantage of using bootstrapping method lies in the fact that the data is (frequently) not distributed normally which is not an issue for the bootstrapping and it will thus provide more reliable results as it does not rely on distributional assumptions about the data.</p>
</div>
<div id="confidence-intervals-for-nominal-data" class="section level2">
<h2><span class="header-section-number">4.3</span> Confidence Intervals for Nominal Data</h2>
<p>We now turn to confidence intervals for nominal data <span class="citation">(see also Thomas and Grunkemeier <a href="#ref-thomas1975confidence" role="doc-biblioref">1975</a>)</span>. When dealing with nominal data, confidence intervals can be determined with the “binom.test” function in the in-built “stats” package. Alternative methods are available via the “BinomCI” and “MultinomCI” functions from the “DescTools” package. More advanced techniques for confidence intervals on nominal data are available via the “PropCIs” package.</p>
<pre class="r"><code>binom.test(2, 20, 0.5,              # binom.test(x, n, p = 0.5, ...)
           alternative=&quot;two.sided&quot;, # define sidedness
           conf.level=0.95)         # define confidence level</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  2 and 20
## number of successes = 2, number of trials = 20, p-value = 0.0004025
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.01234853 0.31698271
## sample estimates:
## probability of success 
##                    0.1</code></pre>
<p>Another way to use the “binom.test” function is shown below.</p>
<pre class="r"><code>Input =(&quot;
 Paw
 right
 left
 right
 right
 right
 right
 left
 right
 right
 right  
&quot;)

Gus = read.table(textConnection(Input),header=TRUE)

Successes = sum(Gus$ Paw == &quot;left&quot;)      # Note the == operator
Failures  = sum(Gus$ Paw == &quot;right&quot;)

Total = Successes + Failures

Expected = 0.5

binom.test(Successes, Total, Expected,
           alternative=&quot;two.sided&quot;,
           conf.level=0.95)</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  Successes and Total
## number of successes = 2, number of trials = 10, p-value = 0.1094
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.02521073 0.55609546
## sample estimates:
## probability of success 
##                    0.2</code></pre>
<pre class="r"><code># extract CIs                  
BinomCI(2, 20,                        # apply BinomCI function
        conf.level = 0.95,            # define ci
        method = &quot;modified wilson&quot;)   # define method for ci extraction</code></pre>
<pre><code>##      est     lwr.ci    upr.ci
## [1,] 0.1 0.01776808 0.3010336</code></pre>
<p>Other methods: “wilson”, “wald”, “agresti-coull”, “jeffreys”, “modified wilson”, “modified jeffreys”, “clopper-pearson”, “arcsine”, “logit”, “witting”.</p>
</div>
<div id="confidence-intervals-for-multinomial-data" class="section level2">
<h2><span class="header-section-number">4.4</span> Confidence Intervals for Multinomial Data</h2>
<p>We use the “MultinomCI” function to extract the confidence intervals form multinominal data.</p>
<pre class="r"><code>observed = c(35,74,22,69)       # define multinominal vector
MultinomCI(observed,            # apply MultinomCI function
           conf.level=0.95,     # define ci
           method=&quot;goodman&quot;)    # define method for ci extraction</code></pre>
<pre><code>##        est     lwr.ci    upr.ci
## [1,] 0.175 0.11253215 0.2619106
## [2,] 0.370 0.28113643 0.4686407
## [3,] 0.110 0.06224338 0.1870880
## [4,] 0.345 0.25846198 0.4431954</code></pre>
</div>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2020. <em>Descriptive Statistics with R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/descriptivestatz.html" class="uri">https://slcladal.github.io/descriptivestatz.html</a>.</p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] stringr_1.4.0     Rmisc_1.5         plyr_1.8.6        lattice_0.20-41  
## [5] psych_2.0.8       knitr_1.30        dplyr_1.0.2       DescTools_0.99.38
## [9] boot_1.3-25      
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.5       highr_0.8        compiler_4.0.2   pillar_1.4.6    
##  [5] class_7.3-17     tools_4.0.2      digest_0.6.25    nlme_3.1-148    
##  [9] evaluate_0.14    lifecycle_0.2.0  tibble_3.0.3     pkgconfig_2.0.3 
## [13] rlang_0.4.7      Matrix_1.2-18    rstudioapi_0.11  parallel_4.0.2  
## [17] yaml_2.2.1       mvtnorm_1.1-1    expm_0.999-5     xfun_0.16       
## [21] e1071_1.7-3      generics_0.0.2   vctrs_0.3.4      gld_2.6.2       
## [25] grid_4.0.2       tidyselect_1.1.0 glue_1.4.2       R6_2.4.1        
## [29] lmom_2.8         rmarkdown_2.3    purrr_0.3.4      magrittr_1.5    
## [33] htmltools_0.5.0  ellipsis_0.3.1   MASS_7.3-51.6    mnormt_2.0.2    
## [37] Exact_2.0        stringi_1.5.3    tmvnsim_1.0-2    crayon_1.3.4</code></pre>
<hr />
<p><a href="https://slcladal.github.io/index.html">Go back to the main page</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-bickel2012descriptive">
<p>Bickel, PJ, and EL Lehmann. 2012. “Descriptive Statistics for Nonparametric Models I. Introduction.” In <em>Selected Works of El Lehmann</em>, 465–71. Springer.</p>
</div>
<div id="ref-gaddis1990introduction">
<p>Gaddis, Gary M, and Monica L Gaddis. 1990. “Introduction to Biostatistics: Part 2, Descriptive Statistics.” <em>Annals of Emergency Medicine</em> 19 (3): 309–15.</p>
</div>
<div id="ref-thomas1975confidence">
<p>Thomas, David R, and Gary L Grunkemeier. 1975. “Confidence Interval Estimation of Survival Probabilities for Censored Data.” <em>Journal of the American Statistical Association</em> 70 (352): 865–71.</p>
</div>
<div id="ref-thompson2009descriptive">
<p>Thompson, Cheryl Bagley. 2009. “Descriptive Data Analysis.” <em>Air Medical Journal</em> 28 (2): 56–59.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
