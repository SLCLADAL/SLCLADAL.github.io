{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "***\n",
                "\n",
                "Please copy this Jupyter notebook so that you are able to edit it.\n",
                "\n",
                "Simply go to: File > Save a copy in Drive.\n",
                "\n",
                "Once you have done that, you are good to go.\n",
                "\n",
                "***\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *Sentiment Analysis in R*](https://ladal.edu.au/sentiment.html). \n",
                "\n",
                "***\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "If you are using this notebook on Google Colab or your own computer and you have not already installed the R packages listed below, you need to install them. You can install them by running the code chunk below. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t0 <- Sys.time()\n",
                "# install packages\n",
                "install.packages(\"dplyr\")\n",
                "install.packages(\"stringr\")\n",
                "install.packages(\"tibble\")\n",
                "install.packages(\"ggplot2\")\n",
                "install.packages(\"tidytext\")\n",
                "install.packages(\"textdata\")\n",
                "install.packages(\"Hmisc\")\n",
                "# check time\n",
                "t1 <- Sys.time()\n",
                "cat(\"The installation took \", round(t1-t0, 1), \" minutes.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# activate packages\n",
                "library(dplyr)\n",
                "library(stringr)\n",
                "library(tibble)\n",
                "library(ggplot2)\n",
                "library(tidytext)\n",
                "library(textdata)\n",
                "library(Hmisc)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.\n",
                "\n",
                "\n",
                "## Loading data\n",
                "\n",
                "In the following, we will perform a SA to investigate the emotionality of five different novels. We will start with the first example and load five pieces of literature. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "darwin <- base::readRDS(url(\"https://slcladal.github.io/data/origindarwin.rda\", \"rb\"))\n",
                "twain <- base::readRDS(url(\"https://slcladal.github.io/data/twainhuckfinn.rda\", \"rb\"))\n",
                "orwell <- base::readRDS(url(\"https://slcladal.github.io/data/orwell.rda\", \"rb\"))\n",
                "lovecraft <- base::readRDS(url(\"https://slcladal.github.io/data/lovecraftcolor.rda\", \"rb\"))\n",
                "# inspect data\n",
                "darwin %>%\n",
                "  as.data.frame() %>%\n",
                "  head() \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "## Using your own data\n",
                "\n",
                "While the tutorial uses data from the LADAL website, you can also use your own data. You can see below what you need to do to upload and use your own data.\n",
                "\n",
                "The code chunk below allows you to upload two files from your own computer. To be able to load your own data, you need to click on the folder symbol to the left of the screen:\n",
                "\n",
                "![Colab Folder Symbol](https://slcladal.github.io/images/ColabFolder.png)\n",
                "\n",
                "\n",
                "Then on the upload symbol.\n",
                "\n",
                "![Colab Upload Symbol](https://slcladal.github.io/images/ColabUpload.png)\n",
                "Next, upload the files you want to analyze and then the respective files names in the file argument of the scan function. When you then execute the code (like to code chunk below, you will upload your own data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mytext1 <- scan(file = \"linguistics01.txt\",\n",
                "            what = \"char\", \n",
                "            sep = \"\", \n",
                "            quote = \"\", \n",
                "            quiet = T, \n",
                "            skipNul = T) %>%\n",
                "            paste0(collapse = \" \")\n",
                "mytext2 <- scan(file = \"linguistics02.txt\",\n",
                "            what = \"char\", \n",
                "            sep = \"\", \n",
                "            quote = \"\", \n",
                "            quiet = T, \n",
                "            skipNul = T) %>%\n",
                "            paste0(collapse = \" \")\n",
                "# inspect\n",
                "mytext1; mytext2\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Keep in mind though that you need to adapt the names of the texts in the code chunks below so that the code below work on your own texts!**\n",
                "\n",
                "***\n",
                "\n",
                "## Data Processing\n",
                "\n",
                "We now write function to clean data. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "txtclean <- function(x, title){\n",
                "  require(dplyr)\n",
                "  require(stringr)\n",
                "  require(tibble)\n",
                "  x <- x %>%\n",
                "    iconv(to = \"UTF-8\") %>%     # convert to UTF-8\n",
                "    base::tolower() %>%         # convert to lower case\n",
                "    paste0(collapse = \" \") %>%  # collapse into single text\n",
                "    stringr::str_squish()%>%    # remove superfluous white spaces\n",
                "    stringr::str_split(\" \") %>% # split into individual words\n",
                "    unlist() %>%                # unlist\n",
                "    tibble::tibble() %>%        # convert into a table\n",
                "    dplyr::select(word = 1, everything()) %>%\n",
                "    dplyr::mutate(novel = title) %>%\n",
                "    dplyr::anti_join(stop_words) %>%  # remove function words\n",
                "    dplyr::mutate(word = str_remove_all(word, \"\\\\W\")) %>% # remove non-word symbols\n",
                "    dplyr::filter(word != \"\")         # remove empty elements\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Process and clean texts.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# process text data\n",
                "darwin_clean <- txtclean(darwin, \"darwin\")\n",
                "lovecraft_clean <- txtclean(lovecraft, \"lovecraft\")\n",
                "orwell_clean <- txtclean(orwell, \"orwell\")\n",
                "twain_clean <- txtclean(twain, \"twain\")\n",
                "# inspect cleaned darwin text\n",
                "darwin_clean %>%\n",
                "  as.data.frame() %>%\n",
                "  head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Basic Sentiment Analysis\n",
                "\n",
                "In a next step, download Mohammad and Turney's (2013) *Word-Emotion Association Lexicon*.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nrc <- base::readRDS(url(\"https://slcladal.github.io/data/nrc.rda\", \"rb\"))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we combine the data with the *Word-Emotion Association Lexicon*. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels_anno <- rbind(darwin_clean, twain_clean, orwell_clean, lovecraft_clean) %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  dplyr::mutate(words = n()) %>%\n",
                "  dplyr::left_join(nrc) %>%\n",
                "  dplyr::mutate(novel = factor(novel),\n",
                "         sentiment = factor(sentiment))\n",
                "# inspect data\n",
                "novels_anno %>%\n",
                "  as.data.frame() %>%\n",
                "  head() \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now summarize the results of the SA and calculate the percentages of the prevalence of emotions across the books.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels <- novels_anno %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  dplyr::group_by(novel, sentiment) %>%\n",
                "  dplyr::summarise(sentiment = unique(sentiment),\n",
                "                   sentiment_freq = n(),\n",
                "                   words = unique(words)) %>%\n",
                "  dplyr::filter(is.na(sentiment) == F) %>%\n",
                "  dplyr::mutate(percentage = round(sentiment_freq/words*100, 1))\n",
                "# inspect data\n",
                "novels %>%\n",
                "  as.data.frame() %>%\n",
                "  head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After performing the SA, visualize the results and show the scores fro each core emotion by book.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels %>%\n",
                "  dplyr::filter(sentiment != \"positive\",\n",
                "                sentiment != \"negative\") %>%\n",
                "  ggplot(aes(sentiment, percentage, fill = novel)) +    \n",
                "  geom_bar(stat=\"identity\",  \n",
                "           position=position_dodge()) + \n",
                "  scale_fill_manual(name = \"\", values=c(\"orange\", \"gray70\", \"red\", \"grey30\")) +\n",
                "  theme_bw() +\n",
                "  theme(legend.position = \"top\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also display the emotions by book and re-level sentiment so that the different core emotions are ordered from more negative (*red*) to more positive (*blue*).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels %>%\n",
                "  dplyr::filter(sentiment != \"positive\",\n",
                "                sentiment != \"negative\") %>%\n",
                "  dplyr::mutate(sentiment = factor(sentiment, \n",
                "                            levels = c(\"anger\", \"fear\", \"disgust\", \"sadness\",\n",
                "                                       \"surprise\", \"anticipation\", \"trust\", \"joy\"))) %>%\n",
                "  ggplot(aes(novel, percentage, fill = sentiment)) +    \n",
                "  geom_bar(stat=\"identity\", position=position_dodge()) + \n",
                "  scale_fill_brewer(palette = \"RdBu\") +\n",
                "  theme_bw() +\n",
                "  theme(legend.position = \"right\") +\n",
                "  coord_flip()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Identifying important emotives\n",
                "\n",
                "We now check, which words have contributed to the emotionality scores. In other words, we investigate, which words are most important for the emotion scores within each novel. For the sake of interpretability, we will remove several core emotion categories and also the polarity.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels_impw <- novels_anno %>%\n",
                "  dplyr::filter(!is.na(sentiment),\n",
                "         sentiment != \"anticipation\",\n",
                "         sentiment != \"surprise\",\n",
                "         sentiment != \"disgust\",\n",
                "         sentiment != \"negative\",\n",
                "         sentiment != \"sadness\",\n",
                "         sentiment != \"positive\") %>%\n",
                "  dplyr::mutate(sentiment = factor(sentiment, levels = c(\"anger\", \"fear\",  \"trust\", \"joy\"))) %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  dplyr::count(word, sentiment, sort = TRUE) %>%\n",
                "  dplyr::group_by(novel, sentiment) %>%\n",
                "  dplyr::top_n(4) %>%\n",
                "  dplyr::mutate(score = n/sum(n))\n",
                "# inspect data\n",
                "novels_impw %>%\n",
                "  as.data.frame() %>%\n",
                "  head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now visualize the top four words for the remaining core emotion categories. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels_impw %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  slice_max(score, n = 20) %>%\n",
                "  dplyr::arrange(desc(score)) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  ggplot(aes(x = reorder(word, score), y = score, fill = word)) +\n",
                "  facet_wrap(novel~sentiment, ncol = 4, scales = \"free_y\") +\n",
                "  geom_col(show.legend = FALSE) +\n",
                "  coord_flip() +\n",
                "  labs(x = \"Words\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Calculating and dispalying polarity\n",
                "\n",
                "Now, we visualize the polarity of each book, i.e. the ratio of the number of positive emotion words divided by the number of negative words.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels %>%\n",
                "  dplyr::filter(sentiment == \"positive\" | sentiment == \"negative\") %>%\n",
                "  dplyr::select(-percentage, -words) %>%\n",
                "  dplyr::mutate(sentiment_sum = sum(sentiment_freq),\n",
                "         positive = sentiment_sum-sentiment_freq) %>%\n",
                "  dplyr::filter(sentiment != \"positive\") %>%\n",
                "  dplyr::rename(negative = sentiment_freq) %>%\n",
                "  dplyr::select(novel, positive, negative) %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  dplyr::summarise(polarity = positive/negative) %>%\n",
                "  ggplot(aes(reorder(novel, polarity, mean), polarity, fill = novel)) +    \n",
                "  geom_bar(stat = \"identity\") + \n",
                "  geom_text(aes(y = polarity-0.1, label = round(polarity, 2)), \n",
                "            color = \"white\", size = 4) + \n",
                "  theme_bw() +\n",
                "  labs(y = \"Polarity\\n(ration of positive to negative emitives)\",\n",
                "       x = \"\") +\n",
                "  coord_cartesian(y= c(0,2)) +\n",
                "  scale_y_continuous(breaks = seq(0,2,1),\n",
                "                     labels = c(\"more negative\", \"neutral\", \"more positive\")) +\n",
                "  theme(legend.position = \"none\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Overall, all books are in the positive range (the polarity score is not negative) and we see that *lovecraft* is the book with the most negative emotion words while *darwin* is the most positive book as it has the highest average polarity ratio.\n",
                "\n",
                "# Calculating and dispalying changes in polarity\n",
                "\n",
                "There are two main methods for tracking changes in polarity: binning and moving averages. binning splits the data up into sections and calculates the polarity ration within each bin. Moving averages calculate the mean within windows that are then shifted forward. We begin with an exemplification of binning and then move on to calculating moving averages. \n",
                "\n",
                "## Binning\n",
                "\n",
                "The following code chunk uses binning to determine the polarity and subsequently displaying changes in polarity across the development of the novels' plots.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "novels_bin <- novels_anno %>%\n",
                "  dplyr::group_by(novel) %>%\n",
                "  dplyr::filter(is.na(sentiment) | sentiment == \"negative\" | sentiment == \"positive\") %>%\n",
                "  dplyr::mutate(sentiment = as.character(sentiment),\n",
                "         sentiment = case_when(is.na(sentiment) ~ \"0\", \n",
                "                               TRUE ~ sentiment),\n",
                "         sentiment= case_when(sentiment == \"0\" ~ 0,\n",
                "                              sentiment == \"positive\" ~ 1,\n",
                "                              TRUE ~ -1),\n",
                "         id = 1:n(),\n",
                "         index = as.numeric(Hmisc::cut2(id, m=100))) %>%\n",
                "  dplyr::group_by(novel, index) %>%\n",
                "  dplyr::summarize(index = unique(index),\n",
                "                   polarity = mean(sentiment))\n",
                "# inspect data\n",
                "novels_bin %>%\n",
                "  as.data.frame() %>%\n",
                "  head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now have an average polarity for each bin and can plot this polarity over the development of the story.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(novels_bin, aes(index, polarity)) + \n",
                "  facet_wrap(vars(novel), scales=\"free_x\") +\n",
                "  geom_smooth(se = F, col = \"black\") + \n",
                "  theme_bw() +\n",
                "  labs(y = \"polarity ratio (mean by bin)\",\n",
                "       x = \"index (bin)\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you are interested in learning more about SA in R, Silge and Robinson (2017) is highly recommended as it goes more into detail and offers additional information.\n",
                "\n",
                "# References\n",
                "\n",
                "Mohammad, Saif M, and Peter D Turney. 2013. Crowdsourcing a Word-Emotion Association Lexicon. *Computational Intelligence* 29 (3): 436–65.\n",
                "\n",
                "Silge, Julia and David Robinson. 2017. Text Mining with R: A Tidy Approach. O’Reilly Media, Inc.\n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/sentiment.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
