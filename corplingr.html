<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-07-24" />

<title>Corpus Linguistics with R - Case Studies</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Research Designs</li>
    <li>
      <a href="researchdesigns.html">Overview</a>
    </li>
    <li>
      <a href="acoustic.html">Acoustic Analysis</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Collection</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="dataprocessingexcel.html">Data Processing with Excel</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization with R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
    <li>
      <a href="collostructions.html">Collostructional Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="textanalysis.html">Introduction</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Corpus Linguistics with R - Case Studies</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-07-24</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This section presents case studies on how to use “R” in corpus linguistics. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/corplingrscript.r">here</a>.</p>
<p>The case studies merely exemplify ways in which “R” can be used in language-based research rather than providing mdels of how to do research. The first case study aims to answer if swearing differs across the genders. In other words, this case study focuses on whether men or women swear more. The second analysis investigates the use of adjectiv amplifiers in Australian English and aims to answer whether <em>very</em> is replaced by <em>really</em> as the dominant amplifying variant.</p>
</div>
<div id="preparation-and-session-set-up" class="section level1">
<h1><span class="header-section-number">2</span> Preparation and session set up</h1>
<p>Since all examples will be performed in “R”, it is necessary to install “R”, “RStudio”, and “Tinn-R”. If these programms (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In a first step, we clean the existing work space and set the options. The option “stringsAsFactors = F” informs “R” that we do not want “R” to convert chacaters into factors (otherwise, character strings would be represented as numbers).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation</code></pre>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the librariesby running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># install libraries
install.packages(c(&quot;tm&quot;, &quot;dplyr&quot;,&quot;stringr&quot;, &quot;visreg&quot;))</code></pre>
<p>One installation may be a little more complex (depending on the type of machine you are using and the version of “R” that the machine is running). To install the development version of the “data.table” package, we need to install it directly from github (rather than a CRAN mirror server).</p>
<pre class="r"><code># manual installation
install.packages(&quot;devtools&quot;)
# load devtools and install development version of data.table
library(devtools)
install_github(&quot;Rdatatable/data.table&quot;, build_vignettes = FALSE)</code></pre>
<p>Once you have installed “R”, “R-Studio”, “Tinn-R”, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="case-study-gender-differences-in-swearing" class="section level1">
<h1><span class="header-section-number">3</span> Case Study: Gender Differences in Swearing</h1>
<p>This case study aims to answer if the frequency with which speakers use swear words is correlated with the gender of speakers. In a first step, we load the load the data into “R”. The way that the corpus data is loaded in this example is somewhat ackward because the data is in a server directory rather than on a harddrive on a simple PC. If the corpus data is not stored in a directory of a server, then you should not use the code shown imediately below but code in the window following the code imediately below.</p>
<pre class="r"><code># define path to corpus
corpuspath &lt;- &quot;https://slcladal.github.io/data/ICEIrelandSample/&quot;
# define corpusfiles
files &lt;- paste(corpuspath, &quot;S1A-00&quot;, 1:20, &quot;.txt&quot;, sep = &quot;&quot;)
files &lt;- gsub(&quot;[0-9]([0-9][0-9][0-9])&quot;, &quot;\\1&quot;, files)
# load corpus files
corpus &lt;- sapply(files, function(x){
  x &lt;- readLines(x)
  x &lt;- paste(x, collapse = &quot; &quot;)
})
# inspect corpus
str(corpus)</code></pre>
<pre><code>##  Named chr [1:20] &quot;&lt;S1A-001 Riding&gt;  &lt;I&gt; &lt;S1A-001$A&gt; &lt;#&gt; Well how did the riding go tonight &lt;S1A-001$B&gt; &lt;#&gt; It was good so it was &quot;| __truncated__ ...
##  - attr(*, &quot;names&quot;)= chr [1:20] &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-001.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-002.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-003.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-004.txt&quot; ...</code></pre>
<p>If the corpus data is stored on your own computer (on not on a serves as is the case in the present example), you shoudl use the follw</p>
<pre class="r"><code># define path to corpus
# WARNING: you need to include your own path!
corpuspath &lt;- &quot;D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io\\data\\ICEIrelandSample&quot;
# define corpusfiles
files &lt;- list.paste(corpuspath, all.names = T)
# load corpus files
corpus &lt;- sapply(files, function(x){
  x &lt;- scan(x, what = &quot;char&quot;, sep = &quot;&quot;, quote = &quot;&quot;, skipNul = T)
  x &lt;- paste(x, sep = &quot; &quot;, collapse = &quot; &quot;)
})
# inspect corpus
str(corpus)</code></pre>
<p>Now that the corpus data is loaded, we can prepare the searches by defining the search patterns.</p>
<pre class="r"><code># load concordancing function
source(&quot;https://slcladal.github.io/rscripts/ConcR_2.5_LoadedFiles.R&quot;)
# define surrounding context for KWIC display
context &lt;- 20
# define that we want everything that preceeds a match for the serach pattern 
all.pre = T
# define search patterns
search.pattern1 &lt;- c(&quot;[A|a]rse[a-z]{0,}&quot;)
search.pattern2 &lt;-  c(&quot;[F|f]uck[a-z]{0,}&quot;)
search.pattern3 &lt;-  c(&quot;[S|s]hit[a-z]{0,}&quot;)
search.pattern4 &lt;-  c(&quot;[C|c]ock[a-z]{0,}&quot;)
search.pattern5 &lt;-  c(&quot;[W|w]hore[a-z]{0,}&quot;)
search.pattern6 &lt;-  c(&quot;[A|a]ss[holes]{0,5}&quot;)
search.pattern7 &lt;-  c(&quot;[D|d]ick[a-z]{0,}&quot;)
search.pattern8 &lt;-  c(&quot;[W|w]anker[a-z]{0,}&quot;)
search.pattern9 &lt;-  c(&quot;[C|c]rap[a-z]{0,}&quot;)
search.pattern10 &lt;-  c(&quot;[B|b]itch[a-z]{0,}&quot;)
search.pattern11 &lt;-  c(&quot;[D|d]amn[a-z]{0,}&quot;)</code></pre>
<p>It would, of course, also be possible to search for all search patterns in a single search but it may be advantageous to split search patterns so that the code is easier to parse and understand. After preparing the search, we perform the concordancing and create a table with the results.</p>
<pre class="r"><code># start search
sw1 &lt;- ConcR(corpus, search.pattern1, context, all.pre = T)
sw2 &lt;- ConcR(corpus, search.pattern2, context, all.pre = T)
sw3 &lt;- ConcR(corpus, search.pattern3, context, all.pre = T)
sw4 &lt;- ConcR(corpus, search.pattern4, context, all.pre = T)
#sw5 &lt;- ConcR(corpus, search.pattern5, context, all.pre = T)
sw6 &lt;- ConcR(corpus, search.pattern6, context, all.pre = T)
#sw7 &lt;- ConcR(corpus, search.pattern7, context, all.pre = T)
sw8 &lt;- ConcR(corpus, search.pattern8, context, all.pre = T)
sw9 &lt;- ConcR(corpus, search.pattern9, context, all.pre = T)
sw10 &lt;- ConcR(corpus, search.pattern10, context, all.pre = T)
#sw11 &lt;- ConcR(corpus, search.pattern11, context, all.pre = T)
# combine search results
swire &lt;- rbind(sw1, sw2, sw3, sw4, sw6, sw8, sw9, sw10)
# convert matrix into a data frame
swire &lt;- as.data.frame(swire)
# inspect structure of the data
str(swire)</code></pre>
<pre><code>## &#39;data.frame&#39;:    125 obs. of  5 variables:
##  $ OriginalString  : chr  &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt&quot; ...
##  $ PreContext      : chr  &quot; doesn&#39;t bother his &quot; &quot; just a pain in the &quot; &quot;2&gt; &lt;[2&gt; pain in the &quot; &quot; thought I can&#39;t be &quot; ...
##  $ Token           : chr  &quot;arse&quot; &quot;arse&quot; &quot;arse&quot; &quot;arsed&quot; ...
##  $ PostContext     : chr  &quot; &lt;#&gt; I mean &lt;S1A-018&quot; &quot; like &lt;#&gt; He was &lt;{&gt;&quot; &quot; &lt;/[2&gt; who is bummin&quot; &quot; talking to you &lt;#&gt; &quot; ...
##  $ EntirePreContext: chr  &quot;&lt;S1A-018 Drama&gt; &lt;I&gt; &lt;S1A-018$A&gt; &lt;#&gt; Ambulance was crap &lt;S1A-018$B&gt; &lt;#&gt; I know that &lt;#&gt; I don&#39;t need you to tell&quot;| __truncated__ &quot;&lt;S1A-019 Clothes&gt; &lt;I&gt; &lt;S1A-019$A&gt; &lt;#&gt; This is the top I was going to &lt;,&gt; I wore to the wedding &lt;{&gt; &lt;[&gt; right &lt;/&quot;| __truncated__ &quot;&lt;S1A-020 Taxi driver&gt; &lt;I&gt; &lt;S1A-020$A&gt; &lt;#&gt; &lt;.&gt; Lu &lt;/.&gt; Louise did you hear about the taxi driver last week &lt;S1A-&quot;| __truncated__ &quot;&lt;S1A-020 Taxi driver&gt; &lt;I&gt; &lt;S1A-020$A&gt; &lt;#&gt; &lt;.&gt; Lu &lt;/.&gt; Louise did you hear about the taxi driver last week &lt;S1A-&quot;| __truncated__ ...</code></pre>
<p>The variable “OriginalString” contains the file name. However, we do not want the entire path to the file but only the file name itself. Therefore, we will clean the variable “OriginalString” so that it only contains the file names.</p>
<pre class="r"><code># clean file names
swire$OriginalString &lt;- gsub(&quot;.*/&quot;, &quot;&quot;, swire$OriginalString)
swire$OriginalString &lt;- gsub(&quot;\\..*&quot;, &quot;&quot;, swire$OriginalString)
# store file names
files &lt;- names(table(swire$OriginalString))
# inspect result
names(table(swire$OriginalString))</code></pre>
<pre><code>##  [1] &quot;S1A-001&quot; &quot;S1A-002&quot; &quot;S1A-003&quot; &quot;S1A-004&quot; &quot;S1A-005&quot; &quot;S1A-006&quot; &quot;S1A-007&quot;
##  [8] &quot;S1A-009&quot; &quot;S1A-010&quot; &quot;S1A-011&quot; &quot;S1A-012&quot; &quot;S1A-013&quot; &quot;S1A-014&quot; &quot;S1A-015&quot;
## [15] &quot;S1A-016&quot; &quot;S1A-017&quot; &quot;S1A-018&quot; &quot;S1A-019&quot; &quot;S1A-020&quot;</code></pre>
<p>Now, we nromalize the tokens that we have extracted by converting them into lower case. Once we have done so, we will inspect the extracted tokens to check if our search strings have indeed captured swear words.</p>
<pre class="r"><code># convert tokens to lower case
swire$Token &lt;- tolower(swire$Token)
# inspect tokens
names(table(swire$Token))</code></pre>
<pre><code>##  [1] &quot;arse&quot;      &quot;arsed&quot;     &quot;ass&quot;       &quot;asse&quot;      &quot;asses&quot;    
##  [6] &quot;assle&quot;     &quot;asso&quot;      &quot;bitch&quot;     &quot;bitches&quot;   &quot;bitchy&quot;   
## [11] &quot;cocktails&quot; &quot;crap&quot;      &quot;crape&quot;     &quot;fuck&quot;      &quot;fucked&quot;   
## [16] &quot;fucking&quot;   &quot;fucks&quot;     &quot;shit&quot;      &quot;shite&quot;     &quot;wanker&quot;</code></pre>
<p>Most of the extracted patters do indeed represent swear words but some tokens do not (e.g. “cocktails”). In other cases, we need to check if the swear word is indeed an instance of swearing or some other use of the word. To remove instances of words that clearly do not represent swear words, we create a vector with those words and remove rows from the table that contain those elements.</p>
<pre class="r"><code># create vector with non-swear words
nonswearwords &lt;- c(&quot;cocktails&quot;, &quot;crape&quot;)
# check number of rows in current data
nrow(swire)</code></pre>
<pre><code>## [1] 125</code></pre>
<pre class="r"><code># remove rows containing nonswearwords
swire &lt;- swire[!swire$Token %in% nonswearwords,]
# check number of rows of data after removal
nrow(swire)</code></pre>
<pre><code>## [1] 122</code></pre>
<p>The results show that we have removed three lines from the table. Next, we inspect the data to check which other instances do not represent swear words. o make this more convenient, we create a new variable that provides a display that is easier to read inspect the KWIC for false hits.</p>
<pre class="r"><code># create new variable
swire$KWIC &lt;- paste(swire$PreContext, &quot; &lt;&lt; &quot;, swire$Token, &quot; &gt;&gt; &quot;, swire$PostContext, sep = &quot;&quot;)
# inspect first lines
head(swire$KWIC)</code></pre>
<pre><code>## [1] &quot; doesn&#39;t bother his  &lt;&lt; arse &gt;&gt;  &lt;#&gt; I mean &lt;S1A-018&quot;   
## [2] &quot; just a pain in the  &lt;&lt; arse &gt;&gt;  like &lt;#&gt; He was &lt;{&gt;&quot;   
## [3] &quot;2&gt; &lt;[2&gt; pain in the  &lt;&lt; arse &gt;&gt;  &lt;/[2&gt; who is bummin&quot;   
## [4] &quot; thought I can&#39;t be  &lt;&lt; arsed &gt;&gt;  talking to you &lt;#&gt; &quot;  
## [5] &quot; all this shite &lt;#&gt;  &lt;&lt; fuck &gt;&gt;  them &lt;#&gt; I &#39;m never&quot;   
## [6] &quot;&lt;/unclear&gt; I &#39;ve to  &lt;&lt; fucking &gt;&gt;  deal with that guy &quot;</code></pre>
<p>While you can, of course, also check the results in “R”, you can also save the results on your PC to inspect them in Excel or another spreadsheet software using the “write.table” function.</p>
<pre class="r"><code># save results on disc 
# WARNING: you need to include your own path!
write.table(swire$KWIC, &quot;D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io\\data/swearwordkwic.txt&quot;, sep = &quot;\t&quot;, quote = F)</code></pre>
<p>The KWIC display shows that almost none of the tokens for “ass” are real swear word uses but instances of “Mass”, “glass” and “pass” and the like (see below).</p>
<div class="figure">
<img src="corplingr_files/figure-html/Fig2-1.png" alt="\label{fig:Fig1} Coding of swear words in Excel." width="576" />
<p class="caption">
 Coding of swear words in Excel.
</p>
</div>
<p>However, some of the instances of “ass” do represent swear word use, e.g. &quot; like a pain in the &lt;&lt; ass &gt;&gt; too you can like &lt;S“. Thus, in a next step, we will exclude those elements which represent swear word use. If the sequence”ass&quot; is part of a word (e.g. “glass”, then there is no space before the “ass” while there is in cases of the prase “pain in the ass”). Therefore, we create a new variable called “remove” and exclude all instances of “ass” that are not preceeded by a space.</p>
<pre class="r"><code># clean data frame
swire$remove &lt;- ifelse(swire$Token == &quot;ass&quot; &amp; nchar(gsub(&quot;.* &quot;, &quot; &quot;, swire$PreContext) &gt; 1), &quot;remove&quot;, &quot;keep&quot;)
# remove items that are not swear words
swire &lt;- swire[swire$remove != &quot;remove&quot;, ]</code></pre>
<p>In addition,w e will exclude instances of “bitchy”, “asses”, “assle”, and “asso” as they also represent non-swear word uses.</p>
<pre class="r"><code># create vector with non-swear word uses
nonswearworduses &lt;- c(&quot;bitchy&quot;, &quot;asses&quot;, &quot;assle&quot;, &quot;asso&quot;)
# remove non-swear word uses
swire &lt;- swire[!swire$Token %in% nonswearworduses, ]
# inspect results
names(table(swire$Token))</code></pre>
<pre><code>##  [1] &quot;arse&quot;    &quot;arsed&quot;   &quot;asse&quot;    &quot;bitch&quot;   &quot;bitches&quot; &quot;crap&quot;    &quot;fuck&quot;   
##  [8] &quot;fucked&quot;  &quot;fucking&quot; &quot;fucks&quot;   &quot;shit&quot;    &quot;shite&quot;   &quot;wanker&quot;</code></pre>
<p>Now, we will extract the speaker to find out who has uttered the swaer word. In addition, we will remove the “remove” column.</p>
<pre class="r"><code># remove columns
swire$remove &lt;- NULL
swire$KWIC &lt;- NULL
# extract speaker
swire$EntirePreContext &lt;- gsub(&quot;.*&lt;S&quot;, &quot;&lt;S&quot;, swire$EntirePreContext)
swire$EntirePreContext &lt;- gsub(&quot; .*&quot;, &quot;&quot;, swire$EntirePreContext)
# rename columns
colnames(swire) &lt;- ifelse(colnames(swire) == &quot;EntirePreContext&quot;, &quot;Speaker&quot;,
                          ifelse(colnames(swire) == &quot;OriginalString&quot;, &quot;File&quot;,colnames(swire)))
# inspect data
head(swire)</code></pre>
<pre><code>##      File           PreContext   Token          PostContext     Speaker
## 1 S1A-018  doesn&#39;t bother his     arse  &lt;#&gt; I mean &lt;S1A-018 &lt;S1A-018$B&gt;
## 2 S1A-019  just a pain in the     arse  like &lt;#&gt; He was &lt;{&gt; &lt;S1A-019$C&gt;
## 3 S1A-020 2&gt; &lt;[2&gt; pain in the     arse  &lt;/[2&gt; who is bummin &lt;S1A-020$C&gt;
## 4 S1A-020  thought I can&#39;t be    arsed  talking to you &lt;#&gt;  &lt;S1A-020$D&gt;
## 5 S1A-005  all this shite &lt;#&gt;     fuck  them &lt;#&gt; I &#39;m never &lt;S1A-005$B&gt;
## 6 S1A-005 &lt;/unclear&gt; I &#39;ve to  fucking  deal with that guy  &lt;S1A-005$B&gt;</code></pre>
<pre class="r"><code># tabulate speaker and swear word frequency
swirespk &lt;- table(swire$Speaker)
swirespk &lt;- data.frame(swirespk)
colnames(swirespk) &lt;- c(&quot;Speaker&quot;, &quot;Swearwords&quot;)
# inspect data
head(swirespk)</code></pre>
<pre><code>##       Speaker Swearwords
## 1 &lt;S1A-003$A&gt;          3
## 2 &lt;S1A-005$B&gt;         10
## 3 &lt;S1A-005$C&gt;          1
## 4 &lt;S1A-010$A&gt;          2
## 5 &lt;S1A-011$A&gt;          2
## 6 &lt;S1A-011$B&gt;          3</code></pre>
<p>Now that we extracted how many swear words the speakers in the corpus have used, we can load the biodata of the speakers.</p>
<pre class="r"><code># load bio data
bio &lt;- read.table(&quot;https://slcladal.github.io/data/data01.txt&quot;, 
                  header = T, sep = &quot;\t&quot;)
# create new speaker id
bio$file.speaker.id &lt;- paste(&quot;&lt;&quot;, bio$text.id, &quot;$&quot;, bio$spk.ref, &quot;&gt;&quot;, sep = &quot;&quot;)
# determine file
bio$File &lt;- bio$text.id
# create shorter table
bio &lt;- data.frame(bio$File, bio$file.speaker.id, bio$sex, bio$age, bio$word.count)
# add column names
colnames(bio) &lt;- c(&quot;File&quot;, &quot;Speaker&quot;, &quot;Gender&quot;, &quot;Age&quot;, &quot;Words&quot;)
# inspect data
head(bio)</code></pre>
<pre><code>##      File     Speaker Gender   Age Words
## 1 S1A-001 &lt;S1A-001$A&gt;   male 34-41   765
## 2 S1A-001 &lt;S1A-001$B&gt; female 34-41  1298
## 3 S1A-002 &lt;S1A-002$A&gt; female 26-33   391
## 4 S1A-002 &lt;S1A-002$B&gt; female 19-25    47
## 5 S1A-002 &lt;S1A-002$C&gt;   male   50+   200
## 6 S1A-002 &lt;S1A-002$D&gt; female   50+   464</code></pre>
<p>In a next step, we combine the table with the speaker information with the table showing the swaer word use.</p>
<pre class="r"><code># remove speakers of files that are not in the sample corpus
bio &lt;- bio[bio$File %in% files,]
# combine frequencies and biodata
swire &lt;- join(bio, swirespk, by = c(&quot;Speaker&quot;), type = &quot;left&quot;)
# replave NA with 0
swire$Swearwords &lt;- ifelse(is.na(swire$Swearwords), 0, swire$Swearwords)
# inspect data
head(swire); table(swire$File)</code></pre>
<pre><code>##      File     Speaker Gender   Age Words Swearwords
## 1 S1A-001 &lt;S1A-001$A&gt;   male 34-41   765          0
## 2 S1A-001 &lt;S1A-001$B&gt; female 34-41  1298          0
## 3 S1A-002 &lt;S1A-002$A&gt; female 26-33   391          0
## 4 S1A-002 &lt;S1A-002$B&gt; female 19-25    47          0
## 5 S1A-002 &lt;S1A-002$C&gt;   male   50+   200          0
## 6 S1A-002 &lt;S1A-002$D&gt; female   50+   464          0</code></pre>
<pre><code>## 
## S1A-001 S1A-002 S1A-003 S1A-004 S1A-005 S1A-006 S1A-007 S1A-009 S1A-010 
##       2       9       6       3       3       5       6       3       5 
## S1A-011 S1A-014 S1A-018 S1A-019 S1A-020 
##       4       1       1       4       4</code></pre>
<pre class="r"><code># clean data
swire &lt;- swire[is.na(swire$Gender) == F, ]
swire &lt;- swire[is.na(swire$Age) == F, ]
swire &lt;- swire[swire$Words != 0, ]
# calculate per-1,000-words frequency
swire$RelativeFrequency &lt;- round(swire$Swearwords/swire$Words*1000)
# inspect data
head(swire)</code></pre>
<pre><code>##      File     Speaker Gender   Age Words Swearwords RelativeFrequency
## 1 S1A-001 &lt;S1A-001$A&gt;   male 34-41   765          0                 0
## 2 S1A-001 &lt;S1A-001$B&gt; female 34-41  1298          0                 0
## 3 S1A-002 &lt;S1A-002$A&gt; female 26-33   391          0                 0
## 4 S1A-002 &lt;S1A-002$B&gt; female 19-25    47          0                 0
## 5 S1A-002 &lt;S1A-002$C&gt;   male   50+   200          0                 0
## 6 S1A-002 &lt;S1A-002$D&gt; female   50+   464          0                 0</code></pre>
<p>Now that we have prepared our data, we can plot swear word use by gender.</p>
<pre class="r"><code># plot swear word use by gender
boxplot(swire$RelativeFrequency ~ swire$Gender, 
        ylim = c(-5, 20),
  main = &quot;Use of swear words by gender in Irish English&quot;,
  col = c(&quot;orange&quot;, &quot;darkgrey&quot;), 
  notch = F)
grid()
# add text
# add + where mean values are
text(1:2, tapply(swire$RelativeFrequency, swire$Gender, mean), &quot;+&quot;)
# add mean value below box
text(1:2, c(-3.5, -3.5), paste(&quot;mean=\n&quot;, round(tapply(swire$RelativeFrequency, swire$Gender, mean), 3), sep = &quot;&quot;))
# include statz in graph
# add results of Wilcox Test
text(.75, 20, &quot;Wilcox Test&quot;)
text(.75, 18, paste(&quot;W=&quot;, as.vector(unlist(wilcox.test(swire$RelativeFrequency ~ swire$Gender)[1])), sep = &quot;&quot;))
text(.75, 16, paste(&quot;p=&quot;, round(wilcox.test(swire$RelativeFrequency ~ swire$Gender)[[3]], 4), sep = &quot;&quot;))</code></pre>
<p><img src="corplingr_files/figure-html/sw18-1.png" width="672" /></p>
<p>Next, we plot the use of swearwords by both age and gender. To do this, we need to calculate the mean frequency of swearwords by age and gender.</p>
<pre class="r"><code># create interaction table
interactiontb &lt;- as.data.frame(tapply(swire$RelativeFrequency , 
                        list(swire$Age, swire$Gender), 
                        mean))
# inspect table
interactiontb</code></pre>
<pre><code>##       female male
## 19-25 0.0000  0.0
## 26-33 0.8846  9.0
## 34-41 0.7778  1.5
## 50+   0.0000  0.0</code></pre>
<p>We will now plot the distribution to see whether there are age related differences in swear word use between men and women.</p>
<pre class="r"><code>plot(interactiontb$female, 
     type = &quot;b&quot;, lwd = 2,  
     lty = 1, 
     pch = 0,  
     cex = 1, 
     ylim = c(0,10),
     col = &quot;orange&quot;,
     axes = F, 
     xlab = &quot;Age&quot;,
     ylab = &quot;Relative frequency (per 1,000 words)&quot;)
lines(interactiontb$male, 
      type = &quot;o&quot;, 
      lwd = 2,  
      lty = 2, 
      pch = 1,
      col = &quot;darkgrey&quot;,
      cex = 1)
axis(1, at = 0:5, lab = c(&quot;&quot;, &quot;19-25&quot;, &quot;26-33&quot;, &quot;34-41&quot;, &quot;42-49&quot;, &quot;50+&quot;))
# add y-axes with specified labels at specified intervals
axis(2, at = seq(0, 10, 2), las = 1, lab = seq(0, 10, 2))
# add legend
legend(&quot;topright&quot;, inset = .05, c(&quot;female&quot;, &quot;male&quot;),
  horiz = F,  pch = c(0,1), lty = c(1,2), col = c(&quot;orange&quot;, &quot;darkgrey&quot;))
# create a box around the plot
box()
# add grid
grid()</code></pre>
<p><img src="corplingr_files/figure-html/sw20-1.png" width="672" /></p>
<p>The graph suggests that the genders do not differ in their use of swear words execpt for the age bracket from 26 to 33 years of age where men swear substantially. In fact, the difference between the genders shown in the plot before is entirely due to the difference in this middle-aged age bracket.</p>
<p>It has to be borne in mind, thoguh, that this is merely a case study and that a more fine-grained analysis on a substantially larger data set were necessary to get a more reliable impression.</p>
<div id="case-study-adjective-amplification" class="section level2">
<h2><span class="header-section-number">3.1</span> Case Study: Adjective Amplification</h2>
<p>In this case study, we will investigate changes in adjective amplification (“very good”, “really nice”, “absolutely awesome”). In contrast to the case study above, this study requires part-of-speech tagging which makes this case study particularly useful as part-of-speech tagging is a common issue in language research.</p>
<p><img src="images/uq2.jpg" width="100%" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
