<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-09-17" />

<title>Case Studies &amp; Use Cases</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="people.html">
    <span class="fa fa-home"></span>
     
    OUR PEOPLE
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    EVENTS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="workshops.html">Workshops &amp; Training</a>
    </li>
    <li>
      <a href="conferences.html">Conferences &amp; Presentations</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Analytics</li>
    <li>
      <a href="introcomputer.html">Working with Computers</a>
    </li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="IntroR_workshop.html">Getting started</a>
    </li>
    <li>
      <a href="stringprocessing.html">String Processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular Expressions</a>
    </li>
    <li>
      <a href="introtables.html">Working with Tables</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="basicgraphs.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="basicgraphs.html">Basic Graphs</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">
    <span class="fa fa-eye"></span>
     
    SERVICES
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    BLOG &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="corplingr.html">Swear words in Irish English</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    CONTACT
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Case Studies &amp; Use Cases</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-09-17</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>This section presents different case studies or use cases that highlight how the the content shown in the tutorials can be put into practice. The case studies thus merely exemplify ways in which R can be used in language-based research rather than providing models of how to do research. The R markdown document of this case study can be downloaded <a href="https://slcladal.github.io/rscripts/corplingr.Rmd">here</a>.</p>
<p><strong>Preparation and session set up</strong></p>
<p>This case study is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R <a href="https://slcladal.github.io/IntroR_workshop.html">here</a>. For this case study, we need to install certain <em>packages</em> from an R <em>library</em> so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# manual installation
install.packages(&quot;devtools&quot;)
# load devtools and install development version of data.table
library(devtools)
install_github(&quot;Rdatatable/data.table&quot;, build_vignettes = FALSE)</code></pre>
<p>Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="gender-and-age-differences-in-swearing" class="section level1">
<h1><span class="header-section-number">1</span> Gender and Age Differences in Swearing</h1>
<p>This case study aims to answer if swearing differs across age groups and genders, i.e. whether old or young or men or women swear more, in a small sample corpus using R. In a first step, we load the load the data into R. The way that the corpus data is loaded in this example is somewhat awkward because the data is in a server directory rather than on a hard drive on a simple PC. If the corpus data is not stored in a directory of a server, then you should not use the code shown immediately below but code in the window following the code immediately below.</p>
<pre class="r"><code># define path to corpus
corpuspath &lt;- &quot;https://slcladal.github.io/data/ICEIrelandSample/&quot;
# define corpusfiles
files &lt;- paste(corpuspath, &quot;S1A-00&quot;, 1:20, &quot;.txt&quot;, sep = &quot;&quot;)
files &lt;- gsub(&quot;[0-9]([0-9][0-9][0-9])&quot;, &quot;\\1&quot;, files)
# load corpus files
corpus &lt;- sapply(files, function(x){
  x &lt;- readLines(x)
  x &lt;- paste(x, collapse = &quot; &quot;)
  x &lt;- tolower(x)
})
# inspect corpus
str(corpus)</code></pre>
<pre><code>##  Named chr [1:20] &quot;&lt;s1a-001 riding&gt;  &lt;i&gt; &lt;s1a-001$a&gt; &lt;#&gt; well how did the riding go tonight &lt;s1a-001$b&gt; &lt;#&gt; it was good so it was &quot;| __truncated__ ...
##  - attr(*, &quot;names&quot;)= chr [1:20] &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-001.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-002.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-003.txt&quot; &quot;https://slcladal.github.io/data/ICEIrelandSample/S1A-004.txt&quot; ...</code></pre>
<p>If the corpus data is stored on your own computer (on not on a serves as is the case in the present example), you should use the following code (you need to adapt the path though as the code below only works on my computer):</p>
<pre class="r"><code># define path to corpus
# WARNING: you need to include your own path!
corpuspath &lt;- &quot;D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io\\data\\ICEIrelandSample&quot;
# define corpusfiles
files &lt;- list.paste(corpuspath, all.names = T)
# load corpus files
corpus &lt;- sapply(files, function(x){
  x &lt;- scan(x, what = &quot;char&quot;, sep = &quot;&quot;, quote = &quot;&quot;, skipNul = T)
  x &lt;- paste(x, sep = &quot; &quot;, collapse = &quot; &quot;)
  x &lt;- tolower(x)
})
# inspect corpus
str(corpus)</code></pre>
<p>Now that the corpus data is loaded, we can prepare the searches by defining the search patterns. We will use regular expressions to retrieve all variants of the swear words. The sequence <code>\\b</code> denotes word boundaries while the sequence <code>[a-z]{0,3}</code> means that the sequences <em>ass</em> can be followed by a string consisting of any character symbol that is maximally three characters long (so that the search would also retrieve <em>asses</em>). We separate the search patters by <code>|</code> as this means <em>or</em>.</p>
<pre class="r"><code>searchpatterns &lt;- c(&quot;\\bass[ingedholes]{0,6}\\b|\\bbitch[a-z]{0,3}\\b|\\b[a-z]{0,}fuck[a-z]{0,3}\\b|\\bshit[a-z]{0,3}\\b|\\bcock[a-z]{0,3}\\b|\\bwanker[a-z]{0,3}\\b|\\bboll[io]{1,1}[a-z]{0,3}\\b|\\bcrap[a-z]{0,3}\\b|\\bbugger[a-z]{0,3}\\b|\\bcunt[a-z]{0,3}\\b&quot;)</code></pre>
<p>After defining the search pattern(s), we extract the kwics (keyword(s) in context) of the swear words.</p>
<pre class="r"><code># activate package
library(quanteda)
# extarct kwic
kwicswears &lt;- kwic(corpus, searchpatterns,window = 10, valuetype = &quot;regex&quot;)
# inspect results
kwicswears</code></pre>
<pre><code>##                                                                      
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-003.txt, 1348]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 525]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 529]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 664]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 1012]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 1026]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 1600]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 1783]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 2921]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 3599]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 3620]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 3847]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-005.txt, 4842]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-010.txt, 2364]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-010.txt, 2928]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-011.txt, 2032]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-011.txt, 2463]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-011.txt, 2680]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-011.txt, 2714]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-011.txt, 3801]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 312]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 1055]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 1845]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 2712]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 4755]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 5122]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-014.txt, 5225]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 472]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 693]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 1937]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 3483]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 3869]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 4897]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-015.txt, 5436]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-017.txt, 4810]
##    [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 18]
##    [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 50]
##    [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 67]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 449]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 894]
##   [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 895]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 3732]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 3936]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 4523]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 4700]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-018.txt, 5901]
##    [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 74]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 2589]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 3978]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 4856]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 4874]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-019.txt, 4879]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt, 1753]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt, 3443]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt, 3474]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt, 3567]
##  [https://slcladal.github.io/data/ICEIrelandSample/S1A-020.txt, 4200]
##                                                                        
##  suppose the worrying thing was then you realised it did | bugger-all |
##              was uh they just want my money and all this |   shite    |
##                      want my money and all this shite&lt;#&gt; |    fuck    |
##                         flick through them bits&lt;#&gt; it&#39; s |   shite    |
##                              5 sylls&lt;/ unclear&gt; i&#39; ve to |  fucking   |
##                             guy because he&#39; s a mason&lt;#&gt; |    fuck    |
##                                 all&lt;#&gt; i&#39; m like dad you |  fucking   |
##                              try again&lt;#&gt; it&#39; s all just |  bollocks  |
##                         visiting&lt;/[&gt; and she was like oh |  fucking   |
##        marching down the corridor going you&#39; ve been out |  fucking   |
##                              the guy goes who&#39; s this&lt;#&gt; |    fuck    |
##                    #&gt; and they were right get her out to |    fuck    |
##                     &lt;#&gt; she was pretending to be a nurse |  fucking   |
##                                    you sell it for&lt;{&gt;&lt;[&gt; |  fucking   |
##                         and i went to brindisi&lt;,&gt; it was |   shite    |
##                                  /&amp;&gt;&lt;#&gt; we didn&#39;t have a |  fucking   |
##                       in our church and in our church&lt;#&gt; |  fucking   |
##                         knew mary&lt;#&gt; we were like oh for |    fuck    |
##                         #&gt; and i&#39; m like big teacher pet |  bitches   |
##                        #&gt; it&#39; s all your fault you dirty |   bitch    |
##                                    &gt;&lt;#&gt; he&#39; s so full of |    shit    |
##                                       &amp;&gt;&lt; s1a-014$ c&gt;&lt;#&gt; |  fucking   |
##               one of them drinks a pint of bass and then |   fucks    |
##                                         c&gt;&lt;#&gt; but nah&lt;#&gt; |    fuck    |
##                                         $ d&gt;&lt;#&gt;&lt;[&gt; doing | bugger-all |
##                &gt; like i didn&#39;t want i didn&#39;t want him to |   bugger   |
##                                      [ 2&gt;&lt;/{ 2&gt; going to |   bugger   |
##                    taken and i&#39; ll be left going to some |    crap    |
##                                 in order&lt; s1a-015$ a&gt;&lt;#&gt; |  bollocks  |
##                 had a few too many to drink and the cops |   fucked   |
##                                   $ a&gt;&lt;#&gt; my mum used to |  bollock   |
##                                  s1a-015$ a&gt;&lt;#&gt; he was a |   wanker   |
##                     your results are in&lt;#&gt; and i thought |  fucking   |
##                          #&gt; you go on like a pain in the |    ass     |
##                                 &lt; s1a-017$ b&gt;&lt;#&gt; och for |    fuck    |
##                           &lt; s1a-018$ a&gt;&lt;#&gt; ambulance was |    crap    |
##                                &lt; s1a-018$ a&gt;&lt;#&gt; you were |    crap    |
##                                        #&gt; i wasn&#39;t&lt;{&gt;&lt;[&gt; |    crap    |
##                             $ a&gt;&lt;#&gt; i thought nadine was |    crap    |
##             noticed her at that drama ball cos she was a |  fucking   |
##             her at that drama ball cos she was a fucking |   wanker   |
##                                   his&lt;,&gt; i mean he&#39; s so |  fucking   |
##                                       &gt;&lt;[&gt; girl&lt;/[&gt; from |  fucking   |
##                               s1a-018$ b&gt;&lt;#&gt; load of oul |  bollocks  |
##           said you know how do you say no without saying |    fuck    |
##                                     because&lt;{&gt;&lt;[&gt; she&#39; s |  fuck-all  |
##                    no i&#39; ll be giving those old fogies a |  fucking   |
##                   where i least expect him cos he&#39; s not |  fucking   |
##                       &lt;/[&gt; uhm which will be some sci-fi |    crap    |
##                                boring and&lt;,&gt;&lt;/[&gt; talking |    crap    |
##                                       $ a&gt;&lt;#&gt;&lt;[&gt; talking |    crap    |
##                             &gt;&lt;[&gt; talking crap&lt;,&gt; talking |    crap    |
##                       &lt;#&gt; you just think i just can&#39;t be |   assed    |
##                              &#39; s&lt;/[ 4&gt; just being really |   bitchy   |
##                                          &gt; not&lt;{ 6&gt;&lt;[ 6&gt; |   bitchy   |
##                                     &lt;#&gt;&lt;[ 2&gt; pain in the |    ass     |
##                      &lt;#&gt; but he was waiting to cross the |  fucking   |
##                                                      
##  you know&lt;&amp;&gt; laughter&lt;/&amp;&gt;                            
##  &lt;#&gt; fuck them&lt;#&gt; i&#39;                                 
##  them&lt;#&gt; i&#39; m never joining them                     
##  &lt; s1a-005$ a&gt;&lt;#&gt; all the                            
##  deal with that guy because he&#39; s a mason            
##  that&lt; s1a-005$ c&gt;&lt;#&gt;&lt;                               
##  joined this&lt;&amp;&gt; laughter&lt;/&amp;&gt;                         
##  &lt; s1a-005$ b&gt;&lt;#&gt; it&#39;                                
##  &lt; s1a-005$ b&gt;&lt;#&gt;&lt;[                                  
##  and whoring haven&#39;t you you bastard&lt;#&gt; and          
##  off&lt;&amp;&gt; laughter&lt;/&amp;&gt;&lt;                                
##  &lt;#&gt; she went out&lt;#&gt; now                             
##  jamming bananas into him&lt; s1a-005$ c&gt;&lt;              
##  &lt;/[&gt; two quid&lt; s1a-010$ b                           
##  &lt;&amp;&gt; laughter&lt;/&amp;&gt; the best                           
##  clue what&lt;{&gt;&lt;[&gt; was going                           
##  ever heard in our church ever again i was gonna     
##  sake like jesus&lt;#&gt; and you&#39; d                       
##  ugh&lt;#&gt; you know as if it didn&#39;t                     
##  &lt; s1a-011$ a&gt;&lt;#&gt; i&#39;                                 
##  &lt;#&gt; i&#39; m going to&lt; unclear                          
##  hell only started drinking here&lt;#&gt; what&#39;            
##  up to bed&lt; s1a-014$ a&gt;&lt;#                            
##  &lt;{&gt;&lt;[&gt; it&lt;/[                                        
##  &lt; unclear&gt; several sylls&lt;/ unclear&gt;&lt;                
##  off and i&#39; d still be sitting in work               
##  off and leave him sitting in work&lt; s1a-014$         
##  poly somewhere&lt;#&gt; being a top of the                
##  &lt;#&gt; i&#39; m still i&#39; m                                 
##  him back into the house again and&lt; s1a-015$         
##  me all the time about records that played backwards&lt;
##  &lt;#&gt; he&#39; s he&#39; s he                                  
##  hell&lt;,&gt; because he&#39; s got a                         
##  too you can like&lt; s1a-015$ c&gt;&lt;                      
##  &#39; s sake&lt;#&gt;&lt;{&gt;&lt;                                     
##  &lt; s1a-018$ b&gt;&lt;#&gt; i know                             
##  &lt; s1a-018$ b&gt;&lt;#&gt; i wasn&#39;t                           
##  in ambulance&lt;/[&gt;&lt; s1a-018$ a                        
##  &lt; s1a-018$ b&gt;&lt;#&gt; no nadine                          
##  wanker just like she was&lt;,&gt; she was                 
##  just like she was&lt;,&gt; she was even                   
##  incredibly&lt;{&gt;&lt;[&gt; stupid&lt;/                           
##  cork&lt; s1a-018$ a&gt;&lt;#&gt;&lt;                               
##  &lt;&amp;&gt; laughter&lt;/&amp;&gt;&lt; s1a-018                           
##  off&lt;&amp;&gt; laughter&lt;/&amp;&gt;&lt;                                
##  personality as far as i&#39; m concerned&lt;/              
##  heart attack&lt;&amp;&gt; laughter&lt;/&amp;&gt;                        
##  showing anywhere&lt; s1a-019$ b&gt;&lt;#&gt;                    
##  &lt;#&gt; and uhm&lt;,&gt; that&#39;                                
##  you know what i mean&lt; s1a-019$ a&gt;                   
##  &lt;,&gt; talking crap&lt;,&gt; he wouldn&#39;t                     
##  &lt;,&gt; he wouldn&#39;t shut up&lt;/[                          
##  &lt;{ 1&gt;&lt;[ 1&gt; talking to                               
##  in that sort of scene or being&lt;{ 5                  
##  but&lt;,&gt; if they&#39; re&lt;/                                
##  &lt;/[ 2&gt;&lt;/{ 2&gt;                                        
##  lights as well&lt;#&gt; so i was standing</code></pre>
<p>We now clean the kwic so that it is easier to see the relevant information.</p>
<pre class="r"><code>kwicswearsdf &lt;- as.data.frame(kwicswears)
colnames(kwicswearsdf) &lt;- c(&quot;File&quot;, &quot;StartPosition&quot;, &quot;EndPosition&quot;, &quot;PreviousContext&quot;, &quot;Token&quot;, &quot;FollowingContext&quot;, &quot;SearchPattern&quot;)
library(dplyr)
library(stringr)
kwicswearsclean &lt;- kwicswearsdf %&gt;%
  select(-StartPosition, -EndPosition, -SearchPattern) %&gt;%
  mutate(File = str_remove_all(File, &quot;.*/&quot;),
         File = str_remove_all(File, &quot;.txt&quot;))
# inspect results
kwicswearsclean</code></pre>
<pre><code>##       File                                         PreviousContext      Token
## 1  S1A-003 suppose the worrying thing was then you realised it did bugger-all
## 2  S1A-005             was uh they just want my money and all this      shite
## 3  S1A-005                  want my money and all this shite &lt; # &gt;       fuck
## 4  S1A-005                    flick through them bits &lt; # &gt; it &#39; s      shite
## 5  S1A-005                         5 sylls &lt; / unclear &gt; i &#39; ve to    fucking
## 6  S1A-005                        guy because he &#39; s a mason &lt; # &gt;       fuck
## 7  S1A-005                            all &lt; # &gt; i &#39; m like dad you    fucking
## 8  S1A-005                         try again &lt; # &gt; it &#39; s all just   bollocks
## 9  S1A-005                    visiting &lt; / [ &gt; and she was like oh    fucking
## 10 S1A-005      marching down the corridor going you &#39; ve been out    fucking
## 11 S1A-005                         the guy goes who &#39; s this &lt; # &gt;       fuck
## 12 S1A-005                  # &gt; and they were right get her out to       fuck
## 13 S1A-005                  &lt; # &gt; she was pretending to be a nurse    fucking
## 14 S1A-010                             you sell it for &lt; { &gt; &lt; [ &gt;    fucking
## 15 S1A-010                     and i went to brindisi &lt; , &gt; it was      shite
## 16 S1A-011                            / &amp; &gt; &lt; # &gt; we didn&#39;t have a    fucking
## 17 S1A-011                   in our church and in our church &lt; # &gt;    fucking
## 18 S1A-011                     knew mary &lt; # &gt; we were like oh for       fuck
## 19 S1A-011                      # &gt; and i &#39; m like big teacher pet    bitches
## 20 S1A-011                     # &gt; it &#39; s all your fault you dirty      bitch
## 21 S1A-014                               &gt; &lt; # &gt; he &#39; s so full of       shit
## 22 S1A-014                               &amp; &gt; &lt; s1a-014 $ c &gt; &lt; # &gt;    fucking
## 23 S1A-014              one of them drinks a pint of bass and then      fucks
## 24 S1A-014                                 c &gt; &lt; # &gt; but nah &lt; # &gt;       fuck
## 25 S1A-014                                 $ d &gt; &lt; # &gt; &lt; [ &gt; doing bugger-all
## 26 S1A-014               &gt; like i didn&#39;t want i didn&#39;t want him to     bugger
## 27 S1A-014                                [ 2 &gt; &lt; / { 2 &gt; going to     bugger
## 28 S1A-015                  taken and i &#39; ll be left going to some       crap
## 29 S1A-015                          in order &lt; s1a-015 $ a &gt; &lt; # &gt;   bollocks
## 30 S1A-015                had a few too many to drink and the cops     fucked
## 31 S1A-015                              $ a &gt; &lt; # &gt; my mum used to    bollock
## 32 S1A-015                            s1a-015 $ a &gt; &lt; # &gt; he was a     wanker
## 33 S1A-015                 your results are in &lt; # &gt; and i thought    fucking
## 34 S1A-015                        # &gt; you go on like a pain in the        ass
## 35 S1A-017                           &lt; s1a-017 $ b &gt; &lt; # &gt; och for       fuck
## 36 S1A-018                     &lt; s1a-018 $ a &gt; &lt; # &gt; ambulance was       crap
## 37 S1A-018                          &lt; s1a-018 $ a &gt; &lt; # &gt; you were       crap
## 38 S1A-018                                # &gt; i wasn&#39;t &lt; { &gt; &lt; [ &gt;       crap
## 39 S1A-018                        $ a &gt; &lt; # &gt; i thought nadine was       crap
## 40 S1A-018            noticed her at that drama ball cos she was a    fucking
## 41 S1A-018            her at that drama ball cos she was a fucking     wanker
## 42 S1A-018                              his &lt; , &gt; i mean he &#39; s so    fucking
## 43 S1A-018                               &gt; &lt; [ &gt; girl &lt; / [ &gt; from    fucking
## 44 S1A-018                         s1a-018 $ b &gt; &lt; # &gt; load of oul   bollocks
## 45 S1A-018          said you know how do you say no without saying       fuck
## 46 S1A-018                             because &lt; { &gt; &lt; [ &gt; she &#39; s   fuck-all
## 47 S1A-019                  no i &#39; ll be giving those old fogies a    fucking
## 48 S1A-019                 where i least expect him cos he &#39; s not    fucking
## 49 S1A-019                   &lt; / [ &gt; uhm which will be some sci-fi       crap
## 50 S1A-019                        boring and &lt; , &gt; &lt; / [ &gt; talking       crap
## 51 S1A-019                               $ a &gt; &lt; # &gt; &lt; [ &gt; talking       crap
## 52 S1A-019                      &gt; &lt; [ &gt; talking crap &lt; , &gt; talking       crap
## 53 S1A-020                    &lt; # &gt; you just think i just can&#39;t be      assed
## 54 S1A-020                         &#39; s &lt; / [ 4 &gt; just being really     bitchy
## 55 S1A-020                                   &gt; not &lt; { 6 &gt; &lt; [ 6 &gt;     bitchy
## 56 S1A-020                               &lt; # &gt; &lt; [ 2 &gt; pain in the        ass
## 57 S1A-020                   &lt; # &gt; but he was waiting to cross the    fucking
##                                         FollowingContext
## 1                        you know &lt; &amp; &gt; laughter &lt; / &amp; &gt;
## 2                              &lt; # &gt; fuck them &lt; # &gt; i &#39;
## 3                    them &lt; # &gt; i &#39; m never joining them
## 4                          &lt; s1a-005 $ a &gt; &lt; # &gt; all the
## 5              deal with that guy because he &#39; s a mason
## 6                           that &lt; s1a-005 $ c &gt; &lt; # &gt; &lt;
## 7                     joined this &lt; &amp; &gt; laughter &lt; / &amp; &gt;
## 8                             &lt; s1a-005 $ b &gt; &lt; # &gt; it &#39;
## 9                              &lt; s1a-005 $ b &gt; &lt; # &gt; &lt; [
## 10         and whoring haven&#39;t you you bastard &lt; # &gt; and
## 11                          off &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt;
## 12                          &lt; # &gt; she went out &lt; # &gt; now
## 13            jamming bananas into him &lt; s1a-005 $ c &gt; &lt;
## 14                        &lt; / [ &gt; two quid &lt; s1a-010 $ b
## 15                       &lt; &amp; &gt; laughter &lt; / &amp; &gt; the best
## 16                       clue what &lt; { &gt; &lt; [ &gt; was going
## 17       ever heard in our church ever again i was gonna
## 18                     sake like jesus &lt; # &gt; and you &#39; d
## 19                    ugh &lt; # &gt; you know as if it didn&#39;t
## 20                             &lt; s1a-011 $ a &gt; &lt; # &gt; i &#39;
## 21                        &lt; # &gt; i &#39; m going to &lt; unclear
## 22          hell only started drinking here &lt; # &gt; what &#39;
## 23                         up to bed &lt; s1a-014 $ a &gt; &lt; #
## 24                                  &lt; { &gt; &lt; [ &gt; it &lt; / [
## 25             &lt; unclear &gt; several sylls &lt; / unclear &gt; &lt;
## 26                off and i &#39; d still be sitting in work
## 27         off and leave him sitting in work &lt; s1a-014 $
## 28               poly somewhere &lt; # &gt; being a top of the
## 29                               &lt; # &gt; i &#39; m still i &#39; m
## 30         him back into the house again and &lt; s1a-015 $
## 31 me all the time about records that played backwards &lt;
## 32                                &lt; # &gt; he &#39; s he &#39; s he
## 33                       hell &lt; , &gt; because he &#39; s got a
## 34                    too you can like &lt; s1a-015 $ c &gt; &lt;
## 35                                &#39; s sake &lt; # &gt; &lt; { &gt; &lt;
## 36                          &lt; s1a-018 $ b &gt; &lt; # &gt; i know
## 37                        &lt; s1a-018 $ b &gt; &lt; # &gt; i wasn&#39;t
## 38                    in ambulance &lt; / [ &gt; &lt; s1a-018 $ a
## 39                       &lt; s1a-018 $ b &gt; &lt; # &gt; no nadine
## 40                wanker just like she was &lt; , &gt; she was
## 41                  just like she was &lt; , &gt; she was even
## 42                     incredibly &lt; { &gt; &lt; [ &gt; stupid &lt; /
## 43                          cork &lt; s1a-018 $ a &gt; &lt; # &gt; &lt;
## 44                      &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt; s1a-018
## 45                          off &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt;
## 46             personality as far as i &#39; m concerned &lt; /
## 47                   heart attack &lt; &amp; &gt; laughter &lt; / &amp; &gt;
## 48                showing anywhere &lt; s1a-019 $ b &gt; &lt; # &gt;
## 49                            &lt; # &gt; and uhm &lt; , &gt; that &#39;
## 50                  you know what i mean &lt; s1a-019 $ a &gt;
## 51                  &lt; , &gt; talking crap &lt; , &gt; he wouldn&#39;t
## 52                       &lt; , &gt; he wouldn&#39;t shut up &lt; / [
## 53                            &lt; { 1 &gt; &lt; [ 1 &gt; talking to
## 54                  in that sort of scene or being &lt; { 5
## 55                            but &lt; , &gt; if they &#39; re &lt; /
## 56                                   &lt; / [ 2 &gt; &lt; / { 2 &gt;
## 57                lights as well &lt; # &gt; so i was standing</code></pre>
<p>We now create another kwic but with much more context because we want to extract the speaker that has uttered the swear word. To this end, we remove everything that proceeds the <code>$</code> symbol as the speakers are identified by characters that follow the <code>$</code> symbol, remove everything that follows the <code>&gt;</code> symbol which end the speaker identification sequence, remove remaining white spaces, and convert the remaining character to upper case.</p>
<pre class="r"><code># extract kwic
kwiclong &lt;- kwic(corpus, searchpatterns,window = 1000, valuetype = &quot;regex&quot;)
kwiclong &lt;- as.data.frame(kwiclong)
colnames(kwiclong) &lt;- c(&quot;File&quot;, &quot;StartPosition&quot;, &quot;EndPosition&quot;, &quot;PreviousContext&quot;, &quot;Token&quot;, &quot;FollowingContext&quot;, &quot;SearchPattern&quot;)
kwiclong &lt;- kwiclong %&gt;%
  select(-StartPosition, -EndPosition, -SearchPattern) %&gt;%
  mutate(File = str_remove_all(File, &quot;.*/&quot;),
         File = str_remove_all(File, &quot;.txt&quot;),
         Speaker = str_remove_all(PreviousContext, &quot;.*\\$&quot;),
         Speaker = str_remove_all(Speaker, &quot;&gt;.*&quot;),
         Speaker = str_squish(Speaker),
         Speaker = toupper(Speaker)) %&gt;%
  select(Speaker)
# inspect results
head(kwiclong)</code></pre>
<pre><code>##   Speaker
## 1       A
## 2       B
## 3       B
## 4       B
## 5       B
## 6       B</code></pre>
<p>We now add the Speaker to our initial kwic. This way, we combine the swear word kwic with the speaker and as we already have the file, we can use the file plus speaker idenification to check if the speaker was a man or a woman.</p>
<pre class="r"><code>swire &lt;- cbind(kwicswearsclean, kwiclong)
# inspect data
swire</code></pre>
<pre><code>##       File                                         PreviousContext      Token
## 1  S1A-003 suppose the worrying thing was then you realised it did bugger-all
## 2  S1A-005             was uh they just want my money and all this      shite
## 3  S1A-005                  want my money and all this shite &lt; # &gt;       fuck
## 4  S1A-005                    flick through them bits &lt; # &gt; it &#39; s      shite
## 5  S1A-005                         5 sylls &lt; / unclear &gt; i &#39; ve to    fucking
## 6  S1A-005                        guy because he &#39; s a mason &lt; # &gt;       fuck
## 7  S1A-005                            all &lt; # &gt; i &#39; m like dad you    fucking
## 8  S1A-005                         try again &lt; # &gt; it &#39; s all just   bollocks
## 9  S1A-005                    visiting &lt; / [ &gt; and she was like oh    fucking
## 10 S1A-005      marching down the corridor going you &#39; ve been out    fucking
## 11 S1A-005                         the guy goes who &#39; s this &lt; # &gt;       fuck
## 12 S1A-005                  # &gt; and they were right get her out to       fuck
## 13 S1A-005                  &lt; # &gt; she was pretending to be a nurse    fucking
## 14 S1A-010                             you sell it for &lt; { &gt; &lt; [ &gt;    fucking
## 15 S1A-010                     and i went to brindisi &lt; , &gt; it was      shite
## 16 S1A-011                            / &amp; &gt; &lt; # &gt; we didn&#39;t have a    fucking
## 17 S1A-011                   in our church and in our church &lt; # &gt;    fucking
## 18 S1A-011                     knew mary &lt; # &gt; we were like oh for       fuck
## 19 S1A-011                      # &gt; and i &#39; m like big teacher pet    bitches
## 20 S1A-011                     # &gt; it &#39; s all your fault you dirty      bitch
## 21 S1A-014                               &gt; &lt; # &gt; he &#39; s so full of       shit
## 22 S1A-014                               &amp; &gt; &lt; s1a-014 $ c &gt; &lt; # &gt;    fucking
## 23 S1A-014              one of them drinks a pint of bass and then      fucks
## 24 S1A-014                                 c &gt; &lt; # &gt; but nah &lt; # &gt;       fuck
## 25 S1A-014                                 $ d &gt; &lt; # &gt; &lt; [ &gt; doing bugger-all
## 26 S1A-014               &gt; like i didn&#39;t want i didn&#39;t want him to     bugger
## 27 S1A-014                                [ 2 &gt; &lt; / { 2 &gt; going to     bugger
## 28 S1A-015                  taken and i &#39; ll be left going to some       crap
## 29 S1A-015                          in order &lt; s1a-015 $ a &gt; &lt; # &gt;   bollocks
## 30 S1A-015                had a few too many to drink and the cops     fucked
## 31 S1A-015                              $ a &gt; &lt; # &gt; my mum used to    bollock
## 32 S1A-015                            s1a-015 $ a &gt; &lt; # &gt; he was a     wanker
## 33 S1A-015                 your results are in &lt; # &gt; and i thought    fucking
## 34 S1A-015                        # &gt; you go on like a pain in the        ass
## 35 S1A-017                           &lt; s1a-017 $ b &gt; &lt; # &gt; och for       fuck
## 36 S1A-018                     &lt; s1a-018 $ a &gt; &lt; # &gt; ambulance was       crap
## 37 S1A-018                          &lt; s1a-018 $ a &gt; &lt; # &gt; you were       crap
## 38 S1A-018                                # &gt; i wasn&#39;t &lt; { &gt; &lt; [ &gt;       crap
## 39 S1A-018                        $ a &gt; &lt; # &gt; i thought nadine was       crap
## 40 S1A-018            noticed her at that drama ball cos she was a    fucking
## 41 S1A-018            her at that drama ball cos she was a fucking     wanker
## 42 S1A-018                              his &lt; , &gt; i mean he &#39; s so    fucking
## 43 S1A-018                               &gt; &lt; [ &gt; girl &lt; / [ &gt; from    fucking
## 44 S1A-018                         s1a-018 $ b &gt; &lt; # &gt; load of oul   bollocks
## 45 S1A-018          said you know how do you say no without saying       fuck
## 46 S1A-018                             because &lt; { &gt; &lt; [ &gt; she &#39; s   fuck-all
## 47 S1A-019                  no i &#39; ll be giving those old fogies a    fucking
## 48 S1A-019                 where i least expect him cos he &#39; s not    fucking
## 49 S1A-019                   &lt; / [ &gt; uhm which will be some sci-fi       crap
## 50 S1A-019                        boring and &lt; , &gt; &lt; / [ &gt; talking       crap
## 51 S1A-019                               $ a &gt; &lt; # &gt; &lt; [ &gt; talking       crap
## 52 S1A-019                      &gt; &lt; [ &gt; talking crap &lt; , &gt; talking       crap
## 53 S1A-020                    &lt; # &gt; you just think i just can&#39;t be      assed
## 54 S1A-020                         &#39; s &lt; / [ 4 &gt; just being really     bitchy
## 55 S1A-020                                   &gt; not &lt; { 6 &gt; &lt; [ 6 &gt;     bitchy
## 56 S1A-020                               &lt; # &gt; &lt; [ 2 &gt; pain in the        ass
## 57 S1A-020                   &lt; # &gt; but he was waiting to cross the    fucking
##                                         FollowingContext Speaker
## 1                        you know &lt; &amp; &gt; laughter &lt; / &amp; &gt;       A
## 2                              &lt; # &gt; fuck them &lt; # &gt; i &#39;       B
## 3                    them &lt; # &gt; i &#39; m never joining them       B
## 4                          &lt; s1a-005 $ a &gt; &lt; # &gt; all the       B
## 5              deal with that guy because he &#39; s a mason       B
## 6                           that &lt; s1a-005 $ c &gt; &lt; # &gt; &lt;       B
## 7                     joined this &lt; &amp; &gt; laughter &lt; / &amp; &gt;       B
## 8                             &lt; s1a-005 $ b &gt; &lt; # &gt; it &#39;       A
## 9                              &lt; s1a-005 $ b &gt; &lt; # &gt; &lt; [       C
## 10         and whoring haven&#39;t you you bastard &lt; # &gt; and       B
## 11                          off &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt;       B
## 12                          &lt; # &gt; she went out &lt; # &gt; now       B
## 13            jamming bananas into him &lt; s1a-005 $ c &gt; &lt;       B
## 14                        &lt; / [ &gt; two quid &lt; s1a-010 $ b       A
## 15                       &lt; &amp; &gt; laughter &lt; / &amp; &gt; the best       A
## 16                       clue what &lt; { &gt; &lt; [ &gt; was going       A
## 17       ever heard in our church ever again i was gonna       B
## 18                     sake like jesus &lt; # &gt; and you &#39; d       B
## 19                    ugh &lt; # &gt; you know as if it didn&#39;t       B
## 20                             &lt; s1a-011 $ a &gt; &lt; # &gt; i &#39;       A
## 21                        &lt; # &gt; i &#39; m going to &lt; unclear       B
## 22          hell only started drinking here &lt; # &gt; what &#39;       C
## 23                         up to bed &lt; s1a-014 $ a &gt; &lt; #       D
## 24                                  &lt; { &gt; &lt; [ &gt; it &lt; / [       C
## 25             &lt; unclear &gt; several sylls &lt; / unclear &gt; &lt;       D
## 26                off and i &#39; d still be sitting in work       B
## 27         off and leave him sitting in work &lt; s1a-014 $       C
## 28               poly somewhere &lt; # &gt; being a top of the       A
## 29                               &lt; # &gt; i &#39; m still i &#39; m       A
## 30         him back into the house again and &lt; s1a-015 $       A
## 31 me all the time about records that played backwards &lt;       A
## 32                                &lt; # &gt; he &#39; s he &#39; s he       A
## 33                       hell &lt; , &gt; because he &#39; s got a       D
## 34                    too you can like &lt; s1a-015 $ c &gt; &lt;       A
## 35                                &#39; s sake &lt; # &gt; &lt; { &gt; &lt;       B
## 36                          &lt; s1a-018 $ b &gt; &lt; # &gt; i know       A
## 37                        &lt; s1a-018 $ b &gt; &lt; # &gt; i wasn&#39;t       A
## 38                    in ambulance &lt; / [ &gt; &lt; s1a-018 $ a       B
## 39                       &lt; s1a-018 $ b &gt; &lt; # &gt; no nadine       A
## 40                wanker just like she was &lt; , &gt; she was       C
## 41                  just like she was &lt; , &gt; she was even       C
## 42                     incredibly &lt; { &gt; &lt; [ &gt; stupid &lt; /       B
## 43                          cork &lt; s1a-018 $ a &gt; &lt; # &gt; &lt;       B
## 44                      &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt; s1a-018       B
## 45                          off &lt; &amp; &gt; laughter &lt; / &amp; &gt; &lt;       A
## 46             personality as far as i &#39; m concerned &lt; /       B
## 47                   heart attack &lt; &amp; &gt; laughter &lt; / &amp; &gt;       A
## 48                showing anywhere &lt; s1a-019 $ b &gt; &lt; # &gt;       A
## 49                            &lt; # &gt; and uhm &lt; , &gt; that &#39;       B
## 50                  you know what i mean &lt; s1a-019 $ a &gt;       C
## 51                  &lt; , &gt; talking crap &lt; , &gt; he wouldn&#39;t       A
## 52                       &lt; , &gt; he wouldn&#39;t shut up &lt; / [       A
## 53                            &lt; { 1 &gt; &lt; [ 1 &gt; talking to       D
## 54                  in that sort of scene or being &lt; { 5       C
## 55                            but &lt; , &gt; if they &#39; re &lt; /       C
## 56                                   &lt; / [ 2 &gt; &lt; / { 2 &gt;       A
## 57                lights as well &lt; # &gt; so i was standing       D</code></pre>
<p>Now, we inspect the extracted swear word tokens to check if our search strings have indeed captured swear words.</p>
<pre class="r"><code># convert tokens to lower case
swire$Token &lt;- tolower(swire$Token)
# inspect tokens
table(swire$Token)</code></pre>
<pre><code>## 
##        ass      assed      bitch    bitches     bitchy    bollock   bollocks 
##          2          1          1          1          2          1          3 
##     bugger bugger-all       crap       fuck   fuck-all     fucked    fucking 
##          2          2          9          8          1          1         16 
##      fucks       shit      shite     wanker 
##          1          1          3          2</code></pre>
<p>FUCK and its variants is by far the most common swear word in our corpus. However, we do not need the type of swear word to answer our research question and we thus summarize the table to show which speaker in which files has used how many swear words.</p>
<pre class="r"><code>swire &lt;- swire %&gt;%
  group_by(File, Speaker) %&gt;%
  summarise(Swearwords = n())
# inspect data
swire</code></pre>
<pre><code>## # A tibble: 22 x 3
## # Groups:   File [10]
##    File    Speaker Swearwords
##    &lt;chr&gt;   &lt;chr&gt;        &lt;int&gt;
##  1 S1A-003 A                1
##  2 S1A-005 A                1
##  3 S1A-005 B               10
##  4 S1A-005 C                1
##  5 S1A-010 A                2
##  6 S1A-011 A                2
##  7 S1A-011 B                3
##  8 S1A-014 B                2
##  9 S1A-014 C                3
## 10 S1A-014 D                2
## # ... with 12 more rows</code></pre>
<p>Now that we extract how many swear words the speakers in the corpus have used, we can load the biodata of the speakers.</p>
<pre class="r"><code># load bio data
bio &lt;- read.table(&quot;https://slcladal.github.io/data/data01.txt&quot;, header = T, sep = &quot;\t&quot;)
# oinspect data
head(bio)</code></pre>
<pre><code>##   id text.id subfile spk.ref             zone      date    sex   age  reside
## 1  1 S1A-001       1       A northern ireland 1990-1994   male 34-41 belfast
## 2  2 S1A-001       1       B northern ireland 1990-1994 female 34-41 belfast
## 3  4 S1A-002       1       A northern ireland 2002-2005 female 26-33 belfast
## 4  5 S1A-002       1       B northern ireland 2002-2005 female 19-25 belfast
## 5  6 S1A-002       1       C northern ireland 2002-2005   male   50+ belfast
## 6  7 S1A-002       1       D northern ireland 2002-2005 female   50+ belfast
##        relig word.count
## 1 protestant        765
## 2 protestant       1298
## 3   catholic        391
## 4   catholic         47
## 5   catholic        200
## 6   catholic        464</code></pre>
<pre class="r"><code>bio &lt;- bio %&gt;%
  rename(File = text.id, 
         Speaker = spk.ref,
         Gender = sex,
         Age = age,
         Words = word.count) %&gt;%
  select(File, Speaker, Gender, Age, Words)
# inspect data
head(bio)</code></pre>
<pre><code>##      File Speaker Gender   Age Words
## 1 S1A-001       A   male 34-41   765
## 2 S1A-001       B female 34-41  1298
## 3 S1A-002       A female 26-33   391
## 4 S1A-002       B female 19-25    47
## 5 S1A-002       C   male   50+   200
## 6 S1A-002       D female   50+   464</code></pre>
<p>In a next step, we combine the table with the speaker information with the table showing the swear word use.</p>
<pre class="r"><code># combine frequencies and biodata
swire &lt;- dplyr::left_join(bio, swire, by = c(&quot;File&quot;, &quot;Speaker&quot;))
# replave NA with 0
swire$Swearwords &lt;- ifelse(is.na(swire$Swearwords), 0, swire$Swearwords)
# inspect data
head(swire)</code></pre>
<pre><code>##      File Speaker Gender   Age Words Swearwords
## 1 S1A-001       A   male 34-41   765          0
## 2 S1A-001       B female 34-41  1298          0
## 3 S1A-002       A female 26-33   391          0
## 4 S1A-002       B female 19-25    47          0
## 5 S1A-002       C   male   50+   200          0
## 6 S1A-002       D female   50+   464          0</code></pre>
<p>We now clean the table by removing speakers for which we do not have any information on their age and gender. Also, we summarize the table to extract the mean frequencies of swear words (per 1,000 words) by age and gender.</p>
<pre class="r"><code># clean data
swire &lt;- swire %&gt;%
  filter(is.na(Gender) == F,
         is.na(Age) == F) %&gt;%
  group_by(Age, Gender) %&gt;%
  summarise(SumWords = sum(Words),
         SumSwearwords = sum(Swearwords),
         FrequencySwearwords = round(SumSwearwords/SumWords*1000, 3)) 
# inspect data
head(swire)</code></pre>
<pre><code>## # A tibble: 6 x 5
## # Groups:   Age [3]
##   Age   Gender SumWords SumSwearwords FrequencySwearwords
##   &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;         &lt;dbl&gt;               &lt;dbl&gt;
## 1 0-18  female      310             0               0    
## 2 0-18  male        235             0               0    
## 3 19-25 female    62535             0               0    
## 4 19-25 male       8826             0               0    
## 5 26-33 female    35137            13               0.37 
## 6 26-33 male      20664            10               0.484</code></pre>
<p>The summary table shows that speakers between the gaes of 0 and 18 are so rare that we will exclude them from the analysis.</p>
<pre class="r"><code>swire &lt;- swire %&gt;%
  filter(Age != &quot;0-18&quot;)
# inspect data
swire</code></pre>
<pre><code>## # A tibble: 10 x 5
## # Groups:   Age [5]
##    Age   Gender SumWords SumSwearwords FrequencySwearwords
##    &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;         &lt;dbl&gt;               &lt;dbl&gt;
##  1 19-25 female    62535             0               0    
##  2 19-25 male       8826             0               0    
##  3 26-33 female    35137            13               0.37 
##  4 26-33 male      20664            10               0.484
##  5 34-41 female    15017             3               0.2  
##  6 34-41 male      22213             2               0.09 
##  7 42-49 female    10785             0               0    
##  8 42-49 male      40923             0               0    
##  9 50+   female    38683             0               0    
## 10 50+   male      64044             0               0</code></pre>
<p>Now that we have prepared our data, we can plot swear word use by gender.</p>
<pre class="r"><code>library(ggplot2)
ggplot(swire, aes(x = Age, y = FrequencySwearwords, group = Gender, color = Gender)) +
  geom_line() +
  theme_bw() +
  scale_color_manual(values = c(&quot;orange&quot;, &quot;darkgrey&quot;))</code></pre>
<p><img src="corplingr_files/figure-html/sw15-1.png" width="672" /></p>
<p>The graph suggests that the genders do not differ in their use of swear words except for the age bracket from 26 to 41: men swear more among speakers aged between 26 and 33 while women swear more between 34 and 41 years of age.</p>
<p>We could now perform a statistical test, e.g. a (Hierarchical) Configural Frequency Analysis (HCFA) or a Linear Regression to check if age and gender correlate significantly with the frequency of swear word use but for this case study, the simple visualization shall suffice.</p>
<p>It has to be borne in mind, though, that this is merely a case study and that a more fine-grained analysis on a substantially larger data set were necessary to get a more reliable impression.</p>
</div>
<div id="how-to-cite-this-case-study" class="section level1 unnumbered">
<h1>How to cite this case study</h1>
<p>Schweinberger, Martin. 2020. <em>Gender and Age Differences in Swearing</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/corplingr.html" class="uri">https://slcladal.github.io/corplingr.html</a>.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
