---
title: "Basics of Quantitative Reasoning: Hypotheses and Significance"
author: "UQ SLC Digital Team"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
bibliography: bibliography.bib
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction
Science can be defined as a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe [@wilson1999science 58]. One of the most fundamental concepts in that definition is the concept of testable explanations. Another name for such explanations is "hypothesis". Thus, Edward Wilson's definition of science can be rephrased (somewhat crudely) as the methodological testing of hypotheses. This goes to show that hypotheses are at the very heart of the scientific endeveor and, in the fowllowing, we will try to understand what hypotheses are, how to formulate them, and  what logic underpins hypothesis testing. To begin with, we will focus on a practical example to avoid talking merely about abstract ideas. The example we will look at is the English comparative construction. 

## Example: Comparatives in English
In English, the comparative forms of adjectives can be formed according to two strategies: either synthetically/morphologically as in [(1)](#1ex) or analytically/periphrastically as in [(2)](#2ex).

As a general rule, the comparative of adjectives that have only one syllable are formed by using the morphological strategy while adjectives that have three or more syllables are formed using the periphrastic strategy. However, in some cases where adjectives consist of two syllables, speakers may choose which strategy they apply. In our example, we want to find out, how to proceed when trying to understand the reasons why a speakers chooses the first strategy in one  case and the second strategy in another.   


 (1){#1ex} synthetic/morphological comparative {#1ex}  
proud $\rightarrow$ prouder


 (2)) analytic/periphrastic comparative {#2ex}  
proud $\rightarrow$ more proud


To investigate this phenomenon more closely, we should first determine which variables or factors influence which comparative strategy a speaker uses. To answer whcih factors afffect the comparative choice, we need to have a look at the respective literature. In the literature on the English comparative constructions the follwoing influencing factors ahve been named:

1. Length of the adjective:

Adjectives that consits of a single syllable tend to form the comparative form via the morphological strategy  as in (\ref{3ex}) while multisyllabic adjectives tend to form the comparative via the periphrastic strategy as in (\ref{4ex}). 


(3) synthetic/morphological comparative {#3ex} 

cool $\rightarrow$ cooler

(4) analytic/periphrastic comparative {#4ex}

attractive $\rightarrow$ more attractive

2.  Syntactic function

Adjectives in attributive position prefer the morphological strategy, while adjectives in predicative position prefer the the periphrastic strategy.

(5)  The prouder boy of the two was smiling. {#5ex}

(6) The boy to the left was more proud. {#6ex}


3. Ending

Adjectives which end in –ly or -y prefer the morphological strategy.

4. Following *than*

If a *than* follows the comparative, then the adjective prefers the morphological strategy as in (\ref{7ex}).

(7)  This joke is funnier than the other one. {#7ex}

It helps to create an oerview table for the variables that have been shown in the literture to significantly  affect the choice of the comparative strategy. Both better and worse examples of such overview tables are shown in [@gries2009statistics 27-30]. To answer our example question, we have to define the variables in order to formulate a proper hypothesis in the next step.

An example for such a hypothesis would, for instance, be "If an adjectives has only one syllable, then a typical native speaker will prefer the morphological variant". The next question then is how to test such a hypothesis and which concepts underly hypothssis testing.

## Hypotheses {#hypotheses}

Probabaly the most important task in empirical research is hypothesis testing. A proper scientific hypothesis is commonly - but not neccessarily - a general assumption in the form of a statement. Hypotheses are tested by comparing systematic observation with the predictions of the hypothesis. More specifically, in order to test hypothesis one seeks for observations which contradict and are at odds with the hypothesis. If we find such a counter example and we have determined that it is an accurate observation, then the hypothesis is falsified, i.e. is is not correct. 

If we proposed the hypothesis "Apples always fall down." and we find an example of an apple not falling down, then our hypothesis would be falsified. 

BREAK: 

1. Can you thnk of cases where apples do not fall down? 

2. How would we have to modify our hypothesis to accommodate potential counter-examples?


The fact that hypothesis must be falsifiable is a defining feature of hypotheses and it means that for a statement to be a hypothesis, it must be falsifiable (which does not mean that it must be false!).

The for trying to falsifying rather than prooving or validating hypothesis, lies in the act that falsification is possible while providing proof for an emirical fact is impossible: If we make only one observation which refutes a hypothesis, the hypothesis is falsified. No matter how many evidence we have for that hypothesis, the hypothesis remains falsified. It is therefore impossible to proove an empirical hypothesis! There are, however, statements that cannot be disproven or falsified - either for technical reasons (\@ref(exh3)) or because they are subjectiv  (\@ref(exh4)).


(8) There are forms of life in the Andromeda galaxy. {#exh3}

(9) I like chocolate ice cream better than vanilla ice cream. {#exh4}


Statements that cannot be falsified are called "speculation". Speculation is nothing bad or somehting worthless - on the contrary! - but they simply fall outside of the realm of empirical science. Exacmples for the creativity and the usefulness of specualtion are, for instance, art, literture, music, and philosophy. 

Summing up, hypotheses can be defined as possessing at least two criteria:

1. Hypotheses are falsifiziable statements about empirical reality.

2. Hypothesen are testable statments about the empirical world.


Universality cannot be considered a defining feature of hypotheses, because it is - striktly speaking - not neccessary. For instance, we could formulate the hypothesis that a certain archeological model is correct, if we find certain artefacts at a specific place in a certain layer of earth. This hypothesis relates to a a very specific singular event but it would still be a falsifiable and testatble statement (and thus a hypothesis). 

### Types of Hypotheses
On a very fiúndamental level, we can differentiate between null-hypotheses (H$_{0}$), that claim non-existence of either a state of being or a difference, and alternative or test-hypothesis (H$_{1}$) that claim or postulate the existence of of either a state of being or a difference. Among test-hypotheses, we can furthermore distinguish between undirected hypotheses which claim that one sample is different from another sample, and directed hypotheses which claim that a feature of one sample is bigger, smaller, more frequent, or less frequent, etc. Thus, a hypothesis that group A will perform better in an exam is a diercted testhypothesis while an undirected hypothesis would merely claim that they differ in their test restults. In cotrast, the null-hypothesis would claim that there is no difference between the groups in terms of their performance in that exam. 

An additional distinction among hypotheses is the difference between deterministic and probabilistic hypotheses. While we are edaling with a determinitic hypothesis in  (\ref{exh1}) because it is a categorical claim, we are dealing with a probabilistic hypothesis in (\ref{exh2}) bcause, here, the hypothesis simply claims that the likelihood of Y is higher if X is the case (but not neccessarily categorically).

(10) If the length of two words in an English phrase is different, then the shorter word will always preceed the longer word. {#exh1}

(11) If the length of two words in an English phrase is different, then it is more likely for the shorter word to preceed the longer word than vice versa. {#exh2}

## Why we test the Null-Hypothesis
Although it is counter-intuitive, we do not actually test the test-hypothesis but we test the null-hypothesis. This means that hypothesis testing in  empirical research typically follows the scheme described below.

1. Hypothese (H$_{1}$) aus der Beobachtung/dem Model deduzieren

2. Dazugehörige Nullhypothese (H$_{0}$) formulieren

3. Festlegung des Signifikanzniveaus

4. Potentielle Resultate formulieren: welche Resultate sind möglich und was würden diese für die jeweilige Hypothese bedeuten?

5. Experiment/Studie designen

6. Durchführung der Studie

7. Statistische Analyse

8. Interpretation und Auswertung der Ergebnisse.


Wir werden nun kurz auf das Formulierung der Hypothesen eingehen und es schematisch darstellen. Hypothesen zu Formulieren bedeutet, dass man erwartete Ergebnisse formuliert und diese Ergebnisse formal beschreibt.

* Nullhypothese (H_{0}) 
Gruppen A und B unterscheiden sich nicht systematisch! ($\mu$A = $\mu$B)

* Alternativhypothese (H_{1}a)
Gruppen A und B unterscheiden sich systematisch. ($\mu$A $\neq$ $\mu$B; ungerichtet)

* Alternativhypothese (H_{1}b)
Gruppen A hat signifikant bessere Ergebnisse/höhere Werte/etc. erzielt als Gruppe B. ($\mu$A $>$ $\mu$B; gerichtet)


Was bedeutet das nun und was testen wir eigentlich? Wir testen, wie wahrscheinlich es ist, das die Ergebnisse durch Zufall zustande gekommen sind. Ist die Wahrscheinlichkeit hoch (p $\ge$ .05), dass die Ergebnisse zufällig zustande gekommen sind, dann verwerfen wir die H_{0} nicht. Ist die Wahrscheinlichkeit gering (p $<$ .05), dass die Ergebnisse zufällig zustande gekommen sind, dann verwerfen wir die H_{0} und nehmen statt dessen die H_{1} an! Um diese Logik besser zu verstehen, werden wir im Folgenden auf Wahrscheinlichkeiten eingehen und welche Rolle diese in der quantitativen Forschung spielen.

% bearbeiten XXX
### Aufgaben

1. Welche der unteren Sätze sind Hypothesen? Erläutern Sie kurz.

a) Rauchen könnte gesundheitsschädlich sein.

b) Alkohol ist eine Einstiegsdroge.

c) Wenn Alkohol eine Einstiegsdroge ist, dann sollte es verboten werden.

d) Wenn Alkohol eine Einstiegsdroge ist, Nikotin jedoch nicht, dann haben signifikant mehr Abhängige harter Drogen zuvor Alkohol konsumiert als Nikotin.

e) Alkohol ist eine Einstiegsdroge, wenn es illegal ist.

f) Colorless green ideas sleep furiously.

g) Nachtigallen träumen in Italienisch.


2. Welche drei Merkmale haben Hypothesen?

3. Denken sie sich (a) drei Beispiele für gerichtete Hypothesen und (b) drei Beispiele für ungerichtete Hypothesen aus.

4. Es ist häufig nicht so einfach Hypothesen von anderen Aussagen zu trennen. Überlegen Sie sich zusammen mit einem Partner Beispiele für Aussagen, die keine Hypothesen sind und erläutern Sie im Anschluss einer anderen Gruppe, warum Ihre Aussagen keine Hypothesen sind und wie Sie vorgegangen sind.

5. Überlegen Sie sich nun zusammen mit einem Partner Beispiele für Aussagen, die man sowohl als Hypothese als auch als Nichthypothesen kategorisieren könnte und erläutern Sie im Anschluss einer anderen Gruppe, warum Ihre Aussagen keine bzw. warum es Hypothesen sind und wie Sie vorgegangen sind.


## Signifikanz und Signifikanzniveau {#signifikanz}
Um Hypothesen zu testen, brauchen wir Wahrscheinlichkeiten. Genauer gesagt benötigen wir die Angabe über die Irrtumswahrscheinlichkeit (probability of error). Diese gibt die Wahrscheinlichkeit an, dass bei vorliegender Datenlage die Nullhypothese gilt. Es ist üblich auf diese Wahrscheinlichkeit mit dem Begriff p-Wert (p-value) zu referieren. In einer etwas einfacheren (leider auch etwas ungenauen und sogar etwas falschen) Formulierung gibt der p-Wert an, wie groß die Wahrscheinlichkeit ist, dass die gefundenen Effekte in den Daten auf Zufall zurückzuführen sind.

Man sollte vor der Untersuchung ein sogenanntes $\alpha$ Signifikanzniveau festlegen. Das $\alpha$ Signifikanzniveau gibt an, wie hoch bzw. niedrig der p-Wert sein darf ohne dass man davon ausgehen muss, das kein signifikanter Zusammenhang zwischen den untersuchten Variablen vorliegt. Es ist hierbei gebräuchlich zwischen drei Stufen des $\alpha$ Signifikanzniveaus unterscheiden:

* $p<$.001: *hoch signifikant*, wird mit drei Sternchen (***) angezeigt

* $p<$.01: *sehr signifikant*, wird mit zwei Sternchen (**) angezeigt

* $p<$.05: *signifikant*, wird mit einem Sternchen (*) angezeigt


Wie bereits gesagt, müssen wir, bevor wir testen, einen Wert festlegen, ab dem wir die Nullhypothese ablehnen, das sogenannte Signifikanzniveau. Es liegt normalerweise bei 5\%. Wenn die Irrtumswahrscheinlichkeit kleiner als 5\% ist ($p<$.05), lehnen wir die Nullhypothese ab. Schlussfolgerung: Der Zusammenhang zwischen den Variablen ist statistisch signifikant (WICHTIG: Nur, weil die Nullhypothese abgelehnt werden kann, heißt das nicht, dass H_{1} (oder Testhypothese) bewiesen wurde. Statistik kann Hypothesen NIE beweisen.).

## Probability

In the follwoing, we will turn to probabiliyt and why understanding probabilty is relevant for testing hypotheses. This is important at this point because statistics, and thus hypothesis testing, fundamentally builds upon probabilies and probability distributions. In order to understand how probability works, we will investaigte what happens when we flip a coin. The question we are asking urselves here is "*What is the probablility of getting three heads when flipping the coin three times?*".

The probablility of getting three heads when flipping a coin three times is point five to the power of three: .5^3 = .5 \* .5 \* .5 = .125. The probability of getting head twice when flipping the coin three times is .375. How do we know?




Die Wahrscheinlichkeit, dass bei 3 Würfen dreimal Kopf fällt ist .125:\\
.5^{3}= .5 * .5 * .5 = .125

Die Wahrscheinlichkeit, dass bei drei Würfen zweimal Kopf fällt ist .375:\\
.125 + .125 + .125 = 0.375\\
Wie kommen wir darauf?\\[.2cm]

\begin{table}[H]
\begin{minipage}{\textwidth}
\begin{center}
\begin{footnotesize}
\begin{tabular}{cccccc}
\hline
Erster Wurf & Zweiter Wurf & Dritter Wurf & Kopf & Zahl & p \\
\hline
K & K & K & 3 & 0 & 0.125 \\
K & K & Z & 2 & 1 & 0.125 \\
K & Z & K & 2 & 1 & 0.125 \\
Z & K & K & 2 & 1 & 0.125 \\
K & Z & Z & 1 & 2 & 0.125 \\
Z & K & Z & 1 & 2 & 0.125 \\
Z & Z & K & 1 & 2 & 0.125 \\
Z & Z & Z & 0 & 3 & 0.125 \\
\hline\\
\end{tabular}
\end{footnotesize}
\caption{Wahrscheinlichkeiten bei drei Münzwürfen}
\label{tab:munz}
\end{center}
\end{minipage}
\end{table}

Wir sind nun in der Lage sein zu sagen, wie hoch die Wahrscheinlichkeit ist, bei 100 Würfen 100 mal Kopf zu erhalten: .5^{100} = 7.888609 * 10^{-31}

Lassen Sie uns wetten \dots
\begin{itemize}
\item[--] Kopf - Martin gewinnt (und bekommt \euro{1})
\item[--] Zahl - Sie gewinnen (und bekommen \euro{1})
\end{itemize}
Nehmen wir folgende Hypothesen an \dots \\
\begin{itemize}
\item[--] H_{0}: Ich schummele nicht, d.h. Kopf fällt genauso häufig wie Zahl, nämlich 1.5 mal.
\item[--] H_{1}: Ich schummele, d.h. Kopf fällt häufiger als 1.5 mal.
\end{itemize}

Wir werfen 3 mal. Kopf fällt 2 mal. Wie wahrscheinlich ist es, dass ich nicht schummele und Kopf trotzdem mehr als 2 mal fällt? (In anderen Worten: Was ist die Wahrscheinlichkeit p, dass ich 2 mal oder mehr gewinne und nicht schummele?) Wenn Sie das Signifikanzniveau bei .05 ansetzen, könnten Sie mich dann als Schummler bezichtigen?\\[.2cm]

\begin{table}[H]
\begin{minipage}{\textwidth}
\begin{center}
\begin{footnotesize}
\begin{tabular}{cccccc}
\hline
Erster Wurf & Zweiter Wurf & Dritter Wurf & Kopf & Zahl & p \\
\hline
K & K & K & 3 & 0 & 0.125 \\
K & K & Z & 2 & 1 & 0.125 \\
K & Z & K & 2 & 1 & 0.125 \\
Z & K & K & 2 & 1 & 0.125 \\
K & Z & Z & 1 & 2 & 0.125 \\
Z & K & Z & 1 & 2 & 0.125 \\
Z & Z & K & 1 & 2 & 0.125 \\
Z & Z & Z & 0 & 3 & 0.125 \\
\hline\\
\end{tabular}
\end{footnotesize}
\caption{Wahrscheinlichkeiten bei drei Münzwürfen}
\label{tab:munz}
\end{center}
\end{minipage}
\end{table}

Wie in Spalte 4 zu sehen ist, gibt es drei Ergebnisse, bei denen Sie zwei von drei Würfen verlieren: Reihe 2, 3 und 4. Das wären 0.125 + 0.125 + 0.125 = 0.375. Dazu muss jetzt noch der Fall addiert werden, bei dem Sie dreimal verlieren (Reihe 1; vgl. Grafik \ref{fig:prob0}). Das sind noch einmal 0.125 Das ergibt dann zusammen: 0.375 + 0.125 = 0.5. Das ist zehnmal höher als das Signifikanzniveau, somit können Sie mich nicht als Schummler betiteln.

```{r fig.width=10, fig.height=8, echo=FALSE, warning=FALSE}
library(png)
ima <- readPNG("resources/probabilities.png")
plot(c(100, 250), c(300, 450), type = "n", xlab = "", ylab = "", xaxt = "n",yaxt = "n")
lim <- par()
rasterImage(ima, lim$usr[1], lim$usr[3], lim$usr[2], lim$usr[4])
```

\begin{figure}[H]
\centering
\includegraphics[width=.75\textwidth]{images/probabilities.png}
\caption{Wahrscheinlichkeiten null, einmal, zweimal oder dreimal Kopf bei drei Würfen zu erhalten}
\label{fig:prob0}
\end{figure}

Wie kann man solche Wahrscheinlichkeiten einfacher berechnen? Man kann solche Wahrscheinlichkeiten von einem Computer berechnen lassen, wie dies unten mit \verb!R! geschehen ist.


\begin{lstlisting}
# wahrscheinlichkeiten: 0, 1, 2 und 3 mal kopf
# bei drei wuerfen
dbinom(0:3, 3, 0.5)
# wahrscheinlichkeiten: 2 oder 3 mal kopf
# bei drei wuerfen
sum(dbinom(2:3, 3, 0.5))
# wahrscheinlichkeiten: 100 mal kopf
# bei 100 wuerfen
dbinom(100, 100, 0.5)
# wahrscheinlichkeit: 58 mal oder mehr kopf
# bei 100 wuerfen
sum(dbinom(58:100, 100, 0.5))
# wahrscheinlichkeit: 59 mal oder mehr kopf
# bei 100 wuerfen
sum(dbinom(59:100, 100, 0.5))
# wo sinkt die wahrscheinlichkeit unter 5 prozent
# bei 100 wuerfen kopf zu erhalten
qbinom(0.05, 100, 0.5, lower.tail=FALSE)

qnorm(0.05, lower.tail=TRUE)
\end{lstlisting}
Wir haben es mit einer gerichteten Hypothese und nicht mit einer ungerichtete Hypothese zu tun, da wir als H_{1} angenommen hatte, dass ich schummele und Kopf somit häufiger als 1.5 mal fällt. Aus diesem Grund testen wir einseitig (one-tailed). Bei ungerichteten Hypothesen, z.B. Ich werde häufiger oder seltener als Sie gewinnen, testen wir zweiseitig (two-tailed). Um dies zu verdeutlichen betrachten wir den Fall, bei dem wir nicht nur drei Mal Würfeln, sondern 100 Mal. Das obere Panel in Grafik (\ref{fig:prob1}) zeigt die Wahrscheinlichkeiten bei 0 bis 100 Würfelwürfen 0 bis 100 Mal Kopf zu erhalten. Das mittlere Panel zeigt ab wann wir annehmen können, dass sich der vorliegende Würfel (bei $\alpha$=5\%) von einem normalen Würfel unterscheidet und das untere Panel in Grafik (\ref{fig:prob1}) zeigt, ab wann wir davon ausgehen können (bei $\alpha$=5\%), dass ich Schummele., d.h. dass ich häufiger Kopf erhalte, als es durch Zufall der Fall wäre

\begin{figure}[H]
\centering
\includegraphics[width=.75\textwidth]{images/prob1.png}
\caption{Wahrscheinlichkeiten bei 100 Würfelwürfen Kopf zu erhalten}
\label{fig:prob1}
\end{figure}

Wenn Sie das mittlere und das untere Panel in Grafik (\ref{fig:prob1}) vergleichen, fällt auf, dass bei einseitigen Tests die Anzahl der Kopfwürfe, die notwendig sind, um die H_{0} zu verwerfen, niedriger ist als die Anzahl bei zwei-seitigen Tests. Es ist aus diesem Grund sinnvoll die H_{0} gerichtet zu formulieren, da so einfacher signifikante Unterschiede erkannt werden können.

Noch einige Anmerkungen, bevor wir zur Inferenzstatistik übergehen. Bei Variablen, die intervallskaliert sind, funktioniert diese Methode des Wahrscheinlichkeitstests nicht mehr, da es zum Beispiel nicht möglich ist, alle denkbaren Reaktionszeiten auf einen Stimulus zu kalkulieren. In solchen Fällen greift man auf Verteilungen (gängig ist die Normalverteilung) zurück um Wahrscheinlichkeiten zu bestimmen. In diesem Fall werden Werte, die in den Bereich des Flächeninhalts fallen, der weniger als 5\% der Fläche ausmacht, als signifikant betrachtet (vgl. Grafik (\ref{fig:prob2})).

\begin{figure}[H]
\centering
\includegraphics[width=.75\textwidth]{images/prob2.png}
\caption{Normalverteilte Wahrscheinlichkeiten}
\label{fig:prob2}
\end{figure}

Die in Grafik (\ref{fig:prob2}) dargestellte Normalverteilung hat bestimmte, mathematisch beschreibbare Eigenschaften, die es uns ermöglicht beispielsweise den Flächeninhalt bestimmter Abschnitte zu bestimmten. Beispielsweise sind das arithmetische Mittel, der Median und der Modalwert bei der Normalverteilung identisch, 50\% der Flächeninhalts unter der Normalkurve befindet sich rechts, 50\% links des Mittelwerts, 68\% der Flächeninhalts befinden sich zwischen -1 und +1 Standardabweichung, 95\% des Flächeninhalts befinden sich zwischen -2 und +2 Standardabweichungen, 99.7\% des Flächeninhalts befinden sich zwischen -3 und +3 Standardabweichungen, 5\% des Flächeninhalts befinden sich zusammen jenseits von -1.96 und +1.96 Standradabweichungen und 5\% des Flächeninhalts befinden sich jenseits von 1.68 Standradabweichungen vom Mittelwert. Diese Tatsachen macht man sich zu nutze, wenn man die Normalverteilung heranzieht, um zu testen, wie wahrscheinlich ein bestimmtes Ergebnis ist, wenn man die Normalverteilung zugrunde legt.

\subsection*{Aufgaben}
\begin{enumerate}
\item Erstellen Sie eine Tabelle der Wahrscheinlichkeitspfade aller möglichen Ergebnisse bei 4 Münzwürfen (Sie können sich an Tabelle (tab:munz) orientieren).
\item Wie wahrscheinlich ist es bei 7 Münzwürfen genau 3 mal Kopf zu erhalten?
\item Wie wahrscheinlich ist es bei 7 Münzwürfen genau 2 oder 5 mal Kopf zu erhalten?
\item Wie wahrscheinlich ist es bei 7 Münzwürfen genau 5 mal oder häufiger Kopf zu erhalten?
\item Wie wahrscheinlich ist es bei 7 Münzwürfen zwischen 3 und 6 mal Kopf zu erhalten?
\end{enumerate}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# References
