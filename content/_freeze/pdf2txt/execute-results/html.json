{
  "hash": "82817a1b9eb6302017b305662c2139a5",
  "result": {
    "markdown": "---\ntitle: \"Converting PDFs to txt files with R\"\nauthor: \"Martin Schweinberger\"\ndate: \"2022-08-31\"\n---\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://slcladal.github.io/images/uq1.jpg){width=100%}\n:::\n:::\n\n\n# Introduction{-}\n\nThis tutorial shows how to extract text from one or more pdf-files using optical character recognition (OCR) and then saving the text(s) in txt-files on your computer. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://slcladal.github.io/images/gy_chili.jpg){width=15% style=\"float:right; padding:10px\"}\n:::\n:::\n\n\nThis tutorial is aimed at beginners and intermediate users of R with the aim of showcasing how to convert pdfs into txt files using R. The aim is not to provide a fully-fledged analysis but rather to show and exemplify selected useful methods associated with extracting texts from pdfs. \n\nThis tutorial uses two packages for OCR and text extraction: `pdftools` which is very fast and is very recommendable when dealing with very legible and clean pdf-files (such as pdf-files of websites and books that were rendered directly from, e.g., word-documents, and the `tesseract` package which is slower but works much better when the data is unclean and represents, e.g., scans of books, faxes, or reports. In addition, we show how we can combine OCR with spell-checking via the `hunspell` package (see [here](https://cran.r-project.org/web/packages/hunspell/vignettes/intro.html) for more information) when using the `tesseract` package (but this an also be done for any other textual data in R).\n\n<div class=\"warning\" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>\n<span>\n<p style='margin-top:1em; text-align:center'>\nThe entire R Notebook for the tutorial can be downloaded [**here**](https://slcladal.github.io/content/pdf2txt.Rmd).  If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the [**bibliography file**](https://slcladal.github.io/content/bibliography.bib) and store it in the same folder where you store the Rmd file. <br></p>\n<p style='margin-left:1em;'>\n</p></span>\n</div>\n\n<br>\n\n\n**Preparation and session set up**\n\nThis tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/intror.html). For this tutorials, we need to install certain *packages* from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set options\noptions(stringsAsFactors = F)          # no automatic data transformation\noptions(\"scipen\" = 100, \"digits\" = 12) # suppress math annotation\n# install packages\ninstall.packages(\"pdftools\")\ninstall.packages(\"tesseract\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"here\")\ninstall.packages(\"hunspell\")\ninstall.packages(\"flextable\")\n# install klippy for copy-to-clipboard button in code chunks\ninstall.packages(\"remotes\")\nremotes::install_github(\"rlesur/klippy\")\n```\n:::\n\n\nNext we activate the packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# activate packages\nlibrary(pdftools)\nlibrary(tesseract)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(hunspell)\n# set tesseract engine\neng <- tesseract(\"eng\")\n# activate klippy for copy-to-clipboard button\nklippy::klippy()\n```\n\n::: {.cell-output-display}\n```{=html}\n<script>\n  addClassKlippyTo(\"pre.r, pre.markdown\");\n  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');\n</script>\n```\n:::\n:::\n\n\nOnce you have installed RStudio and have also initiated the session by executing the code shown above, you are good to go.\n\n**How to use the RNotebook for this tutorial**\n\nTo follow this tutorial interactively (by using the RNotebook - or Rmd for short), follow the instructions listed below.\n\n**Data and folder set up**\n\n1. Create a folder somewhere on your computer\n2. In that folder create a sub-folder called *data*\n3. In that *data* folder, create a subfolder called *PDFs* \n4. Download and  save the following pdf-files in that *PDFs* folder: \n[pdf0](https://slcladal.github.io/data/PDFs/pdf0.pdf), [pdf1](https://slcladal.github.io/data/PDFs/pdf1.pdf), [pdf2](https://slcladal.github.io/data/PDFs/pdf2.pdf), and [pdf3](https://slcladal.github.io/data/PDFs/pdf3.pdf).\n\n**R and RStudio set up**\n\n1. Download the [RNotebook](https://slcladal.github.io/content//pdf2txt.Rmd) and save it in the folder you have just created\n2. Open RStudio\n3. Click on `File` in the upper left corner of the R Studio interface\n4. Click on `New Project...`\n5. Select `Existing Directory`\n6. Browse to the folder you have just created and click on `Open`\n7. Now click on `Files` above the lower right panel\n8. Click on the file `pdf2txt.Rmd`\n   + The Markdown file of this tutorial should now be open in the upper left panel of RStudio. To execute the code which prepare the session, load the data, create the graphs, and perform the statistics, simply click on the green arrows in the top right corner of the code boxes.\n   + To render a PDF of this tutorial, simply click on `Knit` above the upper left panel in RStudio.\n\n# OCR with pdftools{-}\n\n## Extract text from one pdf{-}\n\nThe pdf we will convert is a [pdf of the Wikipedia article about corpus linguistics](https://slcladal.github.io/data/PDFs/pdf0.pdf). The first part of that pdf is shown below.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://slcladal.github.io/images/pdf0.png){width=100%}\n:::\n:::\n\n\nGiven that the pdf contains tables, urls, reference, etc., the text that we will extract from the pdf will be rather messy - cleaning the content of the text would be another matter (it would be data processing rather than extraction) and we will thus only focus on the conversion process here and not focus on the data cleaning and processing aspect. \n\nWe begin the extraction by defining a path to the pdf. Once we have defined a path, i.e. where R is supposed to look for that file, we continue by extracting the text from the pdf.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# you can use an url or a path that leads to a pdf document\npdf_path <- \"https://slcladal.github.io/data/PDFs/pdf0.pdf\"\n# extract text\ntxt_output <- pdftools::pdf_text(pdf_path) %>%\n  paste0(collapse = \" \") %>%\n  paste0(collapse = \" \") %>%\n  stringr::str_squish() \n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-d3861e66{table-layout:auto;width:95%;}.cl-d37efbcc{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d37efbd6{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d37f0f9a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d37f397a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d37f3984{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-d3861e66'>\n```\n<caption class=\"Table Caption\">\n\nFirst 1000 characters of the extracted text from a pdf of the wikipedia article on corpus linguistics.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d37f3984\"><p class=\"cl-d37f0f9a\"><span class=\"cl-d37efbcc\">.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d37f397a\"><p class=\"cl-d37f0f9a\"><span class=\"cl-d37efbd6\">Corpus linguistics - Wikipedia https://en.wikipedia.org/wiki/Corpus_linguistics Corpus linguistics Corpus linguistics is the study of language as expressed in corpora (samples) of \"real world\" text. Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field in its natural context (\"realia\"), and with minimal experimental-interference. The field of corpus linguistics features divergent views about the value of corpus annotation. These views range from John McHardy Sinclair, who advocates minimal annotation so texts speak for themselves,[1] to the Survey of English Usage team (University College, London), who advocate annotation as allowing greater linguistic understanding through rigorous recording.[2] The text-corpus method is a digestive approach that derives a set of abstract rules that govern a natural language from texts in that language, and explores how that language relates to other languages. Originally derived manually, cor</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n\n## Extracting text from many pdfs{-}\n\nTo convert many pdf-files, we write a function that preforms the conversion for many documents.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconvertpdf2txt <- function(dirpath){\n  files <- list.files(dirpath, full.names = T)\n  x <- sapply(files, function(x){\n  x <- pdftools::pdf_text(x) %>%\n  paste0(collapse = \" \") %>%\n  stringr::str_squish()\n  return(x)\n    })\n}\n```\n:::\n\n\nWe can now apply the function to the folder in which we have stored the pdf-files we want to convert. In the present case, I have stored 4 pdf-files of Wikipedia articles in a folder called *PDFs* which is located in my *data* folder as described in the section above which detailed how to set up the Rproject folder on your computer). The output is a vector with the texts of the pdf-files. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# apply function\ntxts <- convertpdf2txt(here::here(\"data\", \"PDFs/\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-d3bfa884{table-layout:auto;width:95%;}.cl-d3b9e28c{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d3b9e296{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-d3b9f380{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-d3ba19fa{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d3ba1a04{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d3ba1a05{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-d3ba1a0e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-d3bfa884'>\n```\n<caption class=\"Table Caption\">\n\nFirst 1000 characters of the extracted texts from pdfs of selected wikipedia articles.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d3ba1a0e\"><p class=\"cl-d3b9f380\"><span class=\"cl-d3b9e28c\">.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d3ba19fa\"><p class=\"cl-d3b9f380\"><span class=\"cl-d3b9e296\">Corpus linguistics - Wikipedia https://en.wikipedia.org/wiki/Corpus_linguistics Corpus linguistics Corpus linguistics is the study of language as expressed in corpora (samples) of \"real world\" text. Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field in its natural context (\"realia\"), and with minimal experimental-interference. The field of corpus linguistics features divergent views about the value of corpus annotation. These views range from John McHardy Sinclair, who advocates minimal annotation so texts speak for themselves,[1] to the Survey of English Usage team (University College, London), who advocate annotation as allowing greater linguistic understanding through rigorous recording.[2] The text-corpus method is a digestive approach that derives a set of abstract rules that govern a natural language from texts in that language, and explores how that language relates to other languages. Originally derived manually, cor</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d3ba1a04\"><p class=\"cl-d3b9f380\"><span class=\"cl-d3b9e296\">Language - Wikipedia https://en.wikipedia.org/wiki/Language Language A language is a structured system of communication. Language, in a broader sense, is the method of communication that involves the use of – particularly human – languages.[1][2][3] The scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major figures in linguistics include Ferdinand de Saussure and Noam Chomsky. Estimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on the arbitrary distinction (dichotomy) between languages </span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d3ba19fa\"><p class=\"cl-d3b9f380\"><span class=\"cl-d3b9e296\">Natural language processing - Wikipedia https://en.wikipedia.org/wiki/Natural_language_processing Natural language processing Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. Contents History Rule-based vs. statistical NLP Major evaluations and tasks Syntax Semantics An automated online assistant Discourse providing customer service on a Speech web page, an example of an Dialogue application where natural Cognition language processing is a major component.[1] See also References Further reading History The history of natural language processing (NLP) generally started in the 195</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-d3ba1a05\"><p class=\"cl-d3b9f380\"><span class=\"cl-d3b9e296\">Computational linguistics - Wikipedia https://en.wikipedia.org/wiki/Computational_linguistics Computational linguistics Computational linguistics is an interdisciplinary field concerned with the statistical or rule-based modeling of natural language from a computational perspective, as well as the study of appropriate computational approaches to linguistic questions. Traditionally, computational linguistics was performed by computer scientists who had specialized in the application of computers to the processing of a natural language. Today, computational linguists often work as members of interdisciplinary teams, which can include regular linguists, experts in the target language, and computer scientists. In general, computational linguistics draws upon the involvement of linguists, computer scientists, experts in artificial intelligence, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among </span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe table above shows the first 1000 characters of the texts extracted from 4 pdf-files of Wikipedia articles associated with language technology (*corpus linguistics*, *linguistics*, *natural language processing*, and *computational linguistics*). \n\n## Saving the texts{-}\n\nTo save the texts in txt-files on your disc, you can simply replace the predefined location (the data folder of your Rproject located by the string `here::here(\"data\")` with the folder where you want to store the txt-files and then execute the code below. Also, we will name the texts (or the txt-files if you like) as *pdftext* plus their index number.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add names to txt files\nnames(txts) <- paste0(here::here(\"data\",\"pdftext\"), 1:length(txts), sep = \"\")\n# save result to disc\nlapply(seq_along(txts), function(i)writeLines(text = unlist(txts[i]),\n    con = paste(names(txts)[i],\".txt\", sep = \"\")))\n```\n:::\n\n\nIf you check the data folder in your Rproject folder, you should find 4 files called *pdftext1*, *pdftext2*, *pdftext3*, *pdftext4*.\n\n# OCR with tesseract{-}\n\nIn this section, we use the `tesseract` package for OCR (see [here](https://cran.r-project.org/web/packages/tesseract/vignettes/intro.html) for more information and a more thorough tutorial on usign the `tesseract` package). The `tesseract` package provides R bindings [Tesseract](https://opensource.google/projects/tesseract): a powerful optical character recognition (OCR) engine that supports over 100 languages. The engine is highly configurable in order to tune the detection algorithms and obtain the best possible results.\n\nWe start by creating a vector of paths to the pdf-files that we want to extract the text from.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfls <- list.files(here::here(\"data/PDFs\"), full.names = T)\n# load\nocrs <- sapply(fls, function(x){\n  # store name\n  nm <- stringr::str_replace_all(x, \".*/(.*?).pdf\", \"\\\\1\")\n  # perform ocr\n  x <- tesseract::ocr(x, engine = eng) %>%\n    paste0(collapse = \" \")\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConverting page 1 to pdf0_1.png... done!\nConverting page 2 to pdf0_2.png... done!\nConverting page 1 to pdf1_1.png... done!\nConverting page 2 to pdf1_2.png... done!\nConverting page 3 to pdf1_3.png... done!\nConverting page 4 to pdf1_4.png... done!\nConverting page 5 to pdf1_5.png... done!\nConverting page 6 to pdf1_6.png... done!\nConverting page 7 to pdf1_7.png... done!\nConverting page 8 to pdf1_8.png... done!\nConverting page 9 to pdf1_9.png... done!\nConverting page 10 to pdf1_10.png... done!\nConverting page 11 to pdf1_11.png... done!\nConverting page 1 to pdf2_1.png... done!\nConverting page 2 to pdf2_2.png... done!\nConverting page 3 to pdf2_3.png... done!\nConverting page 4 to pdf2_4.png... done!\nConverting page 1 to pdf3_1.png... done!\nConverting page 2 to pdf3_2.png... done!\nConverting page 3 to pdf3_3.png... done!\nConverting page 4 to pdf3_4.png... done!\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-ddf23abe{table-layout:auto;width:95%;}.cl-dded28d0{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-dded28e4{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-dded3884{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-dded5d64{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-dded5d6e{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-dded5d78{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-dded5d79{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-ddf23abe'>\n```\n<caption class=\"Table Caption\">\n\nFirst 1000 characters of the extracted text from the  wikipedia article on corpus linguistics.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-dded5d79\"><p class=\"cl-dded3884\"><span class=\"cl-dded28d0\">.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-dded5d64\"><p class=\"cl-dded3884\"><span class=\"cl-dded28e4\">Corpus linguistics - Wikipedia https://en.wikipedia.org/wiki/Corpus_linguistics</span><br><span class=\"cl-dded28e4\">WIKIPEDIA</span><br><span class=\"cl-dded28e4\">e e e</span><br><span class=\"cl-dded28e4\">Corpus linguistics</span><br><span class=\"cl-dded28e4\">Corpus linguistics is the study of language as expressed in corpora (samples) of \"real world\" text. Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the</span><br><span class=\"cl-dded28e4\">field in its natural context (\"realia\"), and with minimal experimental-interference.</span><br><span class=\"cl-dded28e4\">The field of corpus linguistics features divergent views about the value of corpus annotation. These views range from John McHardy Sinclair, who advocates minimal annotation so texts speak for</span><br><span class=\"cl-dded28e4\">themselves, to the Survey of English Usage team (University College, London), who advocate annotation as allowing greater linguistic understanding through rigorous recording.|2!</span><br><span class=\"cl-dded28e4\">The text-corpus method is a digestive approach that derives a set of abstract rules that govern a natural language from texts in that language, and explores how that language relates to other languages.</span><br><span class=\"cl-dded28e4\">Originally derived </span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-dded5d6e\"><p class=\"cl-dded3884\"><span class=\"cl-dded28e4\">Language - Wikipedia https://en.wikipedia.org/wiki/Language</span><br><span class=\"cl-dded28e4\">WIKIPEDIA</span><br><span class=\"cl-dded28e4\">Language</span><br><span class=\"cl-dded28e4\">A language is a structured system of communication. Language, in a broader sense, is the method of communication that involves the use of — particularly human —</span><br><span class=\"cl-dded28e4\">languages. J[2II3]</span><br><span class=\"cl-dded28e4\">The scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been o</span><br><span class=\"cl-dded28e4\">debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have ~ ‘</span><br><span class=\"cl-dded28e4\">held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major Pty An</span><br><span class=\"cl-dded28e4\">figures in linguistics include Ferdinand de Saussure and Noam Chomsky. . Lie</span><br><span class=\"cl-dded28e4\">Estimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on the arbitrary distinction ; </span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-dded5d64\"><p class=\"cl-dded3884\"><span class=\"cl-dded28e4\">Natural language processing - Wikipedia https://en.wikipedia.org/wiki/Natural_ language processing</span><br><span class=\"cl-dded28e4\">WIKIPEDIA</span><br><span class=\"cl-dded28e4\">e</span><br><span class=\"cl-dded28e4\">Natural language processing</span><br><span class=\"cl-dded28e4\">Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions ass</span><br><span class=\"cl-dded28e4\">between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. ee ce ee oo</span><br><span class=\"cl-dded28e4\">Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. ——— non</span><br><span class=\"cl-dded28e4\">~ &amp;</span><br><span class=\"cl-dded28e4\">Contents am</span><br><span class=\"cl-dded28e4\">History i cseunec</span><br><span class=\"cl-dded28e4\">Rule-based vs. statistical NLP jim</span><br><span class=\"cl-dded28e4\">Hi I'm your automated online ser corewer &amp;</span><br><span class=\"cl-dded28e4\">Major evaluations and tasks ssa How may nt ou? f= kj</span><br><span class=\"cl-dded28e4\">Syntax caeiieties</span><br><span class=\"cl-dded28e4\">Semantics eee</span><br><span class=\"cl-dded28e4\">. An automated online assistant</span><br><span class=\"cl-dded28e4\">Discourse a</span><br><span class=\"cl-dded28e4\">providing customer service ona</span><br><span class=\"cl-dded28e4\">Speech web page, an example of an</span><br><span class=\"cl-dded28e4\">Dialogue application where natural</span><br><span class=\"cl-dded28e4\">Cognition language processing is</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-dded5d78\"><p class=\"cl-dded3884\"><span class=\"cl-dded28e4\">Computational linguistics - Wikipedia https://en.wikipedia.org/wiki/Computational_ linguistics</span><br><span class=\"cl-dded28e4\">WIKIPEDIA</span><br><span class=\"cl-dded28e4\">e e e e</span><br><span class=\"cl-dded28e4\">Computational linguistics</span><br><span class=\"cl-dded28e4\">Computational linguistics is an interdisciplinary field concerned with the statistical or rule-based modeling of natural language from a computational perspective, as well as the study of appropriate</span><br><span class=\"cl-dded28e4\">computational approaches to linguistic questions.</span><br><span class=\"cl-dded28e4\">Traditionally, computational linguistics was performed by computer scientists who had specialized in the application of computers to the processing of a natural language. Today, computational linguists</span><br><span class=\"cl-dded28e4\">often work as members of interdisciplinary teams, which can include regular linguists, experts in the target language, and computer scientists. In general, computational linguistics draws upon the</span><br><span class=\"cl-dded28e4\">involvement of linguists, computer scientists, experts in artificial intelligence, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and</span><br><span class=\"cl-dded28e4\">neur</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAlthough the results already look very promising, we want to see how we can combine automated spell-checking/correction with OCR as this is necessary when dealing with less pristine documents.\n\n## Spell correction{-}\n\nIn a first step, we write a function that loops over each text and checks which words occur in a English language dictionary (which we do not specify as it is the default). This spell checking makes use of the the `hunspell` package (see [here](https://cran.r-project.org/web/packages/hunspell/vignettes/intro.html) for more information). Hunspell is based on *MySpell* and is backward-compatible with *MySpell* and *aspell* dictionaries. This means that we can import and/or make use of many different language dictionaries and it is quite likely that the dictionaries for other languages may already available on your system!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create token list\ntokens_ocr <- sapply(ocrs, function(x){\n  x <- hunspell::hunspell_parse(x)\n})\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-1636a220{table-layout:auto;width:95%;}.cl-1632c970{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1632c97a{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1632d7c6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1632f742{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1632f74c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1632f74d{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1632f74e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-1636a220'>\n```\n<caption class=\"Table Caption\">\n\nFirst 1000 characters of the spell-checked  wikipedia article on corpus linguistics.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1632f74e\"><p class=\"cl-1632d7c6\"><span class=\"cl-1632c970\">.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1632f742\"><p class=\"cl-1632d7c6\"><span class=\"cl-1632c97a\">c(\"Corpus\", \"linguistics\", \"Wikipedia\", \"https\", \"en\", \"wikipedia\", \"org\", \"wiki\", \"Corpus\", \"linguistics\", \"WIKIPEDIA\", \"e\", \"e\", \"e\", \"Corpus\", \"linguistics\", \"Corpus\", \"linguistics\", \"is\", \"the\", \"study\", \"of\", \"language\", \"as\", \"expressed\", \"in\", \"corpora\", \"samples\", \"of\", \"real\", \"world\", \"text\", \"Corpus\", \"linguistics\", \"proposes\", \"that\", \"reliable\", \"language\", \"analysis\", \"is\", \"more\", \"feasible\", \"with\", \"corpora\", \"collected\", \"in\", \"the\", \"field\", \"in\", \"its\", \"natural\", \"context\", \"realia\", </span><br><span class=\"cl-1632c97a\">\"and\", \"with\", \"minimal\", \"experimental\", \"interference\", \"The\", \"field\", \"of\", \"corpus\", \"linguistics\", \"features\", \"divergent\", \"views\", \"about\", \"the\", \"value\", \"of\", \"corpus\", \"annotation\", \"These\", \"views\", \"range\", \"from\", \"John\", \"McHardy\", \"Sinclair\", \"who\", \"advocates\", \"minimal\", \"annotation\", \"so\", \"texts\", \"speak\", \"for\", \"themselves\", \"to\", \"the\", \"Survey\", \"of\", \"English\", \"Usage\", \"team\", \"University\", \"College\", \"London\", \"who\", \"advocate\", \"annotation\", \"as\", \"allowin</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1632f74c\"><p class=\"cl-1632d7c6\"><span class=\"cl-1632c97a\">c(\"Language\", \"Wikipedia\", \"https\", \"en\", \"wikipedia\", \"org\", \"wiki\", \"Language\", \"WIKIPEDIA\", \"Language\", \"A\", \"language\", \"is\", \"a\", \"structured\", \"system\", \"of\", \"communication\", \"Language\", \"in\", \"a\", \"broader\", \"sense\", \"is\", \"the\", \"method\", \"of\", \"communication\", \"that\", \"involves\", \"the\", \"use\", \"of\", \"particularly\", \"human\", \"languages\", \"J\", \"II\", \"The\", \"scientific\", \"study\", \"of\", \"language\", \"is\", \"called\", \"linguistics\", \"Questions\", \"concerning\", \"the\", \"philosophy\", \"of\", \"language\", </span><br><span class=\"cl-1632c97a\">\"such\", \"as\", \"whether\", \"words\", \"can\", \"represent\", \"experience\", \"have\", \"been\", \"o\", \"debated\", \"at\", \"least\", \"since\", \"Gorgias\", \"and\", \"Plato\", \"in\", \"ancient\", \"Greece\", \"Thinkers\", \"such\", \"as\", \"Rousseau\", \"have\", \"argued\", \"that\", \"language\", \"originated\", \"from\", \"emotions\", \"while\", \"others\", \"like\", \"Kant\", \"have\", \"held\", \"that\", \"it\", \"originated\", \"from\", \"rational\", \"and\", \"logical\", \"thought\", \"th\", \"century\", \"philosophers\", \"such\", \"as\", \"Wittgenstein\", \"argued\", \"that</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1632f742\"><p class=\"cl-1632d7c6\"><span class=\"cl-1632c97a\">c(\"Natural\", \"language\", \"processing\", \"Wikipedia\", \"https\", \"en\", \"wikipedia\", \"org\", \"wiki\", \"Natural\", \"language\", \"processing\", \"WIKIPEDIA\", \"e\", \"Natural\", \"language\", \"processing\", \"Natural\", \"language\", \"processing\", \"NLP\", \"is\", \"a\", \"subfield\", \"of\", \"linguistics\", \"computer\", \"science\", \"information\", \"engineering\", \"and\", \"artificial\", \"intelligence\", \"concerned\", \"with\", \"the\", \"interactions\", \"ass\", \"between\", \"computers\", \"and\", \"human\", \"natural\", \"languages\", \"in\", \"particular\", \"how\", </span><br><span class=\"cl-1632c97a\">\"to\", \"program\", \"computers\", \"to\", \"process\", \"and\", \"analyze\", \"large\", \"amounts\", \"of\", \"natural\", \"language\", \"data\", \"ee\", \"ce\", \"ee\", \"oo\", \"Challenges\", \"in\", \"natural\", \"language\", \"processing\", \"frequently\", \"involve\", \"speech\", \"recognition\", \"natural\", \"language\", \"understanding\", \"and\", \"natural\", \"language\", \"generation\", \"non\", \"Contents\", \"am\", \"History\", \"i\", \"cseunec\", \"Rule\", \"based\", \"vs\", \"statistical\", \"NLP\", \"jim\", \"Hi\", \"I'm\", \"your\", \"automated\", \"online\", \"ser\", </span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1632f74d\"><p class=\"cl-1632d7c6\"><span class=\"cl-1632c97a\">c(\"Computational\", \"linguistics\", \"Wikipedia\", \"https\", \"en\", \"wikipedia\", \"org\", \"wiki\", \"Computational\", \"linguistics\", \"WIKIPEDIA\", \"e\", \"e\", \"e\", \"e\", \"Computational\", \"linguistics\", \"Computational\", \"linguistics\", \"is\", \"an\", \"interdisciplinary\", \"field\", \"concerned\", \"with\", \"the\", \"statistical\", \"or\", \"rule\", \"based\", \"modeling\", \"of\", \"natural\", \"language\", \"from\", \"a\", \"computational\", \"perspective\", \"as\", \"well\", \"as\", \"the\", \"study\", \"of\", \"appropriate\", \"computational\", \"approaches\", </span><br><span class=\"cl-1632c97a\">\"to\", \"linguistic\", \"questions\", \"Traditionally\", \"computational\", \"linguistics\", \"was\", \"performed\", \"by\", \"computer\", \"scientists\", \"who\", \"had\", \"specialized\", \"in\", \"the\", \"application\", \"of\", \"computers\", \"to\", \"the\", \"processing\", \"of\", \"a\", \"natural\", \"language\", \"Today\", \"computational\", \"linguists\", \"often\", \"work\", \"as\", \"members\", \"of\", \"interdisciplinary\", \"teams\", \"which\", \"can\", \"include\", \"regular\", \"linguists\", \"experts\", \"in\", \"the\", \"target\", \"language\", \"and\", \"computer\", \"s</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n\nIn a next step, we can correct errors resulting from the OCR process, correct the errors and paste th texts back together (which is all done by the code chunk below). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# clean\nclean_ocrtext <- sapply(tokens_ocr, function(x){\n  correct <- hunspell::hunspell_check(x)\n  x <- ifelse(correct == F, \n              x[hunspell::hunspell_check(x)],\n              x)\n  x <- paste0(x, collapse = \" \")\n})\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-164c0fc0{table-layout:auto;width:95%;}.cl-1648ad1c{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1648ad26{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1648b6d6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1648cf90{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1648cf9a{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1648cf9b{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1648cfa4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-164c0fc0'>\n```\n<caption class=\"Table Caption\">\n\nFirst 1000 characters of the processed text from a pdf of the wikipedia article on corpus linguistics.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1648cfa4\"><p class=\"cl-1648b6d6\"><span class=\"cl-1648ad1c\">.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1648cf90\"><p class=\"cl-1648b6d6\"><span class=\"cl-1648ad26\">Corpus linguistics Wikipedia en en wiki org wiki Corpus linguistics WIKIPEDIA e e e Corpus linguistics Corpus linguistics is the study of language as expressed in corpora samples of real world text Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field in its natural context minimal and with minimal experimental interference The field of corpus linguistics features divergent views about the value of corpus annotation These views range from John minimal Sinclair who advocates minimal annotation so texts speak for themselves to the Survey of English Usage team University College London who advocate annotation as allowing greater linguistic understanding through rigorous recording The text corpus method is a digestive approach that derives a set of abstract rules that govern a natural language from texts in that language and explores how that language relates to other languages Originally derived manually corpora now are automatica</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1648cf9a\"><p class=\"cl-1648b6d6\"><span class=\"cl-1648ad26\">Language Wikipedia en en wiki org wiki Language WIKIPEDIA Language A language is a structured system of communication Language in a broader sense is the method of communication that involves the use of particularly human languages J II The scientific study of language is called linguistics Questions concerning the philosophy of language such as whether words can represent experience have been o debated at least since in and Plato in ancient Greece Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought as century philosophers such as Wittgenstein argued that philosophy is really the study of language Major include An figures in linguistics include Ferdinand of Saussure and of Chomsky Lie Estimates of the number of human languages in the world vary between and However any precise estimate depends on the arbitrary distinction Natural Y is dichotomy between languages and dialect Natu</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1648cf90\"><p class=\"cl-1648b6d6\"><span class=\"cl-1648ad26\">Natural language processing Wikipedia en en wiki org wiki Natural language processing WIKIPEDIA e Natural language processing Natural language processing of is a science of linguistics computer science information engineering and artificial intelligence concerned with the interactions ass between computers and human natural languages in particular how to program computers to process and analyze large amounts of natural language data processing frequently involve speech Challenges in natural language processing frequently involve speech recognition natural language understanding and natural language generation non Contents am History i online Rule based vs statistical How may Hi I'm your automated online online assistant Major evaluations and tasks service How may page an f of Syntax Dialogue Semantics where An automated online assistant Discourse a providing customer service also Speech web page an example of an Dialogue application where natural Cognition language processing is a majo</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-1648cf9b\"><p class=\"cl-1648b6d6\"><span class=\"cl-1648ad26\">Computational linguistics Wikipedia en en wiki org wiki Computational linguistics WIKIPEDIA e e e e Computational linguistics Computational linguistics is an interdisciplinary field concerned with the statistical or rule based modeling of natural language from a computational perspective as well as the study of appropriate computational approaches to linguistic questions Traditionally computational linguistics was performed by computer scientists who had specialized in the application of computers to the processing of a natural language Today computational linguists often work as members of interdisciplinary teams which can include regular linguists experts in the target language and computer scientists In general computational linguistics draws upon the involvement of linguists computer scientists experts in artificial intelligence mathematicians logicians philosophers cognitive scientists cognitive psychologists among anthropologists and linguistics among others Computational linguis</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n\nWe have reached the end of this tutorial and we hope that the tutoral helps you in performing OCR on your own pdfs.\n\n# Citation & Session Info {-}\n\nSchweinberger, Martin. 2022. *Converting PDFs to txt files with R*. Brisbane: The University of Queensland. url: https://slcladal.github.io/pdf2txt.html (Version 2022.08.31).\n\n\n```\n@manual{schweinberger2022pdf2txt,\n  author = {Schweinberger, Martin},\n  title = {Converting PDFs to txt files with R},\n  note = {https://slcladal.github.io/pdf2txt.html},\n  year = {2022},\n  organization = \"The University of Queensland, Australia. School of Languages and Cultures},\n  address = {Brisbane},\n  edition = {2022.08.31}\n}\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.1 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    \n [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   \n [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] hunspell_3.0.1  here_1.0.1      forcats_0.5.1   stringr_1.4.0  \n [5] dplyr_1.0.9     purrr_0.3.4     readr_2.1.2     tidyr_1.2.0    \n [9] tibble_3.1.7    ggplot2_3.3.6   tidyverse_1.3.2 tesseract_5.1.0\n[13] pdftools_3.3.0 \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3          jsonlite_1.8.0      modelr_0.1.8       \n [4] assertthat_0.2.1    askpass_1.1         googlesheets4_1.0.0\n [7] cellranger_1.1.0    yaml_2.3.5          qpdf_1.2.0         \n[10] gdtools_0.2.4       pillar_1.7.0        backports_1.4.1    \n[13] glue_1.6.2          uuid_1.1-0          digest_0.6.29      \n[16] rvest_1.0.2         colorspace_2.0-3    htmltools_0.5.2    \n[19] pkgconfig_2.0.3     broom_1.0.0         haven_2.5.0        \n[22] scales_1.2.0        officer_0.4.3       tzdb_0.3.0         \n[25] googledrive_2.0.0   generics_0.1.3      ellipsis_0.3.2     \n[28] withr_2.5.0         klippy_0.0.0.9500   cli_3.3.0          \n[31] magrittr_2.0.3      crayon_1.5.1        readxl_1.4.0       \n[34] evaluate_0.15       fs_1.5.2            fansi_1.0.3        \n[37] xml2_1.3.3          tools_4.2.1         data.table_1.14.2  \n[40] hms_1.1.1           gargle_1.2.0        lifecycle_1.0.1    \n[43] flextable_0.7.3     munsell_0.5.0       reprex_2.0.1       \n[46] zip_2.2.0           compiler_4.2.1      systemfonts_1.0.4  \n[49] rlang_1.0.4         grid_4.2.1          rstudioapi_0.13    \n[52] rappdirs_0.3.3      htmlwidgets_1.5.4   base64enc_0.1-3    \n[55] rmarkdown_2.14      gtable_0.3.0        DBI_1.1.3          \n[58] R6_2.5.1            lubridate_1.8.0     knitr_1.39         \n[61] fastmap_1.1.0       utf8_1.2.2          rprojroot_2.0.3    \n[64] stringi_1.7.8       Rcpp_1.0.8.3        vctrs_0.4.1        \n[67] dbplyr_2.2.1        tidyselect_1.1.2    xfun_0.31          \n```\n:::\n:::\n\n\n\n***\n\n[Back to top](#introduction)\n\n[Back to HOME](https://slcladal.github.io/index.html)\n\n***\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/clipboard-1.7.1/clipboard.min.js\"></script>\n<link href=\"site_libs/primer-tooltips-1.4.0/build.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/klippy-0.0.0.9500/css/klippy.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/klippy-0.0.0.9500/js/klippy.min.js\"></script>\n<link href=\"site_libs/tabwid-1.0.0/tabwid.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/tabwid-1.0.0/scrool.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}