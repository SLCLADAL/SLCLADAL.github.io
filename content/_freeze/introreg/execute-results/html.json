{
  "hash": "69677bf4c25d41292e6d55954015109a",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Regression Analysis\"\nauthor: \"Martin Schweinberger\"\ndate: \"2022-08-31\"\n---\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://slcladal.github.io/images/uq1.jpg){width=100%}\n:::\n:::\n\n\n# Introduction{-}\n\nThis tutorial introduces regression analyses (also called regression modeling) using R.^[I'm extremely grateful to Stefan Thomas Gries who provided very helpful feedback and pointed out many errors in previous versions of this tutorial. All remaining errors are, of course, my own.] Regression models are among the most widely used quantitative methods in the language sciences to assess if and how predictors (variables or interactions between variables) correlate with a certain response. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://slcladal.github.io/images/yr_chili.jpg){width=15% style=\"float:right; padding:10px\"}\n:::\n:::\n\n\nThis tutorial is aimed at intermediate and advanced users of R with the aim of showcasing how to perform regression analysis using R. The aim is not to provide a fully-fledged analysis but rather to show and exemplify common regression types, model diagnostics, and model fitting using R. \n\n<br>\n<div class=\"warning\" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>\n<span>\n<p style='margin-top:1em; text-align:center'>\nThe entire R Notebook for the tutorial can be downloaded [**here**](https://slcladal.github.io/content/introreg.Rmd).  If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the [**bibliography file**](https://slcladal.github.io/content/bibliography.bib) and store it in the same folder where you store the Rmd or the Rproj file. <br></p>\n<p style='margin-left:1em;'>\n</p></span>\n</div>\n\n<br>\n\nRegression models are so popular because they can\n\n* incorporate many predictors in a single model (multivariate: allows to test the impact of one predictor while the impact of (all) other predictors is controlled for)\n\n* extremely flexible and and can be fitted to different types of predictors and dependent variables\n\n* provide output that can be easily interpreted\n\n* conceptually relative simple and not overly complex from a  mathematical perspective\n\nR offers various ready-made functions with which implementing different types of regression models is very easy.\n\nThe most widely use regression models are\n\n* linear regression (dependent variable is numeric, no outliers)\n\n* logistic regression (dependent variable is binary)\n\n* ordinal regression (dependent variable represents an ordered factor, e.g. Likert items)\n\n* multinomial regression (dependent variable is categorical)\n\n\nThe major difference between these types of models is that they take different types of dependent variables: linear regressions take numeric, logistic regressions take nominal variables, ordinal regressions take ordinal variables, and Poisson regressions take dependent variables that reflect counts of (rare) events. Robust regression, in contrast, is a simple multiple linear regression that is able to handle outliers due to a weighing procedure.\n\nIf regression models contain a random effect structure which is used to model nestedness or dependence among data points, the regression models are called *mixed-effect models*. regressions that do not have a random effect component to model  nestedness or dependence are referred to as fixed-effect regressions (we will have a closer look at the difference between fixed and random effects below).\n\nThere are two basic types of regression models: \n\n* fixed-effects regression models \n\n* mixed-effects regression models (which are fitted using the `lme4` package [@lme4] in this tutorial). \n\nFixed-effects regression models are models that assume a non-hierarchical data structure, i.e. data where data points are not nested or grouped in higher order categories (e.g. students within classes). The first part of this tutorial focuses on fixed-effects regression models while the second part focuses on mixed-effects regression models.\n\nThere exists a wealth of literature focusing on  regression analysis and the concepts it is based on.  For instance, there are @achen1982interpreting, @bortz2006statistik, @crawley2005statistics, @faraway2002practical, @field2012discovering (my personal favorite), @gries2021statistics, @levshina2015linguistics,  and @wilcox2009basic to name just a few. Introductions to regression modeling in R are @baayen2008analyzing, @crawley2012r, @gries2021statistics, or @levshina2015linguistics.\n\n# The Basic Principle {-}\n\nThe idea behind regression analysis is expressed formally in the equation below where $f_{(x)}$ is the $y$-value we want to predict, $\\alpha$ is the intercept (the point where the regression line crosses the $y$-axis), $\\beta$ is the coefficient (the slope of the regression line). \n\n\\begin{equation}\nf_{(x)} = \\alpha + \\beta_{i}x + \\epsilon\n\\end{equation}\n\nTo understand what this means, let us imagine that we have collected information about the how tall people are and what they weigh. Now we want to predict the weight of people of a certain height - let's say 180cm.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-9a5b5f68{table-layout:auto;width:75%;}.cl-9a532dca{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9a532dcb{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9a5339c8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9a5358ae{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358b8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358c2{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358c3{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358c4{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358c5{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358cc{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9a5358cd{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9a5b5f68'>\n```\n<caption class=\"Table Caption\">\n\nWeigth and height of a random sample of people.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358cc\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dca\">Height</span></p></td><td class=\"cl-9a5358cd\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dca\">Weight</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358ae\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">173</span></p></td><td class=\"cl-9a5358b8\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">80</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358c4\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">169</span></p></td><td class=\"cl-9a5358c5\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">68</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358ae\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">176</span></p></td><td class=\"cl-9a5358b8\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">72</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358c4\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">166</span></p></td><td class=\"cl-9a5358c5\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">75</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358ae\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">161</span></p></td><td class=\"cl-9a5358b8\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">70</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358c4\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">164</span></p></td><td class=\"cl-9a5358c5\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">65</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358ae\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">160</span></p></td><td class=\"cl-9a5358b8\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">62</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358c4\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">158</span></p></td><td class=\"cl-9a5358c5\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">60</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358ae\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">180</span></p></td><td class=\"cl-9a5358b8\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">85</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9a5358c2\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">187</span></p></td><td class=\"cl-9a5358c3\"><p class=\"cl-9a5339c8\"><span class=\"cl-9a532dcb\">92</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe can run a simple linear regression on the data and we get the following output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model for upper panels\nsummary(glm(Weight ~ 1, data = df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Weight ~ 1, data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-12.90   -7.15   -1.90    5.85   19.10  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   72.900      3.244   22.48 3.24e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 105.2111)\n\n    Null deviance: 946.9  on 9  degrees of freedom\nResidual deviance: 946.9  on 9  degrees of freedom\nAIC: 77.885\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n:::\n\n\nTo estimate how much some weights who is 180cm tall, we would multiply the coefficient (slope of the line) with 180 ($x$) and add the value of the intercept (point where line crosses the $y$-axis). If we plug in the numbers from the regression model below, we get\n\n\\begin{equation}\n-93.77 + 0.98 âˆ— 180 = 83.33 (kg)\n\\end{equation}\n\nA person who is 180cm tall is predicted to weigh 83.33kg. Thus, the predictions of the weights are visualized as the red line in the figure below. Such lines are called *regression lines*. Regression lines are those lines where the sum of the red lines should be minimal. The slope of the regression line is called *coefficient* and the point where the regression line crosses the y-axis at x = 0 is called the *intercept*. Other important concepts in regression analysis are *variance* and *residuals*. *Residuals* are the distance between the line and the points (the red lines) and it is also called *variance*.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](introreg_files/figure-html/intro01-1.png){width=672}\n:::\n:::\n\n\nSome words about the plots in the figure above: the upper left panel shows the raw observed data (black dots). The upper right panel shows the mean weight (blue line) and the residuals (in red). residuals are the distances from the expected or predicted values to the observed values (in this case the mean is the most most basic model which we use to predict values while the observed values simply represent the actual data points). The lower left panel shows observed values and the regression line, i.e, that line which, when drawn through the data points, will have the lowest sum of residuals. The lower right panel shows the regression line and the residuals, i.e. the distances between the expected or predicted values to the actual observed values (in red). Note that the sum of residuals in the lower right panel is much smaller than the sum of residuals in the upper right panel. This suggest that considering Height is a good idea as it explains a substantive amount of residual error and reduces the sum of residuals (or variance).^[I'm very grateful to Antonio Dello Iacono who pointed out that the plots require additional discussion.]\n\nNow that we are familiar with the basic principle of regression modeling - i.e. finding the line through data that has the smallest sum of residuals, we will apply this to a linguistic example.\n\n**Preparation and session set up**\n\nThis tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/intror.html). For this tutorials, we need to install certain *packages* from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install\n#install.packages(\"car\")\ninstall.packages(\"flextable\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"ggpubr\")\ninstall.packages(\"ggfortify\")\ninstall.packages(\"see\")\ninstall.packages(\"performance\")\ninstall.packages(\"report\")\n# install klippy for copy-to-clipboard button in code chunks\ninstall.packages(\"remotes\")\nremotes::install_github(\"rlesur/klippy\")\n```\n:::\n\n\nNow that we have installed the packages, we activate them as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set options\noptions(stringsAsFactors = F)          # no automatic data transformation\noptions(\"scipen\" = 100, \"digits\" = 12) # suppress math annotation\n# load packages\nlibrary(flextable)\nlibrary(ggfortify)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(see)\nlibrary(report)\n# activate klippy for copy-to-clipboard button\nklippy::klippy()\n```\n\n::: {.cell-output-display}\n```{=html}\n<script>\n  addClassKlippyTo(\"pre.r, pre.markdown\");\n  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');\n</script>\n```\n:::\n:::\n\n\n\nOnce you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.\n\n#  Simple Linear Regression{-}\n \nSimple Linear Regression is the most basic type of regression and it it falls into the class of fixed-effects regression models. Regressions are used when we try to understand how independent variables correlate with a dependent or outcome variable. So, if you want to investigate how a certain factor affects an outcome, then a regression is the way to go. We will have a look at two simple examples to understand what the concepts underlying a regression mean and how a regression works. The R code, that we will use, is adapted from many highly recommendable introductions which also focus on regression (among other types of analyses), for example, @gries2021statistics,  @winter2019statistics, @levshina2015linguistics, @winter2019statistics or @wilcox2009basic. @baayen2008analyzing is also very good but probably not the first book one should read about statistics but it is highly recommendable for advanced learners.\n\nAlthough the basic logic underlying regressions is identical to the conceptual underpinnings of *analysis of variance* (ANOVA), a related method, sociolinguists have traditionally favored regression analysis in their studies while ANOVAs have been the method of choice in psycholinguistics. The preference for either method is grounded in historical happenstances and the culture of these subdisciplines rather than in methodological reasoning. However, ANOVA are more restricted in that they can only take numeric dependent variables and they have stricter model assumptions that are violated more readily. In addition, a minor difference between regressions and ANOVA lies in the fact that regressions are based on the $t$-distribution while ANOVAs use the F-distribution (however, the F-value is simply the value of t squared or t^2^). Both t- and F-values report on the ratio between explained and unexplained variance.\n\nThe idea behind regression analysis is expressed formally in the equation below where$f_{(x)}$ is the y-value we want to predict, $\\alpha$ is the intercept (the point where the regression line crosses the y-axis at x = 0), $\\beta$ is the coefficient (the slope of the regression line). \n\n\\begin{equation}\nf_{(x)} = \\alpha + \\beta_{i}x + \\epsilon\n\\end{equation}\n\nIn other words, to estimate how much some weights who is 180cm tall, we would multiply the coefficient (slope of the line) with 180 (x) and add the value of the intercept (point where line crosses the y-axis at x = 0). \n\nHowever, the idea behind regressions can best be described graphically: imagine a cloud of points (like the points in the scatterplot in the upper left panel below). Regressions aim to find that line which has the minimal summed distance between points and the line (like the line in the lower panels). Technically speaking, the aim of a regression is to find the line with the minimal deviance (or the line with the minimal sum of residuals). Residuals are the distance between the line and the points (the red lines) and it is also called *variance*. \n\nThus, regression lines are those lines where the sum of the red lines should be minimal. The slope of the regression line is called *coefficient* and the point where the regression line crosses the y-axis at x = 0 is called the *intercept*.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr1-1.png){width=672}\n:::\n:::\n\n\nA word about standard errors (SE) is in order here because most commonly used statistics programs will provide SE values when reporting regression models. The SE is a measure that tells us how much the coefficients were to vary if the same regression were applied to many samples from the same population. A relatively small SE value therefore indicates that the coefficients will remain very stable if the same regression model is fitted to many different samples with identical parameters. In contrast, a large SE tells you that the model is volatile and not very stable or reliable as the coefficients vary substantially if the model is applied to many samples. \n\n\nMathematically, the SE is the standard deviation (SD) divided by the square root of the sample size (N) (see below).The SD is the square root of the deviance (that is, the SD is the square root of the sum of the mean $\\bar{x}$ minus each data point (x~i~) squared divided by the sample size (N) minus 1).\n\n\\begin{equation}\nStandard Error (SE) = \\frac{\\sum (\\bar{x}-x_{i})^2/N-1}{\\sqrt{N}} = \\frac{SD}{\\sqrt{N}}\n\\end{equation}\n\n\n## Example 1: Preposition Use across Real-Time{-}\n\nWe will now turn to our first example. In this example, we will investigate whether the frequency of prepositions has changed from Middle English to Late Modern English. The reasoning behind this example is that Old English was highly synthetic compared with Present-Day English which comparatively analytic. In other words, while Old English speakers used case to indicate syntactic relations, speakers of Present-Day English use word order and prepositions to indicate syntactic relationships. This means that the loss of case had to be compensated by different strategies and maybe these strategies continued to develop and increase in frequency even after the change from synthetic to analytic had been mostly accomplished. And this prolonged change in compensatory strategies is what this example will focus on. \n\nThe analysis is based on data extracted from the *Penn Corpora of Historical English* (see http://www.ling.upenn.edu/hist-corpora/), that consists of 603 texts written between 1125 and 1900. In preparation of this example, all elements that were part-of-speech tagged as prepositions were extracted from the PennCorpora. \n\nThen, the relative frequencies (per 1,000 words) of prepositions per text were calculated. This frequency of prepositions per 1,000 words represents our dependent variable. In a next step, the date when each letter had been written was extracted. The resulting two vectors were combined into a table which thus contained for each text, when it was written (independent variable) and its relative frequency of prepositions (dependent or outcome variable).\n\nA regression analysis will follow the steps described below: \n\n1. Extraction and processing of the data\n\n2. Data visualization\n\n3. Applying the regression analysis to the data\n\n4. Diagnosing the regression model and checking whether or not basic model assumptions have been violated.\n\nIn a first step, we load functions that we may need (which in this case is a function that we will use to summarize the results of the analysis).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load functions\nsource(\"https://slcladal.github.io/rscripts/slrsummary.r\")\n```\n:::\n\n\nAfter preparing our session, we can now load and inspect the data to get a first impression of its properties.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\nslrdata  <- base::readRDS(url(\"https://slcladal.github.io/data/sld.rda\", \"rb\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-9c88a4d0{table-layout:auto;width:75%;}.cl-9c8339aa{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9c8339be{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9c8349fe{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9c8349ff{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9c838afe{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b08{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b12{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b13{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b1c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b26{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b27{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b30{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b31{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b3a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b44{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b45{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b46{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b4e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b58{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9c838b59{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9c88a4d0'>\n```\n<caption class=\"Table Caption\">\n\nFirst 15 rows of slrdata.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b46\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339aa\">Date</span></p></td><td class=\"cl-9c838b4e\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339aa\">Genre</span></p></td><td class=\"cl-9c838b4e\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339aa\">Text</span></p></td><td class=\"cl-9c838b58\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339aa\">Prepositions</span></p></td><td class=\"cl-9c838b59\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339aa\">Region</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,736</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Science</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">albin</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">166.01</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,711</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Education</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">anon</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">139.86</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,808</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">PrivateLetter</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">austen</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">130.78</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,878</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Education</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">bain</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">151.29</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,743</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Education</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">barclay</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">145.72</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,908</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Education</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">benson</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">120.77</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,906</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Diary</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">benson</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">119.17</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,897</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Philosophy</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">boethja</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">132.96</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,785</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Philosophy</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">boethri</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">130.49</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,776</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Diary</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">boswell</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">135.94</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,905</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Travel</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">bradley</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">154.20</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,711</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Education</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">brightland</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">149.14</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b13\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,762</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Sermon</span></p></td><td class=\"cl-9c838afe\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">burton</span></p></td><td class=\"cl-9c838b08\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">159.71</span></p></td><td class=\"cl-9c838b12\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b27\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,726</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">Sermon</span></p></td><td class=\"cl-9c838b1c\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">butler</span></p></td><td class=\"cl-9c838b30\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">157.49</span></p></td><td class=\"cl-9c838b26\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9c838b31\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">1,835</span></p></td><td class=\"cl-9c838b3a\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">PrivateLetter</span></p></td><td class=\"cl-9c838b3a\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">carlyle</span></p></td><td class=\"cl-9c838b44\"><p class=\"cl-9c8349fe\"><span class=\"cl-9c8339be\">124.16</span></p></td><td class=\"cl-9c838b45\"><p class=\"cl-9c8349ff\"><span class=\"cl-9c8339be\">North</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n\nInspecting the data is very important because it can happen that a data set may not load completely or that variables which should be numeric have been converted to character variables. If unchecked, then such issues could go unnoticed and cause trouble.\n\nWe will now plot the data to get a better understanding of what the data looks like.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(slrdata, aes(Date, Prepositions)) +\n  geom_point() +\n  theme_bw() +\n  labs(x = \"Year\") +\n  labs(y = \"Prepositions per 1,000 words\") +\n  geom_smooth()\np2 <- ggplot(slrdata, aes(Date, Prepositions)) +\n  geom_point() +\n  theme_bw() +\n  labs(x = \"Year\") +\n  labs(y = \"Prepositions per 1,000 words\") +\n  geom_smooth(method = \"lm\") # with linear model smoothing!\n# display plots\nggpubr::ggarrange(p1, p2, ncol = 2, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr6-1.png){width=672}\n:::\n:::\n\n\nBefore beginning with the regression analysis, we will center the Date variable using the `scale` function. We center the values of Date by subtracting each value from the mean of Date. This can be useful when dealing with numeric variables because if we did not center Date, we would get estimated values for year 0 (a year when English did not even exist yet). If a variable is centered, the regression provides estimates of the model refer to the mean of that numeric variable. In other words, centering can be very helpful, especially with respect to the interpretation of the results that regression models report.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# center date\nslrdata %>%\n  dplyr::mutate(Date = scale(Date)) -> slrdata \n```\n:::\n\n\nWe will now begin the regression analysis by generating a first regression model and inspect its results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create initial model\nm1.lm <- lm(Prepositions ~ Date, data = slrdata)\n# inspect results\nsummary(m1.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Prepositions ~ Date, data = slrdata)\n\nResiduals:\n        Min          1Q      Median          3Q         Max \n-69.1012471 -13.8549421   0.5779091  13.3208913  62.8580401 \n\nCoefficients:\n                 Estimate    Std. Error   t value             Pr(>|t|)    \n(Intercept) 132.190093110   0.838637480 157.62483 < 0.0000000000000002 ***\nDate          2.000732730   0.839419427   2.38347             0.017498 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.4339648 on 535 degrees of freedom\nMultiple R-squared:  0.010507008,\tAdjusted R-squared:  0.00865748837 \nF-statistic: 5.68093894 on 1 and 535 DF,  p-value: 0.017498081\n```\n:::\n:::\n\n\n### Interpreting Output {-}\n\nThe summary output starts by repeating the regression equation. Then, the model provides the distribution of the residuals. The residuals should be distributed normally with the absolute values of the Min and Max as well as the 1Q (first quartile) and 3Q (third quartile) being similar or ideally identical. In our case, the values are very similar which suggests that the residuals are distributed evenly and follow a normal distribution. The next part of the report is the coefficients table. The estimate for the intercept is the value of y at x = 0. The estimate for Date represents the slope of the regression line and tells us that with each year, the predicted frequency of prepositions increase by .01732 prepositions. The t-value is the Estimate divided by the standard error (Std. Error). Based on the t-value, the p-value can be calculated manually as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use pt function (which uses t-values and the degrees of freedom)\n2*pt(-2.383, nrow(slrdata)-1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0175196401501\n```\n:::\n:::\n\n\nThe R^2^-values tell us how much variance is explained by our model. The baseline value represents a model that uses merely the mean. 0.0105 means that our model explains only 1.05 percent of the variance (0.010 x 100) - which is a tiny amount. The problem of the multiple R^2^ is that it will increase even if we add variables that explain almost no variance. Hence, multiple R^2^ encourages the inclusion of *junk* variables.\n\n\\begin{equation}\nR^2 = R^2_{multiple} = 1 - \\frac{\\sum (y_i - \\hat{y_i})^2}{\\sum (y_i - \\bar y)^2}\n\\end{equation}\n\nThe adjusted R^2^-value takes the number of predictors into account and, thus, the adjusted R^2^ will always be lower than the multiple R^2^. This is so because the adjusted R^2^ penalizes models for having predictors. The equation for the adjusted R^2^ below shows that the amount of variance that is explained by all the variables in the model (the top part of the fraction) must outweigh the inclusion of the number of variables (k) (lower part of the fraction). Thus, the  adjusted R^2^ will decrease when variables are added that explain little or even no variance while it will increase if variables are added that explain a lot of variance.\n\n\\begin{equation}\nR^2_{adjusted} = 1 - (\\frac{(1 - R^2)(n - 1)}{n - k - 1})\n\\end{equation}\n\nIf there is a big difference between the two R^2^-values, then the model contains (many) predictors that do not explain much variance which is not good. The F-statistic and the associated p-value tell us that the model, despite explaining almost no variance, is still significantly better than an intercept-only base-line model (or using the overall mean to predict the frequency of prepositions per text).\n\nWe can test this and also see where the F-values comes from by comparing the fit of the baseline or null model which only used the overall mean as the sole predictor with the fit of our regression model with used Date as a predictor for preposition use.\n \n\n::: {.cell}\n\n```{.r .cell-code}\n# create intercept-only base-line model\nm0.lm <- lm(Prepositions ~ 1, data = slrdata)\n# compare the base-line and the more saturated model\nanova(m1.lm, m0.lm, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: Prepositions ~ Date\nModel 2: Prepositions ~ 1\n  Res.Df         RSS Df   Sum of Sq       F   Pr(>F)  \n1    535 202058.2576                                  \n2    536 204203.8289 -1 -2145.57126 5.68094 0.017498 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe F- and p-values are exactly those reported by the summary which shows where the F-values comes from and what it means; namely it denote the difference between the base-line and the more saturated model.\n\n\nThe degrees of freedom associated with the residual standard error are the number of cases in the model minus the number of predictors (including the intercept). The residual standard error is square root of the sum of the squared residuals of the model divided by the degrees of freedom. Have a look at he following to clear this up:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DF = N - number of predictors (including intercept)\nDegreesOfFreedom <- nrow(slrdata)-length(coef(m1.lm))\n# sum of the squared residuals\nSumSquaredResiduals <- sum(resid(m1.lm)^2)\n# Residual Standard Error\nsqrt(SumSquaredResiduals/DegreesOfFreedom); DegreesOfFreedom\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 19.4339647585\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 535\n```\n:::\n:::\n\n\n### Model Diagnostics {-}\n\nWe will now check if mathematical assumptions have been violated (homogeneity of variance) or whether the data contains outliers. We check this using diagnostic plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate data\ndf2 <- data.frame(id = 1:length(resid(m1.lm)),\n                 residuals = resid(m1.lm),\n                 standard = rstandard(m1.lm),\n                 studend = rstudent(m1.lm))\n# generate plots\np1 <- ggplot(df2, aes(x = id, y = residuals)) + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  geom_point() +\n  labs(y = \"Residuals\", x = \"Index\")\np2 <- ggplot(df2, aes(x = id, y = standard)) + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  geom_point() +\n  labs(y = \"Standardized Residuals\", x = \"Index\")\np3 <- ggplot(df2, aes(x = id, y = studend)) + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n  geom_point() +\n  labs(y = \"Studentized Residuals\", x = \"Index\")\n# display plots\nggpubr::ggarrange(p1, p2, p3, ncol = 3, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr12-1.png){width=672}\n:::\n:::\n\n\n\nThe left graph shows the residuals of the model (i.e., the differences between the observed and the values predicted by the regression model). The problem with this plot is that the residuals are not standardized and so they cannot be compared to the residuals of other models. To remedy this deficiency, residuals are normalized by dividing the residuals by their standard deviation. Then, the normalized residuals can be plotted against the observed values (center panel). In this way, not only are standardized residuals obtained, but the values of the residuals are transformed into z-values, and one can use the z-distribution to find problematic data points. There are three rules of thumb regarding finding problematic data points through standardized residuals [@field2012discovering 268-269]:\n\n* Points with values higher than 3.29 should be removed from the data.\n\n* If more than 1% of the data points have values higher than 2.58, then the error rate of our model is too high.\n\n* If more than 5% of the data points have values greater than 1.96, then the error rate of our model is too high.\n\n\nThe right panel shows the * studentized residuals* (adjusted predicted values: each data point is divided by the standard error of the residuals). In this way, it is possible to use Student's t-distribution to diagnose our model.\n\nAdjusted predicted values are residuals of a special kind: the model is calculated without a data point and then used to predict this data point. The difference between the observed data point and its predicted value is then called the adjusted predicted value. In summary, studentized residuals are very useful because they allow us to identify influential data points.\n\nThe plots show that there are two potentially problematic data points (the top-most and bottom-most point). These two points are clearly different from the other data points and may therefore be outliers. We will test later if these points need to be removed.\n\nWe will now generate more diagnostic plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate plots\nautoplot(m1.lm) + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) \n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr13-1.png){width=672}\n:::\n:::\n\n\n\nThe diagnostic plots are very positive and we will go through why this is so for each panel. The graph in the upper left panel is useful for finding outliers or for determining the correlation between residuals and predicted values: when a trend becomes visible in the line or points (e.g., a rising trend or a zigzag line), then this would indicate that the model would be problematic (in such cases, it can help to remove data points that are too influential (outliers)).\n\nThe graphic in the upper right panel indicates whether the residuals are normally distributed (which is desirable) or whether the residuals do not follow a normal distribution. If the points lie on the line, the residuals follow a normal distribution. For example, if the points are not on the line at the top and bottom, it shows that the model does not predict small and large values well and that it therefore does not have a good fit.\n\nThe graphic in the lower left panel provides information about *homoscedasticity*. Homoscedasticity means that the variance of the residuals remains constant and does not correlate with any independent variable. In unproblematic cases, the graphic shows a flat line. If there is a trend in the line, we are dealing with heteroscedasticity, that is, a correlation between independent variables and the residuals, which is very problematic for regressions.\n\nThe graph in the lower right panel shows problematic influential data points that disproportionately affect the regression (this would be problematic). If such influential data points are present, they should be either weighted (one could generate a robust rather than a simple linear regression) or they must be removed. The graph displays Cook's distance, which shows how the regression changes when a model without this data point is calculated. The cook distance thus shows the influence a data point has on the regression as a whole. Data points that have a Cook's distance value greater than 1 are problematic [@field2012discovering 269].\n\nThe so-called leverage is also a measure that indicates how strongly a data point affects the accuracy of the regression. Leverage values range between 0 (no influence) and 1 (strong influence: suboptimal!). To test whether a specific data point has a high leverage value, we calculate a cut-off point that indicates whether the leverage is too strong or still acceptable. The following two formulas are used for this:\n\n\\begin{equation}\nLeverage = \\frac{3(k + 1)}{n} |  \\frac{2(k + 1)}{n}\n\\end{equation}\n\nWe will look more closely at leverage in the context of multiple linear regression. We can thus turn to summarized our regression analysis.\n\n**Model Diagnostics Made Easy**\n\nA very handy way to inspect the quality of regression models is offered by the `performance` package as the `check_model` function in the `performance` package extracts and provides summaries of model diagnostics. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create summary table\nperformance::check_model(m1.lm)  \n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr_diag-1.png){width=672}\n:::\n:::\n\n\nUsing the `performance` package to inspect model diagnostics is really easy and neat. However, extracting the diagnostics using the `check_model` function is not always advisable, for instance, when dealing with only a categorical (instead of a numeric predictor). The decision what diagnostics to inspect and how to interpret them thus depends on the model and what the diagnostics are supposed to check. If you are unsure, I suggest you extract all diagnostics and see if there are apparent issues (indicated by high values or deviations from the expected values).\n\nIn addition, we can use the `performance` package to validate(or inspect) the performance of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create summary table\nperformance::model_performance(m1.lm)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |    R2 | R2 (adj.) |   RMSE |  Sigma\n---------------------------------------------------------\n4714.518 | 4727.376 | 0.011 |     0.009 | 19.398 | 19.434\n```\n:::\n:::\n\n\n### Summarizing Results {-}\n\nCommonly, the results of regression analyses are summarized in tabular format and additionally described in prose. We therefore start the write-up with a tabular summary   summarizing the results of the regression analysis in a table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create summary table\nslrsummary(m1.lm)  \n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-9df4fdf0{table-layout:auto;width:75%;}.cl-9df1e00c{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9df1e016{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9df1e8ea{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9df20686{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df20690{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df2069a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df2069b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df2069c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df2069d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206a4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206a5{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206ae{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206af{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206b8{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9df206b9{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9df4fdf0'>\n```\n<caption class=\"Table Caption\">\n\nResults of a simple linear regression analysis.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df206b9\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">Parameters</span></p></td><td class=\"cl-9df206af\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">Estimate</span></p></td><td class=\"cl-9df206af\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">Pearson's r</span></p></td><td class=\"cl-9df206af\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">Std. Error</span></p></td><td class=\"cl-9df206af\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">t value</span></p></td><td class=\"cl-9df206af\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">Pr(&gt;|t|)</span></p></td><td class=\"cl-9df206b8\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e00c\">P-value sig.</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069a\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">(Intercept)</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">132.19</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.84</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">157.62</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0</span></p></td><td class=\"cl-9df20690\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">p &lt; .001***</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069b\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Date</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">2</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.1</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.84</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">2.38</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.0175</span></p></td><td class=\"cl-9df2069d\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">p &lt; .05*</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069a\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Model statistics</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20690\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Value</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069b\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Number of cases in model</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069d\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">537</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069a\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Residual standard error on 535 DF</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20690\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">19.43</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069b\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Multiple R-squared</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069d\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.0105</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069a\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Adjusted R-squared</span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20686\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df20690\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.0087</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df2069b\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">F-statistic (1, 535)</span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069c\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df2069d\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">5.68</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9df206ae\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">Model p-value</span></p></td><td class=\"cl-9df206a4\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df206a4\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df206a4\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df206a4\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df206a4\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\"></span></p></td><td class=\"cl-9df206a5\"><p class=\"cl-9df1e8ea\"><span class=\"cl-9df1e016\">0.0175</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n\nAn alternative but less informative summary table of the results of a regression analysis can be generated using the `tab_model` function from the `sjPlot` package [@sjPlot] (as is shown below).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate summary table\nsjPlot::tab_model(m1.lm) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Prepositions</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">132.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">130.54&nbsp;&ndash;&nbsp;133.84</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Date</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.35&nbsp;&ndash;&nbsp;3.65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.017</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">537</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.011 / 0.009</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n***\n\nTypically, the results of regression analyses are presented in such tables as they include all important measures of model quality and significance, as well as the magnitude of the effects.\n\nIn addition, the results of simple linear regressions should be summarized in writing. \n\nWe can use the `reports` package [@report] to summarize the analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreport::report(m1.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict Prepositions with Date (formula: Prepositions ~ Date). The model explains a statistically significant and very weak proportion of variance (R2 = 0.01, F(1, 535) = 5.68, p = 0.017, adj. R2 = 8.66e-03). The model's intercept, corresponding to Date = 0, is at 132.19 (95% CI [130.54, 133.84], t(535) = 157.62, p < .001). Within this model:\n\n  - The effect of Date is statistically significant and positive (beta = 2.00, 95% CI [0.35, 3.65], t(535) = 2.38, p = 0.017; Std. beta = 0.10, 95% CI [0.02, 0.19])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n:::\n\n\nWe can use this output to write up a final report: \n\nA simple linear regression has been fitted to the data. A visual assessment of the model diagnostic graphics did not indicate any problematic or disproportionately influential data points (outliers) and performed significantly better compared to an intercept-only base line model but only explained .87 percent of the variance (adjusted R^2^: .0087, F-statistic (1, 535): 5,68, p-value: 0.0175\\*). The final minimal adequate linear regression model is based on 537 data points and confirms a significant and positive correlation between the year in which the text was written and the relative frequency of prepositions (coefficient estimate: .02 (standardized \\beta: 0.10, 95% CI [0.02, 0.19]), SE: 0.01, t-value~535~: 2.38, p-value: .0175\\*). Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n\n## Example 2: Teaching Styles{-}\n\nIn the previous example, we dealt with two numeric variables, while the following example deals with a categorical independent variable and a numeric dependent variable. The ability for regressions to handle very different types of variables makes regressions a widely used and robust method of analysis.\n\nIn this example, we are dealing with two groups of students that have been randomly assigned to be exposed to different teaching methods. Both groups undergo a language learning test after the lesson with a maximum score of 20 points. \n\nThe question that we will try to answer is whether the students in group A have performed significantly better than those in group B which would indicate that the teaching method to which group A was exposed works better than the teaching method to which group B was exposed.\n\nLet's move on to implementing the regression in R. In a first step, we load the data set and inspect its structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\nslrdata2  <- base::readRDS(url(\"https://slcladal.github.io/data/sgd.rda\", \"rb\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-9ebf52c6{table-layout:auto;width:75%;}.cl-9eba6392{font-family:'DejaVu Sans';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9eba63a6{font-family:'DejaVu Sans';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9eba756c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eba7576{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9ebaaaaa{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaabe{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaabf{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaac8{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaac9{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaad2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaadc{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ebaaadd{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9ebf52c6'>\n```\n<caption class=\"Table Caption\">\n\nFirst 15 rows of the slrdata2 data.\n\n</caption>\n```{=html}\n<thead><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaadc\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba6392\">Group</span></p></td><td class=\"cl-9ebaaadd\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba6392\">Score</span></p></td></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">15</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">12</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">11</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">18</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">15</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">15</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">9</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">19</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">14</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">13</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">11</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">12</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaaaa\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaabe\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">18</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaabf\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaac8\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">15</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-9ebaaac9\"><p class=\"cl-9eba756c\"><span class=\"cl-9eba63a6\">A</span></p></td><td class=\"cl-9ebaaad2\"><p class=\"cl-9eba7576\"><span class=\"cl-9eba63a6\">16</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNow, we graphically display the data. In this case, a boxplot represents a good way to visualize the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract means\nslrdata2 %>%\n  dplyr::group_by(Group) %>%\n  dplyr::mutate(Mean = round(mean(Score), 1), SD = round(sd(Score), 1)) %>%\n  ggplot(aes(Group, Score)) + \n  geom_boxplot(fill=c(\"orange\", \"darkgray\")) +\n  geom_text(aes(label = paste(\"M = \", Mean, sep = \"\"), y = 1)) +\n  geom_text(aes(label = paste(\"SD = \", SD, sep = \"\"), y = 0)) +\n  theme_bw(base_size = 15) +\n  labs(x = \"Group\") +                      \n  labs(y = \"Test score (Points)\", cex = .75) +   \n  coord_cartesian(ylim = c(0, 20)) +  \n  guides(fill = FALSE)                \n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr22-1.png){width=672}\n:::\n:::\n\n\nThe data indicate that group A did significantly better than group B. We will test this impression by generating the regression model and creating the model and extracting the model summary. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate regression model\nm2.lm <- lm(Score ~ Group, data = slrdata2) \n# inspect results\nsummary(m2.lm)                             \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Score ~ Group, data = slrdata2)\n\nResiduals:\n        Min          1Q      Median          3Q         Max \n-6.76666667 -1.93333333  0.15000000  2.06666667  6.23333333 \n\nCoefficients:\n                Estimate   Std. Error  t value               Pr(>|t|)    \n(Intercept) 14.933333333  0.534571121 27.93517 < 0.000000000000000222 ***\nGroupB      -3.166666667  0.755997730 -4.18873            0.000096692 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.92796662 on 58 degrees of freedom\nMultiple R-squared:  0.232249929,\tAdjusted R-squared:  0.219012859 \nF-statistic:  17.545418 on 1 and 58 DF,  p-value: 0.0000966923559\n```\n:::\n:::\n\n\n\nThe model summary reports that Group A performed significantly better compared with Group B. This is shown by the fact that the p-value (the value in the column with the header (Pr(>|t|)) is smaller than .001 as indicated by the three \\* after the p-values). Also, the negative Estimate for Group B indicates that Group B has lower scores than Group A. We will now generate the diagnostic graphics.^[I'm very grateful to Antonio Dello Iacono who pointed out that a previous version of this tutorial misinterpreted the results as I erroneously reversed the group results.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 3))        # plot window: 1 plot/row, 3 plots/column\nplot(resid(m2.lm))     # generate diagnostic plot\nplot(rstandard(m2.lm)) # generate diagnostic plot\nplot(rstudent(m2.lm)); par(mfrow = c(1, 1))  # restore normal plot window\n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr24-1.png){width=672}\n:::\n:::\n\n\nThe graphics do not indicate outliers or other issues, so we can continue with more diagnostic graphics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2)) # generate a plot window with 2x2 panels\nplot(m2.lm); par(mfrow = c(1, 1)) # restore normal plot window\n```\n\n::: {.cell-output-display}\n![](introreg_files/figure-html/slr25-1.png){width=672}\n:::\n:::\n\n\nThese graphics also show no problems which is why we can now summarize the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tabulate results\nsjPlot::tab_model(m2.lm)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Score</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">14.93</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">13.86&nbsp;&ndash;&nbsp;16.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Group [B]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.17</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;4.68&nbsp;&ndash;&nbsp;-1.65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">60</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.232 / 0.219</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\nWe can use the `reports` package [@report] to summarize the analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreport::report(m2.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict Score with Group (formula: Score ~ Group). The model explains a statistically significant and moderate proportion of variance (R2 = 0.23, F(1, 58) = 17.55, p < .001, adj. R2 = 0.22). The model's intercept, corresponding to Group = A, is at 14.93 (95% CI [13.86, 16.00], t(58) = 27.94, p < .001). Within this model:\n\n  - The effect of Group [B] is statistically significant and negative (beta = -3.17, 95% CI [-4.68, -1.65], t(58) = -4.19, p < .001; Std. beta = -0.96, 95% CI [-1.41, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n:::\n\n\nWe can use this output to write up a final report: \n \n\nA simple linear regression was fitted to the data. A visual assessment of the model diagnostics did not indicate any problematic or disproportionately influential data points (outliers). The final linear regression model is based on 60 data points, performed significantly better than an intercept-only base line model (F (1, 58): 17.55, p-value <. 001^$***$^), and reported that the model explained 21.9 percent of variance which confirmed a good model fit. According to this final model, group A scored significantly better on the language learning test than group B (coefficient: -3.17, 95% CI [-4.68, -1.65], Std. \\beta: -0.96, 95% CI [-1.41, -0.50], SE: 0.48, t-value~58~: -4.19, p-value <. 001^$***$^). Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n\n\n\nThat's it for this tutorial. We hope that you have enjoyed this tutorial and learned how to perform regression analysis including model fitting and model diagnostics as well as reporting regression results.\n\n\n# Citation & Session Info {-}\n\nSchweinberger, Martin. 2022. *Introduction to Regression Analysis*. Brisbane: The University of Queensland. url: https://slcladal.github.io/introreg.html (Version 2022.08.31).\n\n```\n@manual{schweinberger2022introreg,\n  author = {Schweinberger, Martin},\n  title = {Introduction to Regression Analysis},\n  note = {https://slcladal.github.io/regression.html},\n  year = {2022},\n  organization = \"The University of Queensland, Australia. School of Languages and Cultures},\n  address = {Brisbane},\n  edition = {2022.08.31}\n}\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.1 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    \n [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   \n [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      see_0.7.1         performance_0.9.1 sjPlot_2.8.10    \n [5] ggfortify_0.4.14  vip_0.3.2         ggpubr_0.4.0      ggplot2_3.3.6    \n [9] flextable_0.7.3   dplyr_1.0.9      \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-158      insight_0.18.0    tools_4.2.1       backports_1.4.1  \n [5] utf8_1.2.2        R6_2.5.1          sjlabelled_1.2.0  DBI_1.1.3        \n [9] mgcv_1.8-40       colorspace_2.0-3  withr_2.5.0       tidyselect_1.1.2 \n[13] gridExtra_2.3     emmeans_1.7.5     compiler_4.2.1    cli_3.3.0        \n[17] xml2_1.3.3        officer_0.4.3     sandwich_3.0-2    labeling_0.4.2   \n[21] bayestestR_0.12.1 scales_1.2.0      mvtnorm_1.1-3     systemfonts_1.0.4\n[25] stringr_1.4.0     digest_0.6.29     minqa_1.2.4       rmarkdown_2.14   \n[29] base64enc_0.1-3   pkgconfig_2.0.3   htmltools_0.5.2   lme4_1.1-30      \n[33] fastmap_1.1.0     htmlwidgets_1.5.4 rlang_1.0.4       rstudioapi_0.13  \n[37] farver_2.1.1      generics_0.1.3    zoo_1.8-10        jsonlite_1.8.0   \n[41] zip_2.2.0         car_3.1-0         magrittr_2.0.3    patchwork_1.1.1  \n[45] parameters_0.18.1 Matrix_1.4-1      Rcpp_1.0.8.3      munsell_0.5.0    \n[49] fansi_1.0.3       abind_1.4-5       gdtools_0.2.4     lifecycle_1.0.1  \n[53] stringi_1.7.8     multcomp_1.4-19   yaml_2.3.5        carData_3.0-5    \n[57] MASS_7.3-58.1     grid_4.2.1        sjmisc_2.8.9      crayon_1.5.1     \n[61] lattice_0.20-45   ggeffects_1.1.2   cowplot_1.1.1     splines_4.2.1    \n[65] sjstats_0.18.1    klippy_0.0.0.9500 knitr_1.39        pillar_1.7.0     \n[69] uuid_1.1-0        boot_1.3-28       estimability_1.4  ggsignif_0.6.3   \n[73] effectsize_0.7.0  codetools_0.2-18  glue_1.6.2        evaluate_0.15    \n[77] modelr_0.1.8      data.table_1.14.2 nloptr_2.0.3      vctrs_0.4.1      \n[81] gtable_0.3.0      purrr_0.3.4       tidyr_1.2.0       assertthat_0.2.1 \n[85] datawizard_0.4.1  xfun_0.31         xtable_1.8-4      broom_1.0.0      \n[89] coda_0.19-4       rstatix_0.7.0     survival_3.4-0    tibble_3.1.7     \n[93] TH.data_1.1-1     ellipsis_0.3.2   \n```\n:::\n:::\n\n\n\n***\n\n[Back to top](#introduction)\n\n[Back to HOME](https://slcladal.github.io/index.html)\n\n***\n\n\n# References{-}\n\n\n\n",
    "supporting": [
      "introreg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/tabwid-1.0.0/tabwid.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/tabwid-1.0.0/scrool.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/clipboard-1.7.1/clipboard.min.js\"></script>\n<link href=\"site_libs/primer-tooltips-1.4.0/build.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/klippy-0.0.0.9500/css/klippy.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/klippy-0.0.0.9500/js/klippy.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}