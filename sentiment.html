<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-10-04" />

<title>Sentiment Analysis in R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    NEWS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="news.html">Announcements</a>
    </li>
    <li>
      <a href="conferences.html">Events</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="introcomputer.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="reproducibility.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="IntroR_workshop.html">Getting started</a>
    </li>
    <li>
      <a href="stringprocessing.html">String Processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular Expressions</a>
    </li>
    <li>
      <a href="introtables.html">Working with Tables</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="basicgraphs.html">Common Visualization Types</a>
    </li>
    <li>
      <a href="basicgraphs.html">Advanced Visualization Methods</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="vc.html">Phonetics: Creating Vowel Charts with Praat and R</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Useful How-To Tutorials</li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES &amp; CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Sentiment Analysis in R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-10-04</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>This tutorial introduces sentiment analysis (SA) and show how to petrform a SA in R. The entire R-markdown document for the tutorial can be downloaded <a href="https://slcladal.github.io/rscripts/sentiment.Rmd">here</a>.</p>
<div id="preparation-and-session-set-up" class="section level2 unnumbered">
<h2>Preparation and session set up</h2>
<p>This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R <a href="https://slcladal.github.io/IntroR_workshop.html">here</a>. For this tutorials, we need to install certain <em>packages</em> from an R <em>library</em> so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># install libraries
install.packages(c(&quot;Hmisc&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;readr&quot;, &quot;stringr&quot;, 
                   &quot;tidyr&quot;, &quot;tidytext&quot;, &quot;zoo&quot;, &quot;sentimentr&quot;))</code></pre>
<p>Once you have installed R-Studio and initiated the session by executing the code shown above, you are good to go.</p>
</div>
</div>
<div id="sentiment-analysis" class="section level1">
<h1><span class="header-section-number">1</span> Sentiment Analysis</h1>
<p>Sentiment Analysis is a cover term for approaches which extract information on emotion or opinion from natural language <span class="citation">(Silge and Robinson <a href="#ref-silge2017text" role="doc-biblioref">2017</a>)</span>. Sentiment analyses have been successfully applied to analysis of language data in a wide range of disciplines such as psychology, economics, education, as well as political and social sciences. Commonly sentiment analyses are used to determine the stance of a larger group of speakers towards a given phenomenon such as political candidates or parties, product lines or situations. Crucially, sentiment analyses are employed in these domains because they have advantages compared to alternative methods investigating the verbal expression of emotion. One advantage of sentiment analyses is that the emotion coding of sentiment analysis is fully replicable.</p>
<p>Typically, Sentiment Analysis represents a type of classifier only provide information about positive or negative polarity, e.g. whether a tweet is “positive” or “negative”. Therefore, Sentiment Analysis is often regarded as rather coarse-grained and, thus, rather irrelevant for the types of research questions in linguistics.</p>
<p>In the language sciences, Sentiment Analysis can also be a very helpful tool if the type of Sentiment Analysis provides more fine-grained information. In the following, we will perform such a information-rich Sentiment Analysis. The Sentiment Analysis used here does not only provide information about polarity but it will also provide association values for eight core emotions.</p>
<p>The more fine-grained output is made possible by relying on the Word-Emotion Association Lexicon <span class="citation">(Mohammad and Turney <a href="#ref-mohammad2013crowdsourcing" role="doc-biblioref">2013</a>)</span>, which comprises 10,170 terms, and in which lexical elements are assigned scores based on ratings gathered through the crowd-sourced Amazon Mechanical Turk service. For the Word-Emotion Association Lexicon raters were asked whether a given word was associated with one of eight emotions. The resulting associations between terms and emotions are based on 38,726 ratings from 2,216 raters who answered a sequence of questions for each word which were then fed into the emotion association rating (see <span class="citation">Mohammad and Turney (<a href="#ref-mohammad2013crowdsourcing" role="doc-biblioref">2013</a>)</span>). Each term was rated 5 times. For 85 percent of words, at least 4 raters provided identical ratings. For instance, the word <em>cry</em> or <em>tragedy</em> are more readily associated with SADNESS while words such as <em>happy</em> or <em>beautiful</em> are indicative of JOY and words like <em>fit</em> or <em>burst</em> may indicate ANGER. This means that the sentiment analysis here allows us to investigate the expression of certain core emotions rather than merely classifying statements along the lines of a crude positive-negative distinction.</p>
<div id="getting-started" class="section level2 unnumbered">
<h2>Getting started</h2>
<p>Before turning to the SA, we will load the packages for this tutorial.</p>
<pre class="r"><code># activate packages
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
library(tidytext)
library(zoo)
library(Hmisc)
library(sentimentr)</code></pre>
<p>In the following, we will perform a sentiment analysis to investigate the emotionality of five different novels. We will start with the first example and load five pieces of literature.</p>
<pre class="r"><code>darwin &lt;- read_lines(&quot;https://slcladal.github.io/data/origindarwin.txt&quot;, skip = 0)
twain &lt;- read_lines(&quot;https://slcladal.github.io/data/twainhuckfinn.txt&quot;, skip = 0)
orwell &lt;- read_lines(&quot;https://slcladal.github.io/data/orwell.txt&quot;, skip = 0)
lovecraft &lt;- read_lines(&quot;https://slcladal.github.io/data/lovecraftcolor.txt&quot;, skip = 0)
# inspect data
head(darwin, 10)</code></pre>
<pre><code>##  [1] &quot;THE ORIGIN OF SPECIES &quot;                                           
##  [2] &quot;BY &quot;                                                              
##  [3] &quot;CHARLES DARWIN &quot;                                                  
##  [4] &quot;AN HISTORICAL SKETCH &quot;                                            
##  [5] &quot;OF THE PROGRESS OF OPINION ON &quot;                                   
##  [6] &quot;THE ORIGIN OF SPECIES &quot;                                           
##  [7] &quot;INTRODUCTION &quot;                                                    
##  [8] &quot;When on board H.M.S. &#39;Beagle,&#39; as naturalist, I was much struck &quot; 
##  [9] &quot;with certain facts in the distribution of the organic beings in- &quot;
## [10] &quot;habiting South America, and in the geological relations of the &quot;</code></pre>
<p>Write function to clean data</p>
<pre class="r"><code>txtclean &lt;- function(x, title){
  require(dplyr)
  x &lt;- x %&gt;%
    tolower() %&gt;%
    paste0(collapse = &quot; &quot;) %&gt;%
    str_squish()%&gt;%
    str_split(&quot; &quot;) %&gt;%
    unlist() %&gt;%
    tibble() %&gt;%
    select(word = 1, everything()) %&gt;%
    mutate(novel = title) %&gt;%
    anti_join(stop_words) %&gt;%
    mutate(word = str_remove_all(word, &quot;\\W&quot;)) %&gt;%
    filter(word != &quot;&quot;)
}</code></pre>
<p>Process and clean texts.</p>
<pre class="r"><code># process text data
darwin_clean &lt;- txtclean(darwin, &quot;darwin&quot;)
lovecraft_clean &lt;- txtclean(lovecraft, &quot;lovecraft&quot;)
orwell_clean &lt;- txtclean(orwell, &quot;orwell&quot;)
twain_clean &lt;- txtclean(twain, &quot;twain&quot;)
# inspect results
head(darwin_clean)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   word       novel 
##   &lt;chr&gt;      &lt;chr&gt; 
## 1 origin     darwin
## 2 species    darwin
## 3 charles    darwin
## 4 darwin     darwin
## 5 historical darwin
## 6 sketch     darwin</code></pre>
</div>
</div>
<div id="basic-sentiment-analysis" class="section level1">
<h1><span class="header-section-number">2</span> Basic Sentiment Analysis</h1>
<p>In a next step, we clean the data, convert it to lower case, and split it into individual words.</p>
<pre class="r"><code>novels_anno &lt;- rbind(darwin_clean, twain_clean, orwell_clean, lovecraft_clean) %&gt;%
  group_by(novel) %&gt;%
  mutate(words = n()) %&gt;%
  left_join(get_sentiments(&quot;nrc&quot;)) %&gt;%
  mutate(novel = factor(novel),
         sentiment = factor(sentiment))
# inspect results
head(novels_anno, 15)</code></pre>
<pre><code>## # A tibble: 15 x 4
## # Groups:   novel [1]
##    word         novel  words sentiment   
##    &lt;chr&gt;        &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;       
##  1 origin       darwin 78556 &lt;NA&gt;        
##  2 species      darwin 78556 &lt;NA&gt;        
##  3 charles      darwin 78556 &lt;NA&gt;        
##  4 darwin       darwin 78556 &lt;NA&gt;        
##  5 historical   darwin 78556 &lt;NA&gt;        
##  6 sketch       darwin 78556 &lt;NA&gt;        
##  7 progress     darwin 78556 anticipation
##  8 progress     darwin 78556 joy         
##  9 progress     darwin 78556 positive    
## 10 opinion      darwin 78556 &lt;NA&gt;        
## 11 origin       darwin 78556 &lt;NA&gt;        
## 12 species      darwin 78556 &lt;NA&gt;        
## 13 introduction darwin 78556 &lt;NA&gt;        
## 14 board        darwin 78556 anticipation
## 15 hms          darwin 78556 &lt;NA&gt;</code></pre>
<p>We will now summarize the results of the sentiment analysis and calculate the percentages of the prevalence of emotions across the books.</p>
<pre class="r"><code>novels &lt;- novels_anno %&gt;%
  group_by(novel) %&gt;%
  group_by(novel, sentiment) %&gt;%
  dplyr::summarise(sentiment = unique(sentiment),
                   sentiment_freq = n(),
                   words = unique(words)) %&gt;%
  filter(is.na(sentiment) == F) %&gt;%
  mutate(percentage = round(sentiment_freq/words*100, 1))
# inspect data
head(novels, 15)</code></pre>
<pre><code>## # A tibble: 15 x 5
## # Groups:   novel [2]
##    novel     sentiment    sentiment_freq words percentage
##    &lt;fct&gt;     &lt;fct&gt;                 &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;
##  1 darwin    anger                  1293 78556        1.6
##  2 darwin    anticipation           2396 78556        3.1
##  3 darwin    disgust                 875 78556        1.1
##  4 darwin    fear                   2301 78556        2.9
##  5 darwin    joy                    1840 78556        2.3
##  6 darwin    negative               4457 78556        5.7
##  7 darwin    positive               6729 78556        8.6
##  8 darwin    sadness                2133 78556        2.7
##  9 darwin    surprise               1314 78556        1.7
## 10 darwin    trust                  4079 78556        5.2
## 11 lovecraft anger                   197  4847        4.1
## 12 lovecraft anticipation            189  4847        3.9
## 13 lovecraft disgust                 177  4847        3.7
## 14 lovecraft fear                    288  4847        5.9
## 15 lovecraft joy                     111  4847        2.3</code></pre>
<p>After performing the Sentiment Analysis, visualize the results and show the scores fro each core emotion by book.</p>
<pre class="r"><code>novels %&gt;%
  filter(sentiment != &quot;positive&quot;,
         sentiment != &quot;negative&quot;) %&gt;%
  ggplot(aes(sentiment, percentage, fill = novel)) +    
  geom_bar(stat=&quot;identity&quot;,   
           position=position_dodge()) + 
  scale_fill_manual(name = &quot;&quot;, values=c(&quot;orange&quot;, &quot;gray70&quot;, &quot;red&quot;, &quot;grey30&quot;)) +
  theme_bw() +
  theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="sentiment_files/figure-html/bsa5-1.png" width="672" /></p>
<p>We can also display the emotions by book and re-level sentiment so that the different core emotions are ordered from more negative (<em>red</em>) to more positive (<em>blue</em>).</p>
<pre class="r"><code>novels %&gt;%
  filter(sentiment != &quot;positive&quot;,
         sentiment != &quot;negative&quot;) %&gt;%
  mutate(sentiment = factor(sentiment, 
                            levels = c(&quot;anger&quot;, &quot;fear&quot;, &quot;disgust&quot;, &quot;sadness&quot;,
                                   &quot;surprise&quot;, &quot;anticipation&quot;, &quot;trust&quot;, &quot;joy&quot;))) %&gt;%
  ggplot(aes(novel, percentage, fill = sentiment)) +    
  geom_bar(stat=&quot;identity&quot;, position=position_dodge()) + 
  scale_fill_brewer(palette = &quot;RdBu&quot;) +
  theme_bw() +
  theme(legend.position = &quot;right&quot;) +
  coord_flip()</code></pre>
<p><img src="sentiment_files/figure-html/bsa7-1.png" width="672" /></p>
</div>
<div id="identifying-important-emotives" class="section level1">
<h1><span class="header-section-number">3</span> Identifying important emotives</h1>
<p>We now check, which words have contributed to the emotionality scores. In other words, we investigate, which words are most important for the emotion scores within each novel. For the sake of interpretability, we will remove several core emotion categories and also the polarity.</p>
<pre class="r"><code>novels_impw &lt;- novels_anno %&gt;%
  filter(!is.na(sentiment),
         sentiment != &quot;anticipation&quot;,
         sentiment != &quot;surprise&quot;,
         sentiment != &quot;disgust&quot;,
         sentiment != &quot;negative&quot;,
         sentiment != &quot;sadness&quot;,
         sentiment != &quot;positive&quot;) %&gt;%
  mutate(sentiment = factor(sentiment, levels = c(&quot;anger&quot;, &quot;fear&quot;,  &quot;trust&quot;, &quot;joy&quot;))) %&gt;%
  group_by(novel) %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  group_by(novel, sentiment) %&gt;%
  top_n(3) %&gt;%
  mutate(score = n/sum(n))
# inspect results
head(novels_impw, 15)</code></pre>
<pre><code>## # A tibble: 15 x 5
## # Groups:   novel, sentiment [8]
##    novel  word       sentiment     n score
##    &lt;fct&gt;  &lt;chr&gt;      &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;
##  1 darwin structure  trust       249 0.427
##  2 darwin found      trust       171 0.293
##  3 darwin found      joy         171 0.468
##  4 darwin theory     trust       163 0.280
##  5 twain  pretty     trust       159 0.508
##  6 twain  pretty     joy         159 0.508
##  7 orwell war        fear        114 0.471
##  8 darwin doubt      fear        109 0.349
##  9 darwin change     fear        104 0.333
## 10 darwin perfect    joy         102 0.279
## 11 darwin difficulty anger        99 0.414
## 12 darwin difficulty fear         99 0.317
## 13 darwin organ      joy          92 0.252
## 14 darwin struggle   anger        83 0.347
## 15 twain  money      anger        81 0.415</code></pre>
<p>We can now visualize the top three words for the remaining core emotion categories.</p>
<pre class="r"><code>ggplot(novels_impw, aes(x = reorder(word, score, sum), y = score, fill = word)) +
  facet_grid(novel~sentiment,  scales = &quot;free_y&quot;) +
  geom_col(show.legend = FALSE) +
  coord_flip()</code></pre>
<p><img src="sentiment_files/figure-html/contribsa2-1.png" width="672" /></p>
</div>
<div id="calculating-and-dispalying-polarity" class="section level1">
<h1><span class="header-section-number">4</span> Calculating and dispalying polarity</h1>
<p>Now, we visualize the polarity of each book, i.e. the ratio of the number of positive emotion words divided by the number of negative words.</p>
<pre class="r"><code>novels %&gt;%
  filter(sentiment == &quot;positive&quot; | sentiment == &quot;negative&quot;) %&gt;%
  select(-percentage, -words) %&gt;%
  mutate(sentiment_sum = sum(sentiment_freq),
         positive = sentiment_sum-sentiment_freq) %&gt;%
  filter(sentiment != &quot;positive&quot;) %&gt;%
  rename(negative = sentiment_freq) %&gt;%
  select(novel, positive, negative) %&gt;%
  group_by(novel) %&gt;%
  summarise(polarity = positive/negative) %&gt;%
  ggplot(aes(reorder(novel, polarity, mean), polarity)) +    
  geom_point(size = 3) + 
  theme_bw() +
  labs(y = &quot;polarity\n\nmore negative                                more positive\n&quot;,
       x = &quot;novel&quot;)</code></pre>
<p><img src="sentiment_files/figure-html/pol1-1.png" width="672" /></p>
<p>Overall, all books are in the positive range (the polarity score is not negative) and we see that <em>lovecraft</em> is the book with the most negative emotion words while <em>darwin</em> is the most positive book as it has the highest average polarity ratio.</p>
</div>
<div id="calculating-and-dispalying-changes-in-polarity" class="section level1">
<h1><span class="header-section-number">5</span> Calculating and dispalying changes in polarity</h1>
<p>There are two main methods for tracking changes in polarity: binning and moving averages. binning splits the data up into sections and calculates the polarity ration within each bin. Moving averages calculate the mean within windows that are then shifted forward. We begin with an exemplification of binning and then move on to calcualting moving averages.</p>
<div id="binning" class="section level2 unnumbered">
<h2>Binning</h2>
<pre class="r"><code>novels_bin &lt;- novels_anno %&gt;%
  group_by(novel) %&gt;%
  filter(is.na(sentiment) | sentiment == &quot;negative&quot; | sentiment == &quot;positive&quot;) %&gt;%
  mutate(sentiment = as.character(sentiment),
         sentiment = case_when(is.na(sentiment) ~ &quot;0&quot;, 
                               TRUE ~ sentiment),
         sentiment= case_when(sentiment == &quot;0&quot; ~ 0,
                              sentiment == &quot;positive&quot; ~ 1,
                              TRUE ~ -1),
         id = 1:n(),
         index = as.numeric(cut2(id, m=100))) %&gt;%
  group_by(novel, index) %&gt;%
  dplyr::summarize(index = unique(index),
            polarity = mean(sentiment))
# inspect results
head(novels_bin)</code></pre>
<pre><code>## # A tibble: 6 x 3
## # Groups:   novel [1]
##   novel  index polarity
##   &lt;fct&gt;  &lt;dbl&gt;    &lt;dbl&gt;
## 1 darwin     1   0.0396
## 2 darwin     2   0.11  
## 3 darwin     3   0.11  
## 4 darwin     4   0.1   
## 5 darwin     5   0.03  
## 6 darwin     6   0.11</code></pre>
<p>We now have an average polarity for each bin and can plot this polarity over the development of the story.</p>
<pre class="r"><code>ggplot(novels_bin, aes(index, polarity)) + 
  facet_wrap(vars(novel), scales=&quot;free_x&quot;) +
  geom_smooth(se = F, col = &quot;black&quot;) + 
  theme_bw() +
  labs(y = &quot;polarity ratio (mean by bin)&quot;,
       x = &quot;index (bin)&quot;)</code></pre>
<p><img src="sentiment_files/figure-html/bin5-1.png" width="672" /></p>
</div>
<div id="moving-average" class="section level2 unnumbered">
<h2>Moving average</h2>
<p>Another method for tracking changes in polarity over time is to calculate rolling or moving means. It should be noted thought that rolling means are not an optimal method fro tracking chnages over time and rather represent a method for as moothing chaotic time-series data. However, they can be used to complement the analysis of changes that are detected by binning.</p>
<p>To calculate moving averages, we will assign words with positive polarity a value +1 and words with negative polarity a value of -1 (neutral words are coded as 0). A rolling mean calculates the mean over a fixed window span. Once the initial mean is calculated, the window is shifted to the next position and the mean is calculated for that window of values, and so on. We set the window size to 100 words which represents an arbitrary value.</p>
<pre class="r"><code>novels_change &lt;- novels_anno %&gt;%
  filter(is.na(sentiment) | sentiment == &quot;negative&quot; | sentiment == &quot;positive&quot;) %&gt;%
  group_by(novel) %&gt;%
  mutate(sentiment = as.character(sentiment),
         sentiment = case_when(is.na(sentiment) ~ &quot;0&quot;, 
                               TRUE ~ sentiment),
         sentiment= case_when(sentiment == &quot;0&quot; ~ 0,
                              sentiment == &quot;positive&quot; ~ 1,
                              TRUE ~ -1),
         id = 1:n()) %&gt;%
       summarise(id = id,
                 rmean=rollapply(sentiment, 100, mean, align=&#39;right&#39;, fill=NA)) %&gt;%
  na.omit()
# inspect results
head(novels_change)</code></pre>
<pre><code>## # A tibble: 6 x 3
## # Groups:   novel [1]
##   novel     id rmean
##   &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt;
## 1 darwin   100  0.03
## 2 darwin   101  0.04
## 3 darwin   102  0.04
## 4 darwin   103  0.04
## 5 darwin   104  0.04
## 6 darwin   105  0.04</code></pre>
<p>We will now display the values of the rolling mean to check if three are notable trends in how the polarity shifts over the course of the unfolding of the story within George Orwell’s <em>Nineteen Eighty-Four</em>.</p>
<pre class="r"><code>ggplot(novels_change, aes(id, rmean)) +    
  facet_wrap(vars(novel), scales=&quot;free_x&quot;) +
  geom_smooth(se = F, col = &quot;black&quot;) + 
  theme_bw() +
  labs(y = &quot;polarity ratio (rolling mean, k = 100)&quot;,
       x = &quot;index (word in monograph)&quot;)</code></pre>
<p><img src="sentiment_files/figure-html/ma5-1.png" width="672" /></p>
<p>The difference between the rolling mean and the binning is quite notable and results from the fact, that rolling means represent a smoothing method rather than a method to track changes over time.</p>
</div>
</div>
<div id="neutralizing-negation" class="section level1">
<h1><span class="header-section-number">6</span> Neutralizing negation</h1>
<p>So far we have ignored that negation affects the meaning and also the sentiment that is expressed by words. In practice, this means that the sentence <em>you are a good boy</em> and <em>You are not a good boy</em> would receive the same scores as we strictly focused on the use of emotive but ignored how words interact and how the context affects word meaning.</p>
<p>In fact, we removed <em>not</em> and other such negators when we removed stop words. In this section, we want to discover how we can incorporate context in our sentiment analysis. Unfortunately, we have to restrict this example to an anlysis of polarity as performing a context-sensitive sentiment analysis that would extend the <em>Word-Emotion Association Lexicon</em> would be quite complex and require cerating our own sentiment dictionary.</p>
<p>We begin by cleaning George Orwell’s <em>Nineteen Eighty-Four</em>, then splitting it into sentences, and selecting the first 50 sentences as the sample that we will be working with.</p>
<pre class="r"><code># split text into sentences
orwell_sent &lt;- orwell %&gt;%
  iconv(to = &quot;latin1&quot;) %&gt;%
  paste0(collapse = &quot; &quot;) %&gt;%
  str_replace_all(., &quot;([a-z])- ([a-z])&quot;, &quot;\\1\\2&quot;) %&gt;%
  str_squish() %&gt;%
  tibble() %&gt;%
  select(text = 1, everything()) %&gt;%
  unnest_tokens(sentence, text, token = &quot;sentences&quot;) %&gt;%
  top_n(50)
# inspect results
head(orwell_sent, 10)</code></pre>
<pre><code>## # A tibble: 10 x 1
##    sentence                                                                     
##    &lt;chr&gt;                                                                        
##  1 your name was removed from the registers, every record of everything you had~
##  2 you were abolished, annihilated: vaporized was the usual word.               
##  3 your attention, please!                                                      
##  4 you were supposed to stand to attention.                                     
##  5 you remembered huge events which had quite probably not happened, you rememb~
##  6 you think, i dare say, that our chief job is inventing new words.            
##  7 zeal was not enough.                                                         
##  8 your worst enemy, he reflected, was your own nervous system.                 
##  9 you wanted a good time; &#39;they&#39;, meaning the party, wanted to stop you having~
## 10 you take the train -- but look, i&#39;ll draw it out for you.&#39;</code></pre>
<p>In a next step, we load the <code>sentimentr</code> package which allows us to extract negation-sensitive polarity scores for each sentences. In addition, we apply the <code>sentimentr</code> fuction to each sentence and extract their polarity scores.</p>
<pre class="r"><code>orwell_sent_class &lt;- orwell_sent %&gt;%
  mutate(ressent = sentiment(sentence)$sentiment)
# inspect results
head(orwell_sent_class)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   sentence                                                               ressent
##   &lt;chr&gt;                                                                    &lt;dbl&gt;
## 1 your name was removed from the registers, every record of everything ~ -0.241 
## 2 you were abolished, annihilated: vaporized was the usual word.         -0.20  
## 3 your attention, please!                                                 0.722 
## 4 you were supposed to stand to attention.                                0.0945
## 5 you remembered huge events which had quite probably not happened, you~  0     
## 6 you think, i dare say, that our chief job is inventing new words.       0.222</code></pre>
<p>If you are interested in learning more about sentiment analysis in R, <span class="citation">Silge and Robinson (<a href="#ref-silge2017text" role="doc-biblioref">2017</a>)</span> is highly recommended as it goes more into detail and offers additional information.</p>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2020. <em>Sentiment Analysis in R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/sentiment.html" class="uri">https://slcladal.github.io/sentiment.html</a> (Version 2020.09.27).</p>
<pre><code>@manual{schweinberger2020sentiment,
  author = {Schweinberger, Martin},
  title = {Sentiment Analysis in R},
  note = {https://slcladal.github.io/sentiment.html},
  year = {2020},
  organization = {The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/09/27}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19041)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] sentimentr_2.7.1 Hmisc_4.4-1      Formula_1.2-3    survival_3.1-12 
##  [5] lattice_0.20-41  zoo_1.8-8        tidytext_0.2.6   tidyr_1.1.2     
##  [9] stringr_1.4.0    readr_1.3.1      ggplot2_3.3.2    dplyr_1.0.2     
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.5          textshape_1.7.1     png_0.1-7          
##  [4] assertthat_0.2.1    digest_0.6.25       utf8_1.1.4         
##  [7] R6_2.4.1            backports_1.1.10    evaluate_0.14      
## [10] pillar_1.4.6        rlang_0.4.7         curl_4.3           
## [13] rstudioapi_0.11     data.table_1.13.0   textdata_0.4.1     
## [16] textclean_0.9.3     rpart_4.1-15        Matrix_1.2-18      
## [19] checkmate_2.0.0     rmarkdown_2.3       labeling_0.3       
## [22] splines_4.0.2       foreign_0.8-80      htmlwidgets_1.5.1  
## [25] munsell_0.5.0       compiler_4.0.2      janeaustenr_0.1.5  
## [28] xfun_0.16           pkgconfig_2.0.3     base64enc_0.1-3    
## [31] qdapRegex_0.7.2     mgcv_1.8-31         htmltools_0.5.0    
## [34] nnet_7.3-14         tidyselect_1.1.0    tibble_3.0.3       
## [37] gridExtra_2.3       htmlTable_2.1.0     fansi_0.4.1        
## [40] crayon_1.3.4        withr_2.3.0         rappdirs_0.3.1     
## [43] SnowballC_0.7.0     grid_4.0.2          nlme_3.1-148       
## [46] gtable_0.3.0        lifecycle_0.2.0     magrittr_1.5       
## [49] scales_1.1.1        tokenizers_0.2.1    cli_2.0.2          
## [52] stringi_1.5.3       farver_2.0.3        fs_1.5.0           
## [55] syuzhet_1.0.4       latticeExtra_0.6-29 ellipsis_0.3.1     
## [58] generics_0.0.2      vctrs_0.3.4         RColorBrewer_1.1-2 
## [61] tools_4.0.2         glue_1.4.2          purrr_0.3.4        
## [64] hms_0.5.3           jpeg_0.1-8.1        yaml_2.2.1         
## [67] colorspace_1.4-1    cluster_2.1.0       lexicon_1.2.1      
## [70] knitr_1.30</code></pre>
<hr />
<p><a href="https://slcladal.github.io/index.html">Main page</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-mohammad2013crowdsourcing">
<p>Mohammad, Saif M, and Peter D Turney. 2013. “Crowdsourcing a Word-Emotion Association Lexicon.” <em>Computational Intelligence</em> 29 (3): 436–65.</p>
</div>
<div id="ref-silge2017text">
<p>Silge, Julia, and David Robinson. 2017. <em>Text Mining with R: A Tidy Approach</em>. " O’Reilly Media, Inc.".</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
