---
title: "Regression Modellling and ANOVAs"
author: "UQ SLC Digital Team"
date: "2 Dezember 2018"
output: html_document
bibliography: bibliography.bib
---

# Simple Linear Regression
 
This chapter focuses on a very widely used statistical method which is called regression. Regressions are used when we try to understand how independent variables correlate with a dependent or outcome variable. So if you want to investigate how certain criteria affect an outcome, then a regression is the way to go. We will have a look at two simple examples to understand what the concepts underlying a regression mean and how a regression works. After that, we will turn to a more compley case and we will implement a multiple linear regression. The `R`-Code, that we will use, is based on [@field2012discovering].

## Introduction
Although the basic logic underlying regressions is identical to the conceptual underpinnings of analysis of variance (ANOVA), a related method, sociolinguistists have traditionally favoured regression analysis in their studes while ANOVAs have been the method of choice in psycholinguistics. The preference for either method is grounded in historical happenstances and the culture of these subdisciplines rather than in methodological reasoning.

A minor difference between regressions and ANOVA lies in the fact that regressions are based on the $t$-distribution while ANOVAs use the $F$-distribution (however, the $F$-value is merely t^2^). Both  $t$- and $F$-values report on the ratio between explained and unexplained variance.

The idea behind regression analysis is expressed formaly in equation [equation](#eq:slm) and can best be described graphically: Imagine drawing a line through points in a scatterplot (Grafik \ref{fig:scat1} linkes Panel).

$f_{(x)} = \alpha + \beta_{1}x_{i} + \epsilon${#eq:slm}

Regressions aim to find that line which has the minimal summed distance between points and the line (Grafik \ref{fig:scat1} center panel). Technically speaking, the aim of a regression is to find the line with the minimal deviance or the line with the minimal sum of residuals (variance) (Grafik \ref{fig:scat1} right panel). This means that the sum of the length of the lines between the points and the lines should be minimal. The slope of the line is called *coefficient* and the point where the line crosses the y-axis is called the *intercept*.

```{r fig.width=10, fig.height=8, echo=FALSE, warning=FALSE, fig.cap="Scatterplots mit Regressionsgeraden (mitte) und Residuen (rechts)"}
library(png)
ima <- readPNG("resources/scat1.png")
plot(c(100, 250), c(300, 450), type = "n", xlab = "", ylab = "", xaxt = "n",yaxt = "n")
lim <- par()
rasterImage(ima, lim$usr[1], lim$usr[3], lim$usr[2], lim$usr[4])
```

In diesem Zusammenhang sollte noch der Begriff Standardfehler (standard error (SE)) erklärt werden, da dieser Wert in von allen gängigen Statistikprogrammen ausgegeben wird, wenn man eine Regression gerechnet hat. Der Standardfehler gibt Auskunft darüber, wie sehr der Koeffizient variieren wird, wenn man dieselbe Regression auf viele Stichproben derselben Population anwendet. Ein kleiner Standradfehler sagt somit, dass der Wert des Koeffizienten nicht stark variieren wird, wenn man dieselbe Regression auf viele Stichproben mit den gleichen Eigenschaften anwendet, während ein großer Standradfehler besagt, dass man eine hohe Variation erwarten kann.

## A practical example of a simple linear regression - preposition use across real time

In diesem Beispiel werden wir die Häufigkeiten von Präpositionen im Laufe der Geschichte des Englischen anschauen und testen, ob Präpositionen als Wortklasse zu- oder abgenommen haben.

Die Analyse basiert auf den Daten der *Penn Corpora of Historical English* (siehe http://www.ling.upenn.edu/hist-corpora/), die aus 603 Texten, die zwischen 1125 und 1900 geschrieben wurden, bestehen. Zuvor wurden alle als Präposition getaggten Elemente aus diesen Korpora extrahiert, indem nach dem Part-of-Speech Tag \verb!P! gesucht wurde. Anschließend wurden die relativen Häufigkeiten der Präpositionen in den Texten anhand der Wörterzahl der Texte ermittelt. Bei dieser relativen Frequenz, die unsere abhängige Variable darstellt, handelt es sich also um pro-1.000-Wörter Frequenzen von Präpositionen in historischen Texten. Im nächsten Schritt wurde neben die jeweilige relative Häufigkeit die Jahreszahl, in der der Text geschrieben wurde, gestellt.

Die Tabelle auf die wir die einfache Regression anwenden hat folglich zwei Spalten: Eine Spalte mit den relativen Häufigkeiten (abhängige Variable) und eine Spalte mit der Jahreszahl, in der der jeweilige Text geschrieben wurde (unabhängige Variable).

Die folgende Ablauf ist typisch für Regressionsanalysen.

1. Extrahieren und Aufbereiten der Daten
2.  Visualisierung der Daten
3.  Durchführen der Regressionsanalyse
4.  Prüfung, ob Annahmen der Regressionsanalyse verletzt wurden


Wir werden nun beginnen, dass Beispiel in \verb!R! zu implementieren. Im ersten Schritt leeren wir den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.

```{r libraries, warnings = F, message=F}
# entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages("QuantPsyc")
#install.packages("car")
# pakete initialisieren
library(QuantPsyc)
library(car)
library(ggplot2)
source("http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r") # funktion um mehrere grafiken in einem fenster anzuzeigen
source("http://martinschweinberger.de/docs/scripts/slr.summary.tb.r") # funktion zum erstellen von summary tabellen
```


Nachdem wir die notwendigen Pakete usw. in \verb!R! eingelesen haben, können wir nun die Daten laden und uns einen ersten Eindruck über deren Struktur und Eigenschaften verschaffen.

```{r loaddata}
# load data
slr.data <- read.delim("http://martinschweinberger.de/docs/data/slr.data.txt", header = TRUE)
# attach data
attach(slr.data)
# unnoetige spalten entfernen
slr.data <- as.data.frame(cbind(slr.data$datems, slr.data$P.ptw))
# spaltennamen hinzufuegen
colnames(slr.data) <- c("year", "prep.ptw")
# entfernen unvollstaendiger datenpunkte
slr.data <- slr.data[!is.na(slr.data$year) == T, ]
# erste zeilen des datensatzes betrachten
head(slr.data)

# struktur des datensatzes betrachten
str(slr.data)

# eigenschaften des datensatzes betrachten
summary(slr.data)
```



Wir haben nun den Datensatz eingelesen und seine Eigenschaften und seine Struktur betrachtet. Dies ist wichtig, da es durchaus vorkommen kann, dass Variablen, die ursprünglich numerisch waren in kategoriale Variablen umgewandelt wurden. Im nächsten Schritt werden wir die Daten visualisieren, um einen Eindruck der Daten zu gewinnen.

```{r plotting}
# visualisieren der daten
p2 <- ggplot(slr.data, aes(year, prep.ptw)) +
geom_point() +
labs(x = "Year") +
labs(y = "Prepositions per 1,000 words") +
geom_smooth()

p3 <- ggplot(slr.data, aes(year, prep.ptw)) +
geom_point() +
labs(x = "Year") +
labs(y = "Prepositions per 1,000 words") +
geom_smooth(method = "lm") # with linear model smoothing!

multiplot(p2, p3, cols = 2)
```

Bevor wir mit der Regression beginnen, werden wir die Jahreszahlen skalieren, d.h. wir ziehen vom jeweiligen Wert der Jahreszahl den Mittelwert der Jahreszahlen ab. Bei numerischen Variablen kann dies sehr hilfreich bei der Interpretation sein, denn wenn beispielsweise die numerische Variable \textquote{date} nicht skaliert werden würde, würde die Regression die Effekte im Jahr 0 angeben(!). Wenn eine Variable hingegen skaliert ist, dann werden die anderen Variablen nicht relativ zum Nullwert der Variable, sondern zu deren Mittelwert ins Verhältnis gesetzt, d.h. wir erhalten den Effekt der anderen Variablen, wenn die Variable \textquote{date} ihren Mittelwert annimmt.


```{r scaling}
# scaling date
slr.data$prep.ptw <- slr.data$prep.ptw - mean(slr.data$prep.ptw)
```


Wir beginnen nun mit der Regression, indem wir eine erste Regression rechnen und anschließend deren Ergebnisse und diagnostische Plots betrachten.

```{r initialmodel}
# create initial model
prep.lm <- lm(prep.ptw ~ year, data = slr.data)
# inspect results
summary(prep.lm)

# plot model: 3 plots per row in one window
par(mfrow = c(1, 3))
plot(resid(prep.lm))
plot(rstandard(prep.lm))
plot(rstudent(prep.lm))
par(mfrow = c(1, 1)) # restroe default parameters
```

Die linke Grafik zeigt die Residuen des Modells (d.h. die Unterscheide zwischen den beobachteten und den durch das Modell vorhergesagten Werten). Das Problem bei diesem Plot ist, dass die Residuen nicht standardisiert sind und man sie so nicht mit den Residuen anderer Modelle vergleichen kann. Um diesen Mangel zu beheben standardisiert man die Residuen, indem man die Residuen durch deren Standartabweichung dividiert, und plottet sie gegen die beobachteten Werte (mittlerer Plot). Auf diese Weise erhält man nicht nur standardisierte Residuen, sondern die Werte der Residuen sind nun zu z-Werten geworden und man kann die z-Verteilung nutzen, um problematische Punkte zu finden. Es gibt drei Daumenregeln bezüglich des Findens problematischer Datenpunkte aufgrund von Residuen \citep[268--269]{field2012discovering}:

1. Punkte mit extremen Werten, d.h. Werten $\ge$ 3 (um genau zu sein, Werten $\ge$ 3.29), sollten aus den Daten entfernt werden.
2. Falls mehr als 1% der Datenpunkte Werte $\ge$ 2.5 haben (2.58 um genau zu sein), dann sind die Fehler unseres Models zu groß.
3. Falls mehr als 5% der Datenpunkte Werte $\ge$ 2 haben (1.96 um genau zu sein), dann sind die Fehler unseres Models ebenfalls zu groß.


Die rechte Grafik zeigt die *studentized Residuen*, d.h. die angepassten vorhergesagten Werte jedes Datenpunkts werden durch den Standardfehler der Residuen dividiert. Auf diesem Weg ist es möglich die Student's t-Verteilung zu nutzen, um unser Model zu diagnostizieren.

Angepasste vorhergesagte Werte sind ebenfalls Residuen, aber einer besonderen Art: Das Model wird ohne einen Datenpunkt gerechnet und dann genutzt um diesen Datenpunkt vorherzusagen. Der Unterschied zwischen dem beobachteten Datenpunkt und dem vorhergesagten Datenpunkt wird dann angepasster vorhergesagter Wert genannt. Zusammenfassend kann gesagt werden, dass studentized Residuen sehr nützlich dahingehend sind, dass Sie einflussreiche Datenpunkte erkennen lassen.

Die Plots zeigen, dass es zwei potentiell problematische Datenpunkte gibt (die Punkte ganz oben und ganz unten). diese zwei Punkte setzten sich deutlich von den anderen Punkten ab und können demnach Ausreißer (outlier) darstellen. Wir werden später testen, ob diese punkte entfernt werden müssen.

Wir werden nun weitere modelldiagnostische Grafiken generieren.

```{r diagnosticplots}
# generiere eine 2x2 matrize diagnostischer grafiken
par(mfrow = c(2, 2))
plot(prep.lm)
par(mfrow = c(1, 1))
```

Die diagnostischen Grafiken sehen sehr gut aus und wir werden im Folgenden erklären warum. Die Grafik im oberen linken Panel ist nützlich, um (a) Oulier zu finden oder (b) die Korrelation zwischen Residuen und vorhergesagten Werten zu bestimmen: Wenn ein Trend in der Linie oder den Punkten sichtbar wird (bspw. ein aufsteigender Trend oder eine Zickzacklinie), dann hätte unser Model ein Problem und wir müssten wahrscheinlich Datenpunkte entfernen.

Die Grafik im oberen rechten Panel zeigt an, ob die Residuen normal verteilt sind (was wünschenswert ist), ober ob die Residuen nicht einer Normalverteilung folgen. Liegen die Punkte auf der Linie, so folgen die Residuen einer Normalverteilung. Wenn die Punkte beispielsweise am oberen und unteren Ende nicht auf der Linie liegen, so zeigt dies, dass das Model kleine und große Werte nicht gut vorhersagt und daher nicht gut auf die Daten angepasst ist.

Die Grafik im unteren linken Panel gibt Aufschluss über Homoskedastizität. Homoskedastizität bedeutet, dass die Varianz der Residuen konstant bleibt und nicht mit dem Wert der unabhängigen Variable korrelieren. In unproblematischen Fällen zeigt die Grafik eine flache Linie. Liegt eine Trend in der Linie vor, so haben wir es mit Heteroskedastizität, also mit einer Korrelation zwischen unabhängigen Variablen und den Residuen, zu tun, die für Regressionen sehr problematisch ist.

Die Grafik im unteren rechten Panel zeigt problematische einflussreiche Datenpunkte, die die Regression überproportional beeinflussen (dies sollte nicht der Fall sein). Falls solche einflussreichen Datenpunkte vorliegen, so sollten diese entweder (a) gewichtet werden (robuste Regression) oder (b) entfernt werden. Die Grafik zeigt die Cookdistanz, welche zeigt, wie sich die Regression verändert, wenn ein Model ohne diesen Datenpunkt gerechnet wird. Die Cookdistanz zeigt also, welchen Einfluss ein Datenpunkt auf die Regression als ganzes hat. Datenpunkte, die eine Cookdistanz $\ge$ 1 haben sind problematisch \citep[269]{field2012discovering}.

Die sogenannte Leverage ist ebenso ein Maß, das anzeigt, wie stark ein Datenpunkt die Genauigkeit der Regression beeinflusst. Leveragewerte liegen zwischen 0 (kein Einfluss) und 1 (starker Einfluss: suboptimal!). Um zu testen, ob ein spezifischer Datenpunkt einen hohen Leveragewert besitzt, muss man einen Cut-Off-Punkt berechnen, der anzeigt, ob die Leverage zu stark oder noch akzeptabel ist. Folgende zwei Formeln werden hierzu genutzt:

$\frac{3(k + 1)}{n}$

oder

$\frac{2(k + 1)}{n}$

Wir werden im Kontext der multiplen linearen regression genauer auf Leverage eingehen und nun nur noch eine Überblicktabelle der Ergebnisse der Regression generieren.

```{r tabulate results}
# tabulate results
slr.summary(prep.lm)
```

Typischer weise werden die Ergebnisse von Regressionen in solchen Tabellen wiedergegeben, da diese aller wichtigen Kennzahlen der Modellgüte und die Signifikanz wie auch die Stärke der Effekte beinhalten. Die Tabelle ist hier noch einmal abgebildet.

\begin{table}[H]
\begin{minipage}{\textwidth}
\begin{center}
\begin{footnotesize}
\begin{tabular}{l cccccc r}
\hline
& Estimate & Std. $\beta$ & Pearson's r & SE & t-value & Pr$(>|t|)$ & Sig.\\
\hline
(Intercept) & --27.72 & & & 10.86 & --2.55 & 0.011 & p$<$.05* \\
year & 0.02 & 0.1039 & 0.1 & 0.01 & 2.56 & 0.0107 & p$<$.05* \\
\hline
Model statistics & & & & & & & Value \\
\hline
Number of cases & & & & & & & 603 \\
Residual SE (601 DF) & & & & & & & 21.11 \\
Multiple $R^{2}$ & & & & & & & 0.0108 \\
Adjusted $R^{2}$ & & & & & & & 0.0091 \\
F-statistic (1, 601) & & & & & & & 6.55 \\
Model p-value & & & & & & & 0.0107 \\
\hline
\end{tabular}
\end{footnotesize}
\caption{Zusammenfassung der Ergebnisse der einfachen linearen Regression}
\label{tab:slr1}
\end{center}
\end{minipage}
\end{table}

Zusätzlich sollten die Ergebnisse von einfachen linearen Regressionen schriftlich in etwa wie folgt zusammengefasst werden:\\[.2cm]

\noindent Eine einfache lineare Regression wurde auf die Daten angepasst. Eine visuelle Begutachtung der modelldiagostischen Grafiken zeigten keine problematischen Datenpunkte (Ausreißer) oder überproportional einflussreiche Datenpunkte an und wiesen auf einen guten Modellfit hin. Das finale lineare Regressionsmodell basiert auf 603 Datenpunkten und korreliert hoch signifikant mit den Daten ($R^{2}$: 0.0108, F-Statistik (1, 601): 6.553, p-Wert: 0.0107\*) und bestätigt eine signifikante positive Korrelation zwischen dem Jahr in dem der Text geschrieben wurde und der relativen Häufigkeit von Präpositionen in den Texten nach (Koeffizient: .02, Std. $\beta$: 0.1039, SE: 0.01, t-Wert: 2.560, p-Wert: .0107*).

## A practical example of a simple linear regression - teaching styles

Im vorhergehenden Beispiel haben wir es mit zwei numerischen Variablen zu tun gehabt, während es sich in dem folgenden Beispiel um eine kategoriale und eine numerische abhängige Variable handelt. Die Eigenschaft, dass Regressionen mit sehr verschiedenen Variablenarten umgehen können, macht Regressionen zu einer weit verbreiteten und robusten Analysemethode.

In diesem Beispiel haben wir es mit zwei Gruppen von Schülern zu tun, die zufällig einer Gruppe zugewiesen wurden und unterschiedlichen Lehrmethoden ausgesetzt waren. Beide Gruppen unterziehen sich im Anschluss an die Lehreinheit einem Sprachlerntest mit einer Höchstpunktzahl von 20 Punkten. Die Schüler der ersten Gruppen haben folgende Punktzahlen erreicht:

* Gruppe A: 15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14 (mean: 14,93)

Die Schüler der zweiten Gruppe haben diese Punktzahlen erreicht.

* Gruppe B: 11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7 (mean: 11,77)

Unsere Frage ist nun, ob Gruppe A wirklich besser ist oder ob das Ergebnis Zufall ist?

Gehen wir nun dazu über, die Regression in `R` zu implementieren. Wie im vorherigen Beispiel leeren wir den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.

```{r reparation}
# entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages("QuantPsyc")
#install.packages("car")
# pakete initialisieren
library(QuantPsyc)
library(car)
library(ggplot2)
source("http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r") # mehrere ggplots in einem fenster
source("http://martinschweinberger.de/docs/scripts/slr.summary.tb.r") # funktion zum erstellen von summary tabellen
```


Nachdem die notwendigen Spezifikationen durchgeführt wurden, werden wir nun unser Datenset generieren und es anschließend betrachten.

```{r createdata}
# einladen der daten
g1 <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)
g2 <- c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)
g <- c(rep("A", length(g1)), rep("B", length(g2)))
sprtestdata <- data.frame(g, c(g1, g2))
# spaltennamen hinzufuegen
colnames(sprtestdata) <- c("gruppe", "punkte")
# erste zeilen des datensatzes betrachten
head(sprtestdata)

# struktur des datensatzes betrachten
str(sprtestdata)

# eigenschaften des datensatzes betrachten
summary(sprtestdata)
```

Nun stellen wir die Daten grafisch dar. In diesem Fall bietet sich ein Boxplot zur Visualisierung an.

```{r boxplot, fig.cap="Darstellung der Sprachtestdaten"}
# erstelle boxplot
boxplot(punkte ~ gruppe,
data = sprtestdata, # the data we want to display
main = "", # you could specify a title here
ylab = "Punkte", # titel der y-achse
ylim = c(0, 20), # grenzen der y-achse festlegen
xlab = c("Gruppen"), # titel der x-achse
notch = T, # notches einfuegen
col = c("lightgreen", "lightblue")) # box einfaerben
# text darstellen
text(1:2,
c(4.0, 4.0),
cex = 0.85,
labels = paste("mean\n",
c(round(as.vector(by(sprtestdata$punkte, sprtestdata$gruppe, mean))[1], 2),
round(as.vector(by(sprtestdata$punkte, sprtestdata$gruppe, mean))[2], 2),
sep = "")))
rug(jitter(sprtestdata$punkte),
side=4)
grid()
box()
```

Die Daten weisen darauf hin, dass Gruppe A signifikant besser abgeschnitten hat als Gruppe B. Wir werden diesen Eindruck dadurch testen, dass wir im nächsten Schritt das Regressionsmodell und erstellen die modelldiagnostischen Grafiken generieren.

```{r create simple model}
# Simples Lineares Regressionsmodel erstellen
sprtest.lm <- lm(punkte ~ gruppe, data = sprtestdata)
# ergebnisse betrachten
summary(sprtest.lm)

# graphik parameter setzen: 3 plots in einer reihe
par(mfrow = c(1, 3))
plot(resid(sprtest.lm))
plot(rstandard(sprtest.lm))
plot(rstudent(sprtest.lm))
par(mfrow = c(1, 1)) # wiederherstellen der originalparameter
```

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/sprtest1.png}\\[.25cm]
\caption{Diagnostische Grafiken der Sprachtestdaten}
\label{fig:sprtest1}
\end{figure}

Die Grafiken weisen nicht auf Ausreißer oder andere Probleme hin und wir können daher mit weiteren diagnostischen Grafiken fortfahren.

```{r diagnostic plots}
# generiere eine 2x2 matrize diagnostischer grafiken
par(mfrow = c(2, 2))
plot(sprtest.lm)
par(mfrow = c(1, 1))
```

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/sprtest2.png}\\[.25cm]
\caption{Weitere diagnostische Grafiken der Sprachtestdaten}
\label{fig:prep3}
\end{figure}

Auch diese Grafiken weisen auf keine Probleme hin. In diesem Fall können die Daten im nächsten Schritt zusammengefasst werden.

```{r summarize results}
# ergebnisse tabellieren
slr.summary(sprtest.lm)
```

\begin{table}[H]
\begin{minipage}{\textwidth}
\begin{center}
\begin{footnotesize}
\begin{tabular}{l cccccc r}
\hline
& Estimate & Std. $\beta$ & Pearson's r & SE & t-value & Pr$(>|t|)$ & Sig.\\
\hline
(Intercept) & 14.93 & & & 0.53 & 27.94 & 0 & p$<$.001*** \\
GruppeB & -3.17 & -0.4819 & 0.48 & 0.76 & -4.19 & 0 & p$<$.001*** \\
\hline
Model statistics & & & & & & & Value \\
\hline
Number of cases & & & & & & & 60 \\
Residual SE (601 DF) & & & & & & & 2.93 \\
Multiple $R^{2}$ & & & & & & & 0.2322 \\
Adjusted $R^{2}$ & & & & & & & 0.219 \\
F-statistic (1, 58) & & & & & & & 17.55 \\
Model p-value & & & & & & & p$<$.001*** \\
\hline
\end{tabular}
\end{footnotesize}
\caption{Zusammenfassung der Ergebnisse der einfachen linearen Regression}
\label{tab:slr1}
\end{center}
\end{minipage}
\end{table}

Die Ergebnisse dieser einfachen linearen Regressionen können wie folgt zusammengefasst werden:\\[.2cm]

\noindent Eine einfache lineare Regression wurde auf die Daten angepasst. Eine visuelle Begutachtung der modelldiagostischen Grafiken zeigten keine problematischen Datenpunkte (Ausreißer) oder überproportional einflussreiche Datenpunkte an und wiesen auf einen guten Modellfit hin. Das finale lineare Regressionsmodell basiert auf 60 Datenpunkten und korreliert hoch signifikant mit den Daten ($R^{2}$: 0.2322, $F$-Statistik (1, 58): 2.93, p-Wert $<$.001***) und bestätigt, dass Gruppe A signifikant besser bei dem Sprachlerntest abgeschnitten hat als Gruppe B (Koeffizient: -3.17, Std. $\beta$: -0.4819, SE: 0.48, t-Wert: -4.19, p-Wert $<$.001***).


# (Multiple) Linear Regression

Im Gegensatz zu der einfachen linearen Regression, die den Zusammenhang zwischen einer unabhängigen und einer abhängigen Variable testet, kann eine multiple lineare Regression den Einfluss mehrerer unterschiedlicher unabhängiger Variablen und deren Interaktionen auf die abhängige Variable bestimmen (vgl. Formel (\ref{eq:mlr})). Eine einfache lineare Regression kann somit nicht gleichzeitig den Einfluss mehrerer Variablen oder derer Interaktionen bestimmen.

$f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon$

Es gibt ausgiebige Fachliteratur zu multiplen Regressionen und den zugrundeliegenden Konzepten. Insbesondere seien hier \citet{achen1982interpreting}, \citet{bortz2006statistik}, \citet{crawley2005statistics}, \citet{faraway2002practical}, \citet{field2012discovering} (mein persönlicher Favorit!), und \citet{wilcox2009basic} zu nennen. Sehr gute Einführungen dazu, wie Regressionen in `R` implementiert werden können, finden sich u.a. in \citet{baayen2008analyzing}, \citet{crawley2012r} oder \citet{gries2009statistics}.

Eine weitere Anmerkung vorweg: Die modelldiagnostischen Verfahren werden teilweise identisch sein mit denen, die im Kapitel zur einfachen linearen Regression besprochen wurden und sie werden daher nur dann ausgiebiger erläutert, insofern dies nicht bereits geschehen ist.

Eine letzte Anmerkung betrifft die Stichprobengröße, die notwendig ist um eine Regression zu rechnen. Obwohl die Angabe, dass 25 Datenpunkte pro Gruppe ausreichen weit verbreitet ist, ist diese Angabe nicht korrekt, da sich die benötigte Stichprobengröße nach der Größe des Effekts, der bestimmt werden soll, und nach der Anzahl der untersuchten Variablen richtet. Gehen viele unabhängige Variablen in die Regression ein und die Effektstärke der zu testenden Variable(n) ist sehr klein, dann kann man von einer Mindestgröße der Stichprobe von 600 Datenpunkten ausgehen. \citet[273--275]{field2012discovering} geben zur Mindestgröße der benötigten Stichprobe Daumenregeln an die Hand (k = Anzahl der Prädikatoren; kategorische Prädikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):

* Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.
*  Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.
*  Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen.
\end{itemize}

%Grafik \citet[275]{field2012discovering} einfügen. XXX

Sie werden im \verb!R!-code sehen, dass hierzu eine Funktion existiert, die testet, ob die Stichprobe für die Untersuchung angemessen war.

Hinsichtlich der Modellanpassung wird nur auf step-wise step-down Prozeduren, die auf dem AIC (Akaike information criterion) beruhen, eingegangen werden. Es gibt eine Vielzahl von möglichen Prozeduren, die genutzt werden können forced entry, stepwise, hierarchical) und innerhalb dieser Prozeduren gibt es Unterklassen, sodass eine Diskussion den Rahmen dieser Sektion sprengen würde.

## Practical example of a multiple linear regression - presents

In diesem Beispiel werden wir untersuchen, ob der Geldbetrag, den Männer für Geschenke ausgeben, mit der Attraktivität und dem Beziehungsstatus der Frauen, für die Geschenke gekauft wurden, korreliert. Das Beispiel ist \citet{field2012discovering} entnommen. Wir werden nun das Beispiel in \verb!R! implementieren und leeren dazu, wie üblich, den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.

```{r set up session}
# entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages("rms")
#install.packages("glmulti")
#install.packages("lmtest")
#install.packages("MASS")
#install.packages("QuantPsyc")
#install.packages("car")
#install.packages("ggplot2")
# pakete initialisieren
#library(rms)
#library(glmulti)
#library(lmtest)
#library(MASS)
library(car)
library(QuantPsyc)
library(boot)
library(ggplot2)
source("http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.r")
source("http://martinschweinberger.de/docs/scripts/mlinr.summary.r")
source("http://martinschweinberger.de/docs/scripts/SampleSizeMLR.r")
source("http://martinschweinberger.de/docs/scripts/ExpR.r")
# optionen festlegen
options("scipen" = 100, "digits" = 4)
```


Nachdem wir die notwendigen Pakete usw. in \verb!R! eingelesen haben, können wir nun die Daten laden und uns einen ersten Eindruck über deren Struktur und Eigenschaften verschaffen.

```{r load data}
# daten laden
mlrdata <- read.delim("http://martinschweinberger.de/docs/data/mlrdata.txt", header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)

# struktur der daten betrachten
str(mlrdata)

# zusammenfassung der daten betrachten
summary(mlrdata)
```

Wir haben nun den Datensatz eingelesen und seine Struktur betrachtet. Im nächsten Schritt werden wir die Daten visualisieren, um einen Eindruck der Daten und der Verteilungen der Variablen zu gewinnen. Wir werden vier Grafiken erstellen und diese dann in einem Fenster darstellen.

```{r plot data}
p1 <- ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = T, aes(fill = factor(status))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = "") +
labs(y = "Money spent on present (Euro)") +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle("Status")
p2 <- ggplot(mlrdata, aes(attraction, money)) +
geom_boxplot(notch = T, aes(fill = factor(attraction))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = "") +
labs(y = "Money spent on present (Euro)") +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle("Attraction")
p3 <- ggplot(mlrdata, aes(x = money)) +
geom_histogram(aes(y=..density..),
binwidth = 10,
colour = "black", fill = "white") +
geom_density(alpha=.2, fill = "#FF6666") # Overlay with transparent density plot
p4 <- ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = F, aes(fill = factor(status))) +
scale_fill_brewer(palette="Paired") +
facet_wrap(~ attraction, nrow = 1) +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = "") +
labs(y = "Money spent on present (Euro)") +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE)
# Plot the plots
multiplot(p1, p3, p2, p4, cols = 2)
```

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mlr1.png}
\caption{Darstellung der Variablen im MLR Beispiel}
\label{fig:mlr1}
\end{figure}

Die Grafik im oberen linken Panel scheint anzudeuten, dass Männer mehr Geld für Frauen ausgeben, die Single sind, allerdings relativiert sich dieser Eindruck, denn die Grafik im unteren rechten Panel deutet darauf hin, dass Männer nur dann mehr Geld für ein Geschenk ausgeben, wenn die Frau Single ist UND sie an ihr interessiert sind. Den der Beziehungsstatus hat keinen Einfluss auf das Geld für Geschenke für Frauen, an denen Männer nicht interessiert sind. Die Grafik im oberen rechten Panel weist darauf hin, dass Männer substantiell mehr Geld für Geschenke für Frauen ausgeben, an denen sie interessiert sind.

Gehen wir nun dazu über mit der Regression zu beginnen. Im ersten Schritt erzeugen wir vier Baselinemodelle: Zwei minimale Modelle, die nur den Gesamtmittelwert (Intercept) als Prädiktor beinhalten und zwei gesättigte Modelle (saturated models), die alle möglichen Prädikatoren und Interaktionen beinhalten.

```{r generate minimal model}
# generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m0.mlr)

# ergebnisse betrachten
summary(m0.glm)

#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)

# ergebnisse betrachten
summary(m1.glm)
```

Nachdem wir die Baselinemodelle generiert haben, werden wir nun mit dem Modellanpassung (model fitting)beginnen. Modellanpassung bezeichnet den Prozess mit dem man zu demjenigen Modell gelangt, dass das Maximum an Varianz mit einem Minimum an Variablen erklärt. Das zugrunde liegende Prinzip ist daher das \textit{Parsimonie-} oder \textit{Sparsamkeitsprinzip}, welches im Englischen häufig als Ockham's Rasiermesser bezeichnet wird.

Wir werden einen automatischen step-wise step-down Prozess bei der Modellanpassung nutzen, der dasjenige Modell mit dem niedrigsten AIC (Akaike information criterion) Wert sucht.
Das AIC berechnet sich nach Formel (\ref{eq:aic}) und ist ein Maß der Sparsamkeit, dass einen Wert dafür bildet, wie viel Varianz mit wie vielen Variablen erklärt werden kann [cf. @field2012discovering 318]. Um so niedriger der AIC-Wert, umso besser die Balance zwischen erklärter Varianz und der Anzahl der dafür nötigen Variablen. Die AIC-Werte können nun zwischen Modellen verglichen werden, die auf die selben Datenpunkte angepasst sind ($LL$ steht für LogLikelihood und $k$ für die Anzahl der unabhängigen Variablen im Modell).

$-2LL + 2k$
\label{eq:aic}
\end{equation}

Beginnen wir nun mit der Modellanpassung.
```{r model fitting}
# automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = "both")

# minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassugn der modellergebnisse betrachten
summary(m2.mlr)
```

Basierend auf dem Modell mit dem kleinsten AIC-Wert haben wir das minimale adäquate Modell (minimal adequate model) generiert und anschließend haben wir die Zusammenfassung der Ergebnisse des Modells auswerfen lassen. Im Folgenden werden wir den Output, d.h. die Zusammenfassung der Ergebnisse des minimalen adäquaten Modells beleuchten und die verschiedenen Konzepte erläutern.

Das erste Objekt, was die Zusammenfassung berichtet ist der \textit{Call}, d.h. die Formel des des minimalen adäquaten Modells. Daran anschließend wird die Verteilung der Residuen, also der Unterschiede zwischen den vorhergesagten und beobachteten Werten, berichtet. Dann folgt das wichtigste Element der Modellzusammenfassung: Die Tabelle mit den Koeffizienten der Prädikatoren des Modells (dies sind die Koeffizienten der Fixed Effects). Wir werden uns mit dieser Tabelle später genauer beschäftigen. Nach der Tabelle folgen die Modellstatistiken, die Aufschluss darüber geben, wie gut das Modell die Daten modelliert, d.h. wie gut das Modell den beobachteten Daten entspricht. Der Unterschied zwischen diesen Werten und der Tabelle mit den Koeffizienten besteht darin, dass die Modellstatistiken über die Gesamtgüte des Modells berichten, während die Tabelle mit den Koeffizienten nur etwas über die individuellen Faktoren aussagt.

Der multiple $R^{2}$-Wert gibt an, wie viel Varianz das Modell erklärt. Ein Wert von 0 würde bedeuten, dass das Modell gar keine Varianz erklärt, während ein Wert von 1 bedeuten würde, dass das Modell 100\% der Varianz erklärt und somit die Vorhersage des Modells genau den beobachteten Daten entspricht. Dies bedeutet, dass, wenn man den $R^{2}$-Wert mit 100 multipliziert, man den Prozentwert der Varianz erhält, den das Modell erklärt. In unserem Fall sagt der multiple $R^{2}$-Wert von 0.852 also aus, dass unser minimales adäquates Modell 85.2\% der Varianz erklärt. Modelle, die einen multiplen $R^{2}$-Wert von $ge$.05 haben, gelten als substantiell signifikant (substantially significant) \citep[55]{szmrecsanyi2006morphosyntactic}. Manche gehen soweit zu sagen, dass Modelle mindestens einen $R^{2}$-Wert von $\ge$.05 haben müssen, aber dies ist problematisch, da es durchaus vorkommen kann, dass man an sehr schwachen (aber signifikanten) Effekten interessiert ist, die aber zu einem sehr kleinen $R^{2}$-Wert führen. Wichtiger ist, dass das Modell insgesamt signifikant ist, da dies aussagt, dass das Modell zu signifikant besseren Vorhersagen kommt, als es durch Zufall der Fall wäre.

Der angepasste $R^{2}$-Wert (adjusted $R^{2}$) berücksichtigt die Anzahl der Prädikatoren. Darüber hinaus gibt der angepasste $R^{2}$-Wert darüber Aufschluss, wie gut sich das Modell eignet, um Aussagen über die Population (und nicht nur über die Stichprobe) zu tätigen. Wenn der Unterschied zwischen
dem multiplen $R^{2}$-Wert und dem angepassten $R^{2}$-Wert sehr gering ist, dann bedeutet dies, dass sich das Modell dazu eignet Aussagen über die Population als Ganzes zu machen. Wenn der Unterschied allerdings relativ groß ist, dann bedeutet dies, dass das Modell instabil ist und die Datenstruktur, auf die das Modell angepasst wurde, eine suboptimale Verteilung aufweist, z.B. wegen Ausreißern. In anderen Worten bedeutet der Unterschied, dass wenn die Regression auf die Population anstatt der Stichprobe angewandt worden wäre, dann würde sie .5\% weniger Varianz (85.2-84.7) erklären.

Kommen wir nun zu der Tabelle mit den Koeffizienten zurück. Alle Haupteffekte und eine Interaktion zwischen \textquote{status} und \textquote{attraction} sind signifikant. Eine Interaktion besteht dann, wenn die Korrelation zwischen einer unabhängigen und der abhängigen variable von einer anderen unabhängigen variable beeinflusst wird. In unserem Szenario geben Männer nur dann mehr Geld für ein Geschenk für eine Frau aus, wenn sie an ihr (a) interessiert sind und (b) sie Single ist. Die Korrelation zwischen \textquote{money} und \textquote{attraction} wird also von einer anderen Variable \textquote{status} beeinflusst. Wir haben es also mit einer Interaktion zwischen \textquote{attraction} und \textquote{status} zu tun.

Hinsichtlich der Interpretation dieser Ergebnisse ist festzuhalten, dass man Haupteffekte, die an Interaktionen beteiligt sind, nicht interpretieren sollte, da nicht klar ist, wie sich der Anteil an erklärter Varianz zwischen dem Haupteffekten und den Interaktionen aufteilt. Zusätzlich ist festzuhalten, dass, insofern nur Haupteffekte signifikant sind, die Koeffizienten die Korrelation zwischen der abhängigen und der unabhängigen Variable abbilden, wenn die anderen Variablen einen Wert von 0 oder das jeweilige Baseline-Level annehmen.

Bevor wir die Tabelle mit den Koeffizienten weiter interpretieren, werden wir noch die Konfidenzintervalle berechnen und das Baselinemodell mit dem minimalen adäquaten Modell vergleichen, um zu schauen, ob das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell.

```{r confindence}
# konfidenzintervalle der koeffizineten
confint(m2.mlr)

# vergleich zwiscehn dem baseline-modell und dem minimal adequate model
anova(m0.mlr, m2.mlr)

Anova(m0.mlr, m2.mlr, type = "III")
```

Der Vergleich der Modelle zeigt eindeutig, dass das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell. Wir werden nun mit der Modelldiagnose fortfahren, indem wir schauen, ob Datenpunkte entfernt werden sollten, da sie die Passgenauigkeit des Modells (modelfit) überproportional verschlechtern.

```{r finding outliers}
# suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main="QQ Plot")
# Cooks D plot
# D-werte > 4/(n-k-1) sind problematisch
cutoff <- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)
par(mfrow = c(1, 1))
```


\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mlr2.png}
\caption{Diagnistische Grafiken des multiplen linearen Regressionsmodells}
\label{fig:mlr2}
\end{figure}
Die Grafiken deuten darauf hin, dass drei Datenpunkte potentiell problematisch sind (Datenpunkte 52, 64, 83). Wir werden nun diesen Eindruck statistisch evaluieren und die Datenpunkte, falls nötig entfernen.

```{r inspecting outliers}
# entfernen zu einflussreicher datenpunkte
# um dies zu tun extrahieren wir diagnostische
# werte zu allen datenpunkten und addieren die
# spalten mit diesen werten zu unserem
# datensatz hinzu
infl <- influence.measures(m2.mlr)

# addieren der einflussstatistiken zu dem datensatz
mydata <- data.frame(mlrdata, infl[[1]], infl[[2]])
head(mydata)

# zu einflussreiche datenpunkte erkennen
remove <- apply(infl$is.inf, 1, function(x) {
ifelse(x == TRUE, return("remove"), return("keep")) } )

# informationen zu den zu einflussreichen datenpunkten
# zum datensatz hinzuaddieren
mlrdata <- data.frame(mlrdata, remove)

# zeilenzahl des alten datensatzes anzeigen
nrow(mydata)

mlrdata <- mlrdata[mlrdata$remove == "keep", ]

# zeilenzahl des neuen datensatzes anzeigen
nrow(mlrdata)
```

Die Zeilenzahl weist darauf hin, dass zwei potentielle Problemfälle entfernt wurden, da deren Werte inakzeptabel waren, während einer der Punkte im Modell verbleiben durfte. Da wir es nun mit einem veränderten Datensatz zu tun haben, müssen wir die bisherigen Schritte wiederholen. Die einzelnen wiederholten Schritte werden nun nicht weiter erläutert, insofern die Erläuterungen mit den bereits oben ausgeführten weitgehend identisch wäre.

```{r generate new minimal model}
# generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m0.mlr)

# ergebnisse betrachten
summary(m0.glm)

#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)

# ergebnisse betrachten
summary(m1.glm)

#############################
# automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = "both")

# minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassung der modellergebnisse betrachten
summary(m2.mlr)

# konfidenzintervalle der koeffizineten
confint(m2.mlr)

# vergleich zwiscehn dem baseline-modell und dem minimal adequate model
anova(m0.mlr, m2.mlr)

Anova(m0.mlr, m2.mlr, type = "III")

# suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main="QQ Plot")
# Cooks D plot
# D-werte > 4/(n-k-1) sind problematisch
cutoff <- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)
par(mfrow = c(1, 1))
```

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mlr3.png}
\caption{Diagnistische Grafiken des neuen multiplen linearen Regressionsmodells}
\label{fig:mlr3}
\end{figure}
Die diagnostischen Grafiken zeigen nun zwar weitere potentiell problematische Datenpunkte an, allerdings weichen diese Punkte weitaus weniger vom allgemeinen Trend ab, als dies bei den entfernten Punkten der Fall war. Wir berechnen dennoch diagnostische Statistiken und fügen diese zum Datensatz hinzu, um sicher zu gehen, dass nun alle Datenpunkte akzeptabel sind.

```{r generate diagnostic plots}
# addieren von modelldiagnostiken zum datasatz
mlrdata$residuals <- resid(m2.mlr)
mlrdata$standardized.residuals <- rstandard(m2.mlr)
mlrdata$studentized.residuals <- rstudent(m2.mlr)
mlrdata$cooks.distance <- cooks.distance(m2.mlr)
mlrdata$dffit <- dffits(m2.mlr)
mlrdata$leverage <- hatvalues(m2.mlr)
mlrdata$covariance.ratios <- covratio(m2.mlr)
mlrdata$fitted <- m2.mlr$fitted.values
```

Wir nutzen nun die hinzugefügten Diagnosewerte um neue diagnostische Grafiken zu erstellen.

```{r generate new diagnostic plots}
# erstellen diagnostischer grafiken
# (drei grafiken in einem fenster)
p1 <- histogram<-ggplot(mlrdata, aes(studentized.residuals)) +
theme(legend.position = "none") +
geom_histogram(aes(y=..density..),
binwidth = 1,
colour="black",
fill="white") +
labs(x = "Studentized Residual", y = "Density")
p2 <- histogram + stat_function(fun = dnorm, args = list(mean = mean(mlrdata$studentized.residuals, na.rm = TRUE), sd = sd(mlrdata$studentized.residuals, na.rm = TRUE)), colour = "red", size = 1)
p3 <- scatter <- ggplot(mlrdata, aes(fitted, studentized.residuals))
p4 <- scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")+ labs(x = "Fitted Values", y = "Studentized Residual")
p5 <- qqplot.resid <- qplot(sample = mlrdata$studentized.residuals, stat="qq") + labs(x = "Theoretical Values", y = "Observed Values")
p6 <- qqplot.resid
multiplot(p2, p4, p6, cols=3)
```

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mlr4.png}
\caption{Diagnistische Grafiken des neuen multiplen linearen Regressionsmodells}
\label{fig:mlr4}
\end{figure}
Die Grafiken zeigen keine auffälligen Ausreißer. Wir überprüfen diesen Eindruck dennoch statistisch. Hierzu lässt sich folgendes sagen:

* Datenpunkte mit standardisierten Residuenwerten > 3.29 sollten entfernt werden [@field2012discovering 269]

* Wenn mehr als 1\% der Datenpunkte standardisierte Residuenwerte $\ge$ 2.58, so ist der Fehleranteil des Modells inakzeptabel [@field2012discovering 269]

*Wenn mehr als 5\% der Datenpunkte standardisierte Residuenwerte $\ge$ 1.96 haben, so ist der Fehleranteil des Modells inakzeptabel [@field2012discovering 269]

* Zusätzlich sollten Datenpunkte mit Cooks D-Werten $\ge$ 1 entfernt werden\citep[269]{field2012discovering}

* Schließlich sollten Leveragewerte $3(k + 1)/n$ (k = Anzahl der Prädikatoren, N = Anzahl der Datenpunkte) nicht überschreiten \citep[270]{field2012discovering}

* Es sollte keine Autokorrelation innerhalb der unabhängigen Variablen vorliegen, d.h. eine Variable darf nicht mit sich selbst korrelieren (ist dies der Fall muss ein Repeated Measures Design oder ein hierarchisches Regressionsmodell genutzt werden)

* Unabhängige Variablen dürfen untereinander nicht stark korrelieren (Multikollinearität). Daher gilt, dass Datenpunkte mit Varianzinflationsfaktorenwerten (VIF) $\ge$ 10 entfernt werden sollten [@myers1990classical]. Es können aber bereits Werte von 2.5 problematisch sein [@szmrecsanyi2006morphosyntactic 215]!

* Datenpunkte mit 1/VIF Werten $<$ .1 müssen entfernt werden (ab .2 gelten die Datenpunkte als problematisch) [@menard1995applied]

* Der Mittelwert der VIFs sollte $<$ 1 sein [@bowerman1990linear]


```{r more diagnostics}
# 1: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$standardized.residuals > 3.29)

# 2: optimal = 1
# (aufgelistete datenpunkte sollten entfernt werden)
stdres_258 <- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) > 2.58, 1, 0) } ))
(sum(stdres_258) / length(stdres_258)) * 100

# 3: optimal = 5
# (aufgelistete datenpunkte sollten entfernt werden)
stdres_196 <- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) > 1.96, 1, 0) } ))
(sum(stdres_196) / length(stdres_196)) * 100

# 4: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$cooks.distance > 1)

# 5: optimal = 0
# (datenpunkte sollten entfernt werden, wenn cooks distanz nahe 1 ist)
which(mlrdata$leverage >= (3*mean(mlrdata$leverage)))

# 6: checking autocorrelation:
# Durbin-Watson test (optimal: grosser p-wert)
dwt(m2.mlr)

# 7: multicolliniaritaet testen 1
vif(m2.mlr)

# 8: multicolliniaritaet testen 2
1/vif(m2.mlr)

# 9: mittlerer vif wert sollte nicht groesser als 1 sein
mean(vif(m2.mlr))
```

Bis auf den Mittelwert der VIFs, der $<$ 1 sein sollte, tatsächlich aber 2.307 beträgt, sind alle diagnostischen Werte völlig akzeptabel. Wir werden nun testen, ob die Stichprobengröße in unserer Untersuchung ausreicht. Basierend auf [@green1991many] geben [@field2012discovering 273-274] zur Mindestgröße der benötigten Stichprobe Daumenregeln an die Hand (k = Anzahl der Prädikatoren; kategorische Prädikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):

* Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.

* Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.

* Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen.


Zusätzlich werden wir prüfen, wie groß der Wert für `R` basierend auf einer Zufallsstichprobe wäre, um abschätzen zu können, wie groß die Wahrscheinlichkeit eines $\beta$-Fehlers bei der vorliegenden Stichprobengröße ist [vgl. @field2012discovering 274]. Bei $\beta$-Fehlern handelt es sich um die Annahme, ein Prädikator ist nicht signifikant, obwohl er tatsächlich einen signifikanten Einfluss hat (siehe Sektion \ref{fehler}). Die Prüfgröße schwankt zwischen 0 und 1. Umso kleiner der Wert ist, umso besser. Wenn der Wert $\ge$ 1 liegt, dann gibt es Grund zur Sorge und es sollte eine größere Stichprobe gezogen werden.

```{r diagnostics: sample size}
# ist die stichprobe ausreichend gross
smplesz(m2.mlr)

# gefahr von beta-fehlern
expR(m2.mlr)
```

Die Funktion `smplesz` teilt mit, dass die Stichprobengröße nicht optimal ist und 9 Datenpunkte fehlen, um der Anforderung von [@green1991many] zu genügen. Die Wahrscheinlichkeit einen $\beta$-Fehler zu begehen ist hingegen sehr klein (0.0309). Als letzten Schritt tabellarisieren wir die Ergebnisse und fassen diese anschließend in Textform zusammen.

```{r results of final model}
# ergebnisse der mlr betrachten
mlr.summary(m2.mlr, m2.glm, ia = T)
```

\begin{sidewaystable}
\begin{minipage}{\textwidth}
\begin{center}
\begin{small}
\begin{tabular}{l ccccccc r}
\hline
& Estimate & VIF & CI(2.5\%) & CI(97.5\%) & SE & $t$-value & $Pr(>|t|)$ & Sig.\\
\hline
(Intercept) & 99.15 & & 92.1 & 106.21 & 3.6 & 27.56 & 0 & p$<$.001*** \\
statSingle & 55.85 & 2 & 45.78 & 65.93 & 5.14 & 10.87 & 0 & p$<$.001*** \\
attrNoInterest & -47.66 & 1.96 & -57.63 & -37.69 & 5.09 & -9.37 & 0 & p$<$.001*** \\
statSingle:attrNoInterest & -59.46 & 2.96 & -73.71 & -45.21 & 7.27 & -8.18 & 0 & p$<$.001*** \\
\hline
Model statistics & & & & & & & & Value \\
\hline
Number of cases in model & & & & & & & & 98 \\
Residual SE on 94 DF & & & & & & & & 17.99 \\
Multiple $R^{2}$ & & & & & & & & 0.857 \\
Adjusted $R^{2}$ & & & & & & & & 0.853 \\
AIC & & & & & & & & 850.4 \\
BIC & & & & & & & & 863.32 \\
F-Statistik & & &F-Statistik: & 188.36 & DF: & 3, 94 & p-value: 0 & p$<$.001*** \\
\hline
\end{tabular}
\end{small}
\caption{Zusammenfassung der Ergebnisse der multiplen linearen Regression (SE = Standardfehler)}
\label{tab:mlr1}
\end{center}
\end{minipage}
\end{sidewaystable}

Zusätzlich werden die Ergebnisse von multiplen linearen Regressionen schriftlich wie folgt zusammengefasst:



(Falls signifikante Interaktionen vorliegen, sollten die Haupteffekte der Prädikatoren, die an der/n Interaktion/en beteiligt sind, nicht interpretiert werden. Sie werden hier dennoch interpretiert, um zu verdeutlichen, wie die Ergebnisse einer multiplen linearen Regression verschriftlicht werden können.)

Eine multiple lineare Regression wurde mit AIC-basierter (Akaike's Information Criterion) step-wise step-down Prozedur auf die Daten angepasst, um zum finalen minimalen adäquaten Modell zu gelangen. Während der Modelldiagnose wurden zwei Datenpunkte als Ausreißer ermittelt und aus dem Datensatz entfernt. Weitere modelldiagnostischen Grafiken und zusätzliche statistische Modelldiagnosen ergaben nach dem Entfernen der Ausreißer keine weiteren Auffälligkeiten.

Das finale minimale adäquate Modell basiert auf 98 Datenpunkten und korreliert hoch signifikant mit dem Datensatz (Multipler $R^{2}$: .857, Angepasster $R^{2}$: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p$<.001***$). Das finale minimale adäquate Modell enthält sowohl \textquote{attraction} und \textquote{status} als signifikante Haupteffekte. Der Status von Geschenk\-empfängern korreliert hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.14, $t$-Wert: 10.87, p$<.001***$). Dies zeigt, dass wenn eine Person single ist, ihr Geschenk \euro{55,85} mehr wert ist, verglichen mit dem Fall, dass sie in einer Beziehung ist (in diesem Fall ist das Geschenk \euro{99.15}, wenn der Schenker nicht an der Beschenkten interessiert ist. Der Faktor \textquote{attraction} korreliert ebenfalls hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.09, $t$-Wert: -9.37, p$<.001***$). Falls der Schenkende nicht an der Beschenkten interessiert ist, dann gibt er \euro{-47.66} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er sie attraktiv findet (vorausgesetzt die Beschenkte ist in einer Beziehung). Schließlich weist das finale minimale adäquate Modell eine hoch signifikante Interaktion zwischen \textquote{status} und \textquote{attraction} nach (SE: 7.27, $t$-Wert: -8.18, p$<$.001***): Wenn die Beschenkte ein Single ist, aber der Schenker nicht an ihr interessiert ist, dann gibt der Schenker \euro{59,46} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er an der Beschenkten interessiert ist (vgl. Figure \ref{fig:mlr1}).

\pagebreak
\subsection*{Aufgaben}
\begin{enumerate}
\item Laden sich sich den Datensatz \verb!exdatamlr! herunter von \\\verb!http://martinschweinberger.de/docs/data/exdatamlr.txt! und wenden Sie das Gelernte an, indem Sie eine multiple lineare Regression durchführen, um herauszufinden, ob sich Bewegung (move) und Essgewohnheiten (food) auf das Gewicht auswirkt (weight).
\end{enumerate}

\newpage
\subsection{Ausblick: Mixed-Effects Modelle}\label{mem}
Ohne es genauer zu spezifizieren haben wir bisher nur mit Fixed-Effects gearbeitet, d.h. alle Datenpunkte werden so betrachtet, als ob sie auf der gleichen Hierarchieebene liegen. Häufig ist es aber so, dass Datenpunkte keine flache, sondern eine hierarchische Struktur haben, da beispielsweise mehrere Datenpunkte von demselben Sprecher stammen. Um der hierarchischen Struktur Rechnung zu tragen, muss man diese auch modellieren, was mit Hilfe von \textit{Random Effekte} geschehen kann.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mem02.png}\\[.25cm]
\caption{Scatterplots mit einer Regressionsgeraden (links), random intercepts (mitte links), random slopes (mitte rechts) und random intercepts und random slopes (rechts)}
\label{fig:mem02}
\end{figure}

\textit{Random Effekte} haben zwei Ausprägungen: \textit{Random Slopes} (rechtes Panel Grafik \ref{fig:mem02}) und \textit{Random Intercepts} (mittleres Panel Grafik \ref{fig:mem02}). Wir werden uns im Folgenden auf \textit{Random Interecpts} konzentrieren, da dies die weitaus gebräuchlichere Variante ist. Um zu beschreiben, worum es sich bei \textit{Random Intercepts} handelt, fokussieren wir uns auf Grafik \ref{fig:mem01}.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/mem01.png}\\[.25cm]
\caption{Scatterplots mit einer Regressionsgeraden (mitte) und Random Intencepts (rechts)}
\label{fig:mem01}
\end{figure}

Im mittleren Panel von Grafik \ref{fig:mem01} wird genau eine Regressionsgrade genutzt, um Werte vorherzusagen. Wenn wir \textit{Random Slopes} für die drei Gruppen einführen, so entsteht für jede Ausprägung des \textit{Random Effekte}, d.h. für jede Gruppe, eine eigene Regressionsgerade.

Nachdem Random Slopes eingeführt sind, werden, wie bei der multiplen Regression, Prädiktoren (Ffixed Effekte) hinzugefügt, d.h. Mixed-Effects Modelle werden Mixed-Effects Modelle genannt, weil Sie sowohl Random Effekte (meistens Random Intercepts) und einfache Prädiktoren (Fixed Effekte) beinhalten.

Was die Vorgehensweise betrifft, so lässt sich sagen, dass zuerst die Random Effektstruktur eingebaut und evaluiert wird und erst im Anschluß die Fixed Effekte in das Model aufgenommen werden \citep[vgl.][]{field2012discovering}. Man testet, ob das Einfügen von Random Effekten berechtigt ist, indem man ein Model, das nur den Intercept als Prädiktoren hat gegen ein Model, welches nur die Random Intercepts als Prädiktoren hat. Ist die Varianz bei dem Random Effects Modell geringer, so war das Einfügen der Random Intercepts berechtigt.

%\begin{lstlisting}
%# vorbereiten der analyse
%# workspace leeren
%rm(list=ls(all=T))
%# pakcete installieren, die bei mixed-effects modellen hilfreich sind
%# (# entfernen um den code zu aktivieren)
%#install.packages("rms")
%#install.packages("glmulti")
%#install.packages("lmtest")
%#install.packages("MASS")
%#install.packages("QuantPsyc")
%#install.packages("car")
%#install.packages("lme4")
%#install.packages("nlme")
%# packete aktivieren
%#library(rms)
%#library(glmulti)
%#library(lmtest)
%#library(MASS)
%library(RLRsim)
%library(car)
%library(QuantPsyc)
%library(boot)
%library(ggplot2)
%library(nlme)
%#detach(package:nlme)
%library(lme4)
%library(ez)
%library(ggplot2)
%source("http://martinschweinberger.de/docs/scripts/multiplot_ggplot2.R")

%# setzen der optionen
%options("scipen" = 100, "digits" = 4)
%options(stringsAsFactors = F)
%# grafikpfad festlegen
%imageDirectory<-"C:\\01-University\\03-Lehre\\00-Workshops\\StatzforLinguistiswithR\\images"
%\end{lstlisting}
%
%Nachdem die Sitzung nun vorbereitet ist, kann mit dem Einlesen der Daten begonnen werden. Es ist allerdings unbedingt zu bedenken, dass, um de folgenden Code nutzen zu können, eine aktive Internetverbindung benötigt wird und, dass die
%Pfade auf den eigenen Rechner angepasst werden müssen!

%\begin{lstlisting}
%# daten einlesen
%mydata <- read.delim("http://martinschweinberger.de/docs/data/lmemdata.txt", header = TRUE)
%# convertiere date in eine numerische variable
%mydata$date <- as.numeric(mydata$date)
%# inspiziere den neuen datensatz
%head(mydata); str(mydata); summary(mydata)
%
%# visualisieren der variablen (2 panele pro reihe)
%# 3 panele in 1 fenster
%def.par <- par(no.readonly = TRUE)
%nf <- layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = T))
%plot(mydata$pptw ~ mydata$date, ylab = "Frequency", xlab = "year of publication")
%abline(lm(mydata$pptw ~ mydata$date), lty = 3, lwd = 2, col = "red")
%lines(lowess(mydata$date, mydata$pptw), lty = 1, lwd = 2, col = "blue")
%# vergroessern der raender, sodass die label passen
%par(mar = c(11, 4, 1, 2) + 0.1)
%# reorder genre by median
%genrebymedian <- with(mydata, reorder(genre, -pptw, median))
%# plots generieren
%plot(mydata$pptw ~ genrebymedian,
% col = "lightgrey",
% ylab = "Frequency",
% xlab = "",
% las = 2,
% cex = .5)
%# re-set margins
%par(mar = c(5, 4, 1, 2) + 0.1)
%x = mydata$pptw
%h = hist(mydata$pptw,
% ylim =c(0, 150),
% xlim = c(50, 200),
% xlab = "prepositions per text",
% col = "lightgrey",
% main = "")
%xfit <- seq(min(mydata$pptw), max(mydata$pptw), length = 40)
%yfit <- dnorm(xfit, mean = mean(mydata$pptw),sd = sd(mydata$pptw))
%yfit <- yfit*diff(h$mids[1:2])*length(x)
%lines(xfit, yfit, lty = 2, lwd=2)
%# restore original graphic's parameters
%par(def.par)
%
%# plot erstellen
%p1 <- ggplot(mydata, aes(date, pptw)) +
% geom_point() +
% labs(x = "Year") +
% labs(y = "Prepositions per 1,000 words") +
% geom_smooth()
%imageFile <- paste(imageDirectory,"Prepositions over time (lowess smother).png",sep="/")
%ggsave(file = imageFile)
%# plot erstellen
%p2 <- ggplot(mydata, aes(date, pptw)) +
% geom_point() +
% labs(x = "Year") +
% labs(y = "Prepositions per 1,000 words") +
% geom_smooth(method = "lm") # with linear model smoothing!
%multiplot(p1, p2, cols = 2)
%imageFile <- paste(imageDirectory,"Prepositions over time (regression line).png",sep="/")
%ggsave(file = imageFile)
%# genre einfuegen(lowess)
%p3 <- ggplot(mydata, aes(date, pptw)) +
% geom_point() +
% facet_wrap(~ genre, nrow = 4) +
% geom_smooth() +
% theme_bw() +
% labs(x = "Year") +
% labs(y = "Prepositions per 1,000 words") +
% coord_cartesian(ylim = c(0, 220))
%imageFile <- paste(imageDirectory,"Prepositions over time across genres (lowess smoothers).png",sep="/")
%ggsave(file = imageFile)
%p3
%
%# genre einfuegen(lm)
%p4 <- ggplot(mydata, aes(date, pptw)) +
% geom_point() +
% facet_wrap(~ genre, nrow = 4) +
% geom_smooth(method = "lm") +
% theme_bw() +
% labs(x = "Year") +
% labs(y = "Prepositions per 1,000 words") +
% coord_cartesian(ylim = c(0, 220))
%imageFile <- paste(imageDirectory,"Prepositions over time across genres (regression lines).png",sep="/")
%ggsave(file = imageFile)
%p4
%
%\end{lstlisting}
%Wie bereits bei edr einfachen linearen Regression werden wir die numerischen Variablen skalieren. Skalieren bedeutet, dass der Mittelwert der numerischen Variable von jedem Wert dieser Variable abgezogen wird.
%
%\begin{lstlisting}
%mydata$date <- scale(mydata$date)
%head(mydata)
%
%str(mydata)
%
%################################################################################
%# generate a glm baseline model
%m0.glm <- glm(pptw ~ 1, family = gaussian, data = mydata)
%# generate a lm base-line model
%m0.lm <- lm(pptw ~ 1, data = mydata)
%# set up first lme model including only the random effect specifying the random intercepts
%m0.lme = lme(pptw ~ 1, random = ~1|genre, data = mydata, method = "ML")
%# set up first lmer model including only the random effect specifying the random intercepts
%m0.lmer = lmer(pptw ~ 1 + (1|genre), data = mydata, REML = F)
%# compare the base-line mdoel without intercept to the model with intercept
%# WARNING: set REML = T because REML provides better estimates for the random
%# effects part of the model (cf. Field, Miles & Field 2012:879)
%x2 = -2*logLik(m0.lm, REML = T)+2*logLik(m0.lmer, REML = T)
%x2 <- x2 <- x2[[1]]
%test.ran.eff <- list(x2, pchisq(x2, df=2, lower.tail=F))
%# set up m0 model but using the lmer function from the lme4 package
%# WARNING: REML must be FALSE OR method = "ML" (depending on the function)
%# when using anova to compare models!!! (cf. Field, Miles & Field 2012:)
%# "ML produces more accurate estimates of fixed regression parameters, whereas
%# REML produces more accurate estimates of random variances (Twisk 2006). [...]
%# Also, if you want to compare models you must use ML." (Field, Miles & Field 2012:879).
%m0.lmer1 <- lmer(pptw ~ (1|genre) + 1, data = mydata, REML = T)
%m0.lmer2 <- lmer(pptw ~ (1|genre/date) + 1, data = mydata, REML = T)
%anova(m0.lmer1, m0.lmer2)
%
%# the model with the random effect structure (1|genre/date) performs
%# significantly better (also it has a much lower AIC and deviance)
%# therefore, m0.lmer2 is our new m0 model
%m0.lmer <- m0.lmer2
%# test if including the random effect is permitted by applying a restricted likelihood ratio test
%# WARNING: this test can only take simple random effect (1|genre) but not
%# (1|genre/date)
%exactRLRT(m0.lmer1)
%
%# there is another way to comper model with and without random effects: see below!
%
%# create a second model with date as a fixed effect
%# m1.lme <- lme(m0.lme, .~. + date) # alternative way to update the model
%m1.lme = lme(pptw ~ date, random = ~1|genre/date, data = mydata, method = "ML")
%# set up m1 model but using the lmer function from the lme4 package
%m1.lmer = lmer(pptw ~ (1|genre/date) + date, data = mydata, REML = F)
%
%# compare the models to see if including date has improved the model
%# the difference between the modesl is the effect (size) of date!
%anova(m0.lme, m1.lme)
%
%# m1.lme is the better model (sig. p-value & lower AIC)
%# date correlates significantly with pptw (X2(1) = 8.81, p = .003);
%# X2 = L.Ratio;
%# df = subtract df smaller from df larger model
%# inspect results
%summary(m1.lme)
%
%# alternative display of the results
%anova(m1.lme)
%
%# test if date is significant
%anova(m0.lmer, m1.lmer)
%
%# extract estimates and sd for fixed and random effects
%intervals(m1.lme)
%
%# include random slopes
%# ERROR: m2.lme <- lme(pptw ~ date, random = ~1+genre|genre, data = mydata, method = "ML")
%# ERROR: m2.lmer <- lmer(pptw ~ (1+genre|genre) + date, data = mydata)
%
%# diagnostic plot: examining residuals (Pinheiro & Bates 2000:175)
%plot(m1.lme, genre ~ resid(.), abline = 0 )
%
%# the plot shows that there are some outliers (points outside the boxes) and
%# that the variability within letters is greater than in other genres
%# we therefore examine the genres in isolation
%# standardized residuals versus fitted values
%plot(m1.lme, resid(., type = "p") ~ fitted(.) | genre, id = 0.05, adj = -0.3)
%
%# the plot showing the standardized residuals versus fitted values
%# confirms that there are outliers in the letters
%# because there are obviously differences in the variance, we create a new model
%# which uses weights to compensate variance heterogeneiety of variance
%# (cf. Pinheiro & Bates 2000:177)
%m2.lme <- update(m1.lme, weights = varIdent(form = ~ 1 | genre))
%# test if m2.lme is more appropriate for the data than m1.lme
%anova(m1.lme, m2.lme)
%
%# the heteroscedastitic model (i.e. m2.lme which uses weights to account for
%# unequal variance is performing significantly better than the homoscedastistic
%# model m1.lme
%
%# inspect results
%summary(m2.lme)
%
%# alternative display of the results
%anova(m2.lme)
%
%# test if date is significant
%anova(m0.lme, m2.lme)
%
%# extract estimates and sd for fixed and random effects
%intervals(m2.lme)
%
%# extract effect sizes (in the example: the effect size of date)
%# calculate effect size (this effect size measure works for all fixed effects)
%# to calculate the effect size, take the square root of the t-value squared divided
%# by the t-value squared plus the degrees of freedom: r = sqrt(t^2/(t^2+df))
%# WARNING: only apply this function to main effecst not involved in interactions
%# or higher level interactions but not to the main effects involved in
%# interactions as they are meaningless (cf. Field, Miles & Field 2012:641)
%ef.lme <- function(x) {
% df <- summary(x)[[20]][6]
% t <- summary(x)[[20]][8]
% #df <- summary(x)$tTable[, 3]
% #t <- summary(x)$tTable[, 4]
% r <- sqrt((t^2)/((t^2)+df))
% return(paste("Pearson's r = ", round(r, 3)))
% }
%ef.lme(m2.lme)
%
%
%# set up m1 model but using the lmer function from the lme4 package
%#m2.lmer = lmer(pptw ~ (1|genre) + date, data = mydata, REML = F)
%
%# How to calculate the variance explained when only a simple random effect is involved:
%# m2.lmer = lmer(pptw ~ (1|genre) + date, data = mydata, REML = F)
%# summary(m2.lmer)
%# variance of random effect (148) devided by variance of random effect plus
%# residual variance (148+228) times 100 gives the variance explained by the random effect:
%#(148/(148+228))*100 # percentage of variance explained by random effect
%
%# craete lmer with complex random effect structure
%m2.lmer = lmer(pptw ~ (1|genre/date) + date, data = mydata, REML = F)
%# an alternative for testing if including the random intercepts is permitted
%# WARNING: this method is not as good as applying a restricted likelihood
%# ratio test(!) because the p-value is only an approximation
%# IMPORTANT: the second model is a glm object
%2*pchisq(2*as.numeric(logLik(m2.lmer)-logLik(m0.glm)), 2, lower.tail = FALSE)
%
%####################################################################
%### --- model diagnostics
%####################################################################
%# diagnostic plot (Pinheiro & Bates 2000:11, 182)
%# what we wish to see: a cloud of dots in the middle of the window without structure
%# what we do not want to see: a funnel-shaped cloud because this indicates an increase
%# of the errors/residuals with an increase of the predictor(s) (because this would indicate
%# heteroscedasticity)
%# in short: observed valuesagainst fitted values (cf. Pinheiro & Bates 2000:182)
%plot(m2.lme)
%
%# diagnostic plot (Pinheiro & Bates 2000:21)
%plot(m2.lme, form = resid(., type = "p") ~ fitted(.) | genre, abline = 0)
%
%# diagnostic plot: residuals of fitted values against observed values (cf. Pinheiro & Bates 2000:182)
%qqnorm(m2.lme)
%
%# normal plot of the estimated date %in% genre random effects
%qqnorm(m2.lme, ~ranef(., level = 2), id = 0.05, cex = 0.7, xlim = c(-40, 40))
%
%# diagnostic plot: normal plots of the residuals by genre (cf. Pinheiro & Bates 2000:22, 179)
%qqnorm(m2.lme, ~resid(.) | genre )
%
%# inspect the observed responses versus the within-group fitted values
%# (cf. Pinheiro & Bates 2000:178)
%plot(m2.lme, pptw ~ fitted(.), id = 0.05, adj = -0.3, xlim = c(80, 220), cex = .8)
%
%summary(m2.lmer)
%
%\end{lstlisting}

# References

