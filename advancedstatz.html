<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-01-23" />

<title>Advanced Inferential Statistics: Regression Modelling and Random Forests</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="researchdesigns.html">Research Designs</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="loading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization Techniques</a>
    </li>
    <li>
      <a href="advancedgraphs.html">Advanced Visualization Techniques</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptives.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Interential Statistics</a>
    </li>
    <li>
      <a href="advancedstatz.html">Advanced Interential Statistics</a>
    </li>
    <li>
      <a href="groupingstatz.html">Clustering</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis and Corpus Linguistics</li>
    <li>
      <a href="page-c.html">Network Analysis</a>
    </li>
    <li>
      <a href="page-c.html">Topic Modeling</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
    <li>
      <a href="corplingantconcexcel.html">Corpus Linguistics with AntConc, TextPad and Excel</a>
    </li>
    <li>
      <a href="available.html">Available Software</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Advanced Inferential Statistics: Regression Modelling and Random Forests</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-01-23</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">1</span> Multiple Linear Regression</h1>
<p>In contrast to simple linear regression, which estiamtes the effect of a single predictor, multiple linear regression estiamtes the effect of various predictor (cf.Â equation ()). A multiple linear regression can thus test the effects of various predictors simultaneously.</p>
<span class="math display">\[\begin{equation}

f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon

\end{equation}\]</span>
<p>There exists a wealth of literture focusing on multiple linear regressions and the concepts it is based on. For insatnce, there are <span class="citation">(Achen 1982)</span>, <span class="citation">(Bortz 2006)</span>, <span class="citation">(Crawley 2005)</span>, <span class="citation">(Faraway 2002)</span>, <span class="citation">(A. Field, Miles, and Field 2012)</span> (my personal favorite), and <span class="citation">(Wilcox 2009)</span> to name just a few. Introductions to regression modeling in <code>R</code> are <span class="citation">(Baayen 2008)</span>, <span class="citation">(Crawley 2012)</span>, or <span class="citation">(Gries 2009)</span>.</p>
<p>Eine weitere Anmerkung vorweg: Die modelldiagnostischen Verfahren werden teilweise identisch sein mit denen, die im Kapitel zur einfachen linearen Regression besprochen wurden und sie werden daher nur dann ausgiebiger erlÃ¤utert, insofern dies nicht bereits geschehen ist.</p>
<p>Eine letzte Anmerkung betrifft die StichprobengrÃ¶Ãe, die notwendig ist um eine Regression zu rechnen. Obwohl die Angabe, dass 25 Datenpunkte pro Gruppe ausreichen weit verbreitet ist, ist diese Angabe nicht korrekt, da sich die benÃ¶tigte StichprobengrÃ¶Ãe nach der GrÃ¶Ãe des Effekts, der bestimmt werden soll, und nach der Anzahl der untersuchten Variablen richtet. Gehen viele unabhÃ¤ngige Variablen in die Regression ein und die EffektstÃ¤rke der zu testenden Variable(n) ist sehr klein, dann kann man von einer MindestgrÃ¶Ãe der Stichprobe von 600 Datenpunkten ausgehen. <span class="citation">(A. Field, Miles, and Field 2012)</span> (273-275) geben zur MindestgrÃ¶Ãe der benÃ¶tigten Stichprobe Daumenregeln an die Hand (k = Anzahl der PrÃ¤dikatoren; kategorische PrÃ¤dikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):</p>
<ul>
<li>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persÃ¶nlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</li>
<li>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</li>
<li>Wenn man an beidem interessiert ist, sollte man den je hÃ¶heren Wert nehmen. \end{itemize}</li>
</ul>
<p>%Grafik  einfÃ¼gen. XXX</p>
<p>Sie werden im <code>R</code>-code sehen, dass hierzu eine Funktion existiert, die testet, ob die Stichprobe fÃ¼r die Untersuchung angemessen war.</p>
<p>Hinsichtlich der Modellanpassung wird nur auf step-wise step-down Prozeduren, die auf dem AIC (Akaike information criterion) beruhen, eingegangen werden. Es gibt eine Vielzahl von mÃ¶glichen Prozeduren, die genutzt werden kÃ¶nnen forced entry, stepwise, hierarchical) und innerhalb dieser Prozeduren gibt es Unterklassen, sodass eine Diskussion den Rahmen dieser Sektion sprengen wÃ¼rde.</p>
<div id="example-gifts-and-availability" class="section level2">
<h2><span class="header-section-number">1.1</span> Example: Gifts and Availability</h2>
<p>In diesem Beispiel werden wir untersuchen, ob der Geldbetrag, den MÃ¤nner fÃ¼r Geschenke ausgeben, mit der AttraktivitÃ¤t und dem Beziehungsstatus der Frauen, fÃ¼r die Geschenke gekauft wurden, korreliert. Das Beispiel ist  entnommen. Wir werden nun das Beispiel in  implementieren und leeren dazu, wie Ã¼blich, den gegenwÃ¤rtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusÃ¤tzliche Funktionen.</p>
<pre class="r"><code># entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages(&quot;rms&quot;)
#install.packages(&quot;glmulti&quot;)
#install.packages(&quot;lmtest&quot;)
#install.packages(&quot;MASS&quot;)
#install.packages(&quot;QuantPsyc&quot;)
#install.packages(&quot;car&quot;)
#install.packages(&quot;ggplot2&quot;)
# pakete initialisieren
#library(rms)
#library(glmulti)
#library(lmtest)
#library(MASS)
library(car)</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## 
## Attaching package: &#39;car&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:carData&#39;:
## 
##     Adler, Blackmore, Guyer, UN, Vocab</code></pre>
<pre class="r"><code>library(QuantPsyc)</code></pre>
<pre><code>## Loading required package: boot</code></pre>
<pre><code>## 
## Attaching package: &#39;boot&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     logit</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## 
## Attaching package: &#39;QuantPsyc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     norm</code></pre>
<pre class="r"><code>library(boot)
library(ggplot2)
source(&quot;rscripts/multiplot_ggplot2.r&quot;)
source(&quot;rscripts/mlinr.summary.r&quot;)
source(&quot;rscripts/SampleSizeMLR.r&quot;)
source(&quot;rscripts/ExpR.r&quot;)
# optionen festlegen
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)</code></pre>
<p>Nachdem wir die notwendigen Pakete usw. in <code>R</code> eingelesen haben, kÃ¶nnen wir nun die Daten laden und uns einen ersten Eindruck Ã¼ber deren Struktur und Eigenschaften verschaffen.</p>
<pre class="r"><code># daten laden
mlrdata &lt;- read.delim(&quot;data/mlrdata.txt&quot;, header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code># struktur der daten betrachten
str(mlrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code># zusammenfassung der daten betrachten
summary(mlrdata)</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p>Wir haben nun den Datensatz eingelesen und seine Struktur betrachtet. Im nÃ¤chsten Schritt werden wir die Daten visualisieren, um einen Eindruck der Daten und der Verteilungen der Variablen zu gewinnen. Wir werden vier Grafiken erstellen und diese dann in einem Fenster darstellen.</p>
<pre class="r"><code>ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = T, aes(fill = factor(status))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Status&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(attraction, money)) +
geom_boxplot(notch = T, aes(fill = factor(attraction))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Attraction&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(x = money)) +
geom_histogram(aes(y=..density..),
binwidth = 10,
colour = &quot;black&quot;, fill = &quot;white&quot;) +
geom_density(alpha=.2, fill = &quot;#FF6666&quot;) # Overlay with transparent density plot</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = F, aes(fill = factor(status))) +
scale_fill_brewer(palette=&quot;Paired&quot;) +
facet_wrap(~ attraction, nrow = 1) +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>

<p>Die Grafik im oberen linken Panel scheint anzudeuten, dass MÃ¤nner mehr Geld fÃ¼r Frauen ausgeben, die Single sind, allerdings relativiert sich dieser Eindruck, denn die Grafik im unteren rechten Panel deutet darauf hin, dass MÃ¤nner nur dann mehr Geld fÃ¼r ein Geschenk ausgeben, wenn die Frau Single ist UND sie an ihr interessiert sind. Den der Beziehungsstatus hat keinen Einfluss auf das Geld fÃ¼r Geschenke fÃ¼r Frauen, an denen MÃ¤nner nicht interessiert sind. Die Grafik im oberen rechten Panel weist darauf hin, dass MÃ¤nner substantiell mehr Geld fÃ¼r Geschenke fÃ¼r Frauen ausgeben, an denen sie interessiert sind.</p>
<p>Gehen wir nun dazu Ã¼ber mit der Regression zu beginnen. Im ersten Schritt erzeugen wir vier Baselinemodelle: Zwei minimale Modelle, die nur den Gesamtmittelwert (Intercept) als PrÃ¤diktor beinhalten und zwei gesÃ¤ttigte Modelle (saturated models), die alle mÃ¶glichen PrÃ¤dikatoren und Interaktionen beinhalten.</p>
<pre class="r"><code># generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)

summary(m0.mlr)  # inspect model</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -87.45 -38.54  -6.65  33.20 112.61 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 48.6 on 99 degrees of freedom</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m0.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -87.45  -38.54   -6.65   33.20  112.61  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2359)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance: 233562  on 99  degrees of freedom
## AIC: 1063
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -45.08  -14.26    0.46   11.93   44.14  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 360)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance:  34558  on 96  degrees of freedom
## AIC: 878.3
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Nachdem wir die Baselinemodelle generiert haben, werden wir nun mit dem Modellanpassung (model fitting)beginnen. Modellanpassung bezeichnet den Prozess mit dem man zu demjenigen Modell gelangt, dass das Maximum an Varianz mit einem Minimum an Variablen erklÃ¤rt. Das zugrunde liegende Prinzip ist daher das <em>Parsimonie-</em> oder <em>Sparsamkeitsprinzip</em>, welches im Englischen hÃ¤ufig als Ockhamâs Rasiermesser bezeichnet wird.</p>
<p>Wir werden einen automatischen step-wise step-down Prozess bei der Modellanpassung nutzen, der dasjenige Modell mit dem niedrigsten AIC (Akaike information criterion) Wert sucht. Das AIC berechnet sich nach Formel () und ist ein MaÃ der Sparsamkeit, dass einen Wert dafÃ¼r bildet, wie viel Varianz mit wie vielen Variablen erklÃ¤rt werden kann <span class="citation">(cf. A. Field, Miles, and Field 2012, 318)</span>. Um so niedriger der AIC-Wert, umso besser die Balance zwischen erklÃ¤rter Varianz und der Anzahl der dafÃ¼r nÃ¶tigen Variablen. Die AIC-Werte kÃ¶nnen nun zwischen Modellen verglichen werden, die auf die selben Datenpunkte angepasst sind (<span class="math inline">\(LL\)</span> steht fÃ¼r LogLikelihood und <span class="math inline">\(k\)</span> fÃ¼r die Anzahl der unabhÃ¤ngigen Variablen im Modell).</p>
<span class="math display">\[\begin{equation}

-2LL + 2k
\label{eq:aic}

\end{equation}\]</span>
<p>We will not begin fitting the model.</p>
<pre class="r"><code># automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<pre class="r"><code># minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassugn der modellergebnisse betrachten
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<p>Basierend auf dem Modell mit dem kleinsten AIC-Wert haben wir das minimale adÃ¤quate Modell (minimal adequate model) generiert und anschlieÃend haben wir die Zusammenfassung der Ergebnisse des Modells auswerfen lassen. Im Folgenden werden wir den Output, d.h. die Zusammenfassung der Ergebnisse des minimalen adÃ¤quaten Modells beleuchten und die verschiedenen Konzepte erlÃ¤utern.</p>
<p>Das erste Objekt, was die Zusammenfassung berichtet ist der <em>Call</em>, d.h. die Formel des des minimalen adÃ¤quaten Modells. Daran anschlieÃend wird die Verteilung der Residuen, also der Unterschiede zwischen den vorhergesagten und beobachteten Werten, berichtet. Dann folgt das wichtigste Element der Modellzusammenfassung: Die Tabelle mit den Koeffizienten der PrÃ¤dikatoren des Modells (dies sind die Koeffizienten der Fixed Effects). Wir werden uns mit dieser Tabelle spÃ¤ter genauer beschÃ¤ftigen. Nach der Tabelle folgen die Modellstatistiken, die Aufschluss darÃ¼ber geben, wie gut das Modell die Daten modelliert, d.h. wie gut das Modell den beobachteten Daten entspricht. Der Unterschied zwischen diesen Werten und der Tabelle mit den Koeffizienten besteht darin, dass die Modellstatistiken Ã¼ber die GesamtgÃ¼te des Modells berichten, wÃ¤hrend die Tabelle mit den Koeffizienten nur etwas Ã¼ber die individuellen Faktoren aussagt.</p>
<p>Der multiple R<sup>2</sup>-Wert gibt an, wie viel Varianz das Modell erklÃ¤rt. Ein Wert von 0 wÃ¼rde bedeuten, dass das Modell gar keine Varianz erklÃ¤rt, wÃ¤hrend ein Wert von 1 bedeuten wÃ¼rde, dass das Modell 100 percent der Varianz erklÃ¤rt und somit die Vorhersage des Modells genau den beobachteten Daten entspricht. Dies bedeutet, dass, wenn man den R<span class="math inline">\(^{2}\)</span>-Wert mit 100 multipliziert, man den Prozentwert der Varianz erhÃ¤lt, den das Modell erklÃ¤rt. In unserem Fall sagt der multiple R<span class="math inline">\(^{2}\)</span>-Wert von 0.852 also aus, dass unser minimales adÃ¤quates Modell 85.2 percent der Varianz erklÃ¤rt. Modelle, die einen multiplen R<span class="math inline">\(^{2}\)</span>-Wert von <span class="math inline">\(ge\)</span>.05 haben, gelten als substantiell signifikant (substantially significant) <span class="citation">(Szmrecsanyi 2006)</span> 55). Manche gehen soweit zu sagen, dass Modelle mindestens einen <span class="math inline">\(R^{2}\)</span>-Wert von <span class="math inline">\(\ge\)</span>.05 haben mÃ¼ssen, aber dies ist problematisch, da es durchaus vorkommen kann, dass man an sehr schwachen (aber signifikanten) Effekten interessiert ist, die aber zu einem sehr kleinen <span class="math inline">\(R^{2}\)</span>-Wert fÃ¼hren. Wichtiger ist, dass das Modell insgesamt signifikant ist, da dies aussagt, dass das Modell zu signifikant besseren Vorhersagen kommt, als es durch Zufall der Fall wÃ¤re.</p>
<p>Der angepasste <span class="math inline">\(R^{2}\)</span>-Wert (adjusted <span class="math inline">\(R^{2}\)</span>) berÃ¼cksichtigt die Anzahl der PrÃ¤dikatoren. DarÃ¼ber hinaus gibt der angepasste <span class="math inline">\(R^{2}\)</span>-Wert darÃ¼ber Aufschluss, wie gut sich das Modell eignet, um Aussagen Ã¼ber die Population (und nicht nur Ã¼ber die Stichprobe) zu tÃ¤tigen. Wenn der Unterschied zwischen dem multiplen <span class="math inline">\(R^{2}\)</span>-Wert und dem angepassten <span class="math inline">\(R^{2}\)</span>-Wert sehr gering ist, dann bedeutet dies, dass sich das Modell dazu eignet Aussagen Ã¼ber die Population als Ganzes zu machen. Wenn der Unterschied allerdings relativ groÃ ist, dann bedeutet dies, dass das Modell instabil ist und die Datenstruktur, auf die das Modell angepasst wurde, eine suboptimale Verteilung aufweist, z.B. wegen AusreiÃern. In anderen Worten bedeutet der Unterschied, dass wenn die Regression auf die Population anstatt der Stichprobe angewandt worden wÃ¤re, dann wÃ¼rde sie .5 perecnt weniger Varianz (85.2-84.7) erklÃ¤ren.</p>
<p>Kommen wir nun zu der Tabelle mit den Koeffizienten zurÃ¼ck. Alle Haupteffekte und eine Interaktion zwischen â<em>status</em>â und â<em>attraction</em>â sind signifikant. Eine Interaktion besteht dann, wenn die Korrelation zwischen einer unabhÃ¤ngigen und der abhÃ¤ngigen variable von einer anderen unabhÃ¤ngigen variable beeinflusst wird. In unserem Szenario geben MÃ¤nner nur dann mehr Geld fÃ¼r ein Geschenk fÃ¼r eine Frau aus, wenn sie an ihr (a) interessiert sind und (b) sie Single ist. Die Korrelation zwischen â<em>money</em>â und â<em>attraction</em>â wird also von einer anderen Variable â<em>status</em>â beeinflusst. Wir haben es also mit einer Interaktion zwischen â<em>attraction</em>â und â<em>status</em>â zu tun.</p>
<p>Hinsichtlich der Interpretation dieser Ergebnisse ist festzuhalten, dass man Haupteffekte, die an Interaktionen beteiligt sind, nicht interpretieren sollte, da nicht klar ist, wie sich der Anteil an erklÃ¤rter Varianz zwischen dem Haupteffekten und den Interaktionen aufteilt. ZusÃ¤tzlich ist festzuhalten, dass, insofern nur Haupteffekte signifikant sind, die Koeffizienten die Korrelation zwischen der abhÃ¤ngigen und der unabhÃ¤ngigen Variable abbilden, wenn die anderen Variablen einen Wert von 0 oder das jeweilige Baseline-Level annehmen.</p>
<p>Bevor wir die Tabelle mit den Koeffizienten weiter interpretieren, werden wir noch die Konfidenzintervalle berechnen und das Baselinemodell mit dem minimalen adÃ¤quaten Modell vergleichen, um zu schauen, ob das minimale adÃ¤quate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell.</p>
<pre class="r"><code>confint(m2.mlr)       # extract confidence intervals of the coeficients</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre class="r"><code>anova(m0.mlr, m2.mlr) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Vergleich der Modelle zeigt eindeutig, dass das minimale adÃ¤quate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell. Wir werden nun mit der Modelldiagnose fortfahren, indem wir schauen, ob Datenpunkte entfernt werden sollten, da sie die Passgenauigkeit des Modells (modelfit) Ã¼berproportional verschlechtern.</p>
<pre class="r"><code># suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;)</code></pre>
<pre><code>## [1] 52 83</code></pre>
<pre class="r"><code># Cooks D plot
# D-werte &gt; 4/(n-k-1) sind problematisch
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>

<p>The graphs indicate that data points 52, 64, and 83 may be problematic. We will tehrefore statistically evaluate whether these data points need to be removed. In order to find out which data points require removal, we extract the influence measure statistics and add them to out data set.</p>
<pre class="r"><code>infl &lt;- influence.measures(m2.mlr)                   # extarct influence statistics
mydata &lt;- data.frame(mlrdata, infl[[1]], infl[[2]])  # add infl. statistics to data
head(mydata)</code></pre>
<pre><code>##         status    attraction money                  dfb.1_
## 1 Relationship NotInterested 86.33  0.00000000000000236805
## 2 Relationship NotInterested 45.58  0.00000000000000022805
## 3 Relationship NotInterested 68.43 -0.00000000000000091891
## 4 Relationship NotInterested 52.93 -0.00000000000000016896
## 5 Relationship NotInterested 61.86  0.00000000000000011789
## 6 Relationship NotInterested 48.47 -0.00000000000000004889
##                   dfb.sttS dfb.atNI  dfb.sS.N    dffit  cov.r     cook.d
## 1 -0.000000000000001067658  0.27414 -0.193850  0.38770 0.9358 0.03658407
## 2 -0.000000000000000396634 -0.04569  0.032306 -0.06461 1.0817 0.00105355
## 3  0.000000000000001134168  0.13140 -0.092911  0.18582 1.0491 0.00864788
## 4  0.000000000000000269812  0.01111 -0.007854  0.01571 1.0860 0.00006233
## 5 -0.000000000000000001814  0.08021 -0.056718  0.11344 1.0722 0.00324023
## 6  0.000000000000000015629 -0.02334  0.016507 -0.03301 1.0850 0.00027528
##    hat dfb.1_.1 dfb.sttS.1 dfb.atNI.1 dfb.sS.N.1 dffit.1 cov.r.1 cook.d.1
## 1 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 2 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 3 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 4 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 5 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 6 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
##   hat.1
## 1 FALSE
## 2 FALSE
## 3 FALSE
## 4 FALSE
## 5 FALSE
## 6 FALSE</code></pre>
<pre class="r"><code># zu einflussreiche datenpunkte erkennen
remove &lt;- apply(infl$is.inf, 1, function(x) {
ifelse(x == TRUE, return(&quot;remove&quot;), return(&quot;keep&quot;)) } )

# informationen zu den zu einflussreichen datenpunkten
# zum datensatz hinzuaddieren
mlrdata &lt;- data.frame(mlrdata, remove)

# zeilenzahl des alten datensatzes anzeigen
nrow(mydata)</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>mlrdata &lt;- mlrdata[mlrdata$remove == &quot;keep&quot;, ]

# zeilenzahl des neuen datensatzes anzeigen
nrow(mlrdata)</code></pre>
<pre><code>## [1] 98</code></pre>
<p>Die Zeilenzahl weist darauf hin, dass zwei potentielle ProblemfÃ¤lle entfernt wurden, da deren Werte inakzeptabel waren, wÃ¤hrend einer der Punkte im Modell verbleiben durfte. Da wir es nun mit einem verÃ¤nderten Datensatz zu tun haben, mÃ¼ssen wir die bisherigen Schritte wiederholen. Die einzelnen wiederholten Schritte werden nun nicht weiter erlÃ¤utert, insofern die ErlÃ¤uterungen mit den bereits oben ausgefÃ¼hrten weitgehend identisch wÃ¤re.</p>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -76.00 -38.05  -6.39  33.15 105.66 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 46.9 on 97 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -76.00  -38.05   -6.39   33.15  105.66  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2198)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance: 213227  on 97  degrees of freedom
## AIC: 1035
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code># generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -35.76  -13.51   -0.99   10.60   38.77  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 323.5)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance:  30411  on 94  degrees of freedom
## AIC: 850.4
## 
## Number of Fisher Scoring iterations: 2</code></pre>
</div>
<div id="automatic-model-fitting" class="section level2">
<h2><span class="header-section-number">1.2</span> Automatic Model Fitting</h2>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="outlier-detection" class="section level2">
<h2><span class="header-section-number">1.3</span> Outlier Detection</h2>
<p>In a next step, we cerate diagnostic plots in order to check whether there are potentially problematic data points.</p>
<pre><code>## 84 88 
## 82 86</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>

<p>Although the diagnosic plots indicate that additional points may be problematic, but these data points deviate substantially less from the trend than was the case with the data points that have already been removed. To make sure that retaining the data points that are deemed potentially problematic by the diagnostoc plots, is acceptable, we extarct diagnostoic statistics and add them to the data.</p>
<p>We can now use these diagnostic statistics to create more precise diagnostic plots.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>

<p>The new diagnistic plots do not indicate outliers that require removal. With respect to such data points the following parameters should be considered:</p>
<ul>
<li><p>Data points with standardised residuals &gt; 3.29 should be removed <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>If more than 1 percent of data points have standardized residuals exceeding values <span class="math inline">\(\ge\)</span> 2.58, then the errorrate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field 2012, 269)</span>.</p></li>
<li><p>If more than 5 percent of data points have standardized residuals exceeding values <span class="math inline">\(\ge\)</span> 1.96, then the errorrate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>In addition, data points with Cookâs D-values <span class="math inline">\(\ge\)</span> 1 should be removed <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>Also, data points with leverage values <span class="math inline">\(3(k + 1)/n\)</span> (k = Number of predictors, N = Number of cases in model) should be removed <span class="citation">(A. Field, Miles, and Field 2012, 270)</span></p></li>
<li><p>There should not be (any) autocorrelation among predictors. This means that independent variables cannot be correlated with itself (for instance, because data points come from the same subject). If there is autocorrelation among predictots, then a Repeated Measures Design or a (hierarchical) mixed-effects model should be implemented instead.</p></li>
<li><p>Predictors cannot substantiatlly correlate with each other (multicollinearity). If a model contains perdictors that have variance inflation factors (VIF) <span class="math inline">\(\ge\)</span> 10 the model is completely unreliable <span class="citation">(Myers 1990)</span> and predictors causing such VIFs should be removed. Indeed, even VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi 2006, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick 2010)</span> proposes that variables with VIFs exceeding 3 should be removed!</p></li>
<li><p>Data points with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard 1995)</span>.</p></li>
<li><p>The mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and OâConnell 1990)</span>.</p></li>
</ul>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">1.4</span> Model Diagnostics</h2>
<pre><code>## integer(0)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968   0.596
##  Alternative hypothesis: rho != 0</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre><code>## [1] 2.307</code></pre>
<p>Except for the mean VIF value (2.307) which should not exceed 1, all diagnostics are acceptable. We will now test whether the sample size is sufficient for our model. With respect to the minimal sample size and based on <span class="citation">(Green 1991)</span>, <span class="citation">(A. Field, Miles, and Field 2012, 273â74)</span> offer the following rules of thumb (k = number of predictors; categorical predictors with more than two levels shuld be recoded as dummy variables):</p>
<ul>
<li><p>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persÃ¶nlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</p></li>
<li><p>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</p></li>
<li><p>Wenn man an beidem interessiert ist, sollte man den je hÃ¶heren Wert nehmen.</p></li>
</ul>
<p>ZusÃ¤tzlich werden wir prÃ¼fen, wie groÃ der Wert fÃ¼r <code>R</code> basierend auf einer Zufallsstichprobe wÃ¤re, um abschÃ¤tzen zu kÃ¶nnen, wie groÃ die Wahrscheinlichkeit eines <span class="math inline">\(\beta\)</span>-Fehlers bei der vorliegenden StichprobengrÃ¶Ãe ist <span class="citation">(vgl. A. Field, Miles, and Field 2012, 274)</span>. Bei <span class="math inline">\(\beta\)</span>-Fehlern handelt es sich um die Annahme, ein PrÃ¤dikator ist nicht signifikant, obwohl er tatsÃ¤chlich einen signifikanten Einfluss hat (siehe Sektion ). Die PrÃ¼fgrÃ¶Ãe schwankt zwischen 0 und 1. Umso kleiner der Wert ist, umso besser. Wenn der Wert <span class="math inline">\(\ge\)</span> 1 liegt, dann gibt es Grund zur Sorge und es sollte eine grÃ¶Ãere Stichprobe gezogen werden.</p>
</div>
<div id="evaluation-of-sample-size" class="section level2">
<h2><span class="header-section-number">1.5</span> Evaluation of Sample Size</h2>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<p>Die Funktion <code>smplesz</code> teilt mit, dass die StichprobengrÃ¶Ãe nicht optimal ist und 9 Datenpunkte fehlen, um der Anforderung von <span class="citation">(Green 1991)</span> zu genÃ¼gen. Die Wahrscheinlichkeit einen <span class="math inline">\(\beta\)</span>-Fehler zu begehen ist hingegen sehr klein (0.0309). Als letzten Schritt tabellarisieren wir die Ergebnisse und fassen diese anschlieÃend in Textform zusammen.</p>
<pre class="r"><code># ergebnisse der mlr betrachten
mlr.summary(m2.mlr, m2.glm, ia = T)</code></pre>
<pre><code>## Waiting for profiling to be done...
## Waiting for profiling to be done...</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%) CI(97.5%)
## (Intercept)                             99.15          92.1    106.21
## statusSingle                            55.85    2    45.78     65.93
## attractionNotInterested                -47.66 1.96   -57.63    -37.69
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71    -45.21
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                                                          
##                                               Std. Error      t value
## (Intercept)                                          3.6        27.56
## statusSingle                                        5.14        10.87
## attractionNotInterested                             5.09        -9.37
## statusSingle:attractionNotInterested                7.27        -8.18
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                          F-statistic: 188.36 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>

<p>ZusÃ¤tzlich werden die Ergebnisse von multiplen linearen Regressionen schriftlich wie folgt zusammengefasst:</p>
<p>(Falls signifikante Interaktionen vorliegen, sollten die Haupteffekte der PrÃ¤dikatoren, die an der/n Interaktion/en beteiligt sind, nicht interpretiert werden. Sie werden hier dennoch interpretiert, um zu verdeutlichen, wie die Ergebnisse einer multiplen linearen Regression verschriftlicht werden kÃ¶nnen.)</p>
<p>Eine multiple lineare Regression wurde mit AIC-basierter (Akaikeâs Information Criterion) step-wise step-down Prozedur auf die Daten angepasst, um zum finalen minimalen adÃ¤quaten Modell zu gelangen. WÃ¤hrend der Modelldiagnose wurden zwei Datenpunkte als AusreiÃer ermittelt und aus dem Datensatz entfernt. Weitere modelldiagnostischen Grafiken und zusÃ¤tzliche statistische Modelldiagnosen ergaben nach dem Entfernen der AusreiÃer keine weiteren AuffÃ¤lligkeiten.</p>
<p>Das finale minimale adÃ¤quate Modell basiert auf 98 Datenpunkten und korreliert hoch signifikant mit dem Datensatz (Multipler <span class="math inline">\(R^{2}\)</span>: .857, Angepasster <span class="math inline">\(R^{2}\)</span>: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p<span class="math inline">\(&lt;.001***\)</span>). Das finale minimale adÃ¤quate Modell enthÃ¤lt sowohl  und  als signifikante Haupteffekte. Der Status von Geschenk-empfÃ¤ngern korreliert hoch signifikant positiv mit dem Geldbetrag, der fÃ¼r ihre Geschenke ausgegeben wird (SE: 5.14, <span class="math inline">\(t\)</span>-Wert: 10.87, p<span class="math inline">\(&lt;.001***\)</span>). Dies zeigt, dass wenn eine Person single ist, ihr Geschenk {55,85} mehr wert ist, verglichen mit dem Fall, dass sie in einer Beziehung ist (in diesem Fall ist das Geschenk {99.15}, wenn der Schenker nicht an der Beschenkten interessiert ist. Der Faktor  korreliert ebenfalls hoch signifikant positiv mit dem Geldbetrag, der fÃ¼r ihre Geschenke ausgegeben wird (SE: 5.09, <span class="math inline">\(t\)</span>-Wert: -9.37, p<span class="math inline">\(&lt;.001***\)</span>). Falls der Schenkende nicht an der Beschenkten interessiert ist, dann gibt er {-47.66} weniger fÃ¼r ein Geschenk aus, verglichen mit dem Fall, dass er sie attraktiv findet (vorausgesetzt die Beschenkte ist in einer Beziehung). SchlieÃlich weist das finale minimale adÃ¤quate Modell eine hoch signifikante Interaktion zwischen  und  nach (SE: 7.27, <span class="math inline">\(t\)</span>-Wert: -8.18, p<span class="math inline">\(&lt;\)</span>.001***): Wenn die Beschenkte ein Single ist, aber der Schenker nicht an ihr interessiert ist, dann gibt der Schenker {59,46} weniger fÃ¼r ein Geschenk aus, verglichen mit dem Fall, dass er an der Beschenkten interessiert ist (vgl. Figure ).</p>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.6</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Download the data set called <code>exdatamlr</code> from <code>http://martinschweinberger.de/docs/data/exdatamlr.txt</code> and apply what you have learned by implementing a multiple linear regression model so that you can answer how movement (move) and food intake (food) affect weight (given the data at hand).</li>
</ol>
</div>
</div>
<div id="multiple-linear-regression-1" class="section level1">
<h1><span class="header-section-number">2</span> Multiple Linear Regression</h1>
<pre class="r"><code># pakete initialisieren
library(car)
library(QuantPsyc)
library(boot)
library(ggplot2)
# load functions
source(&quot;rscripts/multiplot_ggplot2.R&quot;)
source(&quot;rscripts/mlinr.summary.r&quot;)
source(&quot;rscripts/SampleSizeMLR.r&quot;)
source(&quot;rscripts/ExpR.r&quot;)
# optionen festlegen
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)
# daten laden
mlrdata &lt;- read.delim(&quot;data/mlrdata.txt&quot;, header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code># struktur der daten betrachten
str(mlrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code># zusammenfassung der daten betrachten
summary(mlrdata)</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -87.45 -38.54  -6.65  33.20 112.61 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 48.6 on 99 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -87.45  -38.54   -6.65   33.20  112.61  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2359)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance: 233562  on 99  degrees of freedom
## AIC: 1063
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -45.08  -14.26    0.46   11.93   44.14  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 360)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance:  34558  on 96  degrees of freedom
## AIC: 878.3
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## [1] 52 83</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre><code>##         status    attraction money                  dfb.1_
## 1 Relationship NotInterested 86.33  0.00000000000000236805
## 2 Relationship NotInterested 45.58  0.00000000000000022805
## 3 Relationship NotInterested 68.43 -0.00000000000000091891
## 4 Relationship NotInterested 52.93 -0.00000000000000016896
## 5 Relationship NotInterested 61.86  0.00000000000000011789
## 6 Relationship NotInterested 48.47 -0.00000000000000004889
##                   dfb.sttS dfb.atNI  dfb.sS.N    dffit  cov.r     cook.d
## 1 -0.000000000000001067658  0.27414 -0.193850  0.38770 0.9358 0.03658407
## 2 -0.000000000000000396634 -0.04569  0.032306 -0.06461 1.0817 0.00105355
## 3  0.000000000000001134168  0.13140 -0.092911  0.18582 1.0491 0.00864788
## 4  0.000000000000000269812  0.01111 -0.007854  0.01571 1.0860 0.00006233
## 5 -0.000000000000000001814  0.08021 -0.056718  0.11344 1.0722 0.00324023
## 6  0.000000000000000015629 -0.02334  0.016507 -0.03301 1.0850 0.00027528
##    hat dfb.1_.1 dfb.sttS.1 dfb.atNI.1 dfb.sS.N.1 dffit.1 cov.r.1 cook.d.1
## 1 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 2 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 3 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 4 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 5 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 6 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
##   hat.1
## 1 FALSE
## 2 FALSE
## 3 FALSE
## 4 FALSE
## 5 FALSE
## 6 FALSE</code></pre>
<pre><code>## [1] 100</code></pre>
<pre><code>## [1] 98</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -76.00 -38.05  -6.39  33.15 105.66 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 46.9 on 97 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -76.00  -38.05   -6.39   33.15  105.66  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2198)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance: 213227  on 97  degrees of freedom
## AIC: 1035
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -35.76  -13.51   -0.99   10.60   38.77  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 323.5)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance:  30411  on 94  degrees of freedom
## AIC: 850.4
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 84 88 
## 82 86</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre><code>## integer(0)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968    0.65
##  Alternative hypothesis: rho != 0</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre><code>## [1] 2.307</code></pre>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%) CI(97.5%)
## (Intercept)                             99.15          92.1    106.21
## statusSingle                            55.85    2    45.78     65.93
## attractionNotInterested                -47.66 1.96   -57.63    -37.69
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71    -45.21
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                                                          
##                                               Std. Error      t value
## (Intercept)                                          3.6        27.56
## statusSingle                                        5.14        10.87
## attractionNotInterested                             5.09        -9.37
## statusSingle:attractionNotInterested                7.27        -8.18
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                          F-statistic: 188.36 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>
</div>
<div id="linear-mixed-effects-regression-models" class="section level1">
<h1><span class="header-section-number">3</span> Linear Mixed-Effects Regression Models </h1>
<p>The following focuses on an extension of ordinary multiple regressions: mixed-effects regression models.</p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. having only fixed-effecst measn that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristsi. In such cases, the data is consiederd hierarchical and statistical models should incororate such structiral features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope, while mixed effects models have intercepts for each level of a random effect. If the randon effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and or slope for each speaker.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p><em>Random Effects</em> have two parameters: the intercept (the point where the regression line cross the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models have only 1 intercept and one slope (left panel of the Figure above) while mixed-effects models can have various <em>random intercepts</em> (center left panel ) or various <em>random slopes</em> (center right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the follwoing, we will onyl focus on models with random interecpts becasue this is the by far more common method and because including both random incetrcepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by ârandom interceptsâ.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>caption{Scatterplots mit einer Regressionsgeraden (mitte) und Random Intencepts (rechts)} label{fig:mem01}</p>
<p>The left panel merely shows the data while the center panel includes the regression line for a regression that estimates Weight basedon Height. The right panel shows the regression line and, in addition, random incercepts each each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple rgeression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field 2012)</span>. We test whteher including random effects is warranted by comparing a model, that bases its estiamtes of the dependend variable solely on the base intercept (the mean), with a model, that bases its estiamtes of the dependend variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in <code>R</code> we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load neccessary <code>R</code> packages, specify oprions, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(RLRsim)
#library(car)
#library(QuantPsyc)
#library(boot)
library(nlme)
library(lme4)
#library(ez)
library(ggplot2)
# set options
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      # supress scientific notation
options(stringsAsFactors = F)              # do not convert strings into factors
mydata &lt;- read.delim(&quot;data/lmemdata.txt&quot;, header = TRUE) # read in data
mydata$date &lt;- as.numeric(mydata$date)     # convert date into a numeric variable
head(mydata); nrow(mydata)                 # inspect updated data set</code></pre>
<pre><code>##   date         genre    text  pptw region
## 1 1736 SCIENCE_OTHER   albin 166.0  north
## 2 1711 EDUC_TREATISE    anon 139.9  north
## 3 1808  LETTERS_PRIV  austen 130.8  north
## 4 1878 EDUC_TREATISE    bain 151.3  north
## 5 1743 EDUC_TREATISE barclay 145.7  north
## 6 1908 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (<code>date</code>), the genre of the text (<code>genre</code>), the name of the text (<code>text</code>), the relative frequency of prepositions in the text (<code>pptw</code>), and the region in which the text was written (<code>region</code>). We now plot the data to get a first impression of its structure.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderattely increased over time while the boxplots in the lower left panel show show that the gernres differ quite substantailly with respect to their median frequencies of preositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre><code>##     date         genre    text  pptw region
## 1 109.87 SCIENCE_OTHER   albin 166.0  north
## 2  84.87 EDUC_TREATISE    anon 139.9  north
## 3 181.87  LETTERS_PRIV  austen 130.8  north
## 4 251.87 EDUC_TREATISE    bain 151.3  north
## 5 116.87 EDUC_TREATISE barclay 145.7  north
## 6 281.87 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  5 variables:
##  $ date  : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ genre : chr  &quot;SCIENCE_OTHER&quot; &quot;EDUC_TREATISE&quot; &quot;LETTERS_PRIV&quot; &quot;EDUC_TREATISE&quot; ...
##  $ text  : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ pptw  : num  166 140 131 151 146 ...
##  $ region: chr  &quot;north&quot; &quot;north&quot; &quot;north&quot; &quot;north&quot; ...</code></pre>
<pre><code>## [[1]]
## [1] 220.9
## 
## [[2]]
## [1] 0.000000000000000000000000000000000000000000000001082</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer1: pptw ~ (1 | genre) + 1
## m0.lmer2: pptw ~ (1 | region) + 1
## m0.lmer3: pptw ~ (1 | genre/region) + 1
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.lmer1  3 4502 4515  -2248     4496                                     
## m0.lmer2  3 4719 4731  -2356     4713     0      0                   1    
## m0.lmer3  4 4501 4518  -2246     4493   220      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 
##  simulated finite sample distribution of RLRT.
##  
##  (p-value based on 10000 simulated values)
## 
## data:  
## RLRT = 220, p-value &lt;0.0000000000000002</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m1.lme     2  5 4496 4517  -2243 1 vs 2   10.12  0.0063</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4496 4517  -2243
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.05
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       3.453    14.97
## 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.95     3.183 505   42.09  0.0000
## date          0.02     0.007 505    2.70  0.0071
##  Correlation: 
##      (Intr)
## date 0.003 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.74687 -0.66308  0.01827  0.64043  3.62269 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1770.7  &lt;.0001
## date            1   505     7.3  0.0071</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer: pptw ~ (1 | genre/region) + 1
## m1.lmer: pptw ~ (1 | genre/region) + date
##         Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
## m0.lmer  4 4501 4518  -2246     4493                           
## m1.lmer  5 4496 4517  -2243     4486  7.03      1      0.008 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.713505 133.95499 140.19647
## date          0.004896   0.01787   0.03083
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept))  8.19 12.05 17.73
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 1.172 3.453 10.17
## 
##  Within-group standard error:
## lower  est. upper 
## 14.07 14.97 15.93</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-42-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-2.png" width="672" /></p>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m1.lme     1  5 4496 4517  -2243                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   42.75  0.0002</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4483 4569  -2222
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.14
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       4.183    13.89
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | genre 
##  Parameter estimates:
##             BIBLE   BIOGRAPHY_OTHER        DIARY_PRIV     EDUC_TREATISE 
##            1.0000            0.3582            0.8994            0.7324 
##           FICTION    HANDBOOK_OTHER           HISTORY               LAW 
##            0.8895            1.1417            1.0185            0.7591 
##  LETTERS_NON-PRIV      LETTERS_PRIV        PHILOSOPHY PROCEEDINGS_TRIAL 
##            1.2641            1.2302            0.7753            1.2262 
##    RELIG_TREATISE     SCIENCE_OTHER            SERMON        TRAVELOGUE 
##            1.0108            0.8293            0.9821            1.0663 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 134.01     3.209 505   41.76  0.0000
## date          0.02     0.006 505    3.36  0.0008
##  Correlation: 
##      (Intr)
## date 0.002 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.29018 -0.67307  0.03261  0.64633  3.08450 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1743.6  &lt;.0001
## date            1   505    11.3  0.0008</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   52.87  &lt;.0001</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.719320 134.01179 140.30426
## date          0.008414   0.02022   0.03203
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept)) 8.253 12.14 17.87
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 2.092 4.183 8.363
## 
##  Variance function:
##                    lower   est.  upper
## BIOGRAPHY_OTHER   0.2233 0.3582 0.5747
## DIARY_PRIV        0.6532 0.8994 1.2385
## EDUC_TREATISE     0.5210 0.7324 1.0295
## FICTION           0.6426 0.8895 1.2312
## HANDBOOK_OTHER    0.8170 1.1417 1.5955
## HISTORY           0.7583 1.0185 1.3682
## LAW               0.5499 0.7591 1.0480
## LETTERS_NON-PRIV  0.9974 1.2641 1.6020
## LETTERS_PRIV      0.9907 1.2302 1.5276
## PHILOSOPHY        0.4907 0.7753 1.2250
## PROCEEDINGS_TRIAL 0.8344 1.2262 1.8019
## RELIG_TREATISE    0.6776 1.0108 1.5078
## SCIENCE_OTHER     0.5702 0.8293 1.2063
## SERMON            0.7351 0.9821 1.3121
## TRAVELOGUE        0.7574 1.0663 1.5012
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.62 13.89 16.61</code></pre>
<pre><code>## [1] &quot;Pearson&#39;s r =  0.148&quot;</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000005159</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-42-3.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-4.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-5.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-6.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-7.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-8.png" width="672" /></p>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
</div>
</div>
<div id="multiple-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">4</span> Multiple Binomial Logistic Regression</h1>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  7 variables:
##  $ file.speaker.id: chr  &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; ...
##  $ text.id        : chr  &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; ...
##  $ spk.ref        : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ...
##  $ sex            : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ age            : Factor w/ 2 levels &quot;young&quot;,&quot;old&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ethnicity      : Factor w/ 2 levels &quot;Pakeha&quot;,&quot;Maori&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ suf.eh         : num  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<pre><code>##  file.speaker.id      text.id            spk.ref              sex       
##  Length:25821       Length:25821       Length:25821       female:15852  
##  Class :character   Class :character   Class :character   male  : 9969  
##  Mode  :character   Mode  :character   Mode  :character                 
##                                                                         
##                                                                         
##                                                                         
##     age         ethnicity         suf.eh     
##  young:19150   Pakeha:20024   Min.   :0.000  
##  old  : 6671   Maori : 5797   1st Qu.:0.000  
##                               Median :0.000  
##                               Mean   :0.337  
##                               3rd Qu.:1.000  
##                               Max.   :1.000</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-43-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-43-2.png" width="672" /></p>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age * sex * ethnicity, family = binomial, 
##     data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.095  -0.913  -0.780   1.283   1.868  
## 
## Coefficients:
##                               Estimate Std. Error z value
## (Intercept)                    -0.6594     0.0207  -31.79
## ageold                         -0.7966     0.0563  -14.15
## sexmale                         0.4150     0.0337   12.32
## ethnicityMaori                  0.0639     0.0555    1.15
## ageold:sexmale                  0.0070     0.0852    0.08
## ageold:ethnicityMaori          -0.1599     0.1025   -1.56
## sexmale:ethnicityMaori         -0.0169     0.0819   -0.21
## ageold:sexmale:ethnicityMaori   0.0709     0.1470    0.48
##                                          Pr(&gt;|z|)    
## (Intercept)                   &lt;0.0000000000000002 ***
## ageold                        &lt;0.0000000000000002 ***
## sexmale                       &lt;0.0000000000000002 ***
## ethnicityMaori                               0.25    
## ageold:sexmale                               0.93    
## ageold:ethnicityMaori                        0.12    
## sexmale:ethnicityMaori                       0.84    
## ageold:sexmale:ethnicityMaori                0.63    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25813  degrees of freedom
## AIC: 32152
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age * sex * ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25813      32136                     
## 2     25814      32136 -1   -0.233     0.63</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + 
##     sex:ethnicity, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.099  -0.914  -0.784   1.284   1.861  
## 
## Coefficients:
##                        Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.65800    0.02053  -32.05 &lt;0.0000000000000002 ***
## ageold                 -0.80705    0.05211  -15.49 &lt;0.0000000000000002 ***
## sexmale                 0.41124    0.03277   12.55 &lt;0.0000000000000002 ***
## ethnicityMaori          0.05377    0.05142    1.05               0.296    
## ageold:sexmale          0.03083    0.06943    0.44               0.657    
## ageold:ethnicityMaori  -0.12538    0.07346   -1.71               0.088 .  
## sexmale:ethnicityMaori  0.00513    0.06800    0.08               0.940    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25814  degrees of freedom
## AIC: 32150
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25814      32136                     
## 2     25815      32136 -1 -0.00569     0.94</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity, 
##     family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.098  -0.913  -0.784   1.284   1.860  
## 
## Coefficients:
##                       Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.6583     0.0201  -32.82 &lt;0.0000000000000002 ***
## ageold                 -0.8077     0.0515  -15.69 &lt;0.0000000000000002 ***
## sexmale                 0.4121     0.0307   13.43 &lt;0.0000000000000002 ***
## ethnicityMaori          0.0561     0.0408    1.38               0.169    
## ageold:sexmale          0.0321     0.0674    0.48               0.634    
## ageold:ethnicityMaori  -0.1252     0.0734   -1.71               0.088 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25815  degrees of freedom
## AIC: 32148
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25815      32136                     
## 2     25816      32136 -1   -0.226     0.63</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:ethnicity, 
##     family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.099  -0.912  -0.779   1.282   1.854  
## 
## Coefficients:
##                       Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.6609     0.0194  -34.14 &lt;0.0000000000000002 ***
## ageold                 -0.7937     0.0423  -18.79 &lt;0.0000000000000002 ***
## sexmale                 0.4187     0.0273   15.32 &lt;0.0000000000000002 ***
## ethnicityMaori          0.0555     0.0408    1.36               0.174    
## ageold:ethnicityMaori  -0.1225     0.0732   -1.67               0.094 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25816  degrees of freedom
## AIC: 32146
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1     25816      32136                       
## 2     25817      32139 -1    -2.81    0.094 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity, family = binomial, 
##     data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.086  -0.915  -0.768   1.279   1.840  
## 
## Coefficients:
##                Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)     -0.6549     0.0190  -34.45 &lt;0.0000000000000002 ***
## ageold          -0.8350     0.0346  -24.11 &lt;0.0000000000000002 ***
## sexmale          0.4191     0.0273   15.34 &lt;0.0000000000000002 ***
## ethnicityMaori   0.0173     0.0339    0.51                0.61    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32139  on 25817  degrees of freedom
## AIC: 32147
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity
## Model 2: suf.eh ~ age + sex
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25817      32139                     
## 2     25818      32140 -1   -0.261     0.61</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.081  -0.916  -0.770   1.278   1.837  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6525     0.0184   -35.4 &lt;0.0000000000000002 ***
## ageold       -0.8305     0.0335   -24.8 &lt;0.0000000000000002 ***
## sexmale       0.4201     0.0273    15.4 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32140  on 25818  degrees of freedom
## AIC: 32146
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = suf.eh ~ age + sex, data = mydata, x = T, y = T, 
##      linear.predictors = T)
##  
##                         Model Likelihood    Discrimination    Rank Discrim.    
##                               Ratio Test           Indexes          Indexes    
##  Obs         25821    LR chi2     868.21    R2       0.046    C       0.602    
##   0          17114    d.f.             2    g        0.432    Dxy     0.203    
##   1           8707    Pr(&gt; chi2) &lt;0.0001    gr       1.541    gamma   0.302    
##  max |deriv| 3e-10                          gp       0.091    tau-a   0.091    
##                                             Brier    0.216                     
##  
##            Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept -0.6525 0.0184 -35.39 &lt;0.0001 
##  age=old   -0.8305 0.0335 -24.78 &lt;0.0001 
##  sex=male   0.4201 0.0273  15.42 &lt;0.0001 
## </code></pre>
<pre><code>##                 Wald Statistics          Response: suf.eh 
## 
##  Factor     Chi-Square d.f. P     
##  age        614.0      1    &lt;.0001
##  sex        237.7      1    &lt;.0001
##  TOTAL      802.6      2    &lt;.0001</code></pre>
<pre><code>## 
##      Backwards Step-down - Original Model
## 
##  Deleted               Chi-Sq d.f. P      Residual d.f. P      AIC  
##  age * sex             0.01   1    0.9346 0.01     1    0.9346 -1.99
##  sex * ethnicity       0.05   1    0.8239 0.06     2    0.9723 -3.94
##  age * sex * ethnicity 0.41   1    0.5230 0.46     3    0.9267 -5.54
##  ethnicity             1.85   1    0.1735 2.32     4    0.6778 -5.68
##  age * ethnicity       1.21   1    0.2711 3.53     5    0.6192 -6.47
## 
## Approximate Estimates after Deleting Factors
## 
##              Coef    S.E. Wald Z P
## Intercept -0.6524 0.01843 -35.39 0
## age=old   -0.8301 0.03353 -24.76 0
## sex=male   0.4199 0.02725  15.41 0
## 
## Factors in Final Model
## 
## [1] age sex</code></pre>
<pre><code>##           index.orig training    test optimism index.corrected   n
## Dxy           0.2032   0.2043  0.2036   0.0007          0.2025 200
## R2            0.0458   0.0462  0.0457   0.0005          0.0454 200
## Intercept     0.0000   0.0000 -0.0021   0.0021         -0.0021 200
## Slope         1.0000   1.0000  0.9960   0.0040          0.9960 200
## Emax          0.0000   0.0000  0.0012   0.0012          0.0012 200
## D             0.0336   0.0339  0.0335   0.0003          0.0332 200
## U            -0.0001  -0.0001  0.0000  -0.0001          0.0000 200
## Q             0.0337   0.0339  0.0335   0.0004          0.0332 200
## B             0.2163   0.2162  0.2163  -0.0001          0.2164 200
## g             0.4323   0.4351  0.4328   0.0023          0.4300 200
## gp            0.0910   0.0915  0.0911   0.0004          0.0906 200
## 
## Factors Retained in Backwards Elimination
## 
##  age sex ethnicity age * sex age * ethnicity sex * ethnicity
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *             *                         *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *               *              
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                                                  
##  *   *   *                                                  
##  *   *                                                      
##  *   *             *                         *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *             *                                        
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *         *                                        
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                                                  
##  *   *                       *                              
##  *   *                       *                              
##  *   *   *                                                  
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *               *              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                       *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                                                  
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                       *              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *             *                                        
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                       *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *               *              
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                       *              
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *         *                                        
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  age * sex * ethnicity
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##  *                    
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
## 
## Frequencies of Numbers of Factors Retained
## 
##   2   3   4   5   6   7 
## 135  30  21   7   4   3</code></pre>
<pre><code>## 
## Best penalty:
## 
##  penalty    df
##      0.8 1.999
## 
##  penalty    df   aic   bic aic.c
##     0.00 2.000 864.2 847.9 864.2
##     0.05 2.000 864.2 847.9 864.2
##     0.10 2.000 864.2 847.9 864.2
##     0.15 2.000 864.2 847.9 864.2
##     0.20 2.000 864.2 847.9 864.2
##     0.25 2.000 864.2 847.9 864.2
##     0.30 2.000 864.2 847.9 864.2
##     0.35 2.000 864.2 847.9 864.2
##     0.40 2.000 864.2 847.9 864.2
##     0.45 2.000 864.2 847.9 864.2
##     0.50 2.000 864.2 847.9 864.2
##     0.55 1.999 864.2 847.9 864.2
##     0.60 1.999 864.2 847.9 864.2
##     0.65 1.999 864.2 847.9 864.2
##     0.70 1.999 864.2 847.9 864.2
##     0.75 1.999 864.2 847.9 864.2
##     0.80 1.999 864.2 847.9 864.2</code></pre>
<pre><code>## [1] 868.2</code></pre>
<pre><code>## [1] 2</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## Pseudo R^2 for logistic regression
## Hosmer and Lemeshow R^2   0.026 
## Cox and Snell R^2         0.033 
## Nagelkerke R^2            0.046</code></pre>
<pre><code>##               2.5 %  97.5 %
## (Intercept) -0.6887 -0.6164
## ageold      -0.8965 -0.7651
## sexmale      0.3667  0.4735</code></pre>
<pre><code>## (Intercept)      ageold     sexmale 
##      0.5207      0.4358      1.5221</code></pre>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 0.5022 0.5399
## ageold      0.4080 0.4653
## sexmale     1.4430 1.6057</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ 1
## Model 2: suf.eh ~ age + sex
##   Resid. Df Resid. Dev Df Deviance            Pr(&gt;Chi)    
## 1     25820      33008                                    
## 2     25818      32140  2      868 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>##   file.speaker.id no.eh eh text.id spk.ref    sex   age ethnicity
## 1   &lt;S1A-001#1:F&gt;    95 56  S1A001       F female young    Pakeha
## 2   &lt;S1A-001#1:M&gt;    97 75  S1A001       M   male young    Pakeha
## 3   &lt;S1A-002#1:B&gt;    99 45  S1A002       B female young    Pakeha
## 4   &lt;S1A-002#1:Q&gt;    86 51  S1A002       Q female young    Pakeha
## 5   &lt;S1A-003#1:B&gt;    58 50  S1A003       B   male young    Pakeha
## 6   &lt;S1A-003#1:M&gt;   119 84  S1A003       M   male young    Pakeha</code></pre>
<pre><code>## [1] 66.28</code></pre>
<pre><code>## [1] 66.28</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-43-3.png" width="672" /></p>
<pre><code>##  ageold sexmale 
##   1.005   1.005</code></pre>
<pre><code>##  ageold sexmale 
##  0.9952  0.9952</code></pre>
<pre><code>## [1] 1.005</code></pre>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh    dfb.1_
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
##    dfb.agld  dfb.sxml    dffit cov.r     cook.d       hat dfb.1_.1
## 1  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 2 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
## 3  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 4  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 5 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
## 6 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
##   dfb.agld.1 dfb.sxml.1 dffit.1 cov.r.1 cook.d.1 hat.1
## 1      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 2      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 3      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 4      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 5      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 6      FALSE      FALSE   FALSE   FALSE    FALSE FALSE</code></pre>
<pre><code>## [1] &quot;Sample size sufficient&quot;</code></pre>
<pre><code>##                             Estimate VIF OddsRatio CI(2.5%) CI(97.5%)
## (Intercept)                    -0.65          0.52      0.5      0.54
## ageold                         -0.83   1      0.44     0.41      0.47
## sexmale                         0.42   1      1.52     1.44      1.61
## Model statistics                                                     
## Number of cases in model                                             
## Observed misses                                                      
## Observed successes                                                   
## Null deviance                                                        
## Residual deviance                                                    
## R2 (Nagelkerke)                                                      
## R2 (Hosmer &amp; Lemeshow)                                               
## R2 (Cox &amp; Snell)                                                     
## C                                                                    
## Somers&#39; Dxy                                                          
## AIC                                                                  
## Prediction accuracy                                                  
## Model Likelihood Ratio Test                                          
##                                     Std. Error z value   Pr(&gt;|z|)
## (Intercept)                               0.02  -35.39          0
## ageold                                    0.03  -24.78          0
## sexmale                                   0.03   15.42          0
## Model statistics                                                 
## Number of cases in model                                         
## Observed misses                                               0 :
## Observed successes                                            1 :
## Null deviance                                                    
## Residual deviance                                                
## R2 (Nagelkerke)                                                  
## R2 (Hosmer &amp; Lemeshow)                                           
## R2 (Cox &amp; Snell)                                                 
## C                                                                
## Somers&#39; Dxy                                                      
## AIC                                                              
## Prediction accuracy                                              
## Model Likelihood Ratio Test Model L.R.: 868.21   df: 2 p-value: 0
##                                 Significance
## (Intercept)                      p &lt; .001***
## ageold                           p &lt; .001***
## sexmale                          p &lt; .001***
## Model statistics                       Value
## Number of cases in model               25821
## Observed misses                        17114
## Observed successes                      8707
## Null deviance                       33007.75
## Residual deviance                   32139.54
## R2 (Nagelkerke)                        0.046
## R2 (Hosmer &amp; Lemeshow)                 0.026
## R2 (Cox &amp; Snell)                       0.033
## C                                      0.602
## Somers&#39; Dxy                            0.203
## AIC                                 32145.54
## Prediction accuracy                   66.28%
## Model Likelihood Ratio Test sig: p &lt; .001***</code></pre>
<div id="model-fit-parameters" class="section level2">
<h2><span class="header-section-number">4.1</span> Model Fit Parameters</h2>
<div id="r2-hosmer-lemeshow" class="section level3">
<h3><span class="header-section-number">4.1.1</span> R2 (Hosmer &amp; Lemeshow)</h3>
<p>âRt is the proportional reduction in the absolute value of the log-likelihood measure and as such it is a measure of how much the badness of fit improves as a result of the inclusionof the predictor variables. It can vary between 0 (indicating that the predictors are useless at predicting the outcome variable) and 1 (indicating that the model predicts the outcome variable perfectly)â (<span class="citation">(A. Field, Miles, and Field 2012, 317)</span>).</p>
</div>
<div id="r2-cox-snell" class="section level3">
<h3><span class="header-section-number">4.1.2</span> R2 (Cox &amp; Snell)</h3>
<p>âCox and Snellâs R~s (1989) is based on the deviance of the model (-2LL(newÂ») and the deviance of the baseline model (-2LL(baseline), and the sample size, n [â¦]. However, this statistic never reaches its theoretical maximum of 1.</p>
</div>
<div id="r2-nagelkerke" class="section level3">
<h3><span class="header-section-number">4.1.3</span> R2 (Nagelkerke)</h3>
<p>Since R2 (Cox &amp; Snell) never reaches its theoretical maximum of 1, Nagelkerke (1991) suggested Nagelkerkeâs R^2. (Field, Miles &amp; Field 2012:317-318).</p>
</div>
<div id="somers-dxy" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Somersâ Dxy</h3>
<p>Somersâ Dxy is a rank correlation between predicted probabilities and observed responses ranges between 0 (randomness) and 1 (perfect prediction). (cf. <span class="citation">(Baayen 2008, 204)</span>).</p>
</div>
<div id="c" class="section level3">
<h3><span class="header-section-number">4.1.5</span> C</h3>
<p>C is an index of concordance between the predicted probability and the observed response. When C takes the value 0.5, the predictions are random, when it is 1, prediction is perfect. A value above 0.8 indicates that the model may have some real predictive capacity (cf. <span class="citation">(Baayen 2008, 204)</span>).</p>
</div>
<div id="akaike-information-criteria-aic" class="section level3">
<h3><span class="header-section-number">4.1.6</span> Akaike information criteria (AIC)</h3>
<p>Akaike information criteria (AlC = -2LL + 2k) provide a value that reflects a ratio between the number of predictors in the model and the variance that is explained by these predictors. Changes in AIC can serve as a measure of whether the inclusion of a variable leads to a significant incerase in the amount of variance that is explained by the model. âYou can think of this as the price you pay for something: you get a better value of R2, but you pay a higher price, and was that higher price worth it? These information criteria help you to decide.model. The BIC is the same as the AIC but adjusts the penalty included in the AlC (i.e., 2k) by the number of cases: BlC = -2LL + 2k x log(n) in which n is the number of cases in the modelâ (<span class="citation">(A. Field, Miles, and Field 2012, 318)</span>).</p>
</div>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">5</span> Mixed Effects Binomial Logistic Regression</h1>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  7 variables:
##  $ file.speaker.id: chr  &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; ...
##  $ text.id        : chr  &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; ...
##  $ spk.ref        : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ...
##  $ sex            : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ age            : Factor w/ 2 levels &quot;young&quot;,&quot;old&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ethnicity      : Factor w/ 2 levels &quot;Pakeha&quot;,&quot;Maori&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ suf.eh         : num  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<pre><code>##  file.speaker.id      text.id            spk.ref              sex       
##  Length:25821       Length:25821       Length:25821       female:15852  
##  Class :character   Class :character   Class :character   male  : 9969  
##  Mode  :character   Mode  :character   Mode  :character                 
##                                                                         
##                                                                         
##                                                                         
##     age         ethnicity         suf.eh     
##  young:19150   Pakeha:20024   Min.   :0.000  
##  old  : 6671   Maori : 5797   1st Qu.:0.000  
##                               Median :0.000  
##                               Mean   :0.337  
##                               3rd Qu.:1.000  
##                               Max.   :1.000</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-44-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-44-2.png" width="672" /></p>
<pre><code>## , ,  = female,  = Pakeha
## 
##    
##     young  old
##   0  6820 1930
##   1  3527  450
## 
## , ,  = male,  = Pakeha
## 
##    
##     young  old
##   0  3237 1125
##   1  2535  400
## 
## , ,  = female,  = Maori
## 
##    
##     young  old
##   0  1063 1218
##   1   586  258
## 
## , ,  = male,  = Maori
## 
##    
##     young  old
##   0   759  962
##   1   623  328</code></pre>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">5.1</span> Model Building</h2>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = suf.eh ~ 1, data = mydata, x = T, y = T)
##  
##                        Model Likelihood    Discrimination    Rank Discrim.    
##                              Ratio Test           Indexes          Indexes    
##  Obs         25821    LR chi2      0.00    R2       0.000    C       0.500    
##   0          17114    d.f.            0    g        0.000    Dxy     0.000    
##   1           8707    Pr(&gt; chi2) 1.0000    gr       1.000    gamma   0.000    
##  max |deriv|     0                         gp       0.000    tau-a   0.000    
##                                            Brier    0.223                     
##  
##            Coef   
##  Intercept -0.6758
## </code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + 1
##    Data: mydata
## REML criterion at convergence: 4489
## Random effects:
##  Groups       Name        Std.Dev.
##  region:genre (Intercept)  4.36   
##  genre        (Intercept) 12.54   
##  Residual                 15.02   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## Fixed Effects:
## (Intercept)  
##         134</code></pre>
<pre><code>## [1] 32479</code></pre>
<pre><code>## [1] 33010</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: suf.eh ~ (1 | file.speaker.id)
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##    32479    32495   -16237    32475    25819 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -1.059 -0.741 -0.614  1.193  2.368 
## 
## Random effects:
##  Groups          Name        Variance Std.Dev.
##  file.speaker.id (Intercept) 0.158    0.398   
## Number of obs: 25821, groups:  file.speaker.id, 203
## 
## Fixed effects:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6866     0.0315   -21.8 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">5.2</span> Model Fitting</h2>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m3.glmer: suf.eh ~ age + sex + ethnicity + (1 | file.speaker.id)
## m4.glmer: suf.eh ~ age + sex + ethnicity + age:sex + (1 | file.speaker.id)
## m5.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + (1 | 
## m5.glmer:     file.speaker.id)
## m6.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m6.glmer:     (1 | file.speaker.id)
## m7.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m7.glmer:     age:sex:ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance  Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                  
## m1.glmer  3 32302 32327 -16148    32296 178.65      1 &lt;0.0000000000000002
## m2.glmer  4 32148 32180 -16070    32140 156.50      1 &lt;0.0000000000000002
## m3.glmer  5 32149 32190 -16070    32139   0.26      1               0.609
## m4.glmer  6 32151 32200 -16070    32139   0.12      1               0.728
## m5.glmer  7 32150 32207 -16068    32136   2.91      1               0.088
## m6.glmer  8 32152 32218 -16068    32136   0.01      1               0.940
## m7.glmer  9 32154 32227 -16068    32136   0.23      1               0.629
##             
## m0.glmer    
## m1.glmer ***
## m2.glmer ***
## m3.glmer    
## m4.glmer    
## m5.glmer .  
## m6.glmer    
## m7.glmer    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                 
## m1.glmer  3 32302 32327 -16148    32296   179      1 &lt;0.0000000000000002
##             
## m0.glmer    
## m1.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m1.glmer  3 32302 32327 -16148    32296                                 
## m2.glmer  4 32148 32180 -16070    32140   156      1 &lt;0.0000000000000002
##             
## m1.glmer    
## m2.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m3.glmer: suf.eh ~ age + sex + ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m3.glmer  5 32149 32190 -16070    32139  0.26      1       0.61</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m4.glmer: suf.eh ~ age + sex + ethnicity + age:sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m4.glmer  6 32151 32200 -16070    32139  0.38      2       0.83</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m5.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + (1 | 
## m5.glmer:     file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m5.glmer  7 32150 32207 -16068    32136  3.29      3       0.35</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m6.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m6.glmer:     (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m6.glmer  8 32152 32218 -16068    32136   3.3      4       0.51</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m7.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m7.glmer:     age:sex:ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m7.glmer  9 32154 32227 -16068    32136  3.53      5       0.62</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## mlr.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##           Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer   2 32479 32495 -16237    32475                                 
## mlr.glmer  4 32148 32180 -16070    32140   335      2 &lt;0.0000000000000002
##              
## m0.glmer     
## mlr.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: suf.eh ~ age + sex + (1 | file.speaker.id)
##    Data: mydata
##      AIC      BIC   logLik deviance df.resid 
##    32148    32180   -16070    32140    25817 
## Random effects:
##  Groups          Name        Std.Dev.
##  file.speaker.id (Intercept) 0       
## Number of obs: 25821, groups:  file.speaker.id, 203
## Fixed Effects:
## (Intercept)       ageold      sexmale  
##      -0.652       -0.831        0.420</code></pre>
<pre><code>## Analysis of Variance Table
##     Df Sum Sq Mean Sq F value
## age  1    565     565     565
## sex  1    238     238     238</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                 
## m1.glmer  3 32302 32327 -16148    32296   179      1 &lt;0.0000000000000002
##             
## m0.glmer    
## m1.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m1.glmer  3 32302 32327 -16148    32296                                 
## m2.glmer  4 32148 32180 -16070    32140   156      1 &lt;0.0000000000000002
##             
## m1.glmer    
## m2.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">5.3</span> Extracting Model Fit Parameters</h2>
<p>We now create a lmr object equivalent to the final minimal adequate model but without the random effect.</p>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  coef(mlr.lrm) and fixef(mlr.lmer)
## t = Inf, df = 1, p-value &lt;0.0000000000000002
## alternative hypothesis: true correlation is not equal to 0
## sample estimates:
## cor 
##   1</code></pre>
<pre><code>##          C        Dxy          n    Missing 
##     0.6181     0.2361 25821.0000     0.0000</code></pre>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">5.4</span> Model Diagnostics</h2>
<pre class="r"><code># model diagnostics: plot fitted against residuals
plot(mlr.glmer)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r"><code># plot residuals against fitted
plot(mlr.glmer, form = resid(., type = &quot;response&quot;) ~ fitted(.) | file.speaker.id, abline = 0, cex = .5,id = 0.05, adj = -0.3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: examining residuals (Pinheiro &amp; Bates 2000:175)
plot(mlr.glmer, file.speaker.id ~ resid(.), abline = 0 , cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r"><code># summarize final model
meblrm.summary(m0.glm, m1.glm, m0.glmer, mlr.glmer, dpvar=mydata$suf.eh)</code></pre>
<pre><code>##                                    Group(s) Variance Std. Dev.         
## Random Effect(s)            file.speaker.id        0         0         
## Fixed Effect(s)                    Estimate      VIF OddsRatio CI(2.5%)
## (Intercept)                           -0.65               0.52      0.5
## ageold                                -0.83        1      0.44     0.41
## sexmale                                0.42        1      1.52     1.44
## Model statistics                                                       
## Number of Groups                                                       
## Number of cases in model                                               
## Observed misses                                                        
## Observed successes                                                     
## Residual deviance                                                      
## R2 (Nagelkerke)                                                        
## R2 (Hosmer &amp; Lemeshow)                                                 
## R2 (Cox &amp; Snell)                                                       
## C                                                                      
## Somers&#39; Dxy                                                            
## AIC                                                                    
## BIC                                                                    
## Prediction accuracy                                                    
## Model Likelihood Ratio Test                                            
##                                               L.R. X2      DF         Pr
## Random Effect(s)                               533.06       1          0
## Fixed Effect(s)             CI(97.5%)      Std. Error z value   Pr(&gt;|z|)
## (Intercept)                      0.54            0.02  -35.39          0
## ageold                           0.47            0.03  -24.78          0
## sexmale                          1.61            0.03   15.42          0
## Model statistics                                                        
## Number of Groups                                                        
## Number of cases in model                                                
## Observed misses                                                         
## Observed successes                                                      
## Residual deviance                                                       
## R2 (Nagelkerke)                                                         
## R2 (Hosmer &amp; Lemeshow)                                                  
## R2 (Cox &amp; Snell)                                                        
## C                                                                       
## Somers&#39; Dxy                                                             
## AIC                                                                     
## BIC                                                                     
## Prediction accuracy                                                     
## Model Likelihood Ratio Test           L.R. X2: 868.21   DF: 3 p-value: 0
##                                 Significance
## Random Effect(s)                 p &lt; .001***
## Fixed Effect(s)                 Significance
## (Intercept)                      p &lt; .001***
## ageold                           p &lt; .001***
## sexmale                          p &lt; .001***
## Model statistics                       Value
## Number of Groups                         203
## Number of cases in model               25821
## Observed misses                        17114
## Observed successes                      8707
## Residual deviance                   32139.54
## R2 (Nagelkerke)                        0.046
## R2 (Hosmer &amp; Lemeshow)                 0.026
## R2 (Cox &amp; Snell)                       0.033
## C                                      0.602
## Somers&#39; Dxy                            0.203
## AIC                                 32147.54
## BIC                                 32180.18
## Prediction accuracy                   66.28%
## Model Likelihood Ratio Test sig: p &lt; .001***</code></pre>
</div>
</div>
<div id="conditional-inference-trees" class="section level1">
<h1><span class="header-section-number">6</span> Conditional Inference Trees</h1>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  15 variables:
##  $ Age             : chr  &quot;26-40&quot; &quot;26-40&quot; &quot;26-40&quot; &quot;17-25&quot; ...
##  $ Adjective       : chr  &quot;good&quot; &quot;good&quot; &quot;good&quot; &quot;nice&quot; ...
##  $ FileSpeaker     : chr  &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-003:1$B&gt;&quot; ...
##  $ Function        : chr  &quot;Attributive&quot; &quot;Attributive&quot; &quot;Predicative&quot; &quot;Attributive&quot; ...
##  $ Priming         : chr  &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Occupation      : chr  &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; ...
##  $ ConversationType: chr  &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; ...
##  $ AudienceSize    : chr  &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;Dyad&quot; ...
##  $ very            : int  0 0 0 1 0 1 0 1 0 0 ...
##  $ really          : int  0 0 0 0 0 0 0 0 1 1 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : chr  &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; ...
##  $ SemanticCategory: chr  &quot;Value&quot; &quot;Value&quot; &quot;Value&quot; &quot;HumanPropensity&quot; ...
##  $ Emotionality    : chr  &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;NonEmotional&quot; ...</code></pre>
<pre><code>##  [1] &quot;Age&quot;              &quot;Adjective&quot;        &quot;Function&quot;        
##  [4] &quot;Priming&quot;          &quot;Gender&quot;           &quot;ConversationType&quot;
##  [7] &quot;AudienceSize&quot;     &quot;really&quot;           &quot;Freq&quot;            
## [10] &quot;Gradabilty&quot;       &quot;SemanticCategory&quot; &quot;Emotionality&quot;</code></pre>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  12 variables:
##  $ Age             : Factor w/ 3 levels &quot;17-25&quot;,&quot;26-40&quot;,..: 2 2 2 1 3 3 3 3 1 1 ...
##  $ Adjective       : Factor w/ 6 levels &quot;bad&quot;,&quot;funny&quot;,..: 3 3 3 5 6 6 3 6 6 6 ...
##  $ Function        : Factor w/ 2 levels &quot;Attributive&quot;,..: 1 1 2 1 2 2 1 2 1 1 ...
##  $ Priming         : Factor w/ 2 levels &quot;NoPrime&quot;,&quot;Prime&quot;: 1 1 1 1 1 1 1 1 1 2 ...
##  $ Gender          : Factor w/ 2 levels &quot;Men&quot;,&quot;Women&quot;: 1 1 1 1 1 1 2 2 1 1 ...
##  $ ConversationType: Factor w/ 2 levels &quot;MixedSex&quot;,&quot;SameSex&quot;: 2 2 2 2 2 1 1 1 1 1 ...
##  $ AudienceSize    : Factor w/ 2 levels &quot;Dyad&quot;,&quot;MultipleInterlocutors&quot;: 2 2 2 1 1 2 2 2 2 2 ...
##  $ really          : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 2 2 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : Factor w/ 3 levels &quot;GradabilityUndetermined&quot;,..: 3 3 3 3 3 3 3 1 1 3 ...
##  $ SemanticCategory: Factor w/ 5 levels &quot;Dimension&quot;,&quot;HumanPropensity&quot;,..: 5 5 5 2 5 5 5 2 1 4 ...
##  $ Emotionality    : Factor w/ 3 levels &quot;NegativeEmotional&quot;,..: 3 3 3 2 2 3 3 1 2 2 ...</code></pre>
<pre><code>## png 
##   2</code></pre>
<pre><code>## [1] 100</code></pre>
<pre><code>## [1] 41.08</code></pre>
</div>
<div id="random-forests" class="section level1">
<h1><span class="header-section-number">7</span> Random Forests</h1>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Example 1:</h2>
<pre class="r"><code># prepare data
rfd &lt;- reallyaus
# convert really into a factor
rfd$really &lt;- as.factor(rfd$really)
# start with random forest
# set seed
set.seed(222)
# partition data for evaluating rf 
id &lt;- sample(2, nrow(rfd), replace = T, prob = c(.7, .3))
train &lt;- rfd[id == 1, ]
test &lt;- rfd[id == 2,]
# load library
library(randomForest)
# create initial model
reallyaus_rf1 &lt;- randomForest(really~., data = train)
# inspect model
print(reallyaus_rf1)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 41.47%
## Confusion matrix:
##    0  1 class.error
## 0 79 44      0.3577
## 1 46 48      0.4894</code></pre>
<pre class="r"><code># inspect attibutes
attributes(reallyaus_rf1)</code></pre>
<pre><code>## $names
##  [1] &quot;call&quot;            &quot;type&quot;            &quot;predicted&quot;      
##  [4] &quot;err.rate&quot;        &quot;confusion&quot;       &quot;votes&quot;          
##  [7] &quot;oob.times&quot;       &quot;classes&quot;         &quot;importance&quot;     
## [10] &quot;importanceSD&quot;    &quot;localImportance&quot; &quot;proximity&quot;      
## [13] &quot;ntree&quot;           &quot;mtry&quot;            &quot;forest&quot;         
## [16] &quot;y&quot;               &quot;test&quot;            &quot;inbag&quot;          
## [19] &quot;terms&quot;          
## 
## $class
## [1] &quot;randomForest.formula&quot; &quot;randomForest&quot;</code></pre>
<pre class="r"><code># start model evaluation
# install package
#source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(); library(Biobase)
#install.packages(&quot;Biobase&quot;, repos=c(&quot;http://rstudio.org/_packages&quot;, &quot;http://cran.rstudio.com&quot;, 
#                                      &quot;http://cran.rstudio.com/&quot;, dependencies=TRUE))
#install.packages(&quot;dimRed&quot;, dependencies = TRUE)
#install.packages(&#39;caret&#39;, dependencies = TRUE)

# load caret library
library(caret) # because initially caret did not work, the libraries above had to be installed
# extract prediction for training data
ptrain1 &lt;- predict(reallyaus_rf1, train)
# inspect predictions
head(ptrain1); head(train$really)</code></pre>
<pre><code>## 2 3 4 7 8 9 
## 0 0 0 0 0 1 
## Levels: 0 1</code></pre>
<pre><code>## [1] 0 0 0 0 0 1
## Levels: 0 1</code></pre>
<pre class="r"><code># create confusionMatrix
confusionMatrix(ptrain1, train$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 116  13
##          1   7  81
##                                              
##                Accuracy : 0.908              
##                  95% CI : (0.861, 0.943)     
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.811              
##  Mcnemar&#39;s Test P-Value : 0.264              
##                                              
##             Sensitivity : 0.943              
##             Specificity : 0.862              
##          Pos Pred Value : 0.899              
##          Neg Pred Value : 0.920              
##              Prevalence : 0.567              
##          Detection Rate : 0.535              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.902              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest1 &lt;- predict(reallyaus_rf1, test)
# create confusionMatrix
confusionMatrix(ptest1, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 44 16
##          1 18 19
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.249         
##  Mcnemar&#39;s Test P-Value : 0.864         
##                                         
##             Sensitivity : 0.710         
##             Specificity : 0.543         
##          Pos Pred Value : 0.733         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.454         
##    Detection Prevalence : 0.619         
##       Balanced Accuracy : 0.626         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># determine errorrate of random forest model
plot(reallyaus_rf1, main = &quot;&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<pre class="r"><code># tune model
reallyaus_rf2 &lt;- tuneRF(train[, !colnames(train)== &quot;really&quot;], train[, colnames(train)== &quot;really&quot;], 
                        stepFactor = .5, # for most values 6 appears to be optimal
                        plot = T,
                        ntreeTry = 200,
                        trace = T,
                        improve = .05
)</code></pre>
<pre><code>## mtry = 3  OOB error = 42.4% 
## Searching left ...
## mtry = 6     OOB error = 42.4% 
## 0 0.05 
## Searching right ...
## mtry = 1     OOB error = 43.32% 
## -0.02174 0.05</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<pre class="r"><code># create improved model
reallyaus_rf2 &lt;- randomForest(really~., data = train, 
                              ntree = 200,
                              ntry = 6,
                              importance= T,
                              proximity = T)
# inspect model
print(reallyaus_rf2)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train, ntree = 200,      ntry = 6, importance = T, proximity = T) 
##                Type of random forest: classification
##                      Number of trees: 200
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 40.09%
## Confusion matrix:
##    0  1 class.error
## 0 86 37      0.3008
## 1 50 44      0.5319</code></pre>
<pre class="r"><code># predict based on improved model
ptrain2 &lt;- predict(reallyaus_rf2, train)
# create confusionMatrix
confusionMatrix(ptrain2, train$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 114  15
##          1   9  79
##                                              
##                Accuracy : 0.889              
##                  95% CI : (0.84, 0.928)      
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.773              
##  Mcnemar&#39;s Test P-Value : 0.307              
##                                              
##             Sensitivity : 0.927              
##             Specificity : 0.840              
##          Pos Pred Value : 0.884              
##          Neg Pred Value : 0.898              
##              Prevalence : 0.567              
##          Detection Rate : 0.525              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.884              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest2 &lt;- predict(reallyaus_rf2, test)
# create confusionMatrix
confusionMatrix(ptest2, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 45 17
##          1 17 18
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.24          
##  Mcnemar&#39;s Test P-Value : 1.000         
##                                         
##             Sensitivity : 0.726         
##             Specificity : 0.514         
##          Pos Pred Value : 0.726         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.464         
##    Detection Prevalence : 0.639         
##       Balanced Accuracy : 0.620         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># inspect number of nodes for trees
hist(treesize(reallyaus_rf2), main = &quot;&quot;, col = &quot;lightgray&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-55-2.png" width="672" /></p>
<pre class="r"><code># check variable importance
varImpPlot(reallyaus_rf2, main = &quot;&quot;, pch = 20) </code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<pre class="r"><code># left plot (Accuracy): how much accuracy decreases if factor is left out
# left plot (Gini/Pureness): how much more unpure (ambigious) the distributions become if fector is left out
# extract variable importance values
#importance(reallyaus_rf2)

#which variables have been used in the trees
varUsed(reallyaus_rf2)</code></pre>
<pre><code>##  [1]  817  826  894  745  672  902  831 2114  461 1129  853</code></pre>
<pre class="r"><code># partial dependence plot
partialPlot(reallyaus_rf2, train, Freq, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, ConversationType, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Function, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, SemanticCategory, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Gender, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<pre class="r"><code># extract tree
getTree(reallyaus_rf2, 1, labelVar = T)</code></pre>
<pre><code>##    left daughter right daughter        split var split point status
## 1              2              3       Gradabilty      3.0000      1
## 2              4              5 SemanticCategory      1.0000      1
## 3              6              7          Priming      1.0000      1
## 4              8              9     AudienceSize      1.0000      1
## 5             10             11           Gender      1.0000      1
## 6             12             13        Adjective     22.0000      1
## 7             14             15              Age      1.0000      1
## 8              0              0             &lt;NA&gt;      0.0000     -1
## 9              0              0             &lt;NA&gt;      0.0000     -1
## 10             0              0             &lt;NA&gt;      0.0000     -1
## 11            16             17         Function      1.0000      1
## 12            18             19        Adjective      2.0000      1
## 13            20             21             Freq      1.2295      1
## 14            22             23     Emotionality      2.0000      1
## 15             0              0             &lt;NA&gt;      0.0000     -1
## 16             0              0             &lt;NA&gt;      0.0000     -1
## 17            24             25        Adjective      8.0000      1
## 18            26             27              Age      3.0000      1
## 19            28             29        Adjective      4.0000      1
## 20            30             31         Function      1.0000      1
## 21            32             33     AudienceSize      1.0000      1
## 22            34             35             Freq      2.8177      1
## 23            36             37             Freq     11.6575      1
## 24             0              0             &lt;NA&gt;      0.0000     -1
## 25            38             39       Gradabilty      1.0000      1
## 26             0              0             &lt;NA&gt;      0.0000     -1
## 27             0              0             &lt;NA&gt;      0.0000     -1
## 28            40             41              Age      1.0000      1
## 29            42             43 ConversationType      1.0000      1
## 30            44             45     Emotionality      1.0000      1
## 31            46             47     AudienceSize      1.0000      1
## 32            48             49              Age      2.0000      1
## 33            50             51 SemanticCategory      2.0000      1
## 34             0              0             &lt;NA&gt;      0.0000     -1
## 35            52             53             Freq      5.7459      1
## 36            54             55     Emotionality      1.0000      1
## 37            56             57     AudienceSize      1.0000      1
## 38             0              0             &lt;NA&gt;      0.0000     -1
## 39            58             59             Freq      0.6844      1
## 40            60             61 ConversationType      1.0000      1
## 41            62             63     AudienceSize      1.0000      1
## 42             0              0             &lt;NA&gt;      0.0000     -1
## 43            64             65     AudienceSize      1.0000      1
## 44            66             67           Gender      1.0000      1
## 45            68             69     Emotionality      2.0000      1
## 46            70             71             Freq      0.7032      1
## 47            72             73 SemanticCategory      3.0000      1
## 48            74             75 ConversationType      1.0000      1
## 49             0              0             &lt;NA&gt;      0.0000     -1
## 50            76             77     Emotionality      2.0000      1
## 51             0              0             &lt;NA&gt;      0.0000     -1
## 52             0              0             &lt;NA&gt;      0.0000     -1
## 53             0              0             &lt;NA&gt;      0.0000     -1
## 54            78             79     AudienceSize      1.0000      1
## 55             0              0             &lt;NA&gt;      0.0000     -1
## 56             0              0             &lt;NA&gt;      0.0000     -1
## 57             0              0             &lt;NA&gt;      0.0000     -1
## 58             0              0             &lt;NA&gt;      0.0000     -1
## 59             0              0             &lt;NA&gt;      0.0000     -1
## 60             0              0             &lt;NA&gt;      0.0000     -1
## 61             0              0             &lt;NA&gt;      0.0000     -1
## 62             0              0             &lt;NA&gt;      0.0000     -1
## 63             0              0             &lt;NA&gt;      0.0000     -1
## 64            80             81           Gender      1.0000      1
## 65             0              0             &lt;NA&gt;      0.0000     -1
## 66             0              0             &lt;NA&gt;      0.0000     -1
## 67             0              0             &lt;NA&gt;      0.0000     -1
## 68            82             83 ConversationType      1.0000      1
## 69             0              0             &lt;NA&gt;      0.0000     -1
## 70             0              0             &lt;NA&gt;      0.0000     -1
## 71            84             85              Age      1.0000      1
## 72             0              0             &lt;NA&gt;      0.0000     -1
## 73             0              0             &lt;NA&gt;      0.0000     -1
## 74             0              0             &lt;NA&gt;      0.0000     -1
## 75             0              0             &lt;NA&gt;      0.0000     -1
## 76             0              0             &lt;NA&gt;      0.0000     -1
## 77             0              0             &lt;NA&gt;      0.0000     -1
## 78             0              0             &lt;NA&gt;      0.0000     -1
## 79            86             87 SemanticCategory      2.0000      1
## 80            88             89         Function      1.0000      1
## 81             0              0             &lt;NA&gt;      0.0000     -1
## 82            90             91             Freq      0.9945      1
## 83             0              0             &lt;NA&gt;      0.0000     -1
## 84            92             93           Gender      1.0000      1
## 85            94             95 SemanticCategory      8.0000      1
## 86             0              0             &lt;NA&gt;      0.0000     -1
## 87            96             97             Freq      1.6575      1
## 88             0              0             &lt;NA&gt;      0.0000     -1
## 89             0              0             &lt;NA&gt;      0.0000     -1
## 90            98             99 SemanticCategory      1.0000      1
## 91             0              0             &lt;NA&gt;      0.0000     -1
## 92             0              0             &lt;NA&gt;      0.0000     -1
## 93             0              0             &lt;NA&gt;      0.0000     -1
## 94             0              0             &lt;NA&gt;      0.0000     -1
## 95             0              0             &lt;NA&gt;      0.0000     -1
## 96             0              0             &lt;NA&gt;      0.0000     -1
## 97             0              0             &lt;NA&gt;      0.0000     -1
## 98             0              0             &lt;NA&gt;      0.0000     -1
## 99             0              0             &lt;NA&gt;      0.0000     -1
##    prediction
## 1        &lt;NA&gt;
## 2        &lt;NA&gt;
## 3        &lt;NA&gt;
## 4        &lt;NA&gt;
## 5        &lt;NA&gt;
## 6        &lt;NA&gt;
## 7        &lt;NA&gt;
## 8           1
## 9           0
## 10          0
## 11       &lt;NA&gt;
## 12       &lt;NA&gt;
## 13       &lt;NA&gt;
## 14       &lt;NA&gt;
## 15          1
## 16          0
## 17       &lt;NA&gt;
## 18       &lt;NA&gt;
## 19       &lt;NA&gt;
## 20       &lt;NA&gt;
## 21       &lt;NA&gt;
## 22       &lt;NA&gt;
## 23       &lt;NA&gt;
## 24          0
## 25       &lt;NA&gt;
## 26          1
## 27          0
## 28       &lt;NA&gt;
## 29       &lt;NA&gt;
## 30       &lt;NA&gt;
## 31       &lt;NA&gt;
## 32       &lt;NA&gt;
## 33       &lt;NA&gt;
## 34          1
## 35       &lt;NA&gt;
## 36       &lt;NA&gt;
## 37       &lt;NA&gt;
## 38          0
## 39       &lt;NA&gt;
## 40       &lt;NA&gt;
## 41       &lt;NA&gt;
## 42          1
## 43       &lt;NA&gt;
## 44       &lt;NA&gt;
## 45       &lt;NA&gt;
## 46       &lt;NA&gt;
## 47       &lt;NA&gt;
## 48       &lt;NA&gt;
## 49          0
## 50       &lt;NA&gt;
## 51          0
## 52          0
## 53          1
## 54       &lt;NA&gt;
## 55          0
## 56          1
## 57          0
## 58          0
## 59          0
## 60          1
## 61          1
## 62          1
## 63          0
## 64       &lt;NA&gt;
## 65          1
## 66          0
## 67          1
## 68       &lt;NA&gt;
## 69          0
## 70          0
## 71       &lt;NA&gt;
## 72          1
## 73          0
## 74          0
## 75          1
## 76          1
## 77          0
## 78          0
## 79       &lt;NA&gt;
## 80       &lt;NA&gt;
## 81          0
## 82       &lt;NA&gt;
## 83          0
## 84       &lt;NA&gt;
## 85       &lt;NA&gt;
## 86          0
## 87       &lt;NA&gt;
## 88          0
## 89          0
## 90       &lt;NA&gt;
## 91          0
## 92          0
## 93          1
## 94          0
## 95          1
## 96          0
## 97          1
## 98          1
## 99          1</code></pre>
<pre class="r"><code># mds plot
MDSplot(reallyaus_rf2, test$really)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
</div>
<div id="example-2" class="section level2">
<h2><span class="header-section-number">7.2</span> Example 2:</h2>
<pre><code>##              Age        Adjective         Function          Priming 
##            0.001            0.005            0.012            0.000 
##           Gender ConversationType     AudienceSize             Freq 
##            0.002            0.003            0.002            0.011 
##       Gradabilty SemanticCategory     Emotionality 
##            0.000            0.004            0.001</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<pre class="r"><code># load library
library(Hmisc)
# evaluate random forst
reallyaus.rf.pred &lt;- unlist(treeresponse(reallyaus.rf))[c(FALSE,TRUE)]
somers2(reallyaus.rf.pred, as.numeric(rfd$really) - 1)</code></pre>
<pre><code>##        C      Dxy        n  Missing 
##   0.8069   0.6138 314.0000   0.0000</code></pre>
<pre class="r"><code>##     C         Dxy           n     Missing 
##0.8119422   0.6238843 314.0000000   0.0000000 </code></pre>
</div>
<div id="example-3" class="section level2">
<h2><span class="header-section-number">7.3</span> Example 3:</h2>
<pre class="r"><code>#                     RANDOM FOREST III
# load library
library(party)
# create data
randomforestdata &lt;- reallyaus

cf1 &lt;- cforest(really ~ . , data= randomforestdata, control=cforest_unbiased(mtry=2,ntree=100)) # fit the random forest
varimp(cf1) # get variable importance, based on mean decrease in accuracy</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0013913        0.0169565        0.0082609        0.0008696 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0053043        0.0046087        0.0040870        0.0253043 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0031304        0.0032174        0.0097391</code></pre>
<pre class="r"><code>varimp(cf1, conditional=TRUE) # conditional=True, adjusts for correlations between predict</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##       0.00034783       0.00834783       0.00582609      -0.00191304 
##           Gender ConversationType     AudienceSize             Freq 
##       0.00295652       0.00069565       0.00252174       0.01139130 
##       Gradabilty SemanticCategory     Emotionality 
##       0.00008696       0.00008696       0.00086957</code></pre>
<pre class="r"><code>varimpAUC(cf1)  # more robust towards class imbalance.</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0056743        0.0319284        0.0116915        0.0006288 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0108261        0.0076496        0.0093993        0.0415649 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0085987        0.0060204        0.0077188</code></pre>
<pre class="r"><code>par(mar = c(5, 8, 4, 2) + 0.1)
plot(y = 1:length(varimpAUC(cf1)), x = varimpAUC(cf1)[order(varimpAUC(cf1))], 
     axes = F, ann = F, pch = 20, xlim = c(-0.01, 0.05), main = &quot;Predictor Importance&quot;)
axis(1, at = seq(-0.01, 0.05, 0.005), seq(-0.01, 0.05, 0.005))
axis(2, at = 1:length(varimpAUC(cf1)), names(varimpAUC(cf1))[order(varimpAUC(cf1))], las = 2)
grid()
box()</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
</div>
</div>
<div id="boruta" class="section level1">
<h1><span class="header-section-number">8</span> Boruta</h1>
<pre class="r"><code># load library
library(Boruta)
# create dada for boruta
borutadata &lt;- reallyaus
# run 1
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 6.009 secs.
##  3 attributes confirmed important: Adjective, Freq, Function;
##  3 attributes confirmed unimportant: Age, Priming,
## SemanticCategory;
##  5 tentative attributes left: AudienceSize, ConversationType,
## Emotionality, Gender, Gradabilty;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq
## &lt;environment: 0x000000002f7da990&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<pre class="r"><code># remove superfluous variables
borutadata$Emotionality &lt;- NULL
borutadata$Priming &lt;- NULL
borutadata$Age &lt;- NULL
borutadata$SemanticCategory &lt;- NULL
# run2
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 5.27 secs.
##  4 attributes confirmed important: Adjective, Freq, Function,
## Gradabilty;
##  No attributes deemed unimportant.
##  3 tentative attributes left: AudienceSize, ConversationType,
## Gender;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x000000000cf70f90&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .75)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x000000000ac2a2b0&gt;</code></pre>
<pre class="r"><code>par(mar = c(10, 8, 4, 2) + 0.1)
plot(boruta.ampaus, cex.axis=.75, las=2, xlab=&quot;&quot;, ylab = &quot;&quot;, cex = .75, 
     col = c(&quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,  &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,&quot;grey90&quot;,&quot;grey90&quot;,&quot;grey90&quot;))
abline(v = 3.5, lty = &quot;dashed&quot;)
mtext(&quot;Predictors&quot;, 1, line = 8, at = 7, cex = 1)
mtext(&quot;Control&quot;, 1, line = 8, at = 2, cex = 1)
mtext(&quot;Importance&quot;, 2, line = 2.5, at = 2.5, cex = 1, las = 0)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-achen1982interpreting">
<p>Achen, Christopher H. 1982. <em>Interpreting and Using Regression</em>. Vol. 29. Sage.</p>
</div>
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. a Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-bortz2006statistik">
<p>Bortz, JÃ¼rgen. 2006. <em>Statistik: FÃ¼r Human-Und Sozialwissenschaftler</em>. Springer-Verlag.</p>
</div>
<div id="ref-bowerman1990linear">
<p>Bowerman, Bruce L, and Richard T OâConnell. 1990. <em>Linear Statistical Models: An Applied Approach</em>. Boston: PWS-Kent.</p>
</div>
<div id="ref-crawley2005statistics">
<p>Crawley, Michael J. 2005. <em>Statistics: An Introduction Using R. 2005</em>. Chichester, West Sussex: John Wiley &amp; Sons.</p>
</div>
<div id="ref-crawley2012r">
<p>âââ. 2012. <em>The R Book</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-faraway2002practical">
<p>Faraway, Julian J. 2002. <em>Practical Regression and Anova Using R.</em> University of Bath.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-green1991many">
<p>Green, Samuel B. 1991. âHow Many Subjects Does It Take to Do a Regression Analysis.â <em>Multivariate Behavioral Research</em> 26 (3). Taylor &amp; Francis: 499â510.</p>
</div>
<div id="ref-gries2009statistics">
<p>Gries, Stefan Th. 2009. <em>Statistics for Linguistics Using R: A Practical Introduction</em>. Berlin &amp; New York: Mouton de Gruyter.</p>
</div>
<div id="ref-menard1995applied">
<p>Menard, Scott. 1995. <em>Applied Logistic Regression Analysis: Sage University Series on Quantitative Applications in the Social Sciences</em>. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-myers1990classical">
<p>Myers, Raymond H. 1990. <em>Classical and Modern Regression with Applications</em>. Vol. 2. Duxbury Press Belmont, CA.</p>
</div>
<div id="ref-szmrecsanyi2006morphosyntactic">
<p>Szmrecsanyi, Benedikt. 2006. <em>Morphosyntactic Persistence in Spoken English: A Corpus Study at the Intersection of Variationist Sociolinguistics, Psycholinguistics, and Discourse Analysis</em>. Berlin &amp; New York: Walter de Gruyter.</p>
</div>
<div id="ref-wilcox2009basic">
<p>Wilcox, Rand R. 2009. <em>Basic Statistics: Understanding Conventional Methods and Modern Insights</em>. Oxford University Press.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. âA Protocol for Data Exploration to Avoid Common Statistical Problems.â <em>Methods in Ecology and Evolution</em> 1 (1): 3â14.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
