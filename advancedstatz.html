<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-02-19" />

<title>Advanced Inferential Statistics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Research Designs</li>
    <li>
      <a href="researchdesigns.html">Overview</a>
    </li>
    <li>
      <a href="corpling.html">Corpus Linguistics</a>
    </li>
    <li>
      <a href="experiments.html">Experimental Designs</a>
    </li>
    <li>
      <a href="ca.html">Conversation Analysis</a>
    </li>
    <li>
      <a href="acoustic.html">Acoustic Analysis</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Collection</li>
    <li>
      <a href="introdatacollection.html">Introduction</a>
    </li>
    <li>
      <a href="fieldwork.html">Field Work</a>
    </li>
    <li>
      <a href="interviews.html">Interviews</a>
    </li>
    <li>
      <a href="questionnaires.html">Questionnaires and Surveys</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="loading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization Techniques</a>
    </li>
    <li>
      <a href="advancedgraphs.html">Advanced Visualization Techniques</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Interential Statistics</a>
    </li>
    <li>
      <a href="advancedstatz.html">Advanced Interential Statistics</a>
    </li>
    <li>
      <a href="groupingstatz.html">Agglomerative Procedures</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topic.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
    <li>
      <a href="corplingantconcexcel.html">Corpus Linguistics with AntConc, TextPad and Excel</a>
    </li>
    <li>
      <a href="available.html">Available Software</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Advanced Inferential Statistics</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-02-19</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">1</span> Multiple Linear Regression</h1>
<p>In contrast to simple linear regression, which estimates the effect of a single predictor, multiple linear regression estimates the effect of various predictor (cf. equation ()). A multiple linear regression can thus test the effects of various predictors simultaneously.</p>
<span class="math display">\[\begin{equation}

f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon

\end{equation}\]</span>
<p>There exists a wealth of literature focusing on multiple linear regressions and the concepts it is based on. For instance, there are <span class="citation">(Achen <a href="#ref-achen1982interpreting">1982</a>)</span>, <span class="citation">(Bortz <a href="#ref-bortz2006statistik">2006</a>)</span>, <span class="citation">(Crawley <a href="#ref-crawley2005statistics">2005</a>)</span>, <span class="citation">(Faraway <a href="#ref-faraway2002practical">2002</a>)</span>, <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span> (my personal favourite), and <span class="citation">(Wilcox <a href="#ref-wilcox2009basic">2009</a>)</span> to name just a few. Introductions to regression modelling in <code>R</code> are <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>)</span>, <span class="citation">(Crawley <a href="#ref-crawley2012r">2012</a>)</span>, or <span class="citation">(Gries <a href="#ref-gries2009statistics">2009</a>)</span>.</p>
<p>The model diagnostics we are dealing with here are partly identical to the diagnostic methods discussed in the section on simple linear regression. Because of this overlap, diagnostics will only be described in more detail if they have not been described in the section on simple linear regression.</p>
<p>A brief note on minimum necessary sample or data set size appears necessary here. Although there appears to be a general assumption that 25 data points per group are sufficient, this is not necessarily correct (it is merely a general rule of thumb that is actually often incorrect). Such rules of thumb are inadequate because the required sample size depends on the number of variables in a given model, the size of the effect and the variance of the effect. If a model contains many variables, then this requires a larger sample size than a model which only uses very few predictors. Also, to detect an effect with a very minor effect size, one needs a substantially larger sample compared to cases where the effect is very strong. In fact, when dealing with small effects, model require a minimum of 600 cases to reliably detect these effects. Finally, effects that very robust and do not vary much require a much smaller sample size compared with effects that are spurious and vary substantially. Since the sample size depends on the effect size and variance as well as the number of variables, there is no final one-size-fits-all answer to what the best sample size is.</p>
<p>Another, slightly better but still incorrect, rule of thumb is that the more data, the better. This is not correct because models based on too many cases are prone for overfitting and thus report correlations as being significant that are not. However, given that there are procedures that can correct for overfitting, larger data sets are still preferable to data sets that are simply too small to warrant reliable results. In conclusion, it remains true that the sample size depends on the effect under investigation.</p>
<p>Despite there being no ultimate rule of thumb, <span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span> 273-275), based on <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>, provide data-driven suggestions for the minimal size of data required for regression models that aim to find medium sized effects (k = number of predictors; categorical variables with more than two levels should be transformed into dummy variables):</p>
<ul>
<li>If one is merely interested in the overall model fit (something I have not encountered), then the sample size should be at least 50 + k (k = number of predictors in model).</li>
<li>If one is only interested in the effect of specific variables, then the sample size should be at least 104 + k (k = number of predictors in model).</li>
<li>If one is only interested in both model fit and the effect of specific variables, then the sample size should be at least the higher value of 50 + k or 104 + k (k = number of predictors in model).</li>
</ul>
<p>You will see in the <code>R</code>-code below that there is already a function that test whether or not the sample size is sufficient. (include figure on <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 275)</span>).</p>
<div id="example-gifts-and-availability" class="section level2">
<h2><span class="header-section-number">1.1</span> Example: Gifts and Availability</h2>
<p>The example we will go through here is taken from <span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span>. In this example, the research question is if the money that men spend on presents for women depends on the women’s attractiveness and their relationship status. To answer this research question, we will implement a multiple linear regression and start by preparing the <code>R</code>-session (cleaning the workspace, setting options necessary, installing and activating necessary packages, and loading functions).</p>
<pre class="r"><code>rm(list=ls(all=T))                     # clean workspace
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)  # set options (supress math annotation)
#install.packages(&quot;ggplot2&quot;)           # install ggplot2 package (remove # to activate)
#install.packages(&quot;ggplot2&quot;)           # install car package (remove # to activate)
#install.packages(&quot;QuantPsyc&quot;)         # install QuantPsyc package (remove # to activate)
#install.packages(&quot;boot&quot;)              # install boot package (remove # to activate)
library(ggplot2)                       # activate ggplot2 package
library(car)                           # activate car package
library(QuantPsyc)                     # activate QuantPsyc package
library(boot)                          # activate boot package
source(&quot;rscripts/multiplot_ggplot2.r&quot;) # load function multiplot_ggplot2
source(&quot;rscripts/mlinr.summary.r&quot;)     # load function mlinr.summary
source(&quot;rscripts/SampleSizeMLR.r&quot;)     # load function SampleSizeMLR
source(&quot;rscripts/ExpR.r&quot;)              # load function ExpR</code></pre>
<p>After preparing the session, we can now load the data and inspect its structure and properties.</p>
<pre class="r"><code>mlrdata &lt;- read.delim(&quot;data/mlrdata.txt&quot;, header = TRUE) # load data
head(mlrdata)    # inspect first 6 lines</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code>str(mlrdata)     # inspect structure</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code>summary(mlrdata) # summarize data</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p>The data set consist of three variables stored in three columns. The first column contains the relationship status of the women, the second whether the man is interested in the woman, and the third column represents the money spend on the present. The data set represents 100 cases and the mean amount of money spend on a present is 88.38 dollars. In a next step, we visualize the data to get a more detailed impression of the relationships between variables.</p>
<pre class="r"><code># plot 1
p1 &lt;- ggplot(mlrdata,                   # create plot based on mlrdata
             aes(status, money)) +      # define x- and y-axes
  geom_boxplot(fill=c(&quot;gold&quot;, &quot;indianred4&quot;)) + # define colors
  theme_set(theme_bw(base_size = 8))+ # define theme (black and white theme)
  labs(x = &quot;&quot;) +                        # x-axis label
  labs(y = &quot;Money spent on present (AUD)&quot;, cex = .75) +   # y-axis label
  coord_cartesian(ylim = c(0, 250)) +   # y-axis range
  guides(fill = FALSE) +                # supress legend
  ggtitle(&quot;Status&quot;)                     # define title
# plot 2
p2 &lt;- ggplot(mlrdata,                   # create plot based on mlrdata
             aes(attraction, money)) +  # define x- and y-axes
  geom_boxplot(fill=c(&quot;grey30&quot;, &quot;grey70&quot;)) +  # define colors
theme_set(theme_bw(base_size = 8))+    # define theme (black and white theme)
  labs(x = &quot;&quot;) +                        # x-axis label
  labs(y = &quot;Money spent on present (AUD)&quot;) +  # y-axis label
  coord_cartesian(ylim = c(0, 250)) +   # y-axis range
  guides(fill = FALSE) +                # supress legend
  ggtitle(&quot;Attraction&quot;)                 # define title
# plot 3
p3 &lt;- ggplot(mlrdata,                   # create plot based on mlrdata
             aes(x = money)) +          # define y-axis
  geom_histogram(aes(y=..density..),    # add density statistic
                 binwidth = 10,         # define bin width
                 colour = &quot;black&quot;,      # define bar edge colour
                 fill = &quot;white&quot;) +      # define bar colour
    theme_bw() +                        # black-white theme
  geom_density(alpha=.2, fill = &quot;#FF6666&quot;) # define colour of transparent overlay
# plot 4
p4 &lt;- ggplot(mlrdata, aes(status, money)) +    # create plot based on mlrdata
  geom_boxplot(notch = F, aes(fill = factor(status))) + # cerate boxplot
  scale_fill_brewer(palette=&quot;Set1&quot;) +          # define colour palette
  facet_wrap(~ attraction, nrow = 1) +         # cerate separate panels for attraction
theme_set(theme_bw(base_size = 8)) +          # define theme (black and white theme)
  labs(x = &quot;&quot;) +                               # define x-axis label
  labs(y = &quot;Money spent on present (Euro)&quot;) +  # define y-axis label
  coord_cartesian(ylim = c(0, 250)) +          # define y-axis range
  guides(fill = FALSE)                         # supress legend
multiplot(p1, p3, p2, p4, cols = 2)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The upper left figure consists of a boxplot which shows how much money was spent based on the relationship status of the moan. The figure suggests that men spend more on women who are not in a relationship. The next figure shows the relationship between the money spend on presents and whether or not the men were interested in the women.</p>
<p>The boxplot in the upper right panel suggests that men spend substantially more on women if the men are interested in them. The next figure depicts the distribution of the amounts of money spend on women. In addition, the figure indicates the existence of two outliers (dots in the boxplot)</p>
<p>The histogram in the lower left panel shows that, although the mean amount of money spent on presents is 88.38 dollars, the distribution peaks around 50 dollars indicating that on average, men spend about 50 dollars on presents. Finally, we will plot the amount of money spend on presents against relationship status by attraction in order to check whether the money spent on presents is affected by an interaction between attraction and relationship status.</p>
<p>The boxplot in the lower right panel confirms the existence of an interaction (a non-additive term) as men only spend more money on single women if the men are interested in the women. If men are not interested in the women, then the relationship has no effect as they spend an equal amount of money on the women regardless of whether they are in a relationship or not.</p>
<p>We will now start to implement the regression model. In a first step, we initialize four base-line models: two minimal base-line models that only use the intercept as their sole predictor and two saturated base-line models that contain all possible predictors. The model pairs are generated with the <code>lm</code> and the <code>glm</code> function as these functions offer different model parameters in their output.</p>
<pre class="r"><code>m0.mlr = lm(                       # generate regression object using the lm function
  money ~ 1,                       # define rgression formula (1 = intercept) 
  data = mlrdata)                  # define data set
m0.glm = glm(                      # generate regression object using the glm function
  money ~ 1,                       # define rgression formula (1 = intercept) 
  family = gaussian,               # define linkage function
  data = mlrdata)                  # define data set
m1.mlr = lm(                       # generate regression object using the lm function
  money ~ (status + attraction)^2, # define rgression formula
  data = mlrdata)                  # define data set
m1.glm = glm(                      # generate regression object using the glm function
  money ~ status * attraction,     # define rgression formula 
  family = gaussian,               # define linkage function
  data = mlrdata)                  # define data set</code></pre>
<p>After generating the saturated base-line models we can now start with the model fitting. Model fitting refers to a process that aims at find the model that explains a maximum of variance with a minimum of predictors <span class="citation">(cf. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 318)</span>. Model fitting is therefore based on the <em>principle of parsimony</em> which is related to Occam’s razor according to which explanations that require fewer assumptions are more likely to be true.</p>
</div>
<div id="automatic-model-fitting" class="section level2">
<h2><span class="header-section-number">1.2</span> Automatic Model Fitting</h2>
<p>In this section, we will use a step-wise step-down procedure that uses decreases in AIC (Akaike information criterion) as the criterion to minimize the model in a step-wise manner. This procedure aims at finding the model with the lowest AIC values by evaluating - step-by-step - whether the removal of a predictor (term) leads to a lower AIC value.</p>
<p>The AIC is calculated using the equation below. The lower the AIC value, the better the balance between explained variance and the number of predictors. AIC values can and should only be compared for models that are fit on the same dataset with the same (number of) cases (<span class="math inline">\(LL\)</span> stands for LogLikelihood and <span class="math inline">\(k\)</span> represents the number of predictors in the model).</p>
<span class="math display">\[\begin{equation}

-2LL + 2k
\label{eq:aic}

\end{equation}\]</span>
<p>Interactions are evaluated first and only if all interactions have been removed would the procedure start removing main effects. Other model fitting procedures (forced entry, step-wise step up, hierarchical) are discussed during the implementation of other regression models. We cannot discuss all procedures here as model fitting is rather complex and a discussion of even the most common procedures would to lengthy and time consuming at this point. It is important to note though that there is not perfect model fitting procedure and automated approaches should be handled with care as they are likely to ignore violations of model parameters that can be detected during manual - but time consuming - model fitting procedures. As a general rule of thumb, it is advisable to fit models as carefully and deliberately as possible. We will now begin to fit the model.</p>
<pre class="r"><code>step(m1.mlr, direction = &quot;both&quot;) # automated AIC based model fitting</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<p>The automated model fitting procedure informs us that removing predictors ahs not caused a decrease in the AIC. The saturated model is thus also the final minimal adequate model. We will now inspect the final minimal model and go over the model report.</p>
<pre class="r"><code>m2.mlr = lm(                       # generate regression object using the lm function
  money ~ (status + attraction)^2, # define regression formula
  data = mlrdata)                  # define data set
m2.glm = glm(                      # generate regression object using the glm function
  money ~ (status + attraction)^2, # define regression formula  
  family = gaussian,               # define linkage function 
  data = mlrdata)                  # define data set
summary(m2.mlr)                    # inspect final minimal model</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<p>The first element of the report is called <em>Call</em> and it reports the regression formula of the model. Then, the report provides the residual distribution (the range, median and quartiles of the residuals) which allows drawing inferences about the distribution of differences between observed and expected values. If the residuals are distributed unevenly, then this is a strong indicator that the model is unstable and unreliable because mathematical assumptions on which the model is based are violated.</p>
<p>Next, the model summary reports the most important part: a table with model statistics of the fixed-effects structure of the model. The table contains the estimates (coefficients of the predictors), standard errors, t-values, and the p-values which show whether a predictor significantly correlates with the dependent variable that the model investigates.</p>
<p>All main effects (status and attraction) as well as the interaction between status and attraction is reported as being significantly correlated with the dependent variable (money). An interaction occurs if a correlation between the dependent variable and a predictor is affect by another predictor.</p>
<p>The top most term is called intercept and has a value of 99.15 which represents the base estimate to which all other estimates refer. To exemplify what this means, let us consider what the model would predict a man would spend on a present for a women who is single but the man is not attracted to her: The amount he would spend (based on the model would be 99.15 dollars (the intercept) plus 57.69 dollars (because she is single) minus 47.66 dollars (because he is not interested in her) minus 63.18 dollars because of the interaction between status and attraction.</p>
<pre class="r"><code>#intercept  Single  NotInterested  Single:NotInterested
99.15     + 57.69  + 0           + 0     # 156.8 single + interested </code></pre>
<pre><code>## [1] 156.8</code></pre>
<pre class="r"><code>99.15     + 57.69  - 47.66       - 63.18 # 46.00 single + not interested</code></pre>
<pre><code>## [1] 46</code></pre>
<pre class="r"><code>99.15     - 0      + 0           - 0     # 99.15 relationship + interested</code></pre>
<pre><code>## [1] 99.15</code></pre>
<pre class="r"><code>99.15     - 0      - 47.66       - 0     # 51.49 relationship + not interested</code></pre>
<pre><code>## [1] 51.49</code></pre>
<p>Interestingly, the model predicts that a man would invest even less money in a woman that he is not interested in if she were single compared to being in a relationship! We can derive the same results easier using the <code>predict</code> function.</p>
<pre class="r"><code>prediction &lt;- predict(m2.mlr,            # make prediction based on the model
                      newdata = mlrdata) # for original data
table(round(prediction,2))               # inspect predictions</code></pre>
<pre><code>## 
##  46.01  51.49  99.15 156.85 
##     25     25     25     25</code></pre>
<p>Below the table of coefficient, the summary reports model statistics that provide information about how well the model performs. The difference between the values and the values in the coefficients table is that the model statistics refer to the model as a whole rather than focusing on individual predictors.</p>
<p>The multiple R<sup>2</sup>-value is a measure of how much variance the model explains. A multiple R<sup>2</sup>-value of 0 would inform us that the model does not explain any variance while a value of .852 mean that the model explains 85.2 percent of the variance. A value of 1 would inform us that the model explains 100 percent of the variance and that the predictions of the model match the observed values perfectly. Multiplying the multiple R<sup>2</sup>-value thus provides the percentage of explained variance. Models that have a multiple R<sup>2</sup>-value equal or higher than .05 are deemed substantially significant <span class="citation">(cf Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 55)</span>. It has been claimed that models should explain a minimum of 5 percent of variance but this is problematic as itis not uncommon for models to have very low explanatory power while still performing significantly and systematically better than chance. In addition, the total amount of variance is negligible in cases where one is interested in very weak but significant effects. It is much more important for model to perform significantly better than minimal base-line models because if this is not the case, then the model does not have any predictive and therefore no explanatory power.</p>
<p>The adjusted R<sup>2</sup>-value considers the amount of explained variance in light of the number of predictors in the model (it is thus somewhat similar to the AIC and BIC) and informs about how well the model would perform if it were applied to the population that the sample is drawn from. Ideally, the difference between multiple and adjusted R<sup>2</sup>-value should be very small as this means that the model is not overfitted. If, however, the difference between multiple and adjusted R<sup>2</sup>-value is substantial, then this would strongly suggest that the model is instable and overfitted to the data while being inadequate for drawing inferences about the population. Differences between multiple and adjusted R<sup>2</sup>-values indicate that the data contains outliers that cause the distribution of the data on which the model is based to differ from the distributions that the model mathematically requires to provide reliable estimates. The difference between multiple and adjusted R<sup>2</sup>-value in our model is very small (85.2-84.7=.05) and should not cause concern.</p>
<p>Before continuing, we will calculate the confidence intervals of the coefficients.</p>
<pre class="r"><code>confint(m2.mlr)       # extract confidence intervals of the coefficients</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre class="r"><code>anova(m0.mlr, m2.mlr) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Now, we compare the final minimal adequate model to the base-line model to test whether then final model significantly outperforms the baseline model.</p>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The comparison between the two model confirms that the minimal adequate model performs significantly better (makes significantly more accurate estimates of the outcome variable) compared with the baseline model.</p>
</div>
<div id="outlier-detection" class="section level2">
<h2><span class="header-section-number">1.3</span> Outlier Detection</h2>
<p>After implementing the multiple regression, we now need to look for outliers and perform the model diagnostics by testing whether removing data points disproportionately decreases model fit. To begin with, we generate diagnostic plots.</p>
<pre class="r"><code># start plotting
par(mfrow = c(1, 4))           # display plots in 3 rows and 2 columns
plot(m2.mlr)                   # plot fitted values</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original 1 plot per row and column settings</code></pre>
<pre class="r"><code># determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
# start plotting
par(mfrow = c(1, 2))           # display plots in 3 rows and 2 columns
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;) # cerate qq-plot</code></pre>
<pre><code>## [1] 52 83</code></pre>
<pre class="r"><code>plot(m2.mlr, which=4, cook.levels = cutoff) # plot cook*s distance</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original 1 plot per row and column settings</code></pre>
<p>The graphs indicate that data points 52, 64, and 83 may be problematic. We will therefore statistically evaluate whether these data points need to be removed. In order to find out which data points require removal, we extract the influence measure statistics and add them to out data set.</p>
<pre class="r"><code>infl &lt;- influence.measures(m2.mlr)       # extract influence statistics
mlrdata &lt;- data.frame(mlrdata, infl[[1]], infl[[2]]) # add infl. statistics to data
# annotate too influential data points
remove &lt;- apply(infl$is.inf, 1, function(x) {
  ifelse(x == TRUE, return(&quot;remove&quot;), return(&quot;keep&quot;)) } )
mlrdata &lt;- data.frame(mlrdata, remove)   # add annotation to data
nrow(mlrdata)                            # number of rows before removing outliers</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>mlrdata &lt;- mlrdata[mlrdata$remove == &quot;keep&quot;, ] # remove outliers
nrow(mlrdata)                             # number of rows after removing outliers</code></pre>
<pre><code>## [1] 98</code></pre>
<p>The difference in row in the data set before and after removing data points indicate that two data points which represented outliers have been removed.</p>
</div>
<div id="rerun-regression" class="section level2">
<h2><span class="header-section-number">1.4</span> Rerun Regression</h2>
<p>As we have a different data set now, we need to rerun the regression analysis. As the steps are identical to the regression analysis performed above, the steps will not be described in greater detail.</p>
<pre class="r"><code>m0.mlr = lm(                       # generate regression object using the lm function
  money ~ 1,                       # define regression formula (1 = intercept) 
  data = mlrdata)                  # define data set
m0.glm = glm(                      # generate regression object using the glm function
  money ~ 1,                       # define regression formula (1 = intercept) 
  family = gaussian,               # define linkage function
  data = mlrdata)                  # define data set
m1.mlr = lm(                       # generate regression object using the lm function
  money ~ (status + attraction)^2, # define regression formula
  data = mlrdata)                  # define data set
m1.glm = glm(                      # generate regression object using the glm function
  money ~ status * attraction,     # define regression formula 
  family = gaussian,               # define linkage function
  data = mlrdata)                  # define data set
step(m1.mlr, direction = &quot;both&quot;)   # automated AIC based model fitting</code></pre>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre class="r"><code>m2.mlr = lm(                       # generate regression object using the lm function
  money ~ (status + attraction)^2, # define regression formula
  data = mlrdata)                  # define data set
m2.glm = glm(                      # generate regression object using the glm function
  money ~ status * attraction,     # define regression formula 
  family = gaussian,               # define linkage function
  data = mlrdata)                  # define data set
summary(m2.mlr)                    # inspect final minimal model</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code>confint(m2.mlr)       # extract confidence intervals of the coefficients</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre class="r"><code>anova(m0.mlr, m2.mlr)               # compare baseline with final model</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;) # compare baseline with final model</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="additional-model-diagnostics" class="section level2">
<h2><span class="header-section-number">1.5</span> Additional Model Diagnostics</h2>
<p>After rerunning the regression analysis on the updated data set, we again cerate diagnostic plots in order to check whether there are potentially problematic data points.</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2))           # display plots in 2 rows and 2 columns
plot(m2.mlr)                   # plot fitted values</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original 1 plot per row and column settings</code></pre>
<pre class="r"><code># determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
# start plotting
par(mfrow = c(1, 2))           # display plots in 1 row and 2 columns
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;) # cerate qq-plot</code></pre>
<pre><code>## 84 88 
## 82 86</code></pre>
<pre class="r"><code>plot(m2.mlr, which=4, cook.levels = cutoff) # plot cook*s distance</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original 1 plot per row and column settings</code></pre>
<p>Although the diagnostic plots indicate that additional points may be problematic, but these data points deviate substantially less from the trend than was the case with the data points that have already been removed. To make sure that retaining the data points that are deemed potentially problematic by the diagnostic plots, is acceptable, we extract diagnostic statistics and add them to the data.</p>
<pre class="r"><code># addieren von modelldiagnostiken zum datasatz
mlrdata$residuals &lt;- resid(m2.mlr)
mlrdata$standardized.residuals &lt;- rstandard(m2.mlr)
mlrdata$studentized.residuals &lt;- rstudent(m2.mlr)
mlrdata$cooks.distance &lt;- cooks.distance(m2.mlr)
mlrdata$dffit &lt;- dffits(m2.mlr)
mlrdata$leverage &lt;- hatvalues(m2.mlr)
mlrdata$covariance.ratios &lt;- covratio(m2.mlr)
mlrdata$fitted &lt;- m2.mlr$fitted.values</code></pre>
<p>We can now use these diagnostic statistics to create more precise diagnostic plots.</p>
<pre class="r"><code># plot 5
p5 &lt;- ggplot(mlrdata, 
             aes(studentized.residuals)) +
  theme(legend.position = &quot;none&quot;) +
  theme_set(theme_bw(base_size = 8))+    # define theme (black and white theme)
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour=&quot;black&quot;,
                 fill=&quot;white&quot;) +
  labs(x = &quot;Studentized Residual&quot;, y = &quot;Density&quot;) + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(mlrdata$studentized.residuals, na.rm = TRUE), 
                            sd = sd(mlrdata$studentized.residuals, na.rm = TRUE)), 
                colour = &quot;red&quot;, size = 1)
# plot 6
p6 &lt;- ggplot(mlrdata, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;)+
    theme_set(theme_bw(base_size = 8))+    # define theme (black and white theme)
  labs(x = &quot;Fitted Values&quot;, 
       y = &quot;Studentized Residual&quot;)
# plot 7
p7 &lt;- qplot(sample = mlrdata$studentized.residuals, stat=&quot;qq&quot;) + 
    theme_set(theme_bw(base_size = 8))+    # define theme (black and white theme)
  labs(x = &quot;Theoretical Values&quot;, 
       y = &quot;Observed Values&quot;)
multiplot(p5, p6, p7, cols = 3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>The new diagnostic plots do not indicate outliers that require removal. With respect to such data points the following parameters should be considered:</p>
<ul>
<li><p>Data points with standardised residuals &gt; 3.29 should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>If more than 1 percent of data points have standardized residuals exceeding values &gt; 2.58, then the error rate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span>.</p></li>
<li><p>If more than 5 percent of data points have standardized residuals exceeding values &gt; 1.96, then the error rate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>In addition, data points with Cook’s D-values &gt; 1 should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>Also, data points with leverage values <span class="math inline">\(3(k + 1)/n\)</span> (k = Number of predictors, N = Number of cases in model) should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 270)</span></p></li>
<li><p>There should not be (any) autocorrelation among predictors. This means that independent variables cannot be correlated with itself (for instance, because data points come from the same subject). If there is autocorrelation among predictors, then a Repeated Measures Design or a (hierarchical) mixed-effects model should be implemented instead.</p></li>
<li><p>Predictors cannot substantially correlate with each other (multicollinearity). If a model contains predictors that have variance inflation factors (VIF) &gt; 10 the model is completely unreliable <span class="citation">(Myers <a href="#ref-myers1990classical">1990</a>)</span> and predictors causing such VIFs should be removed. Indeed, even VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol">2010</a>)</span> proposes that variables with VIFs exceeding 3 should be removed!</p></li>
<li><p>Data points with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard <a href="#ref-menard1995applied">1995</a>)</span>.</p></li>
<li><p>The mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and O’Connell <a href="#ref-bowerman1990linear">1990</a>)</span>.</p></li>
</ul>
<pre class="r"><code># 1: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$standardized.residuals &gt; 3.29)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 2: optimal = 1
# (listed data points should be removed)
stdres_258 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 2.58, 1, 0) } ))
(sum(stdres_258) / length(stdres_258)) * 100</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># 3: optimal = 5
# (listed data points should be removed)
stdres_196 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 1.96, 1, 0) } ))
(sum(stdres_196) / length(stdres_196)) * 100</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre class="r"><code># 4: optimal = 0
# (listed data points should be removed)
which(mlrdata$cooks.distance &gt; 1)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 5: optimal = 0
# (data points should be removed if cooks distance is close to 1)
which(mlrdata$leverage &gt;= (3*mean(mlrdata$leverage)))</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 6: checking autocorrelation:
# Durbin-Watson test (optimal: grosser p-wert)
dwt(m2.mlr)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968    0.64
##  Alternative hypothesis: rho != 0</code></pre>
<pre class="r"><code># 7: test multicolliniarity 1
vif(m2.mlr)</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre class="r"><code># 8: test multicolliniarity 2
1/vif(m2.mlr)</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre class="r"><code># 9: mean vif should not exceed 1 
mean(vif(m2.mlr))</code></pre>
<pre><code>## [1] 2.307</code></pre>
<p>Except for the mean VIF value (2.307) which should not exceed 1, all diagnostics are acceptable. We will now test whether the sample size is sufficient for our model. With respect to the minimal sample size and based on <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>, <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 273–74)</span> offer the following rules of thumb (k = number of predictors; categorical predictors with more than two levels should be recoded as dummy variables):</p>
</div>
<div id="evaluation-of-sample-size" class="section level2">
<h2><span class="header-section-number">1.6</span> Evaluation of Sample Size</h2>
<p>After performing the diagnostics, we will now test whether the sample size is adequate and what the values of <code>R</code> would be based on a random distribution in order to be able to estimate how likely a <span class="math inline">\(\beta\)</span>-error is given the present sample size <span class="citation">(cf. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 274)</span>. Beta errors (or <span class="math inline">\(\beta\)</span>-errors) refer to the erroneous assumption that a predictor is not significant (based on the analysis and given the sample) although it does have an effect in the population. In other words, <span class="math inline">\(\beta\)</span>-error means to overlook a significant effect because of weaknesses of the analysis. The test statistics ranges between 0 and 1 where lower values are better. If the values approximate 1, then there is serious concern as the model is not reliable given the sample size. In such cases, unfortunately, the best option is to increase the sample size.</p>
<pre class="r"><code>smplesz(m2.mlr) # check if sample size is sufficient</code></pre>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre class="r"><code>expR(m2.mlr)    # check for beta-error likelihood </code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<p>The function <code>smplesz</code> reports that the sample size is insufficient by 9 data points according to <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>. The likelihood of <span class="math inline">\(\beta\)</span>-errors, however, is very small (0.0309). As a last step, we summarize the results of the regression analysis.</p>
<pre class="r"><code>mlrsummary &lt;- mlr.summary(m2.mlr, m2.glm, ia = T)  # tabulate regression results
mlrsummary[,-c(4:5)]</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%)      t value
## (Intercept)                             99.15          92.1        27.56
## statusSingle                            55.85    2    45.78        10.87
## attractionNotInterested                -47.66 1.96   -57.63        -9.37
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71        -8.18
## Model statistics                                                        
## Number of cases in model                                                
## Residual Standard Error on 94 DF                                        
## Multiple R2                                                             
## Adjusted R2                                                             
## AIC                                                                     
## BIC                                                                     
## F-statistic                                                 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>
<p>(Falls signifikante Interaktionen vorliegen, sollten die Haupteffekte der Prädikatoren, die an der/n Interaktion/en beteiligt sind, nicht interpretiert werden. Sie werden hier dennoch interpretiert, um zu verdeutlichen, wie die Ergebnisse einer multiplen linearen Regression verschriftlicht werden können.)</p>
<p>The results of the regression analysis can be summarized as follows:</p>
<p>A multiple linear regression was fitted to the data in a step-wise step-down, AIC-based (Akaike’s Information Criterion) procedure to the data and arrived at a final minimal model. During the model diagnostics, two outliers were detected and removed. Further diagnostics did not find other issues after the removal. The final minimal adequate regression model is based on 98 data points and performs highly significantly better than a minimal baseline model (Multiple R<sup>2</sup>: .857, Adjusted R<sup>2</sup>: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p&lt;.001<span class="math inline">\(***\)</span>). The final minimal adequate regression model reports <em>attraction</em> and <em>status</em> as significant main effects. The relationship status of women correlates highly significantly and positively with the amount of money spend on the women’s presents (SE: 5.14, t-value: 10.87, p&lt;.001<span class="math inline">\(***\)</span>). This shows that men spend 156.8 dollars on presents are single while they spend 99,15 dollars if the women are in a relationship. Whether men are attracted to women also correlates highly significantly and positively with the money they spend on women (SE: 5.09, t-values: -9.37, p&lt;.001<span class="math inline">\(***\)</span>). If men are not interested in women, they spend 47.66 dollar less on a present for women compared with women the men are interested in.</p>
<p>Furthermore, the final minimal adequate regression model reports a highly significant interaction between relationship <em>status</em> and <em>attraction</em> (SE: 7.27, t-value: -8.18, p&lt;.001<span class="math inline">\(***\)</span>): If women are single but man are not interested in them, men spend 59.46 dollars less on their presents compared to all other constellations.</p>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.7</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Download the data set called <code>exdatamlr</code> from <code>http://martinschweinberger.de/docs/data/exdatamlr.txt</code> and apply what you have learned by implementing a multiple linear regression model so that you can answer how movement (move) and food intake (food) affect weight (given the data at hand).</li>
</ol>
</div>
</div>
<div id="linear-mixed-effects-regression-models" class="section level1">
<h1><span class="header-section-number">2</span> Linear Mixed-Effects Regression Models </h1>
<p>The following focuses on an extension of ordinary multiple linear regressions: mixed-effects regression linear regression. Mixed-effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of mixed-effects regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. having only fixed-effects means that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristic. In such cases, the data is considered hierarchical and statistical models should incorporate such structural features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope (as in the left panel in the figure below), while mixed effects models have intercepts for each level of a random effect. If the random effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and or slope for each speaker.</p>
<pre class="r"><code># random intercepts and random slops
x &lt;- 0:10
y = 0:10
# start plot
par(mfrow = c(1, 4))
# intercepts
plot(x, y, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ylab=&#39;Weight&#39;, xlab = &quot;Height&quot;, xlim = c(0, 10), ylim = c(-5, 10))
axis(2, seq(-5,10, 5), seq(50, 110, 20))
abline(0, 1, lty = 1, col =&quot;black&quot;)
mtext(&quot;Fixed-Effects Model:\n1 Intercept + 1 Slope&quot;, 1, 2, cex = .6)
box()
# random intercepts
plot(x, y, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, xlim = c(0, 10), ylim = c(-5, 10))
abline(4, 1, col =&quot;black&quot;)
abline(2, 1, col =&quot;black&quot;)
abline(2, 1, col =&quot;black&quot;)
abline(0, 1, col =&quot;black&quot;)
abline(-1, 1, col =&quot;black&quot;)
abline(-2, 1, col =&quot;black&quot;)
abline(-4, 1, col =&quot;black&quot;)
mtext(&quot;Mixed-Effects Model:\n1 Intercept per Random Effect Level\n+ 1 Slope&quot;, 1, 3, cex = .6)
box()
# random slopes
plot(x, y, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, xlim = c(0, 10), ylim = c(-5, 10))
abline(0, 1.75, col =&quot;black&quot;)
abline(0, 1.5, col =&quot;black&quot;)
abline(0, 1.25, col =&quot;black&quot;)
abline(0, 0, col =&quot;black&quot;)
abline(0, -.25, col =&quot;black&quot;)
abline(0, -.5, col =&quot;black&quot;)
abline(0, -.75, col =&quot;black&quot;)
mtext(&quot;Mixed-Effects Model:\n1 Intercept\n+ 1 Slope per Random Effect Level&quot;, 1, 3, cex = .6)
box()
# random slopesund random intercepts
plot(x, y, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, xlim = c(0, 10), ylim = c(-5, 10))
abline(2, 1.75, col =&quot;black&quot;)
abline(-1, 1.5, col =&quot;black&quot;)
abline(1, 1.25, col =&quot;black&quot;)
abline(4, 0, col =&quot;black&quot;)
abline(-4, -.25, col =&quot;black&quot;)
abline(0, -.5, col =&quot;black&quot;)
abline(-1, -.75, col =&quot;black&quot;)
mtext(&quot;Mixed-Effects Model:\n1 Intercept per Random Effect Level\n+ 1 Slope per Random Effect Level&quot;, 1, 3, cex = .6)
box()</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code># restore original graphic&#39;s parameters
par(mfrow = c(1, 1))</code></pre>
<p><em>Random Effects</em> have two parameters: the intercept (the point where the regression line cross the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models have only 1 intercept and one slope (left panel of the Figure above) while mixed-effects models can have various <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<pre class="r"><code>Height &lt;- c(169, 176, 164, 160, 158, 173, 166, 161, 180, 187, 170, 177, 163, 161, 157)
Weight &lt;- c(68, 72, 65, 62, 60, 80, 75, 70, 85, 92, 88, 92, 85, 82, 80) # plot scatterplot and the regression line
z &lt;- c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;)
tb &lt;- data.frame(Height,Weight, z)
a &lt;- tb[z == &quot;a&quot;, ]
a &lt;- a[, 1:2]
b &lt;- tb[z == &quot;b&quot;, ]
b &lt;- b[, 1:2]
c &lt;- tb[z == &quot;c&quot;, ]
c &lt;- c[, 1:2]
d &lt;- tb[, 1:2]
# plot
par(mfrow = c(1, 3))
# plot 1
plot(a, xlim = c(150, 200), ylim = c(50, 100))
text(b[,1], b[,2], &quot;+&quot;)
text(c[,1], c[,2], &quot;*&quot;)
# plot 2
plot(a, xlim = c(150, 200), ylim = c(50, 100))
mod0 &lt;- lm(d$Weight ~ d$Height, data = d)
abline(mod0, lty=1, col = &quot;black&quot;)
text(b[,1], b[,2], &quot;+&quot;)
text(c[,1], c[,2], &quot;*&quot;)
# plot 3
plot(a, xlim = c(150, 200), ylim = c(50, 100))
grid()
mod1 &lt;- lm(a$Weight ~ a$Height, data = a)
abline(mod0, lty=1, col = &quot;black&quot;)
abline(mod0[[1]][[1]]+10, mod0[[1]][[2]], lty = 2, col = &quot;red&quot;)
abline(mod0[[1]][[1]]-10, mod0[[1]][[2]], lty = 3, col = &quot;blue&quot;)
abline(mod0[[1]][[1]]-1, mod0[[1]][[2]], lty = 4, col = &quot;green&quot;)
text(b[,1], b[,2], &quot;+&quot;)
text(c[,1], c[,2], &quot;*&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>The left panel merely shows the data while the centre panel includes the regression line for a regression that estimates Weight based on Height. The right panel shows the regression line and, in addition, random intercepts each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the depended variable solely on the base intercept (the mean), with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">2.2</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in <code>R</code> we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load necessary <code>R</code> packages, specify options, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(RLRsim)
#library(car)
#library(QuantPsyc)
#library(boot)
library(nlme)
library(lme4)
#library(ez)
library(ggplot2)
# set options
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      # supress scientific notation
options(stringsAsFactors = F)              # do not convert strings into factors
mydata &lt;- read.delim(&quot;data/lmemdata.txt&quot;, header = TRUE) # read in data
mydata$date &lt;- as.numeric(mydata$date)     # convert date into a numeric variable
head(mydata); nrow(mydata)                 # inspect updated data set</code></pre>
<pre><code>##   date         genre    text  pptw region
## 1 1736 SCIENCE_OTHER   albin 166.0  north
## 2 1711 EDUC_TREATISE    anon 139.9  north
## 3 1808  LETTERS_PRIV  austen 130.8  north
## 4 1878 EDUC_TREATISE    bain 151.3  north
## 5 1743 EDUC_TREATISE barclay 145.7  north
## 6 1908 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (<code>date</code>), the genre of the text (<code>genre</code>), the name of the text (<code>text</code>), the relative frequency of prepositions in the text (<code>pptw</code>), and the region in which the text was written (<code>region</code>). We now plot the data to get a first impression of its structure.</p>
<pre class="r"><code># visualize variables (2 plots per row)
# 3 plots in 1 window
def.par &lt;- par(no.readonly = TRUE)
nf &lt;- layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = T))
plot(mydata$pptw ~ mydata$date, ylab = &quot;Frequency&quot;, xlab = &quot;year of publication&quot;)
abline(lm(mydata$pptw ~ mydata$date), lty = 3, lwd = 2, col = &quot;red&quot;)
# re-set margins to fit the labels
par(mar = c(7.2, 4, 1, 2) + 0.1)
# reorder genre by median
genrebymedian &lt;- with(mydata, reorder(genre, -pptw, median))
#   generate plots
plot(mydata$pptw ~ genrebymedian,
  col = &quot;lightgrey&quot;,
  ylab = &quot;Frequency&quot;,
  xlab = &quot;&quot;,
  las = 2,
  cex.axis = .7,
  cex = .5)
# re-set margins
par(mar = c(5, 4, 1, 2) + 0.1)
x = mydata$pptw
h = hist(mydata$pptw,
    ylim =c(0, 150),
    xlim = c(50, 200),
    xlab = &quot;prepositions per text&quot;,
    col = &quot;lightgrey&quot;,
    main = &quot;&quot;)
xfit &lt;- seq(min(mydata$pptw), max(mydata$pptw), length = 40)
yfit &lt;- dnorm(xfit, mean = mean(mydata$pptw),sd = sd(mydata$pptw))
yfit &lt;- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, lty = 2, lwd=2)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre class="r"><code># restore original graphic&#39;s parameters
par(def.par)</code></pre>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderately increased over time while the boxplots in the lower left panel show that the genres differ quite substantially with respect to their median frequencies of prepositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<pre class="r"><code># plot 8
p8 &lt;- ggplot(mydata, aes(date, pptw)) +
  geom_point() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;)  + 
  theme_set(theme_bw(base_size = 10))
# plot 9
p9 &lt;- ggplot(mydata, aes(region, pptw)) +
  geom_boxplot() +
  labs(x = &quot;Region&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;) # with linear model smoothing!
# include genre (lowess)
multiplot(p8, p9, cols = 2)</code></pre>
<p><img src="advancedstatz_files/figure-html/plotprep2-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mydata, aes(date, pptw)) +
  geom_point() +
  facet_wrap(~ genre, nrow = 4) +
  geom_smooth(method = &quot;lm&quot;) +
  theme_bw() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  coord_cartesian(ylim = c(0, 220))</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Centering or scaling numeric variables is useful for later interpretation of regression models: if the date variable was not centered, the regression would show the effects of variables at year 0(!). If numeric variables are scaled, other variables are variables are considered relative not to 0 but to the mean of that variable (in this case the mean of years in our data). Centering simply means that the mean of the numeric variable is subtracted from each value.</p>
<pre class="r"><code>mydata$date &lt;- scale(mydata$date, scale = F)
head(mydata)</code></pre>
<pre><code>##     date         genre    text  pptw region
## 1 109.87 SCIENCE_OTHER   albin 166.0  north
## 2  84.87 EDUC_TREATISE    anon 139.9  north
## 3 181.87  LETTERS_PRIV  austen 130.8  north
## 4 251.87 EDUC_TREATISE    bain 151.3  north
## 5 116.87 EDUC_TREATISE barclay 145.7  north
## 6 281.87 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre class="r"><code>str(mydata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  5 variables:
##  $ date  : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ genre : chr  &quot;SCIENCE_OTHER&quot; &quot;EDUC_TREATISE&quot; &quot;LETTERS_PRIV&quot; &quot;EDUC_TREATISE&quot; ...
##  $ text  : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ pptw  : num  166 140 131 151 146 ...
##  $ region: chr  &quot;north&quot; &quot;north&quot; &quot;north&quot; &quot;north&quot; ...</code></pre>
<pre class="r"><code># generate a glm baseline model
m0.glm &lt;- glm(pptw ~ 1, family = gaussian, data = mydata)
# generate a lm base-line model
m0.lm &lt;- lm(pptw ~ 1, data = mydata)
# set up first lme model including only the random effect specifying the random intercepts
m0.lme = lme(pptw ~ 1, random = ~1|genre, data = mydata, method = &quot;ML&quot;)
# set up first lmer model including only the random effect specifying the random intercepts
m0.lmer = lmer(pptw ~ 1 + (1|genre), data = mydata, REML = F)</code></pre>
</div>
<div id="testing-random-effects" class="section level2">
<h2><span class="header-section-number">2.3</span> Testing Random Effects</h2>
<p>As a first step in the modelling process, we now need to determine whether or not including a random effect structure is justified. We do so by comparing the base-line model without random intercepts to the model with random intercepts using a Likelihood Ratio Test. A short word of warning is in order here regarding the specific of the model: we need to set <code>REML = T</code> because Relative Estimate Maximum Likelihood (REML) provides better estimates for the random effects part of the model compared with the simpler Maximum Likelihood (ML) specification (cf. Field, Miles &amp; Field 2012:879).</p>
<pre class="r"><code>x2 = -2*logLik(m0.lm, REML = T)+2*logLik(m0.lmer, REML = T)
x2 &lt;- x2 &lt;- x2[[1]]
list(x2, pchisq(x2, df=2, lower.tail=F))</code></pre>
<pre><code>## [[1]]
## [1] 220.9
## 
## [[2]]
## [1] 0.000000000000000000000000000000000000000000000001082</code></pre>
<p>The inclusion of a random effect structure with random intercepts is justified based on the Likelihood Ratio Test.</p>
<p>However, we also want to test which random effects structure is the best. We therefore create several models with different random effect structures and compare these models to see which random effect structure has the highest explanatory power.</p>
<p>We generate a m0.lmer model but using the <code>lmer</code> function from the <code>lme4</code> package. When we compare models, the REML specification must be FALSE or set to <code>method = &quot;ML&quot;</code> (Maximum Likelihood) (depending on the function) when we use ANOVAs to compare models (cf. Field, Miles &amp; Field 2012:). This is because “<code>ML</code> produces more accurate estimates of fixed regression parameters, whereas <code>REML</code> produces more accurate estimates of random variances (Twisk 2006). […] Also, if you want to compare models you must use ML” (Field, Miles &amp; Field 2012:879).</p>
<pre class="r"><code>m0.lmer1 &lt;- lmer(pptw ~ (1|genre) + 1, data = mydata, REML = T)
m0.lmer2 &lt;- lmer(pptw ~ (1|region) + 1, data = mydata, REML = T)
m0.lmer3 &lt;- lmer(pptw ~ (1|genre/region) + 1, data = mydata, REML = T)
anova(m0.lmer1, m0.lmer2, m0.lmer3)</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer1: pptw ~ (1 | genre) + 1
## m0.lmer2: pptw ~ (1 | region) + 1
## m0.lmer3: pptw ~ (1 | genre/region) + 1
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.lmer1  3 4502 4515  -2248     4496                                     
## m0.lmer2  3 4719 4731  -2356     4713     0      0                   1    
## m0.lmer3  4 4501 4518  -2246     4493   220      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># the model with the random effect structure (1|genre/region) performs
# significantly better (also it has a much lower AIC and deviance)
# therefore, m0.lmer3 is our new m0 model
m0.lmer &lt;- m0.lmer3
# test if including the random effect is permitted by applying a restricted likelihood ratio test
# WARNING: this test can only take simple random effect (1|genre) but not
# (1|genre/date)
exactRLRT(m0.lmer1)</code></pre>
<pre><code>## 
##  simulated finite sample distribution of RLRT.
##  
##  (p-value based on 10000 simulated values)
## 
## data:  
## RLRT = 220, p-value &lt;0.0000000000000002</code></pre>
<pre class="r"><code># there is another way to compare model with and without random effects: see below!

# create a second model with date as a fixed effect
# m1.lme &lt;- lme(m0.lme, .~. + date) # alternative way to update the model
m1.lme = lme(pptw ~ date, random = ~1|genre/region, data = mydata, method = &quot;ML&quot;)
# set up m1 model but using the lmer function from the lme4 package
m1.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)

# compare the models to see if including date has improved the model
# the difference between the models is the effect (size) of date!
anova(m0.lme, m1.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m1.lme     2  5 4496 4517  -2243 1 vs 2   10.12  0.0063</code></pre>
<pre class="r"><code># m1.lme is the better model (sig. p-value &amp; lower AIC)
# date correlates significantly with pptw (X2(1) = 8.81, p = .003);
# X2 = L.Ratio;
# df = subtract df smaller from df larger model
# inspect results
summary(m1.lme)</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4496 4517  -2243
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.05
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       3.453    14.97
## 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.95     3.183 505   42.09  0.0000
## date          0.02     0.007 505    2.70  0.0071
##  Correlation: 
##      (Intr)
## date 0.003 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.74687 -0.66308  0.01827  0.64043  3.62269 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre class="r"><code># alternative display of the results
anova(m1.lme)</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1770.7  &lt;.0001
## date            1   505     7.3  0.0071</code></pre>
<pre class="r"><code># test if date is significant
anova(m0.lmer, m1.lmer)</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer: pptw ~ (1 | genre/region) + 1
## m1.lmer: pptw ~ (1 | genre/region) + date
##         Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
## m0.lmer  4 4501 4518  -2246     4493                           
## m1.lmer  5 4496 4517  -2243     4486  7.03      1      0.008 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># extract estimates and sd for fixed and random effects
intervals(m1.lme)</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.713505 133.95499 140.19647
## date          0.004896   0.01787   0.03083
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept))  8.19 12.05 17.73
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 1.172 3.453 10.17
## 
##  Within-group standard error:
## lower  est. upper 
## 14.07 14.97 15.93</code></pre>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">2.4</span> Model Diagnostics</h2>
<p>We can now evaluate the goodness of fit of the model and check if mathematical requirements and assumptions have been violated. In a first step, we generate diagnostic plots that focus on the random effect structure.</p>
<pre class="r"><code>plot(m1.lme, genre ~ resid(.), abline = 0 ) # generate diagnostic plots</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>The plot shows that there are some outliers (points outside the boxes) and that the variability within letters is greater than in other genres we therefore examine the genres in isolation standardized residuals versus fitted values (Pinheiro &amp; Bates 2000:175).</p>
<pre class="r"><code>plot(m1.lme, resid(., type = &quot;p&quot;) ~ fitted(.) | genre, id = 0.05, adj = -0.3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>The plot showing the standardized residuals versus fitted values confirms that there are outliers in the letters because there are obviously differences in the variance, we create a new model which uses weights to compensate heterogeneity of variance (cf. Pinheiro &amp; Bates 2000:177).</p>
<pre class="r"><code>m2.lme &lt;- update(m1.lme, weights = varIdent(form = ~ 1 | genre))
# test if m2.lme is more appropriate for the data than m1.lme
anova(m1.lme, m2.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m1.lme     1  5 4496 4517  -2243                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   42.75  0.0002</code></pre>
<p>The heteroscedastic model (i.e. m2.lme which uses weights to account for unequal variance) is performing significantly better than the homoscedasticity model m1.lme. We therefore inspect the results of the new heteroscedastic model.</p>
<pre class="r"><code>summary(m2.lme)        # inspect results</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4483 4569  -2222
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.14
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       4.183    13.89
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | genre 
##  Parameter estimates:
##             BIBLE   BIOGRAPHY_OTHER        DIARY_PRIV     EDUC_TREATISE 
##            1.0000            0.3582            0.8994            0.7324 
##           FICTION    HANDBOOK_OTHER           HISTORY               LAW 
##            0.8895            1.1417            1.0185            0.7591 
##  LETTERS_NON-PRIV      LETTERS_PRIV        PHILOSOPHY PROCEEDINGS_TRIAL 
##            1.2641            1.2302            0.7753            1.2262 
##    RELIG_TREATISE     SCIENCE_OTHER            SERMON        TRAVELOGUE 
##            1.0108            0.8293            0.9821            1.0663 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 134.01     3.209 505   41.76  0.0000
## date          0.02     0.006 505    3.36  0.0008
##  Correlation: 
##      (Intr)
## date 0.002 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.29018 -0.67307  0.03261  0.64633  3.08450 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre class="r"><code>anova(m2.lme)          # ANOVA display of the results</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1743.6  &lt;.0001
## date            1   505    11.3  0.0008</code></pre>
<pre class="r"><code>anova(m0.lme, m2.lme)  # test if date is significant</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   52.87  &lt;.0001</code></pre>
<pre class="r"><code>intervals(m2.lme)      # extract estimates and sd for fixed and random effects</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.719320 134.01179 140.30426
## date          0.008414   0.02022   0.03203
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept)) 8.253 12.14 17.87
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 2.092 4.183 8.363
## 
##  Variance function:
##                    lower   est.  upper
## BIOGRAPHY_OTHER   0.2233 0.3582 0.5747
## DIARY_PRIV        0.6532 0.8994 1.2385
## EDUC_TREATISE     0.5210 0.7324 1.0295
## FICTION           0.6426 0.8895 1.2312
## HANDBOOK_OTHER    0.8170 1.1417 1.5955
## HISTORY           0.7583 1.0185 1.3682
## LAW               0.5499 0.7591 1.0480
## LETTERS_NON-PRIV  0.9974 1.2641 1.6020
## LETTERS_PRIV      0.9907 1.2302 1.5276
## PHILOSOPHY        0.4907 0.7753 1.2250
## PROCEEDINGS_TRIAL 0.8344 1.2262 1.8019
## RELIG_TREATISE    0.6776 1.0108 1.5078
## SCIENCE_OTHER     0.5702 0.8293 1.2063
## SERMON            0.7351 0.9821 1.3121
## TRAVELOGUE        0.7574 1.0663 1.5012
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.62 13.89 16.61</code></pre>
</div>
<div id="effect-sizes" class="section level2">
<h2><span class="header-section-number">2.5</span> Effect Sizes</h2>
<p>We will now extract effect sizes (in the example: the effect size of date) and calculate normalized effect size measures (this effect size measure works for all fixed effects). To calculate the effect size, take the square root of the squared t-value divided by the t-value squared plus the degrees of freedom:</p>
<p>r = <code>sqrt(t^2^/(t^2^+df))</code>.</p>
<p>A brief word of warning is in order here: only apply this function to main effects not involved in interactions as they are meaningless because the amount of variance explained by main effects involved in interactions is unclear (cf. Field, Miles &amp; Field 2012:641).</p>
<pre class="r"><code>ef.lme &lt;- function(x) {
  df &lt;- summary(x)[[20]][6]
  t &lt;-  summary(x)[[20]][8]
  #df &lt;- summary(x)$tTable[, 3]
  #t &lt;- summary(x)$tTable[, 4]
  r &lt;- sqrt((t^2)/((t^2)+df))
  return(paste(&quot;Pearson&#39;s r = &quot;, round(r, 3)))
  }
ef.lme(m2.lme)</code></pre>
<pre><code>## [1] &quot;Pearson&#39;s r =  0.148&quot;</code></pre>
<p>We now generate another m1 model but we use the <code>lmer</code> function from the <code>lme4</code> package rather than the <code>glmer</code> function.</p>
<pre class="r"><code>m2.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)
summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
<p>We now calculate the variance explained when only a simple random effect is involved. This is done by dividing the variance of the random effect (145.2) by variance of random effect plus residual variance (145.2+224.1) times 100. The results represents the percentage of variance explained by the random effect: <code>(145.2/(145.2+2284.1))*100</code>.</p>
<p>Create lmer with complex random effect structure</p>
<p>An alternative for testing if including the random intercepts is permitted.</p>
<p>WARNING: this method is not as good as applying a restricted likelihood ratio test(!) because the p-value is only an approximation IMPORTANT: the second model is a glm object</p>
<pre class="r"><code>m2.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)
2*pchisq(2*as.numeric(logLik(m2.lmer)-logLik(m0.glm)), 2, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000005159</code></pre>
</div>
<div id="rerun-model-diagnostics" class="section level2">
<h2><span class="header-section-number">2.6</span> Rerun Model Diagnostics</h2>
<p>Diagnostic plot (Pinheiro &amp; Bates 2000:11, 182) what we wish to see: a cloud of dots in the middle of the window without structure what we do not want to see: a funnel-shaped cloud because this indicates an increase of the errors/residuals with an increase of the predictor(s) (because this would indicate heteroscedasticity) in short: observed values against fitted values (cf. Pinheiro &amp; Bates 2000:182)</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2))           # display plots in 2 rows and 2 columns
plot(m2.lme)</code></pre>
<p><img src="advancedstatz_files/figure-html/diagnostics2-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<pre class="r"><code># diagnostic plot (Pinheiro &amp; Bates 2000:21)
plot(m2.lme, form = resid(., type = &quot;p&quot;) ~ fitted(.) | genre, abline = 0, cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: residuals of fitted values against observed values (cf. Pinheiro &amp; Bates 2000:182)
qqnorm(m2.lme)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<pre class="r"><code># normal plot of the estimated date %in% genre random effects
qqnorm(m2.lme, ~ranef(., level = 2), id = 0.05, cex = 0.7, xlim = c(-40, 40))</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: normal plots of the residuals by genre (cf. Pinheiro &amp; Bates 2000:22, 179)
qqnorm(m2.lme, ~resid(.) | genre )</code></pre>
<p><img src="advancedstatz_files/figure-html/diagnosticsgenre-1.png" width="672" /></p>
<pre class="r"><code># inspect the observed responses versus the within-group fitted values
# (cf. Pinheiro &amp; Bates 2000:178)
plot(m2.lme, pptw ~ fitted(.), id = 0.05, adj = -0.3, xlim = c(80, 220), cex = .8)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
</div>
<div id="reporting-results" class="section level2">
<h2><span class="header-section-number">2.7</span> Reporting Results</h2>
<pre class="r"><code>summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
</div>
</div>
<div id="multiple-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">3</span> Multiple Binomial Logistic Regression</h1>
<p>Logistic regression is a multivariate analysis technique that builds on and is very similar in terms of its implementation to linear regression but logistic regressions take dependent variables that represent nominal rather than numeric scaling. The difference requires that the linear regression must be modified in certain ways to avoid producing non-sensical outcomes. The most fundamental difference between logistic and linear regressions is that logistic regression work on the probabilities of an outcome (the likelihood), rather than the outcome itself. In addition, the likelihoods on which the logistic regression works must be logged (logarithmized) in order to avoid produce predictions that produce values greater than 1 (instance occurs) and 0 (instance does not occur).</p>
<p>To understand what this mean, we will use a very simple example. In this example, we want to see whether the height of men affect their likelihood of being in a relationship. The data we use represents a data set consisting of two variables: height and relationship.</p>
<pre class="r"><code>bodyheight=rnorm(20,180,10) # generates 20 values, with mean of 30 &amp; s.d.=2
bodyheight=sort(bodyheight) # sorts these values in ascending order.
relationship=c(0,0,0,0,0,1,0,1,0,0,1,1,0,1,1,1,0,1,1,1) # assign &#39;survival&#39; to these 20 individuals non-randomly... most mortality occurs at smaller body size
blrex=as.data.frame(cbind(bodyheight,relationship)) # saves data frame with two columns: body size &amp; survival
library(knitr)
kable(blrex, caption = &quot;Example data set representing the height and relationship status of a sample of men.&quot;)</code></pre>
<table>
<caption>Example data set representing the height and relationship status of a sample of men.</caption>
<thead>
<tr class="header">
<th align="right">bodyheight</th>
<th align="right">relationship</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">172.1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">174.1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">174.3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">174.3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">174.8</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">175.0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">175.6</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">175.7</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">175.8</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">177.9</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">182.3</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">182.5</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">182.9</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">183.8</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">184.2</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">188.4</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">189.1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">198.4</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">202.8</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">204.8</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>library(ggplot2)                              # activate library
# plot 1
p1 &lt;- ggplot(blrex,                           # create plot based on blrex
             aes(bodyheight, relationship)) + # define x- and y-axes
  geom_point() +                              # plot dots
  geom_smooth(method = &quot;lm&quot;, se = F) +        # draw linear regression line
  labs(x = &quot;Height&quot;) +                        # x-axis label
  labs(y = &quot;Relationship&quot;, cex = .75) +   # y-axis label
  theme_set(theme_bw(base_size = 8))+         # define theme (black and white theme)
  coord_cartesian(ylim = c(-0.2, 1.2), xlim = c(160, 200)) +      # axes range
  scale_y_continuous(breaks=seq(0, 1, 1), labels = c(&quot;Not in Relationship&quot;, &quot;In Relationship&quot;)) +
  guides(fill = FALSE)                        # supress legend
# plot 2
p2 &lt;- ggplot(blrex, aes(x=bodyheight, y=relationship)) +
  geom_point() +                              # plot dots
  geom_smooth(method = &quot;glm&quot;,                 # draw regression line
    method.args = list(family = &quot;binomial&quot;),  # draw binomial regression line 
    se = FALSE) +                             # supress errorband
  coord_cartesian(ylim = c(-0.2, 1.2), xlim = c(160, 200)) +      # axes range
  labs(x = &quot;Height&quot;) +                        # x-axis label
  scale_y_continuous(breaks=seq(0, 1, 1), labels = c(&quot;Not in Relationship&quot;, &quot;In Relationship&quot;)) +
  labs(y = &quot;Relationship&quot;, cex = .75)    # y-axis label
multiplot(p1, p2, cols = 2)                   # draw two plots in one window</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>The left panel of the Figure above shows that a linear model would predict values for the relationship status, which represents a factor (0 = Not in Relationship and 1 = In Relationship), that are non-sensical because 1.1 does not make sense if the only options are 0 OR 1. The logistic function shown in the right panel of the Figure above solves this problem by working on the logged probabilities of an outcome rather than on the actual outcome.</p>
<div id="example-1-eh-in-kiwi-english" class="section level2">
<h2><span class="header-section-number">3.1</span> Example 1: Eh in Kiwi English</h2>
<p>To exemplify hot to implement a logistic regression in <code>R</code>, we will analyse the use of the discourse particle <em>eh</em> in New Zealand English and test which factors correlate with its occurrence. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender, ethnicity, and age of that speaker and whether or not the speech unit contained an <em>eh</em>. To begin with, we clean the current work space, set option, install and activate relevant packages, load customized functions, and load the example data set.</p>
<pre class="r"><code>rm(list=ls(all=T))                     # clean workspace
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)  # set options (supress math annotation)
#install.packages(effects)   # install effects package (remove # to activate)
#install.packages(ggplot2)   # install ggplot2 package (remove # to activate)
#install.packages(mlogit)    # install mlogit package (remove # to activate)
#install.packages(plyr)      # install plyr package (remove # to activate)
#install.packages(rms)       # install rms package (remove # to activate)
#install.packages(sjPlot)    # install sjPlot package (remove # to activate)
#install.packages(visreg)    # install visreg package (remove # to activate)
library(effects)   # activate effects package
library(ggplot2)   # activate ggplot2 package
library(mlogit)    # activate mlogit package
library(plyr)      # activate plyr package
library(rms)       # activate rms package
library(sjPlot)    # activate sjPlot package
library(visreg)    # activate visreg package
source(&quot;rscripts/multiplot_ggplot2.R&quot;) # load multiplot function
source(&quot;rscripts/blr.summary.R&quot;)       # load function for summarizing blr results
blrdata &lt;- read.table(&quot;data/blrdata.txt&quot;, # read in data blrdata.txt
                      comment.char = &quot;&quot;,  # the data does not contain comments
                      quote = &quot;&quot;,         # the data does not contain quotes
                      sep = &quot;\t&quot;,         # the data is tab separetd
                      header = T)         # the variables have headers
str(blrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  5 variables:
##  $ ID       : chr  &quot;&lt;S1A-001#M&gt;&quot; &quot;&lt;S1A-001#M&gt;&quot; &quot;&lt;S1A-001#M&gt;&quot; &quot;&lt;S1A-001#M&gt;&quot; ...
##  $ Gender   : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Age      : chr  &quot;Young&quot; &quot;Young&quot; &quot;Young&quot; &quot;Young&quot; ...
##  $ Ethnicity: chr  &quot;Pakeha&quot; &quot;Pakeha&quot; &quot;Pakeha&quot; &quot;Pakeha&quot; ...
##  $ EH       : int  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<p>The summary of the data show that the data set contains 25,821 observations of five variables. The variable <code>ID</code> contains strings that represent a combination file and speaker of a speech unit. The second variable represents the gender, the third the age, and the fourth the ethnicity of speakers. The fifth variable represents whether or not a speech unit contained the discourse particle <em>eh</em>. The first six lines of the data set are shown in the Table below.</p>
<pre class="r"><code>library(knitr)
kable(head(blrdata), caption = &quot;First six line of the blrdata data set.&quot;)</code></pre>
<table>
<caption>First six line of the blrdata data set.</caption>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">Ethnicity</th>
<th align="right">EH</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Next, we factorize the variables in our data set. In other words, we specify that the strings represent variable levels and define new reference levels because as a default <code>R</code> will use the variable level which first occurs in alphabet ordering as the reference level for each variable, we redefine the variable levels for Age and Ethnicity.</p>
<pre class="r"><code>vrs &lt;- c(&quot;Age&quot;, &quot;Gender&quot;, &quot;Ethnicity&quot;, &quot;ID&quot;)  # define variables to be factorized
fctr &lt;- which(colnames(blrdata) %in% vrs)     # define vector with variables
blrdata[,fctr] &lt;- lapply(blrdata[,fctr], factor) # factorize variables
blrdata$Age &lt;- relevel(blrdata$Age, &quot;Young&quot;) # relevel Age (Young = Reference)
blrdata$Ethnicity &lt;- relevel(                # relevel Ethnicity
  blrdata$Ethnicity, &quot;Pakeha&quot;) # define Pakeha as Reference level)</code></pre>
<p>After preparing the data, we will now plot the data to get an overview of potential relationships between variables.</p>
<pre class="r"><code>p1 &lt;- ggplot(blrdata,                            # cerate plot based on blrdata
             aes(Gender, EH, color = Gender)) +  # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +   # define statistics for points
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Gender&quot;, y = &quot;Probability of EH&quot;)+     # define axes label
  guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;))  # define colours
p2 &lt;- ggplot(blrdata,                            # cerate plot based on blrdata
             aes(Age, EH, color = Age)) +  # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +   # define statistics for points
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Age&quot;, y = &quot;Probability of EH&quot;) +       # define axes labels
  guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkblue&quot;, &quot;lightblue&quot;))
p3 &lt;- ggplot(blrdata,                             # cerate plot based on blrdata
             aes(Ethnicity, EH, colour = Ethnicity)) +  # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +   # define statistics for points
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Ethnicity&quot;, y = &quot;Probability of EH&quot;, colour = &quot;Ethnicity&quot;) + # define axes labels
  guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
p4 &lt;- ggplot(blrdata,                             # cerate plot based on blrdata
             aes(Ethnicity, EH, colour = Gender)) +  # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +   # define statistics for points
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Ethnicity&quot;, y = &quot;Probability of EH&quot;, colour = &quot;Gender&quot;)+ # define axes labels
  scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;))  # define colours
p5 &lt;- ggplot(blrdata,                            # cerate plot based on blrdata
             aes(Gender, EH, colour = Age)) +    # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;,     # define statistics for points 
               aes(group= Age)) +                # define grouping factor
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars 
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Sex&quot;, y = &quot;Probability of EH&quot;, colour = &quot;Age&quot;) + # define axes labels
  guides(fill = FALSE) +                         # supress legend
  scale_color_manual(values = c(&quot;darkblue&quot;, &quot;lightblue&quot;))
p6 &lt;- ggplot(blrdata,                            # cerate plot based on blrdata
             aes(Age, EH, colour = Ethnicity)) +    # define axes and colouring factor
  stat_summary(fun.y = mean, geom = &quot;point&quot;,     # define statistics for points 
               aes(group= Ethnicity)) +                # define grouping factor
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +    # define  statistics for error bars
  stat_summary(fun.data = mean_cl_boot,          # define  statistics for error bars
               geom = &quot;errorbar&quot;, width = 0.2) + # define statistics for error bars
  coord_cartesian(ylim = c(0, 0.5)) +            # define y-axis range
  theme_set(theme_bw(base_size = 10)) +          # define theme
  labs(x = &quot;Age&quot;, y = &quot;Probability of EH&quot;, colour = &quot;Ethnicity&quot;) + # define axes labels
  guides(fill = FALSE) +                         # supress legend
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
# display the plots
multiplot(p1, p4, p2, p5, p3, p6, cols = 3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>With respect to main effects, the Figure above indicates that men use <em>eh</em> more frequently than women, that young speakers sue it more frequently compared with old speakers, and that speakers that are descendants of European settlers (Pakeha) use <em>eh</em> more frequently compared with Maori (the native inhabitants of New Zealand).</p>
<p>The plots in the lower panels do not indicate significant interactions between use of <em>eh</em> and the Age, Gender, and Ethnicity of speakers. In a next step, we will start building the logistic regression model.</p>
</div>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">3.2</span> Model Building</h2>
<p>As a first step, we need to define contrasts and add a distance matrix to the options. Contrasts define what should be tested and therefore has influence on how the results of the regression analysis are presented.</p>
<pre class="r"><code>options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;)) # set contrasts
blrdata.dist &lt;- datadist(blrdata)  # cerate distance matrix
options(datadist = &quot;blrdata.dist&quot;) # include distance matrix in options</code></pre>
<p>Next, we generate four base-line models: two minimal models that predict the use of <em>eh</em> sole based on the intercept and two initial saturated regression models that include all variables and their interactions.</p>
<pre class="r"><code>m0.glm = glm(EH ~ 1, family = binomial, data = blrdata) # baseline model glm
m0.lrm = lrm(EH ~ 1, data = blrdata, x = T, y = T) # baseline model lrm
m1.glm = glm(EH ~ Age*Gender*Ethnicity, family = binomial, data = blrdata)
m1.lrm = lrm(EH ~ Age*Gender*Ethnicity, data = blrdata, x = T, y = T)</code></pre>
<p>A few words on <code>glm</code> vs <code>lrm</code>: Baayen (2008:196-197) states that lrm should be the function of choice in cases where each row contains exactly 1 success OR failure (1 or 0) while glm is preferable if there are two columns holding the number of successes and the number of failures respectively. I have tried it both ways and both functions work fine if each row contains exactly 1 success OR failure but only glm can handle the latter case.</p>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">3.3</span> Model fitting</h2>
<p>We will now start with the model building procedure. In the present case, we will use a manual step-wise step-down protocol during which predictors are removed from the model if they do not significantly to the model fit.</p>
<pre class="r"><code>m2.glm &lt;- update(m1.glm, . ~ . -Age:Gender:Ethnicity) # remove Age:Gender:Ethnicity
anova(m1.glm, m2.glm, test = &quot;Chi&quot;)  # did removal significantly decrease model fit</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age * Gender * Ethnicity
## Model 2: EH ~ Age + Gender + Ethnicity + Age:Gender + Age:Ethnicity + 
##     Gender:Ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25813      32136                     
## 2     25814      32136 -1   -0.233     0.63</code></pre>
<p>The ANOVA shows that the fit of the saturated model (m1.glm) and the model without the interaction between Age, Gender, and Ethnicity (m2.glm) do not differ significantly. The lack of a significant difference is provided in the value of Pr(&gt;Chi) (0.63) which is higher than .05. Because the models do not differ significantly, we continue with the smaller model (m3.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m3.glm &lt;- update(m2.glm, . ~ . -Gender:Ethnicity)
anova(m2.glm, m3.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Age:Gender + Age:Ethnicity + 
##     Gender:Ethnicity
## Model 2: EH ~ Age + Gender + Ethnicity + Age:Gender + Age:Ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25814      32136                     
## 2     25815      32136 -1 -0.00569     0.94</code></pre>
<p>The ANOVA shows that the fit of the saturated model (m2.glm) and the model without the interaction between Gender and Ethnicity (m3.glm) do not differ significantly. The lack of a significant difference is provided in the value of Pr(&gt;Chi) (0.94) which is higher than .05. Because the models do not differ significantly, we continue with the smaller model (m3.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m4.glm &lt;- update(m3.glm, . ~ . -Age:Gender)
anova(m3.glm, m4.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Age:Gender + Age:Ethnicity
## Model 2: EH ~ Age + Gender + Ethnicity + Age:Ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25815      32136                     
## 2     25816      32136 -1   -0.226     0.63</code></pre>
<p>The ANOVA shows that the fit of the saturated model (m3.glm) and the model without the interaction between Age and Gender (m4.glm) do not differ significantly. The lack of a significant difference is provided in the value of Pr(&gt;Chi) (0.63) which is higher than .05. Because the models do not differ significantly, we continue with the smaller model (m4.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m5.glm &lt;- update(m4.glm, . ~ . -Age:Ethnicity)
anova(m4.glm, m5.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Age:Ethnicity
## Model 2: EH ~ Age + Gender + Ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1     25816      32136                       
## 2     25817      32139 -1    -2.81    0.094 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA shows that the fit of the saturated model (m4.glm) and the model without the interaction between Age and Ethnicity (m5.glm) do not differ significantly. The lack of a significant difference is provided in the value of Pr(&gt;Chi) (0.09) which is higher than .05. Because the models do not differ significantly, we continue with the smaller model (m5.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m6.glm &lt;- update(m5.glm, . ~ . -Ethnicity)
anova(m5.glm, m6.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25817      32139                     
## 2     25818      32140 -1   -0.261     0.61</code></pre>
<p>The ANOVA shows that the fit of the saturated model (m5.glm) and the model without the main effect for Ethnicity (m6.glm) do not differ significantly. The lack of a significant difference is provided in the value of Pr(&gt;Chi) (0.61) which is higher than .05. Because the models do not differ significantly, we continue with the smaller model (m6.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m7.glm &lt;- update(m6.glm, . ~ . -Gender)
anova(m7.glm, m6.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance            Pr(&gt;Chi)    
## 1     25819      32377                                    
## 2     25818      32140  1      237 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA shows that the fit of the more saturated model (m6.glm) and the model without the main effect for Gender (m7.glm) differ significantly. The significant difference is provided in the value of Pr(&gt;Chi) (&lt;0.0000000000000002 ***) which is smaller than .05. Because the models differ significantly, we continue with the more saturated model (m6.glm) as this is the correct procedure based on the principle of parsimony.</p>
<pre class="r"><code>m8.glm &lt;- update(m6.glm, . ~ . -Age)
anova(m8.glm, m6.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Gender
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance            Pr(&gt;Chi)    
## 1     25819      32808                                    
## 2     25818      32140  1      669 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA shows that the fit of the more saturated model (m6.glm) and the model without the main effect for Age (m8.glm) differ significantly. The significant difference is provided in the value of Pr(&gt;Chi) (&lt;0.0000000000000002 ***) which is smaller than .05. Because the models differ significantly, we continue with the more saturated model (m6.glm) as this is the correct procedure based on the principle of parsimony.</p>
<p>As we have now arrived at the final minimal adequate model (m6.glm), we generate a final minimal model using the <code>lrm</code> model.</p>
<pre class="r"><code>m6.lrm &lt;- lrm(EH ~ Age+Gender, data = blrdata, x = T, y = T, linear.predictors = T)
m6.lrm</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = EH ~ Age + Gender, data = blrdata, x = T, y = T, 
##      linear.predictors = T)
##  
##                         Model Likelihood    Discrimination    Rank Discrim.    
##                               Ratio Test           Indexes          Indexes    
##  Obs         25821    LR chi2     868.21    R2       0.046    C       0.602    
##   0          17114    d.f.             2    g        0.432    Dxy     0.203    
##   1           8707    Pr(&gt; chi2) &lt;0.0001    gr       1.541    gamma   0.302    
##  max |deriv| 3e-10                          gp       0.091    tau-a   0.091    
##                                             Brier    0.216                     
##  
##               Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept    -0.2324 0.0223 -10.44 &lt;0.0001 
##  Age=Old      -0.8305 0.0335 -24.78 &lt;0.0001 
##  Gender=Women -0.4201 0.0273 -15.42 &lt;0.0001 
## </code></pre>
<pre class="r"><code>anova(m6.lrm)</code></pre>
<pre><code>##                 Wald Statistics          Response: EH 
## 
##  Factor     Chi-Square d.f. P     
##  Age        614.0      1    &lt;.0001
##  Gender     237.7      1    &lt;.0001
##  TOTAL      802.6      2    &lt;.0001</code></pre>
<p>After fitting the model, we validate the model to avoid arriving at a final minimal model that is overfitted to the data at hand.</p>
</div>
<div id="model-validation" class="section level2">
<h2><span class="header-section-number">3.4</span> Model Validation</h2>
<p>To validate the final minimal model, we apply the <code>validate</code> function and apply it to the initial saturated model. The output of the <code>validate</code> function shows how often predictors are retained if the sample is re-selected with the same size but with placing back the drawn data point. The execution of the function requires some patience as it is rather computationally expensive.</p>
<pre class="r"><code>validate(m1.lrm, bw = T, B = 200) # model validation</code></pre>
<pre><code>## 
##      Backwards Step-down - Original Model
## 
##  Deleted                  Chi-Sq d.f. P      Residual d.f. P      AIC  
##  Age * Gender             0.01   1    0.9346 0.01     1    0.9346 -1.99
##  Gender * Ethnicity       0.05   1    0.8239 0.06     2    0.9723 -3.94
##  Age * Gender * Ethnicity 0.41   1    0.5230 0.46     3    0.9267 -5.54
##  Ethnicity                1.85   1    0.1735 2.32     4    0.6778 -5.68
##  Age * Ethnicity          1.21   1    0.2711 3.53     5    0.6192 -6.47
## 
## Approximate Estimates after Deleting Factors
## 
##                 Coef    S.E. Wald Z P
## Intercept    -0.2324 0.02227 -10.44 0
## Age=Old      -0.8301 0.03353 -24.76 0
## Gender=Women -0.4199 0.02725 -15.41 0
## 
## Factors in Final Model
## 
## [1] Age    Gender</code></pre>
<pre><code>##           index.orig training    test optimism index.corrected   n
## Dxy           0.2032   0.2047  0.2036   0.0011          0.2021 200
## R2            0.0458   0.0462  0.0457   0.0005          0.0453 200
## Intercept     0.0000   0.0000 -0.0018   0.0018         -0.0018 200
## Slope         1.0000   1.0000  0.9963   0.0037          0.9963 200
## Emax          0.0000   0.0000  0.0011   0.0011          0.0011 200
## D             0.0336   0.0339  0.0335   0.0004          0.0332 200
## U            -0.0001  -0.0001  0.0000  -0.0001          0.0000 200
## Q             0.0337   0.0340  0.0335   0.0005          0.0332 200
## B             0.2163   0.2162  0.2163  -0.0001          0.2164 200
## g             0.4323   0.4354  0.4330   0.0024          0.4300 200
## gp            0.0910   0.0915  0.0911   0.0004          0.0906 200
## 
## Factors Retained in Backwards Elimination
## 
##  Age Gender Ethnicity Age * Gender Age * Ethnicity Gender * Ethnicity
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                                        
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                *                                              
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                                        
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                                        
##  *   *      *                      *               *                 
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                *                                              
##  *   *                                                               
##  *   *                             *                                 
##  *   *      *                                                        
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                      *               *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *      *                                                        
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                      *                 
##  *   *                                                               
##  *   *      *                      *               *                 
##  *   *                                                               
##  *   *                *                                              
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                             *                 
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                *                            *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                *            *                                 
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                             *                 
##  *   *                             *                                 
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                                        
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *                                                        
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                             *                                 
##  *   *                                             *                 
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *                                                               
##  *   *      *         *                                              
##  *   *                                                               
##  *   *                                                               
##  *   *      *                      *                                 
##  *   *                             *                                 
##  *   *      *                      *               *                 
##  *   *      *                                                        
##  *   *                                                               
##  Age * Gender * Ethnicity
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##  *                       
##                          
##  *                       
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##  *                       
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##                          
##  *                       
##  *                       
##                          
##                          
##                          
##  *                       
##                          
##                          
##                          
##                          
##                          
##                          
##                          
## 
## Frequencies of Numbers of Factors Retained
## 
##   2   3   4   5   6 
## 135  35  25   4   1</code></pre>
<p>The <code>validate</code> function shows that retaining two predictors (Age and Gender) is the best option and thereby confirms our final minimal adequate model as the best minimal model. In addition, we check whether we need to include a penalty for data points because they have too strong of an impact of the model fit. To see whether a penalty is warranted, we apply the <code>pentrace</code> function to the final minimal adequate model.</p>
<pre class="r"><code>pentrace(m6.lrm, seq(0, 0.8, by = 0.05)) # determine penalty</code></pre>
<pre><code>## 
## Best penalty:
## 
##  penalty    df
##      0.8 1.999
## 
##  penalty    df   aic   bic aic.c
##     0.00 2.000 864.2 847.9 864.2
##     0.05 2.000 864.2 847.9 864.2
##     0.10 2.000 864.2 847.9 864.2
##     0.15 2.000 864.2 847.9 864.2
##     0.20 2.000 864.2 847.9 864.2
##     0.25 2.000 864.2 847.9 864.2
##     0.30 2.000 864.2 847.9 864.2
##     0.35 2.000 864.2 847.9 864.2
##     0.40 2.000 864.2 847.9 864.2
##     0.45 2.000 864.2 847.9 864.2
##     0.50 2.000 864.2 847.9 864.2
##     0.55 1.999 864.2 847.9 864.2
##     0.60 1.999 864.2 847.9 864.2
##     0.65 1.999 864.2 847.9 864.2
##     0.70 1.999 864.2 847.9 864.2
##     0.75 1.999 864.2 847.9 864.2
##     0.80 1.999 864.2 847.9 864.2</code></pre>
<p>The <code>pentrace</code> function proposes a penalty of .8 but the values are so similar that a penalty is unnecessary. In a next step, we rename the final models.</p>
<pre class="r"><code>lr.glm &lt;- m6.glm  # rename final minimal adeqaute glm model
lr.lrm &lt;- m6.lrm  # rename final minimal adeqaute lrm model</code></pre>
<p>Now, we calculate a Model Likelihood Ratio Test to check if the final model performs significantly better than the initial minimal base-line model. The result of this test is provided as a default if we call a summary of the lrm object.</p>
<pre class="r"><code>modelChi &lt;- lr.glm$null.deviance - lr.glm$deviance
chidf &lt;- lr.glm$df.null - lr.glm$df.residual
chisq.prob &lt;- 1 - pchisq(modelChi, chidf)
modelChi; chidf; chisq.prob</code></pre>
<pre><code>## [1] 868.2</code></pre>
<pre><code>## [1] 2</code></pre>
<pre><code>## [1] 0</code></pre>
<p>The code above provides three values: a <span class="math inline">\(\chi\)</span><sup>2</sup>, the degrees of freedom, and a p-value. The p-value is lower than .05 and the results of the Model Likelihood Ratio Test therefore confirm that the final minimal adequate model performs significantly better than the initial minimal base-line model. Another way to extract the model likelihood test statistics is to use an ANOVA to compare the final minimal adequate model to the minimal base-line model.</p>
<p>The Model Likelihood Ratio Test</p>
<pre class="r"><code>anova(m0.glm, lr.glm, test = &quot;Chi&quot;) # Model Likelihood Ratio Test</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ 1
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance            Pr(&gt;Chi)    
## 1     25820      33008                                    
## 2     25818      32140  2      868 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>In a next step, we calculate pseudo-R<sup>2</sup> values which represent the amount of residual variance that is explained by the final minimal adequate model. We cannot use the ordinary R<sup>2</sup> because the model works on the logged likelihoods rather than the values of the dependent variable.</p>
<pre class="r"><code># calculate pseudo R^2
# number of cases
ncases &lt;- length(fitted(lr.glm))
R2.hl &lt;- modelChi/lr.glm$null.deviance
R.cs &lt;- 1 - exp ((lr.glm$deviance - lr.glm$null.deviance)/ncases)
R.n &lt;- R.cs /( 1- ( exp (-(lr.glm$null.deviance/ ncases))))
# function for extracting pseudo-R^2
logisticPseudoR2s &lt;- function(LogModel) {
  dev &lt;- LogModel$deviance
    nullDev &lt;- LogModel$null.deviance
    modelN &lt;-  length(LogModel$fitted.values)
    R.l &lt;-  1 -  dev / nullDev
    R.cs &lt;- 1- exp ( -(nullDev - dev) / modelN)
    R.n &lt;- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
    cat(&quot;Pseudo R^2 for logistic regression\n&quot;)
    cat(&quot;Hosmer and Lemeshow R^2  &quot;, round(R.l, 3), &quot;\n&quot;)
    cat(&quot;Cox and Snell R^2        &quot;, round(R.cs, 3), &quot;\n&quot;)
    cat(&quot;Nagelkerke R^2           &quot;, round(R.n, 3),    &quot;\n&quot;) }
logisticPseudoR2s(lr.glm)</code></pre>
<pre><code>## Pseudo R^2 for logistic regression
## Hosmer and Lemeshow R^2   0.026 
## Cox and Snell R^2         0.033 
## Nagelkerke R^2            0.046</code></pre>
<p>The low pseudo-R<sup>2</sup> values show that our model has very low explanatory power as it only accounts for approximately 2.6 to 4.6 percent of the variance in the data. Next, we extract the confidence intervals for the coefficients of the model.</p>
<pre class="r"><code># extract the confidence intervals for the coefficients
confint(lr.glm)</code></pre>
<pre><code>##               2.5 %  97.5 %
## (Intercept) -0.2761 -0.1888
## AgeOld      -0.8965 -0.7651
## GenderWomen -0.4735 -0.3667</code></pre>
<p>Despite having low explanatory and predictive power, the age of speakers and their gender is significant as the confidence intervals of the coefficients do not overlap with 0.</p>
</div>
<div id="effect-size" class="section level2">
<h2><span class="header-section-number">3.5</span> Effect Size</h2>
<p>In a next step, we compute odds ratios and their confidence intervals. Odds Ratios represent a common measure of effect size and can be used to compare effect sizes across models. Odds ratios rang between 0 and infinity. Values of 1 indicate that there is not effect. The further away the values from 1, the stronger the effect. If the values are lower than 1, then the variable level correlates negatively with the occurrence of the outcome (the likelihood decreases) while values above 1 indicate a positive correlation and show that the variable level causes an increase in the likelihood of the outcome (the occurrence of EH).</p>
<pre class="r"><code>exp(lr.glm$coefficients) # odds ratios</code></pre>
<pre><code>## (Intercept)      AgeOld GenderWomen 
##      0.7926      0.4358      0.6570</code></pre>
<pre class="r"><code>exp(confint(lr.glm))     # confidence intervals of the coefficients</code></pre>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 0.7588 0.8280
## AgeOld      0.4080 0.4653
## GenderWomen 0.6228 0.6930</code></pre>
<p>The odds ratios confirm that older speakers use <em>eh</em> significantly less often compared with younger speakers and that women use <em>eh</em> less frequently than men as the confidence intervals of the odds rations do not overlap with 1. In a next step, we calculate the prediction accuracy of the model.</p>
</div>
<div id="accuracy" class="section level2">
<h2><span class="header-section-number">3.6</span> Accuracy</h2>
<p>In order to calculate the prediction accuracy of the model, we rearrange the data so that it does not reflect one speech unit per row but the number of speech units with <em>eh</em> and the number of speech units without <em>eh</em> per speaker! Thus, we transform the data into a per speaker rather than a per speech-unit format.</p>
<pre class="r"><code>blrdata_byspeaker &lt;- table(blrdata$ID, blrdata$EH)
blrdata_byspeaker &lt;- data.frame(rownames(blrdata_byspeaker), blrdata_byspeaker[, 1], blrdata_byspeaker[, 2])
names(blrdata_byspeaker) &lt;- c(&quot;ID&quot;, &quot;NOEH&quot;, &quot;EH&quot;)
rownames(blrdata_byspeaker) &lt;- 1:length(blrdata_byspeaker[,1])

blrdata_byspeaker &lt;- join(blrdata_byspeaker,  # join by-speaker data and biodata
                          blrdata, by = &quot;ID&quot;, # join by ID
                          type = &quot;left&quot;,      # only speakers for which bio data is provided
                          match = &quot;first&quot;)    # 
blrdata_byspeaker$EH &lt;- NULL                  # remove EH column</code></pre>
<pre class="r"><code>library(knitr)    # load library
kable(head(blrdata_byspeaker), caption = &quot;First six rows of the by-speaker data.&quot;)</code></pre>
<table>
<caption>First six rows of the by-speaker data.</caption>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="right">NOEH</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">Ethnicity</th>
<th align="right">EH</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><S1A-001#F></td>
<td align="right">95</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="right">97</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-002#B></td>
<td align="right">99</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><S1A-002#Q></td>
<td align="right">86</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-003#B></td>
<td align="right">58</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-003#M></td>
<td align="right">119</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code># use by.spk data to fit another model which we will use to test the accuracy of the model
lr.glm.spk &lt;- glm(cbind(EH, NOEH) ~ Age*Gender + Ethnicity + Age:Ethnicity, data = blrdata_byspeaker, family = binomial)
correct &lt;- sum(blrdata_byspeaker$EH * (predict(lr.glm.spk, type = &quot;response&quot;) &gt;= 0.5)) + sum(blrdata_byspeaker$NOEH * (predict(lr.glm.spk, type=&quot;response&quot;) &lt; 0.5))
tot &lt;- sum(blrdata_byspeaker$EH) + sum(blrdata_byspeaker$NOEH)
predict.acc &lt;- (correct/tot)*100
predict.acc</code></pre>
<pre><code>## [1] 99.6</code></pre>
<p>The models predicts 66.28 of cases accurately which appears to be a satisfactory result but in order to evaluate the prediction accuracy, we need to compare it to the accuracy of the minimal base-line model.</p>
<pre class="r"><code>lr.glm.spk.base &lt;- glm(cbind(EH, NOEH) ~ 1, data = blrdata_byspeaker, family = binomial)
correct.b &lt;- sum(blrdata_byspeaker$EH * (predict(lr.glm.spk.base, type = &quot;response&quot;) &gt;= 0.5)) + sum(blrdata_byspeaker$NOEH * (predict(lr.glm.spk.base, type=&quot;response&quot;) &lt; 0.5))
tot.b &lt;- sum(blrdata_byspeaker$EH) + sum(blrdata_byspeaker$NOEH)
predict.acc.base &lt;- (correct.b/tot.b)*100
predict.acc.base   # inspect predictions</code></pre>
<pre><code>## [1] 99.6</code></pre>
<p>Both, the final-minimal and the minimal base-line model have the same prediction accuracy. This is interesting and we need to determine why this is the case. WE will extract the predictions based on both models to find out why the predictions are identical.</p>
<pre class="r"><code>which(lr.glm.spk$fitted &gt; .5)</code></pre>
<pre><code>## named integer(0)</code></pre>
<pre class="r"><code>which(lr.glm.spk.base$fitted &gt; .5)</code></pre>
<pre><code>## named integer(0)</code></pre>
<p>The reason why both models arrive at the same predictions is that because both models always predict an absence of EH.</p>
<pre class="r"><code># plot effects using the visreg package (cf. Breheny &amp; Burchett 2013)
par(mfrow = c(1, 2))
visreg(lr.glm, &quot;Age&quot;, xlab = &quot;Age&quot;, ylab = &quot;Logged Odds (EH)&quot;, ylim = c(-3, 0))
visreg(lr.glm, &quot;Gender&quot;, xlab = &quot;Gender&quot;, ylab = &quot;Logged Odds (EH)&quot;, ylim = c(-3, 0))</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">3.7</span> Model Diagnostics</h2>
<p>We are now in a position to perform model diagnostics and test if the model violates distributional requirements. In a first step, we test for the existence of multicollinearity.</p>
<div id="multicollinearity" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Multicollinearity</h3>
<p>To check whether the final minimal model contains predictors that correlate with each other, we extract variance inflation factors (VIF). If a model contains predictors that have variance inflation factors (VIF) &gt; 10 the model is completely unreliable and cannot claim the multicollinearity is absent <span class="citation">(Myers <a href="#ref-myers1990classical">1990</a>)</span>. Predictors causing such VIFs should be removed. Indeed, predictors with VIF values greater than 4 are usually already problematic but, for large data sets, even VIFs greater than 2 can lead inflated standard errors (Jaeger 2013:<a href="http://wiki.bcs.rochester.edu/HlpLab/LSA2013Regression?action=AttachFile&amp;do=view&amp;target=LSA13-Lecture6-CommonIssuesAndSolutions.pdf" class="uri">http://wiki.bcs.rochester.edu/HlpLab/LSA2013Regression?action=AttachFile&amp;do=view&amp;target=LSA13-Lecture6-CommonIssuesAndSolutions.pdf</a>). Also, VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol">2010</a>)</span> proposes that variables with VIFs exceeding 3 should be removed.</p>
<pre class="r"><code>vif(lr.glm)</code></pre>
<pre><code>##      AgeOld GenderWomen 
##       1.005       1.005</code></pre>
<p>In addition, predictors with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard <a href="#ref-menard1995applied">1995</a>)</span> and the mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and O’Connell <a href="#ref-bowerman1990linear">1990</a>)</span>.</p>
<pre class="r"><code>mean(vif(lr.glm))</code></pre>
<pre><code>## [1] 1.005</code></pre>
</div>
<div id="outlier-detection-1" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Outlier detection</h3>
<p>In order to detect potential outliers, we will calculate diagnostic parameters and add these to our data set.</p>
<pre class="r"><code>infl &lt;- influence.measures(lr.glm) # calculate influence statistics
blrdata &lt;- data.frame(blrdata, infl[[1]], infl[[2]]) # add influence statistics</code></pre>
<pre class="r"><code>library(knitr)    # load library
kable(head(blrdata), caption = &quot;First six rows of the data set with added influence statistics.&quot;)</code></pre>
<table>
<caption>First six rows of the data set with added influence statistics.</caption>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">Ethnicity</th>
<th align="right">EH</th>
<th align="right">dfb.1_</th>
<th align="right">dfb.AgOl</th>
<th align="right">dfb.GndW</th>
<th align="right">dffit</th>
<th align="right">cov.r</th>
<th align="right">cook.d</th>
<th align="right">hat</th>
<th align="left">dfb.1_.1</th>
<th align="left">dfb.AgOl.1</th>
<th align="left">dfb.GndW.1</th>
<th align="left">dffit.1</th>
<th align="left">cov.r.1</th>
<th align="left">cook.d.1</th>
<th align="left">hat.1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
<td align="right">-0.0107</td>
<td align="right">0.0038</td>
<td align="right">0.0079</td>
<td align="right">-0.0107</td>
<td align="right">1</td>
<td align="right">0.0000</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
<td align="right">0.0127</td>
<td align="right">-0.0044</td>
<td align="right">-0.0094</td>
<td align="right">0.0127</td>
<td align="right">1</td>
<td align="right">0.0001</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
<td align="right">-0.0107</td>
<td align="right">0.0038</td>
<td align="right">0.0079</td>
<td align="right">-0.0107</td>
<td align="right">1</td>
<td align="right">0.0000</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
<td align="right">-0.0107</td>
<td align="right">0.0038</td>
<td align="right">0.0079</td>
<td align="right">-0.0107</td>
<td align="right">1</td>
<td align="right">0.0000</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
<td align="right">0.0127</td>
<td align="right">-0.0044</td>
<td align="right">-0.0094</td>
<td align="right">0.0127</td>
<td align="right">1</td>
<td align="right">0.0001</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
<td align="right">0.0127</td>
<td align="right">-0.0044</td>
<td align="right">-0.0094</td>
<td align="right">0.0127</td>
<td align="right">1</td>
<td align="right">0.0001</td>
<td align="right">0.0001</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
</tr>
</tbody>
</table>
</div>
<div id="sample-size" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Sample Size</h3>
<p>We now check whether the sample size is sufficient for our analysis <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>.<br />
* if you are interested in the overall model: 50 + 8k (k = number of predictors) * if you are interested in individual predictors: 104 + k * if you are interested in both: take the higher value!</p>
<pre class="r"><code># function to evaluate sample size
smplesz &lt;- function(x) {
  ifelse((length(x$fitted) &lt; (104 + ncol(summary(x)$coefficients)-1)) == TRUE,
    return(
      paste(&quot;Sample too small: please increase your sample by &quot;,
      104 + ncol(summary(x)$coefficients)-1 - length(x$fitted),
      &quot; data points&quot;, collapse = &quot;&quot;)),
    return(&quot;Sample size sufficient&quot;)) }
# apply unction to model
smplesz(lr.glm)</code></pre>
<pre><code>## [1] &quot;Sample size sufficient&quot;</code></pre>
<p>According to rule of thumb provided in <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>, the sample size is sufficient for our analysis.</p>
</div>
</div>
<div id="summarizing-results" class="section level2">
<h2><span class="header-section-number">3.8</span> Summarizing Results</h2>
<pre class="r"><code>blrmsummary &lt;- blrm.summary(lr.glm, lr.lrm, predict.acc) # summarize regression analysis
blrmsummary[, -c(4:5)] # remove columns with confidence intervals</code></pre>
<pre><code>##                             Estimate VIF OddsRatio         Std. Error
## (Intercept)                    -0.23          0.79               0.02
## AgeOld                         -0.83   1      0.44               0.03
## GenderWomen                    -0.42   1      0.66               0.03
## Model statistics                                                     
## Number of cases in model                                             
## Observed misses                                                      
## Observed successes                                                   
## Null deviance                                                        
## Residual deviance                                                    
## R2 (Nagelkerke)                                                      
## R2 (Hosmer &amp; Lemeshow)                                               
## R2 (Cox &amp; Snell)                                                     
## C                                                                    
## Somers&#39; Dxy                                                          
## AIC                                                                  
## Prediction accuracy                                                  
## Model Likelihood Ratio Test                        Model L.R.: 868.21
##                             z value   Pr(&gt;|z|)     Significance
## (Intercept)                  -10.44          0      p &lt; .001***
## AgeOld                       -24.78          0      p &lt; .001***
## GenderWomen                  -15.42          0      p &lt; .001***
## Model statistics                                          Value
## Number of cases in model                                  25821
## Observed misses                            0 :            17114
## Observed successes                         1 :             8707
## Null deviance                                          33007.75
## Residual deviance                                      32139.54
## R2 (Nagelkerke)                                           0.046
## R2 (Hosmer &amp; Lemeshow)                                    0.026
## R2 (Cox &amp; Snell)                                          0.033
## C                                                         0.602
## Somers&#39; Dxy                                               0.203
## AIC                                                    32145.54
## Prediction accuracy                                       99.6%
## Model Likelihood Ratio Test   df: 2 p-value: 0 sig: p &lt; .001***</code></pre>
<p><strong>R2 (Hosmer &amp; Lemeshow)</strong></p>
<p>“Rt is the proportional reduction in the absolute value of the log-likelihood measure and as such it is a measure of how much the badness of fit improves as a result of the inclusion of the predictor variables. It can vary between 0 (indicating that the predictors are useless at predicting the outcome variable) and 1 (indicating that the model predicts the outcome variable perfectly)” (<span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 317)</span>).</p>
<p><strong>R2 (Cox &amp; Snell)</strong></p>
<p>“Cox and Snell’s R~s (1989) is based on the deviance of the model (-2LL(new») and the deviance of the baseline model (-2LL(baseline), and the sample size, n […]. However, this statistic never reaches its theoretical maximum of 1.</p>
<p><strong>R2 (Nagelkerke)</strong></p>
<p>Since R2 (Cox &amp; Snell) never reaches its theoretical maximum of 1, Nagelkerke (1991) suggested Nagelkerke’s R^2. (Field, Miles &amp; Field 2012:317-318).</p>
<p><strong>Somers’ Dxy</strong></p>
<p>Somers’ Dxy is a rank correlation between predicted probabilities and observed responses ranges between 0 (randomness) and 1 (perfect prediction). (cf. <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 204)</span>).</p>
<p><strong>C</strong> C is an index of concordance between the predicted probability and the observed response. When C takes the value 0.5, the predictions are random, when it is 1, prediction is perfect. A value above 0.8 indicates that the model may have some real predictive capacity (cf. <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 204)</span>).</p>
<p><strong>Akaike information criteria (AIC)</strong></p>
<p>Akaike information criteria (AlC = -2LL + 2k) provide a value that reflects a ratio between the number of predictors in the model and the variance that is explained by these predictors. Changes in AIC can serve as a measure of whether the inclusion of a variable leads to a significant increase in the amount of variance that is explained by the model. “You can think of this as the price you pay for something: you get a better value of R<sup>2</sup>, but you pay a higher price, and was that higher price worth it? These information criteria help you to decide. The BIC is the same as the AIC but adjusts the penalty included in the AlC (i.e., 2k) by the number of cases: BlC = -2LL + 2k x log(n) in which n is the number of cases in the model” (<span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 318)</span>).</p>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">4</span> Mixed Effects Binomial Logistic Regression</h1>
<p>We now turn to an extension of binomial logistic regression: mixed-effects binomial logistic regression. As is the case with linear mixed-effects models logistic mixed effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>As is the case with linear mixed-effects models, binomial logistic mixed-effect models are multivariate analysis that treat data points as hierarchical or grouped in some way. In other words, they take into account that the data is nested in the sense that data points are produced by the same speaker or are grouped by some other characteristics. In mixed-models, hierarchical structures are modelled as <em>random effects</em>. If the random effect structure represents speakers then this means that a mixed-model would have a separate intercept and/or slope for each speaker.</p>
<p><em>Random Effects</em> in linear models two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to linear mixed-effects models, random effects differ in the position and the slope of the logistic function that is applied to the likelihood of the dependent variable. <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<pre class="r"><code>x1 &lt;- c(62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 72.5, 73.5, 74.5, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86)
x2 &lt;- x1-2
x3 &lt;- x2-2
x4 &lt;- x3-2
x5 &lt;- x1+2
x6 &lt;- x5+2
x7 &lt;- x6+2
x11 &lt;- x1-(mean(x1)-x1)
x12 &lt;- x1-(mean(x1)-x1)*1.5
x13 &lt;- x1-(mean(x1)-x1)*3
x14 &lt;- x1-(mean(x1)-x1)^1.5
x15 &lt;- x1-(mean(x1)-x1)^1.75
x16 &lt;- x1-(mean(x1)-x1)^.9
x17 &lt;- x1-(mean(x1)-x1)^.5
x21 &lt;- x1-(mean(x1)-x1)
x22 &lt;- x1-(mean(x1)-x1)*1.5
x23 &lt;- x1-(mean(x1)-x1)*3
x24 &lt;- x1-(mean(x1)-x1)*1.5
x25 &lt;- x1-(mean(x1)-x1)*2
x26 &lt;- x1-(mean(x1)-x1)*.9
x27 &lt;- x1-(mean(x1)-x1)*.5
y &lt;- c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;)
yn &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) 
logd &lt;- data.frame(x1, x2, x3, x4, x5, x6, x7, y, yn)
colnames(logd) &lt;- c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;y&quot;, &quot;yn&quot;)
m1 = glm(yn ~ x1, data=logd, family = binomial(link=&quot;logit&quot;))
m2 = glm(yn ~ x2, data=logd, family = binomial(link=&quot;logit&quot;))
m3 = glm(yn ~ x3, data=logd, family = binomial(link=&quot;logit&quot;))
m4 = glm(yn ~ x4, data=logd, family = binomial(link=&quot;logit&quot;))
m5 = glm(yn ~ x5, data=logd, family = binomial(link=&quot;logit&quot;))
m6 = glm(yn ~ x6, data=logd, family = binomial(link=&quot;logit&quot;))
m7 = glm(yn ~ x7, data=logd, family = binomial(link=&quot;logit&quot;))
m11 = glm(yn ~ x11, data=logd, family = binomial(link=&quot;logit&quot;))
m12 = glm(yn ~ x12, data=logd, family = binomial(link=&quot;logit&quot;))
m13 = glm(yn ~ x13, data=logd, family = binomial(link=&quot;logit&quot;))
m14 = glm(yn ~ x14, data=logd, family = binomial(link=&quot;logit&quot;))
m15 = glm(yn ~ x15, data=logd, family = binomial(link=&quot;logit&quot;))
m16 = glm(yn ~ x16, data=logd, family = binomial(link=&quot;logit&quot;))
m17 = glm(yn ~ x17, data=logd, family = binomial(link=&quot;logit&quot;))
m21 = glm(yn ~ x21, data=logd, family = binomial(link=&quot;logit&quot;))
m22 = glm(yn ~ x22, data=logd, family = binomial(link=&quot;logit&quot;))
m23 = glm(yn ~ x23, data=logd, family = binomial(link=&quot;logit&quot;))
m24 = glm(yn ~ x24, data=logd, family = binomial(link=&quot;logit&quot;))
m25 = glm(yn ~ x25, data=logd, family = binomial(link=&quot;logit&quot;))
m26 = glm(yn ~ x26, data=logd, family = binomial(link=&quot;logit&quot;))
m27 = glm(yn ~ x27, data=logd, family = binomial(link=&quot;logit&quot;))
par(mfrow = c(2, 2))
plot(yn  ~ x1, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, data = logd, xlab=&quot;x1&quot;, ylab=&quot;yn&quot;, pch=19)       
axis(2, seq(0,1,1), seq(0,1,1))
curve(predict(m1,data.frame(x1=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
mtext(&quot;Fixed-Effects Model:\n1 Intercept + 1 Slope&quot;, 1, 2, cex = .6)
mtext(&quot;Probability&quot;, 2, 2, cex = .6)

plot(yn  ~ x1, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, data = logd, xlab=&quot;x1&quot;, ylab=&quot;yn&quot;, pch=19)     
mtext(&quot;Mixed-Effects Model:\n1 Intercept per Random Effect Level\n+ 1 Slope&quot;, 1, 3, cex = .6)
curve(predict(m1,data.frame(x1=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m2,data.frame(x2=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m3,data.frame(x3=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m4,data.frame(x4=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m5,data.frame(x5=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m6,data.frame(x6=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m7,data.frame(x7=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)

plot(yn  ~ x11, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, data = logd, xlim=c(50,100), ylab=&quot;yn&quot;, pch=19) 
mtext(&quot;Mixed-Effects Model:\n1 Intercept\n+ 1 Slope per Random Effect Level&quot;, 1, 3, cex = .6)
mtext(&quot;Probability&quot;, 2, 2, cex = .6)
curve(predict(m21,data.frame(x21=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m22,data.frame(x22=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m23,data.frame(x23=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m24,data.frame(x24=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m25,data.frame(x25=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m26,data.frame(x26=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m27,data.frame(x27=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)

plot(yn  ~ x11, type = &quot;n&quot;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, ann=FALSE, data = logd, xlim=c(50,100), ylab=&quot;yn&quot;, pch=19) 
mtext(&quot;Mixed-Effects Model:\n1 Intercept per Random Effect Level\n+ 1 Slope per Random Effect Level&quot;, 1, 3, cex = .6)
curve(predict(m11,data.frame(x11=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m12,data.frame(x12=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m13,data.frame(x13=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m14,data.frame(x14=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m15,data.frame(x15=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m16,data.frame(x16=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)
curve(predict(m17,data.frame(x17=x),type=&quot;response&quot;), lty=1, lwd=1, col=&quot;darkgrey&quot;, add=TRUE)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>The upper left panel merely shows the logistic curve representing the predictions of a fixed-effects logistic regression with a single intercept and slope. The upper right panel shows the logistic curves representing the predictions of a of a mixed-effects logistic regression with random intercepts for each level of a grouping variable. The lower left panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with one intercept but random slopes for each level of a grouping variable. The lower right panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with random intercepts and random slopes for each level of a grouping variable.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the dependent variable solely on the base intercept, with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-discourse-like-in-irish-english" class="section level2">
<h2><span class="header-section-number">4.2</span> Example: Discourse LIKE in Irish English</h2>
<p>In this example we will investigate which factors correlate with the use of <em>final discourse like</em> (e.g. “<em>The weather is shite, like!</em>”) in Irish English. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender (Gender: Men versus Women) and age of that speaker (Age: Old versus Young), whether the interlocutors were of the same or a different gender (ConversationType: SameGender versus MixedGender), and whether another <em>final discourse like</em> had been used up to three speech units before (Priming: NoPrime versus Prime), whether or not the speech unit contained an <em>final discourse like</em> (SUFLike: 1 = yes, 0 = no. To begin with, we clean the current work space, set option, install and activate relevant packages, load customized functions, and load the example data set.</p>
<pre class="r"><code>rm(list=ls(all=T))  # clean current workspace
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)     # set options
library(Hmisc)      # activate library
library(RLRsim)     # activate library
library(sjPlot)     # activate library
library(visreg)     # activate library
library(mlogit)     # activate library
library(plyr)       # activate library
library(rms)        # activate library
library(ggplot2)    # activate library
library(effects)    # activate library
library(lme4)       # activate library
library(languageR)  # activate library
source(&quot;rscripts/multiplot_ggplot2.R&quot;)    # load multiplot function
source(&quot;rscripts/PseudoR2lmerBinomial.R&quot;) # load pseudor2 function
source(&quot;rscripts/meblr.summary.R&quot;)        # load summary function</code></pre>
<p>Next, we load the data and inspect the structure of the data set,</p>
<pre class="r"><code># read in existing s´data set mblrdata.txt
mblrdata &lt;- read.table(&quot;data/mblrdata.txt&quot;, # load data
                       comment.char = &quot;&quot;,   # data does not contain comments
                       quote = &quot;&quot;,          # data does not contain quotes
                       sep = &quot;\t&quot;,          # data is tab separated
                       header = T)          # data has column names
str(mblrdata)                               # inspect data structure</code></pre>
<pre><code>## &#39;data.frame&#39;:    10170 obs. of  6 variables:
##  $ ID              : chr  &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Age             : chr  &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; ...
##  $ ConversationType: chr  &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; ...
##  $ Priming         : chr  &quot;Prime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ SUFlike         : int  1 0 0 0 0 0 0 0 0 0 ...</code></pre>
<p>As all variables except for the dependent variable (SUFlike) are character strings, we factorize the independent variables.</p>
<pre class="r"><code>vrs &lt;- c(&quot;ID&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;ConversationType&quot;, &quot;Priming&quot;)  # define variables to be factorized
fctr &lt;- which(colnames(mblrdata) %in% vrs)     # define vector with variables
mblrdata[,fctr] &lt;- lapply(mblrdata[,fctr], factor) # factorize variables
mblrdata$Age &lt;- relevel(mblrdata$Age, &quot;Young&quot;) # relevel Age (Young = Reference)</code></pre>
<p>Before continuing, we check if speakers need to be collapsed because they nest too few data points. As a general rule of thumb, random effects should have a minimum of 20 data points per level.</p>
<pre class="r"><code>plot(table(mblrdata$ID)[order(table(mblrdata$ID), decreasing = T)],
     ylim = c(0,150),
      cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<p>The plot indicates that the vast majority of speakers represent more than 20 cases. However, we will collapse speakers that represent fewer data points.</p>
<pre class="r"><code>collapsespeaker &lt;- table(mblrdata$ID)[which(table(mblrdata$ID) &lt; 21)]
mblrdata$ID &lt;- ifelse(mblrdata$ID %in% collapsespeaker, &quot;Other&quot;, mblrdata$ID)</code></pre>
<p>After preparing the data, we have a look at the first six lines of the data set.</p>
<pre class="r"><code>library(knitr)    # load library
kable(head(mblrdata), caption = &quot;First six rows of the data set.&quot;)</code></pre>
<table>
<caption>First six rows of the data set.</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">ConversationType</th>
<th align="left">Priming</th>
<th align="right">SUFlike</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">Prime</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We now plot the data to inspect the relationships within the data set.</p>
<pre class="r"><code>p1 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, color = Gender)) +
  scale_fill_brewer() +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;))
p2 &lt;- ggplot(mblrdata, aes(Age, SUFlike, color = Age)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkblue&quot;, &quot;lightblue&quot;))
p3 &lt;- ggplot(mblrdata, aes(ConversationType, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;ConversationType&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;ConversationType&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
p4 &lt;- ggplot(mblrdata, aes(Priming, SUFlike, colour = Priming)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Priming&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Priming&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;grey30&quot;, &quot;grey60&quot;))
p5 &lt;- ggplot(mblrdata, aes(Age, SUFlike, colour = Gender)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= Gender)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
    scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Gender&quot;)
p6 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= ConversationType)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Age&quot;) +
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
# display the plots
multiplot(p1, p3, p5, p2, p4, p6, cols = 2)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>The upper left panel in the Figure above indicates that men sue discourse like more frequently than women. The centre right panel suggests that priming significantly increases the likelihood of discourse like being used. The centre left panel suggests that speakers use discourse like more frequently in mixed-gender conversations. However, the lower right panel indicates an interaction between gender and conversation type as women appear to use discourse like less frequently in same gender conversations while the conversation type does not seem to have an effect on men. After visualizing the data, we will now turn to the model building process.</p>
</div>
<div id="model-building-1" class="section level2">
<h2><span class="header-section-number">4.3</span> Model Building</h2>
<p>In a first step, we set the options and generate a distance matrix of the data.</p>
<pre class="r"><code># set options
options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;))
mblrdata.dist &lt;- datadist(mblrdata)
options(datadist = &quot;mblrdata.dist&quot;)</code></pre>
<p>In a next step, we generate fixed-effects minimal base-line models and a base-line mixed-model using the <code>glmer</code> function with a random intercept for ID (a lmer object of the final minimal adequate model will be created later).</p>
<pre class="r"><code>m0.glm = glm(SUFlike ~ 1, family = binomial, data = mblrdata) # baseline model glm
m0.lrm = lrm(SUFlike ~ 1, data = mblrdata, x = T, y = T) # baseline model lrm
m0.glmer = glmer(SUFlike ~ (1|ID), data = mblrdata, family = binomial) # base-line mixed-model</code></pre>
</div>
<div id="testing-the-random-effect" class="section level2">
<h2><span class="header-section-number">4.4</span> Testing the Random Effect</h2>
<p>Now, we check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.</p>
<pre class="r"><code>aic.glmer &lt;- AIC(logLik(m0.glmer))
aic.glm &lt;- AIC(logLik(m0.glm))
aic.glmer; aic.glm</code></pre>
<pre><code>## [1] 9193</code></pre>
<pre><code>## [1] 9310</code></pre>
<p>The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, we also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.</p>
<pre class="r"><code># test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) # sig m0.glmer better than m0.glm</code></pre>
<pre><code>## [1] 0.000000000000000000000000001273</code></pre>
<p>The p-value of the Model Likelihood Ratio Test is lower than .05 which shows that the inclusion of the random-effects structure is warranted. We can now continue with the model fitting process.</p>
</div>
<div id="model-fitting-1" class="section level2">
<h2><span class="header-section-number">4.5</span> Model Fitting</h2>
<p>The next step is to fit the model which means that we aim to find the “best” model, i.e. the minimal adequate model. In this case, we will use a manual step-wise step-up, forward elimination procedure. Before we begin with the model fitting process we need to add ´control = glmerControl(optimizer = “bobyqa”)´ to avoid unneccesary failures to converge.</p>
<pre class="r"><code>m0.glmer &lt;- glmer(SUFlike ~ 1+ (1|ID), family = binomial, data = mblrdata, control=glmerControl(optimizer=&quot;bobyqa&quot;))</code></pre>
<p>During each step of the fitting procedure, we test whether certain assumptions on which the model relies are violated. To avoid <em>incomplete information</em> (a combination of variables does not occur in the data), we tabulate the variables we intend to include and make sure that all possible combinations are present in the data. Including variables although not all combinations are present in the data would lead to unreliable models that report (vastly) inaccurate results. A special case of incomplete information is <em>complete separation</em> which occurs if one predictor perfectly explains an outcome (in that case the incomplete information would be caused by a level of the dependent variable). In addition, we make sure that the VIFs do not exceed a maximum of 3 as higher values would indicate multicollinearity and thus that the model is unstable. Only once we have confirmed that the incomplete information, complete separation, and <em>multicollinearity</em> are not a major concern, we generate the more saturated model and test whether the inclusion of a predictor leads to a significant reduction in residual deviance. If the predictor explains a significant amount of variance, it is retained in the model while being disregarded in case it does not explain a sufficient quantity of variance.</p>
<pre class="r"><code># add Priming
ifelse(min(ftable(mblrdata$Priming, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m1.glm &lt;- update(m0.glm, .~.+Priming)
m1.glmer &lt;- update(m0.glmer, .~.+Priming)
anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Age
ifelse(min(ftable(mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m2.glm &lt;- update(m1.glm, .~.+Age)
ifelse(max(vif(m2.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m2.glmer &lt;- update(m1.glmer, .~.+Age)
anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;) #mar sig (p=.0.61) BUT BIC inflation  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m2.glmer: SUFlike ~ (1 | ID) + Priming + Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)  
## m1.glmer  3 8688 8710  -4341     8682                          
## m2.glmer  4 8687 8716  -4339     8679  3.44      1      0.064 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Gender
ifelse(min(ftable(mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m3.glm &lt;- update(m1.glm, .~.+Gender)
ifelse(max(vif(m3.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m3.glmer &lt;- update(m1.glmer, .~.+Gender)
anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add ConversationType
ifelse(min(ftable(mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m4.glm &lt;- update(m3.glm, .~.+ConversationType)
ifelse(max(vif(m4.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m4.glmer &lt;- update(m3.glmer, .~.+ConversationType)
anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Priming*Age
ifelse(min(ftable(mblrdata$Priming, mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m5.glm &lt;- update(m4.glm, .~.+Priming*Age)
ifelse(max(vif(m5.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m5.glmer &lt;- update(m4.glmer, .~.+Priming*Age)
anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) # not sig (p=0.6)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m5.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m5.glmer:     Priming:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m4.glmer  5 8560 8596  -4275     8550                        
## m5.glmer  7 8563 8613  -4274     8549  1.03      2        0.6</code></pre>
<pre class="r"><code># add Priming*Gender
ifelse(min(ftable(mblrdata$Priming, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m6.glm &lt;- update(m4.glm, .~.+Priming*Gender)
ifelse(max(vif(m6.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*ConversationType
ifelse(min(ftable(mblrdata$Priming, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m7.glm &lt;- update(m4.glm, .~.+Priming*ConversationType)
ifelse(max(vif(m7.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*Gender
ifelse(min(ftable(mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m8.glm &lt;- update(m4.glm, .~.+Age*Gender)
ifelse(max(vif(m8.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*ConversationType
ifelse(min(ftable(mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m9.glm &lt;- update(m4.glm, .~.+Age*ConversationType)
ifelse(max(vif(m9.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m9.glmer &lt;- update(m4.glmer, .~.+Age*ConversationType)
anova(m9.glmer, m4.glmer, test = &quot;Chi&quot;) # not sig (p=0.3)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m9.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m9.glmer:     ConversationType:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m4.glmer  5 8560 8596  -4275     8550                        
## m9.glmer  7 8561 8612  -4274     8547   2.4      2        0.3</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Gender*ConversationType
ifelse(min(ftable(mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m10.glm &lt;- update(m4.glm, .~.+Gender*ConversationType)
ifelse(max(vif(m10.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m11.glm &lt;- update(m4.glm, .~.+Priming*Age*Gender)
ifelse(max(vif(m11.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m12.glm &lt;- update(m4.glm, .~.+Priming*Age*ConversationType)
ifelse(max(vif(m12.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m13.glm &lt;- update(m4.glm, .~.+Priming*Gender*ConversationType)
ifelse(max(vif(m13.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m14.glm &lt;- update(m4.glm, .~.+Age*Gender*ConversationType)
ifelse(max(vif(m14.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m15.glm &lt;- update(m4.glm, .~.+Priming*Age*Gender*ConversationType)
ifelse(max(vif(m15.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>In a next step, we test which models are the most adequate by comparing all models to get an overview of model parameters. This way it is possible to check which model has the lowest AIC, BIC, and the highest <span class="math inline">\(\chi\)</span><sup>2</sup> value</p>
<pre class="r"><code># comparisons of glmer objects
m1.m0 &lt;- anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) 
m2.m1 &lt;- anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;) 
m3.m1 &lt;- anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) 
m4.m3 &lt;- anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) 
m5.m4 &lt;- anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) 
m9.m4 &lt;- anova(m9.glmer, m4.glmer, test = &quot;Chi&quot;) 
# create a list of the model comparisons
mdlcmp &lt;- list(m1.m0, m2.m1, m3.m1, m4.m3, m5.m4, m9.m4)
# load function for summary
source(&quot;rscripts/ModelFittingSummarySWSU.R&quot;) # for GLMEM (step-wise step-up)
mdlft &lt;- mdl.fttng.swsu(mdlcmp)
mdlft &lt;- mdlft[,-2]
library(knitr)    # load library
kable(mdlft, caption = &quot;Model fitting process summary.&quot;)</code></pre>
<table>
<caption>Model fitting process summary.</caption>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="left">Term Added</th>
<th align="left">Compared to…</th>
<th align="left">DF</th>
<th align="left">AIC</th>
<th align="left">BIC</th>
<th align="left">LogLikelihood</th>
<th align="left">Residual Deviance</th>
<th align="left">X2</th>
<th align="left">X2DF</th>
<th align="left">p-value</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m1.glmer</td>
<td align="left">1+Priming</td>
<td align="left">m0.glmer</td>
<td align="left">3</td>
<td align="left">8688.39</td>
<td align="left">8710.07</td>
<td align="left">-4341.19</td>
<td align="left">8682.39</td>
<td align="left">506.84</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m2.glmer</td>
<td align="left">Age</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8686.95</td>
<td align="left">8715.86</td>
<td align="left">-4339.47</td>
<td align="left">8678.95</td>
<td align="left">3.44</td>
<td align="left">1</td>
<td align="left">0.06373</td>
<td align="left">p &lt; .10(*)</td>
</tr>
<tr class="odd">
<td align="left">m3.glmer</td>
<td align="left">Gender</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8596.76</td>
<td align="left">8625.67</td>
<td align="left">-4294.38</td>
<td align="left">8588.76</td>
<td align="left">93.63</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m4.glmer</td>
<td align="left">ConversationType</td>
<td align="left">m3.glmer</td>
<td align="left">5</td>
<td align="left">8559.57</td>
<td align="left">8595.7</td>
<td align="left">-4274.78</td>
<td align="left">8549.57</td>
<td align="left">39.19</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">m5.glmer</td>
<td align="left">Age+Priming:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">8562.54</td>
<td align="left">8613.13</td>
<td align="left">-4274.27</td>
<td align="left">8548.54</td>
<td align="left">1.03</td>
<td align="left">2</td>
<td align="left">0.59875</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m9.glmer</td>
<td align="left">Age+ConversationType:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">8561.17</td>
<td align="left">8611.76</td>
<td align="left">-4273.58</td>
<td align="left">8547.17</td>
<td align="left">2.4</td>
<td align="left">2</td>
<td align="left">0.30176</td>
<td align="left">n.s.</td>
</tr>
</tbody>
</table>
<p>We now rename our final minimal adequate model, test whether it performs significantly better than the minimal base-line model, and print the regression summary.</p>
<pre class="r"><code>mlr.glmer &lt;- m4.glmer # rename final minimal adequate model
mlr.glm &lt;- m4.glm # rename final minimal adequate fixed-effects model
anova(mlr.glmer, m0.glmer, test = &quot;Chi&quot;) # final model better than base-line model</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## mlr.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##           Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer   2 9193 9208  -4595     9189                                 
## mlr.glmer  5 8560 8596  -4275     8550   640      3 &lt;0.0000000000000002
##              
## m0.glmer     
## mlr.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>print(mlr.glmer, corr = F) # inspect final minimal adequate model</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##    Data: mblrdata
##      AIC      BIC   logLik deviance df.resid 
##     8560     8596    -4275     8550    10165 
## Random effects:
##  Groups Name        Std.Dev.
##  ID     (Intercept) 0.126   
## Number of obs: 10170, groups:  ID, 225
## Fixed Effects:
##                (Intercept)                PrimingPrime  
##                     -0.954                       1.700  
##                GenderWomen  ConversationTypeSameGender  
##                     -0.761                      -0.435</code></pre>
<pre class="r"><code>anova(mlr.glmer)  # ANOVA summary</code></pre>
<pre><code>## Analysis of Variance Table
##                  Df Sum Sq Mean Sq F value
## Priming           1    481     481   480.6
## Gender            1    195     195   195.1
## ConversationType  1     44      44    44.2</code></pre>
<p>To extract the effect sizes of the significant fixed effects, we compare the model with that effect to a model without that effect so that we can ascertain how much variance that effect explains.</p>
<pre class="r"><code>anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) #  Priming effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) # Gender effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) #  ConversationType effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">4.6</span> Extracting Model Fit Parameters</h2>
<p>We now create an <code>lrm</code> and <code>lmer</code> object that are equivalent to the final minimal adequate model (but the former without the random effect).</p>
<pre class="r"><code>mlr.lrm &lt;- lrm(SUFlike ~ Priming + Gender + ConversationType, data = mblrdata, x = T, y = T)
m1.glm = glm(SUFlike ~ Priming + Gender + ConversationType, family = binomial, data = mblrdata) # baseline model glm
# we now create a lmer object equivalent to the final minimal adequate model
mlr.lmer &lt;- lmer(SUFlike ~ Age + Gender + ConversationType + (1|ID), data = mblrdata, family = binomial)</code></pre>
<p>We now check on the lmer object if the fixed effects of the <code>lrm</code> and of the <code>lmer</code> model correlate (cf Baayen 2008:281).</p>
<pre class="r"><code>cor.test(coef(mlr.lrm), fixef(mlr.lmer))</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  coef(mlr.lrm) and fixef(mlr.lmer)
## t = 2.7, df = 2, p-value = 0.1
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.5169  0.9975
## sample estimates:
##    cor 
## 0.8827</code></pre>
<p>The fixed effects correlate strongly (.8827) which is a good indicator as it suggests that the coefficient estimates are sufficiently stable. We now activate the <code>Hmisc</code> package (if not already active) to extract model fit parameters (cf. Baayen 2008:281).</p>
<pre class="r"><code>library(Hmisc)   # activate Hmisc library
probs = 1/(1+exp(-fitted(mlr.lmer)))
probs = binomial()$linkinv(fitted(mlr.lmer))
somers2(probs, as.numeric(mblrdata$SUFlike))</code></pre>
<pre><code>##          C        Dxy          n    Missing 
##     0.6323     0.2646 10170.0000     0.0000</code></pre>
<p>The model fit parameters indicate a sufficient but not very good fit. The C-value indicates a goodness of fit between predicted and observed responses (occurrences of SUFlike). If the C-value is 0.5, the predictions are random, while the predictions are perfect if the C-value is 1. C-values above 0.8 indicates real predictive capacity (Baayen 2008:204).</p>
<p>Somers’ D<sub>xy</sub> is a value that represents a rank correlation between predicted probabilities and observed responses. Somers’ D<sub>xy</sub> values range between 0, which indicates complete randomness, and 1, which indicates perfect prediction (Baayen 2008:204). This a value of .2646 suggests that the model performs better than chance but not substantially so. We will now perform the model diagnostics.</p>
</div>
<div id="model-diagnostics-2" class="section level2">
<h2><span class="header-section-number">4.7</span> Model Diagnostics</h2>
<p>We begin the model diagnostics by generating a diagnostic that plots the fitted or predicted values against the residuals.</p>
<pre class="r"><code>plot(mlr.glmer)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-115-1.png" width="672" /></p>
<pre class="r"><code># plot residuals against fitted
stripParams &lt;- list(cex=.3, lines=1.5)
plot(mlr.glmer, form = resid(., type = &quot;response&quot;) ~ fitted(.) | ID, abline = 0, par.strip.text = stripParams,cex = .3,id = 0.05, adj = -0.3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-116-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: examining residuals (Pinheiro &amp; Bates 2000:175)
plot(mlr.glmer, ID ~ resid(.), abline = 0 , cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-117-1.png" width="672" /></p>
<pre class="r"><code># summarize final model
mblrmtb &lt;- meblrm.summary(m0.glm, m1.glm, m0.glmer, mlr.glmer, dpvar=mblrdata$SUFlike)
mblrmtb &lt;- mblrmtb[, -c(4:5)]
library(knitr)    # load library
kable(mblrmtb, caption = &quot;Results of a Mixed-Effects Binomial Logistic Regression Model.&quot;)</code></pre>
<table>
<caption>Results of a Mixed-Effects Binomial Logistic Regression Model.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Group(s)</th>
<th align="left">Variance</th>
<th align="left">Std. Dev.</th>
<th align="left">L.R. X2</th>
<th align="left">DF</th>
<th align="left">Pr</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Random Effect(s)</td>
<td align="left">ID</td>
<td align="left">0.02</td>
<td align="left">0.13</td>
<td align="left">118.61</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>Fixed Effect(s)</td>
<td align="left">Estimate</td>
<td align="left">VIF</td>
<td align="left">OddsRatio</td>
<td align="left">Std. Error</td>
<td align="left">z value</td>
<td align="left">Pr(&gt;|z|)</td>
<td align="left">Significance</td>
</tr>
<tr class="odd">
<td>(Intercept)</td>
<td align="left">-0.95</td>
<td align="left"></td>
<td align="left">0.39</td>
<td align="left">0.06</td>
<td align="left">-14.93</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>PrimingPrime</td>
<td align="left">1.7</td>
<td align="left">1.01</td>
<td align="left">5.47</td>
<td align="left">0.07</td>
<td align="left">22.85</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td>GenderWomen</td>
<td align="left">-0.76</td>
<td align="left">1.21</td>
<td align="left">0.47</td>
<td align="left">0.08</td>
<td align="left">-9.9</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>ConversationTypeSameGender</td>
<td align="left">-0.43</td>
<td align="left">1.22</td>
<td align="left">0.65</td>
<td align="left">0.07</td>
<td align="left">-6.65</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td>Model statistics</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">Value</td>
</tr>
<tr class="even">
<td>Number of Groups</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">225</td>
</tr>
<tr class="odd">
<td>Number of cases in model</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">10170</td>
</tr>
<tr class="even">
<td>Observed misses</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8430</td>
</tr>
<tr class="odd">
<td>Observed successes</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">1740</td>
</tr>
<tr class="even">
<td>Residual deviance</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8549.57</td>
</tr>
<tr class="odd">
<td>R2 (Nagelkerke)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.126</td>
</tr>
<tr class="even">
<td>R2 (Hosmer &amp; Lemeshow)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.086</td>
</tr>
<tr class="odd">
<td>R2 (Cox &amp; Snell)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.075</td>
</tr>
<tr class="even">
<td>C</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.708</td>
</tr>
<tr class="odd">
<td>Somers’ Dxy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.416</td>
</tr>
<tr class="even">
<td>AIC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8559.57</td>
</tr>
<tr class="odd">
<td>BIC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8595.7</td>
</tr>
<tr class="even">
<td>Prediction accuracy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">82.69%</td>
</tr>
<tr class="odd">
<td>Model Likelihood Ratio Test</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">L.R. X2: 758.28</td>
<td align="left">DF: 4</td>
<td align="left">p-value: 0</td>
<td align="left">sig: p &lt; .001***</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="conditional-inference-trees" class="section level1">
<h1><span class="header-section-number">5</span> Conditional Inference Trees</h1>
<p>We now turn to tree-structure models, the most basic of which we will be dealing with here are conditional inference trees. Like random forests, conditional inference trees are non-parametric and thus do not rely on distributional requirements. In addition, tree-structure models are very useful because they can deal with different types of variables. Tree-structure models are particularly interesting for linguists because they can handle moderate sample sizes and many high-order interactions better then regression models. The tree structure represents recursive partitioning of the data to minimize residual deviance.</p>
<p>Before we implement a conditional inference tree in R, we will have a look at how it works. We will do this in more detail here as random forests and Boruta anlyses are extensions of conditional inference trees and are therefore based on the same concepts.</p>
<p>Below is a conditional inference tree of the iris-data set. All conditional inference trees answer a simple question, namely “How do we classify elements based on the given predictors?”. The answer that conditional inference trees provide is the classification of the elements based on the levels of the predictors. If predictors are not significant or all elements can be classified correctly without them (i.e. if these predictors are unneccessary), then they are not included in the decision tree. The conditional inference tree shows that we only need one predictor to classify all flowers as either being an example of the species “setosa” or another species. If the petal of a flower in the data set is shorter than 1.9, then the flower is a setosa, while it is not if the petal length is greater than 1.9.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-119-1.png" width="672" /></p>
<p>The top of the decision tree is called “root” or “root node”, the categories at the end of branches are called “leaves” or “leaf nodes”. Nodes that are in-between the root and leaves are called “internal nodes” or just “nodes”. The root node has only arrows or lines pointing away from it, internal nodes have lines going to and from them, while leaf nodes only have lines pointing towards them.</p>
<p>Let us imagine, we are dealing with a very small data set that consits of only four cases and four variables. In our example, we want to predict whether a person makes use of discourse <em>like</em> given their age, gender, and social status. The first six lines of this ficticious data set are displayed in the table below:</p>
<table>
<caption>Example data set to illustrate conditional inference trees.</caption>
<thead>
<tr class="header">
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">SocialStatus</th>
<th align="right">LikeUser</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Woman</td>
<td align="left">Old</td>
<td align="left">High</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Man</td>
<td align="left">Young</td>
<td align="left">Low</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Man</td>
<td align="left">Old</td>
<td align="left">Low</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Woman</td>
<td align="left">Young</td>
<td align="left">High</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Man</td>
<td align="left">Young</td>
<td align="left">Low</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Man</td>
<td align="left">Old</td>
<td align="left">Low</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>In a first step, it need to be determined, what the root of the decision tree should be. In order to do so, we tabulate for each variable level, how many speakers of that level have used discourse <em>like</em> (LikeUsers) and how many have not used discourse <em>like</em> (NonLikeUsers).</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-121-1.png" width="672" /></p>
<pre><code>##    
##     Man Woman
##   0 125    39
##   1  34   105</code></pre>
<pre><code>##    
##     Old Young
##   0 127    33
##   1  37   100</code></pre>
<pre><code>##    
##     High Low
##   0   31 129
##   1   92  45</code></pre>
<p>None of the predictors is perfect (the perdictors are therefore refered to as “impure”). To determine which variable is the root, we will caluculate the degree of “impurity” for each variable - the variable which has the lowest impurity value will be the root.</p>
<p>The most common measure of impurity in the conext of conditional inference trees is called “Gini”. For each level we apply the following equation to determine the impuruty value:</p>
<p>\begin{equation}</p>
<p>G_{x} = 1 - ( p_{1} )<sup>2</sup> - ( p_{0} )<sup>2</sup></p>
<p>\begin{equation}</p>
<p>For the node for men, this would mean the following:</p>
<p>\begin{equation}</p>
<p>G_{men} = 1-()<sup>2</sup> - ()<sup>2</sup> = .3362209</p>
<p>\begin{equation}</p>
<p>For women, we caculate G or Gini as follows:</p>
<p>\begin{equation}</p>
<p>G_{women} = 1-()<sup>2</sup> - ()<sup>2</sup> = .3949653</p>
<p>\begin{equation}</p>
<p>To calculate the Gini value of Gender, we need to calculate the weighted avergage leaf node impurity (weighted because the number of speakers is different in each group). We calculate the weighted avergage leaf node impurity using the forluar below.</p>
<p>\begin{equation}</p>
<p>G_{Gender} =  G_{men} +  G_{women}</p>
<p>G_{Gender} =  .336 +  .395 = .364139</p>
<p>\begin{equation}</p>
<p>We now need to calculate the Gini values for all predictors in our data set.</p>
<pre class="r"><code>#install.packages(Rling)       # install Rling library (remove # to activate)
library(Rling)                 # activate Rling library
options(stringsAsFactors = F)  # set options: do not convert strings
options(scipen = 999)          # set options: supress math. notation
options(max.prAmplified=10000) # set options</code></pre>
<pre class="r"><code>reallyaus &lt;- read.table(&quot;data/ampaus05_statz.txt&quot;, # load data
                        sep = &quot;\t&quot;,                # data is tab separated 
                        header = T)                # data has headers 
str(reallyaus)          # inspect data</code></pre>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  15 variables:
##  $ Age             : chr  &quot;26-40&quot; &quot;26-40&quot; &quot;26-40&quot; &quot;17-25&quot; ...
##  $ Adjective       : chr  &quot;good&quot; &quot;good&quot; &quot;good&quot; &quot;nice&quot; ...
##  $ FileSpeaker     : chr  &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-003:1$B&gt;&quot; ...
##  $ Function        : chr  &quot;Attributive&quot; &quot;Attributive&quot; &quot;Predicative&quot; &quot;Attributive&quot; ...
##  $ Priming         : chr  &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Occupation      : chr  &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; ...
##  $ ConversationType: chr  &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; ...
##  $ AudienceSize    : chr  &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;Dyad&quot; ...
##  $ very            : int  0 0 0 1 0 1 0 1 0 0 ...
##  $ really          : int  0 0 0 0 0 0 0 0 1 1 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : chr  &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; ...
##  $ SemanticCategory: chr  &quot;Value&quot; &quot;Value&quot; &quot;Value&quot; &quot;HumanPropensity&quot; ...
##  $ Emotionality    : chr  &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;NonEmotional&quot; ...</code></pre>
<pre class="r"><code># remove superfluous columns
reallyaus$FileSpeaker &lt;- NULL
reallyaus$Occupation &lt;- NULL
reallyaus$very &lt;- NULL
# define vector for data inspection
clfct &lt;- c(&quot;Age&quot;, &quot;Adjective&quot;, &quot;Function&quot;, &quot;Priming&quot;, &quot;Gender&quot;, &quot;ConversationType&quot;, 
          &quot;AudienceSize&quot;, &quot;really&quot;, &quot;Gradabilty&quot;, &quot;SemanticCategory&quot;, &quot;Emotionality&quot;)
# factorize data
reallyaus[clfct] &lt;- lapply(reallyaus[clfct], factor)
# inspect data
str(reallyaus)</code></pre>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  12 variables:
##  $ Age             : Factor w/ 3 levels &quot;17-25&quot;,&quot;26-40&quot;,..: 2 2 2 1 3 3 3 3 1 1 ...
##  $ Adjective       : Factor w/ 6 levels &quot;bad&quot;,&quot;funny&quot;,..: 3 3 3 5 6 6 3 6 6 6 ...
##  $ Function        : Factor w/ 2 levels &quot;Attributive&quot;,..: 1 1 2 1 2 2 1 2 1 1 ...
##  $ Priming         : Factor w/ 2 levels &quot;NoPrime&quot;,&quot;Prime&quot;: 1 1 1 1 1 1 1 1 1 2 ...
##  $ Gender          : Factor w/ 2 levels &quot;Men&quot;,&quot;Women&quot;: 1 1 1 1 1 1 2 2 1 1 ...
##  $ ConversationType: Factor w/ 2 levels &quot;MixedSex&quot;,&quot;SameSex&quot;: 2 2 2 2 2 1 1 1 1 1 ...
##  $ AudienceSize    : Factor w/ 2 levels &quot;Dyad&quot;,&quot;MultipleInterlocutors&quot;: 2 2 2 1 1 2 2 2 2 2 ...
##  $ really          : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 2 2 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : Factor w/ 3 levels &quot;GradabilityUndetermined&quot;,..: 3 3 3 3 3 3 3 1 1 3 ...
##  $ SemanticCategory: Factor w/ 5 levels &quot;Dimension&quot;,&quot;HumanPropensity&quot;,..: 5 5 5 2 5 5 5 2 1 4 ...
##  $ Emotionality    : Factor w/ 3 levels &quot;NegativeEmotional&quot;,..: 3 3 3 2 2 3 3 1 2 2 ...</code></pre>
<pre class="r"><code>library(partykit)
# create data
citd &lt;- reallyaus
# set.seed
set.seed(111) 
# apply bonferroni correction (1 minus alpha multiplied by n of predictors)
control = ctree_control(mincriterion = 1-(.05*14))
# create initial conditional inference tree model
citd.ctree &lt;- ctree(really ~ Age + Adjective + Function + Priming + Gender + 
                      ConversationType + AudienceSize +  Freq + 
                      Gradabilty + SemanticCategory + Emotionality,
                    data = citd)
# plot final ctree
plot(citd.ctree, gp = gpar(fontsize = 8))</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-126-1.png" width="672" /></p>
<pre class="r"><code># test prediction accuracy
ptb &lt;- table(predict(citd.ctree), citd$really)
(((ptb[1]+ptb[4])+(ptb[2]+ptb[3]))/sum(table(predict(citd.ctree), citd$really)))*100</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>##100

# determine baseline
(table(citd$really)[[2]]/sum(table(citd$really)))*100</code></pre>
<pre><code>## [1] 41.08</code></pre>
<pre class="r"><code>## 41.08</code></pre>
</div>
<div id="random-forests" class="section level1">
<h1><span class="header-section-number">6</span> Random Forests</h1>
<p>Random Forests are an extension of Conditional Inference Trees. Like Conditional Inference Trees, Random Forests represent a non-parametric partitioning method that is particularly useful when dealing with relatively small sample sizes and many predictors (including interactions).</p>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">6.1</span> Example 1:</h2>
<pre class="r"><code>rfd &lt;- reallyaus                     # prepare data
rfd$really &lt;- as.factor(rfd$really)  # convert really into a factor
set.seed(222)                       # set seed</code></pre>
<p>After the data preparation, we can now start with the random forest analysis.</p>
<pre class="r"><code># partition data for evaluating rf 
id &lt;- sample(2, nrow(rfd), replace = T, prob = c(.7, .3))
train &lt;- rfd[id == 1, ]
test &lt;- rfd[id == 2,]</code></pre>
<pre class="r"><code># load library
library(randomForest)
# create initial model
reallyaus_rf1 &lt;- randomForest(really~., data = train)
# inspect model
print(reallyaus_rf1)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 41.47%
## Confusion matrix:
##    0  1 class.error
## 0 79 44      0.3577
## 1 46 48      0.4894</code></pre>
<pre class="r"><code># inspect attibutes
attributes(reallyaus_rf1)</code></pre>
<pre><code>## $names
##  [1] &quot;call&quot;            &quot;type&quot;            &quot;predicted&quot;      
##  [4] &quot;err.rate&quot;        &quot;confusion&quot;       &quot;votes&quot;          
##  [7] &quot;oob.times&quot;       &quot;classes&quot;         &quot;importance&quot;     
## [10] &quot;importanceSD&quot;    &quot;localImportance&quot; &quot;proximity&quot;      
## [13] &quot;ntree&quot;           &quot;mtry&quot;            &quot;forest&quot;         
## [16] &quot;y&quot;               &quot;test&quot;            &quot;inbag&quot;          
## [19] &quot;terms&quot;          
## 
## $class
## [1] &quot;randomForest.formula&quot; &quot;randomForest&quot;</code></pre>
<pre class="r"><code># start model evaluation
# install package
#source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(); library(Biobase)
#install.packages(&quot;Biobase&quot;, repos=c(&quot;http://rstudio.org/_packages&quot;, &quot;http://cran.rstudio.com&quot;, 
#                                      &quot;http://cran.rstudio.com/&quot;, dependencies=TRUE))
#install.packages(&quot;dimRed&quot;, dependencies = TRUE)
#install.packages(&#39;caret&#39;, dependencies = TRUE)</code></pre>
<pre class="r"><code># load caret library
library(caret) # because initially caret did not work, the libraries above had to be installed

ptrain1 &lt;- predict(reallyaus_rf1, train) # extract prediction for training data
head(ptrain1); head(train$really)         # inspect predictions</code></pre>
<pre><code>## 2 3 4 7 8 9 
## 0 0 0 0 0 1 
## Levels: 0 1</code></pre>
<pre><code>## [1] 0 0 0 0 0 1
## Levels: 0 1</code></pre>
<pre class="r"><code>confusionMatrix(ptrain1, train$really)  # generate confusion matrix</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 116  13
##          1   7  81
##                                              
##                Accuracy : 0.908              
##                  95% CI : (0.861, 0.943)     
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.811              
##  Mcnemar&#39;s Test P-Value : 0.264              
##                                              
##             Sensitivity : 0.943              
##             Specificity : 0.862              
##          Pos Pred Value : 0.899              
##          Neg Pred Value : 0.920              
##              Prevalence : 0.567              
##          Detection Rate : 0.535              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.902              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest1 &lt;- predict(reallyaus_rf1, test)
# create confusionMatrix
confusionMatrix(ptest1, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 44 16
##          1 18 19
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.249         
##  Mcnemar&#39;s Test P-Value : 0.864         
##                                         
##             Sensitivity : 0.710         
##             Specificity : 0.543         
##          Pos Pred Value : 0.733         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.454         
##    Detection Prevalence : 0.619         
##       Balanced Accuracy : 0.626         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># determine errorrate of random forest model
plot(reallyaus_rf1, main = &quot;&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-132-1.png" width="672" /></p>
<pre class="r"><code># tune model
reallyaus_rf2 &lt;- tuneRF(train[, !colnames(train)== &quot;really&quot;], 
                        train[, colnames(train)== &quot;really&quot;], 
                        stepFactor = .5, # for most values 6 appears to be optimal
                        plot = T,
                        ntreeTry = 200,
                        trace = T,
                        improve = .05
)</code></pre>
<pre><code>## mtry = 3  OOB error = 42.4% 
## Searching left ...
## mtry = 6     OOB error = 42.4% 
## 0 0.05 
## Searching right ...
## mtry = 1     OOB error = 43.32% 
## -0.02174 0.05</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-133-1.png" width="672" /></p>
<pre class="r"><code># create improved model
reallyaus_rf2 &lt;- randomForest(really~., data = train, 
                              ntree = 200,
                              ntry = 6,
                              importance= T,
                              proximity = T)
# inspect model
print(reallyaus_rf2)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train, ntree = 200,      ntry = 6, importance = T, proximity = T) 
##                Type of random forest: classification
##                      Number of trees: 200
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 40.09%
## Confusion matrix:
##    0  1 class.error
## 0 86 37      0.3008
## 1 50 44      0.5319</code></pre>
<pre class="r"><code># predict based on improved model
ptrain2 &lt;- predict(reallyaus_rf2, train)
# create confusionMatrix
confusionMatrix(ptrain2, train$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 114  15
##          1   9  79
##                                              
##                Accuracy : 0.889              
##                  95% CI : (0.84, 0.928)      
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.773              
##  Mcnemar&#39;s Test P-Value : 0.307              
##                                              
##             Sensitivity : 0.927              
##             Specificity : 0.840              
##          Pos Pred Value : 0.884              
##          Neg Pred Value : 0.898              
##              Prevalence : 0.567              
##          Detection Rate : 0.525              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.884              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest2 &lt;- predict(reallyaus_rf2, test)
# create confusionMatrix
confusionMatrix(ptest2, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 45 17
##          1 17 18
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.24          
##  Mcnemar&#39;s Test P-Value : 1.000         
##                                         
##             Sensitivity : 0.726         
##             Specificity : 0.514         
##          Pos Pred Value : 0.726         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.464         
##    Detection Prevalence : 0.639         
##       Balanced Accuracy : 0.620         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># inspect number of nodes for trees
hist(treesize(reallyaus_rf2), main = &quot;&quot;, col = &quot;lightgray&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-133-2.png" width="672" /></p>
<pre class="r"><code># check variable importance
varImpPlot(reallyaus_rf2, main = &quot;&quot;, pch = 20) </code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-134-1.png" width="672" /></p>
<pre class="r"><code># left plot (Accuracy): how much accuracy decreases if factor is left out
# left plot (Gini/Pureness): how much more unpure (ambiguous) the distributions become if factor is left out
# extract variable importance values
#importance(reallyaus_rf2)

#which variables have been used in the trees
varUsed(reallyaus_rf2)</code></pre>
<pre><code>##  [1]  817  826  894  745  672  902  831 2114  461 1129  853</code></pre>
<pre class="r"><code># partial dependence plot
partialPlot(reallyaus_rf2, train, Freq, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-135-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, ConversationType, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-136-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Function, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-137-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, SemanticCategory, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-138-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Gender, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
<pre class="r"><code># extract tree
getTree(reallyaus_rf2, 1, labelVar = T)</code></pre>
<pre><code>##    left daughter right daughter        split var split point status
## 1              2              3       Gradabilty      3.0000      1
## 2              4              5 SemanticCategory      1.0000      1
## 3              6              7          Priming      1.0000      1
## 4              8              9     AudienceSize      1.0000      1
## 5             10             11           Gender      1.0000      1
## 6             12             13        Adjective     22.0000      1
## 7             14             15              Age      1.0000      1
## 8              0              0             &lt;NA&gt;      0.0000     -1
## 9              0              0             &lt;NA&gt;      0.0000     -1
## 10             0              0             &lt;NA&gt;      0.0000     -1
## 11            16             17         Function      1.0000      1
## 12            18             19        Adjective      2.0000      1
## 13            20             21             Freq      1.2295      1
## 14            22             23     Emotionality      2.0000      1
## 15             0              0             &lt;NA&gt;      0.0000     -1
## 16             0              0             &lt;NA&gt;      0.0000     -1
## 17            24             25        Adjective      8.0000      1
## 18            26             27              Age      3.0000      1
## 19            28             29        Adjective      4.0000      1
## 20            30             31         Function      1.0000      1
## 21            32             33     AudienceSize      1.0000      1
## 22            34             35             Freq      2.8177      1
## 23            36             37             Freq     11.6575      1
## 24             0              0             &lt;NA&gt;      0.0000     -1
## 25            38             39       Gradabilty      1.0000      1
## 26             0              0             &lt;NA&gt;      0.0000     -1
## 27             0              0             &lt;NA&gt;      0.0000     -1
## 28            40             41              Age      1.0000      1
## 29            42             43 ConversationType      1.0000      1
## 30            44             45     Emotionality      1.0000      1
## 31            46             47     AudienceSize      1.0000      1
## 32            48             49              Age      2.0000      1
## 33            50             51 SemanticCategory      2.0000      1
## 34             0              0             &lt;NA&gt;      0.0000     -1
## 35            52             53             Freq      5.7459      1
## 36            54             55     Emotionality      1.0000      1
## 37            56             57     AudienceSize      1.0000      1
## 38             0              0             &lt;NA&gt;      0.0000     -1
## 39            58             59             Freq      0.6844      1
## 40            60             61 ConversationType      1.0000      1
## 41            62             63     AudienceSize      1.0000      1
## 42             0              0             &lt;NA&gt;      0.0000     -1
## 43            64             65     AudienceSize      1.0000      1
## 44            66             67           Gender      1.0000      1
## 45            68             69     Emotionality      2.0000      1
## 46            70             71             Freq      0.7032      1
## 47            72             73 SemanticCategory      3.0000      1
## 48            74             75 ConversationType      1.0000      1
## 49             0              0             &lt;NA&gt;      0.0000     -1
## 50            76             77     Emotionality      2.0000      1
## 51             0              0             &lt;NA&gt;      0.0000     -1
## 52             0              0             &lt;NA&gt;      0.0000     -1
## 53             0              0             &lt;NA&gt;      0.0000     -1
## 54            78             79     AudienceSize      1.0000      1
## 55             0              0             &lt;NA&gt;      0.0000     -1
## 56             0              0             &lt;NA&gt;      0.0000     -1
## 57             0              0             &lt;NA&gt;      0.0000     -1
## 58             0              0             &lt;NA&gt;      0.0000     -1
## 59             0              0             &lt;NA&gt;      0.0000     -1
## 60             0              0             &lt;NA&gt;      0.0000     -1
## 61             0              0             &lt;NA&gt;      0.0000     -1
## 62             0              0             &lt;NA&gt;      0.0000     -1
## 63             0              0             &lt;NA&gt;      0.0000     -1
## 64            80             81           Gender      1.0000      1
## 65             0              0             &lt;NA&gt;      0.0000     -1
## 66             0              0             &lt;NA&gt;      0.0000     -1
## 67             0              0             &lt;NA&gt;      0.0000     -1
## 68            82             83 ConversationType      1.0000      1
## 69             0              0             &lt;NA&gt;      0.0000     -1
## 70             0              0             &lt;NA&gt;      0.0000     -1
## 71            84             85              Age      1.0000      1
## 72             0              0             &lt;NA&gt;      0.0000     -1
## 73             0              0             &lt;NA&gt;      0.0000     -1
## 74             0              0             &lt;NA&gt;      0.0000     -1
## 75             0              0             &lt;NA&gt;      0.0000     -1
## 76             0              0             &lt;NA&gt;      0.0000     -1
## 77             0              0             &lt;NA&gt;      0.0000     -1
## 78             0              0             &lt;NA&gt;      0.0000     -1
## 79            86             87 SemanticCategory      2.0000      1
## 80            88             89         Function      1.0000      1
## 81             0              0             &lt;NA&gt;      0.0000     -1
## 82            90             91             Freq      0.9945      1
## 83             0              0             &lt;NA&gt;      0.0000     -1
## 84            92             93           Gender      1.0000      1
## 85            94             95 SemanticCategory      8.0000      1
## 86             0              0             &lt;NA&gt;      0.0000     -1
## 87            96             97             Freq      1.6575      1
## 88             0              0             &lt;NA&gt;      0.0000     -1
## 89             0              0             &lt;NA&gt;      0.0000     -1
## 90            98             99 SemanticCategory      1.0000      1
## 91             0              0             &lt;NA&gt;      0.0000     -1
## 92             0              0             &lt;NA&gt;      0.0000     -1
## 93             0              0             &lt;NA&gt;      0.0000     -1
## 94             0              0             &lt;NA&gt;      0.0000     -1
## 95             0              0             &lt;NA&gt;      0.0000     -1
## 96             0              0             &lt;NA&gt;      0.0000     -1
## 97             0              0             &lt;NA&gt;      0.0000     -1
## 98             0              0             &lt;NA&gt;      0.0000     -1
## 99             0              0             &lt;NA&gt;      0.0000     -1
##    prediction
## 1        &lt;NA&gt;
## 2        &lt;NA&gt;
## 3        &lt;NA&gt;
## 4        &lt;NA&gt;
## 5        &lt;NA&gt;
## 6        &lt;NA&gt;
## 7        &lt;NA&gt;
## 8           1
## 9           0
## 10          0
## 11       &lt;NA&gt;
## 12       &lt;NA&gt;
## 13       &lt;NA&gt;
## 14       &lt;NA&gt;
## 15          1
## 16          0
## 17       &lt;NA&gt;
## 18       &lt;NA&gt;
## 19       &lt;NA&gt;
## 20       &lt;NA&gt;
## 21       &lt;NA&gt;
## 22       &lt;NA&gt;
## 23       &lt;NA&gt;
## 24          0
## 25       &lt;NA&gt;
## 26          1
## 27          0
## 28       &lt;NA&gt;
## 29       &lt;NA&gt;
## 30       &lt;NA&gt;
## 31       &lt;NA&gt;
## 32       &lt;NA&gt;
## 33       &lt;NA&gt;
## 34          1
## 35       &lt;NA&gt;
## 36       &lt;NA&gt;
## 37       &lt;NA&gt;
## 38          0
## 39       &lt;NA&gt;
## 40       &lt;NA&gt;
## 41       &lt;NA&gt;
## 42          1
## 43       &lt;NA&gt;
## 44       &lt;NA&gt;
## 45       &lt;NA&gt;
## 46       &lt;NA&gt;
## 47       &lt;NA&gt;
## 48       &lt;NA&gt;
## 49          0
## 50       &lt;NA&gt;
## 51          0
## 52          0
## 53          1
## 54       &lt;NA&gt;
## 55          0
## 56          1
## 57          0
## 58          0
## 59          0
## 60          1
## 61          1
## 62          1
## 63          0
## 64       &lt;NA&gt;
## 65          1
## 66          0
## 67          1
## 68       &lt;NA&gt;
## 69          0
## 70          0
## 71       &lt;NA&gt;
## 72          1
## 73          0
## 74          0
## 75          1
## 76          1
## 77          0
## 78          0
## 79       &lt;NA&gt;
## 80       &lt;NA&gt;
## 81          0
## 82       &lt;NA&gt;
## 83          0
## 84       &lt;NA&gt;
## 85       &lt;NA&gt;
## 86          0
## 87       &lt;NA&gt;
## 88          0
## 89          0
## 90       &lt;NA&gt;
## 91          0
## 92          0
## 93          1
## 94          0
## 95          1
## 96          0
## 97          1
## 98          1
## 99          1</code></pre>
<pre class="r"><code># mds plot
MDSplot(reallyaus_rf2, test$really)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
</div>
<div id="example-2" class="section level2">
<h2><span class="header-section-number">6.2</span> Example 2:</h2>
<pre class="r"><code># detach partykit
detach(&quot;package:partykit&quot;, unload=TRUE)
# load package party
library(party)
# prepare data
rfd &lt;- reallyaus
# set seed
set.seed(333)

# create initial model
reallyaus.rf &lt;- cforest(really ~ Age + Adjective + Function + Priming + Gender + 
                          ConversationType + AudienceSize +  Freq + 
                          Gradabilty + SemanticCategory + Emotionality,
                        data = rfd, controls = cforest_unbiased(ntree = 50, mtry = 3))
# determine importance of factors
reallyaus.varimp &lt;- varimp(reallyaus.rf, conditional = T)
round(reallyaus.varimp, 3)</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##            0.001            0.005            0.012            0.000 
##           Gender ConversationType     AudienceSize             Freq 
##            0.002            0.003            0.002            0.011 
##       Gradabilty SemanticCategory     Emotionality 
##            0.000            0.004            0.001</code></pre>
<pre class="r"><code># plot result
dotchart(sort(reallyaus.varimp), pch = 20, main = &quot;Conditional importance of variables&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-141-1.png" width="672" /></p>
<pre class="r"><code># load library
library(Hmisc)
# evaluate random forst
reallyaus.rf.pred &lt;- unlist(treeresponse(reallyaus.rf))[c(FALSE,TRUE)]
somers2(reallyaus.rf.pred, as.numeric(rfd$really) - 1)</code></pre>
<pre><code>##        C      Dxy        n  Missing 
##   0.8069   0.6138 314.0000   0.0000</code></pre>
<pre class="r"><code>##     C         Dxy           n     Missing 
##0.8119422   0.6238843 314.0000000   0.0000000 </code></pre>
</div>
<div id="example-3" class="section level2">
<h2><span class="header-section-number">6.3</span> Example 3:</h2>
<pre class="r"><code>#                     RANDOM FOREST III
# load library
library(party)
# create data
randomforestdata &lt;- reallyaus

cf1 &lt;- cforest(really ~ . , data= randomforestdata, control=cforest_unbiased(mtry=2,ntree=100)) # fit the random forest
varimp(cf1) # get variable importance, based on mean decrease in accuracy</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0013913        0.0169565        0.0082609        0.0008696 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0053043        0.0046087        0.0040870        0.0253043 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0031304        0.0032174        0.0097391</code></pre>
<pre class="r"><code>varimp(cf1, conditional=TRUE) # conditional=True, adjusts for correlations between predict</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##       0.00034783       0.00834783       0.00582609      -0.00191304 
##           Gender ConversationType     AudienceSize             Freq 
##       0.00295652       0.00069565       0.00252174       0.01139130 
##       Gradabilty SemanticCategory     Emotionality 
##       0.00008696       0.00008696       0.00086957</code></pre>
<pre class="r"><code>varimpAUC(cf1)  # more robust towards class imbalance.</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0056743        0.0319284        0.0116915        0.0006288 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0108261        0.0076496        0.0093993        0.0415649 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0085987        0.0060204        0.0077188</code></pre>
<pre class="r"><code>par(mar = c(5, 8, 4, 2) + 0.1)
plot(y = 1:length(varimpAUC(cf1)), x = varimpAUC(cf1)[order(varimpAUC(cf1))], 
     axes = F, ann = F, pch = 20, xlim = c(-0.01, 0.05), main = &quot;Predictor Importance&quot;)
axis(1, at = seq(-0.01, 0.05, 0.005), seq(-0.01, 0.05, 0.005))
axis(2, at = 1:length(varimpAUC(cf1)), names(varimpAUC(cf1))[order(varimpAUC(cf1))], las = 2)
grid()
box()</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-145-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
</div>
</div>
<div id="boruta" class="section level1">
<h1><span class="header-section-number">7</span> Boruta</h1>
<p>Boruta (Kursa &amp; Rudnicki 2010, 2018) is a variable selection procedure and it represents an extension of random forest analyses (cf. Breiman 2001; Tagliamonte &amp; Baayen 2012). The name “Boruta” is derived from a demon in Slavic mythology who dwelled in pine forests. Boruta is an alternative to regression modelling that is better equipped to handle small data sets because it uses a distributional approach during which hundreds of (random) forests are grown from permutated data sets. This means that Boruta outperforms random forest analyses because it does not provide merely a single value for each predictor but a distribution of values leading to higher reliability.</p>
<p>The Boruta analysis consists out of five steps.</p>
<ul>
<li><p>In a first step, the Boruta algorithm copies the data set and adds randomness to the data by (re-)shuffling data points and thereby creating randomized variables. These randomized variables are referred to as shadow features.</p></li>
<li><p>Secondly, a random forest classifier is trained on the extended data set.</p></li>
<li><p>In a third step, a feature importance measure (Mean Decrease Accuracy represented by z-scores) is calculated to determine the relative importance of all predictors (both original or real variables and the randomized shadow features).</p></li>
<li><p>In the next step, it is checked at each iteration of the process whether a real predictor has a higher importance compared with the best shadow feature. The algorithm keeps track of the performance of the original variables by storing whether they outperformed the best shadow feature or not in a vector.</p></li>
<li><p>In the fifth step, predictors that did not outperform the best shadow feature are removed and the process continues without them. After a set number of iterations, or if all the variables have been either confirmed as outperforming the best shadow feature, the algorithm stops.</p></li>
</ul>
<p>Despite its obvious advantages of Boruta over random forest analyses and regression modelling, it can neither handle multicollinearity not hierarchical data structures where data points are nested or grouped by a given predictor (as is the case in the present analysis as data points are grouped by adjective type). As Boruta is a variable selection procedure, it is also limited in the sense that it provides information on which predictors to include and how good these predictors are (compared to the shadow variables) while it is neither able to take hierarchical data structure into account, nor does it provide information about how one level of a factor compares to other factors. In other words, Boruta shows that a predictor is relevant and how strong it is but it does not provide information on how the likelihood of an outcome being used differs between variable levels, for instance between men and women.</p>
</div>
<div id="boruta-in-r" class="section level1">
<h1><span class="header-section-number">8</span> Boruta in <code>R</code></h1>
<p>We begin by preparing the session. In a first step, we load the necessary library and the data.</p>
<pre class="r"><code># load library
library(Boruta)
# create dada for boruta
borutadata &lt;- reallyaus
# run 1
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 5.979 secs.
##  3 attributes confirmed important: Adjective, Freq, Function;
##  3 attributes confirmed unimportant: Age, Priming,
## SemanticCategory;
##  5 tentative attributes left: AudienceSize, ConversationType,
## Emotionality, Gender, Gradabilty;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq
## &lt;environment: 0x0000000009e95958&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-147-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-148-1.png" width="672" /></p>
<pre class="r"><code># remove superfluous variables
borutadata$Emotionality &lt;- NULL
borutadata$Priming &lt;- NULL
borutadata$Age &lt;- NULL
borutadata$SemanticCategory &lt;- NULL
# run2
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 5.245 secs.
##  4 attributes confirmed important: Adjective, Freq, Function,
## Gradabilty;
##  No attributes deemed unimportant.
##  3 tentative attributes left: AudienceSize, ConversationType,
## Gender;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x000000000d739ba0&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .75)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-150-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-151-1.png" width="672" /></p>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x0000000010193d08&gt;</code></pre>
<pre class="r"><code>par(mar = c(10, 8, 4, 2) + 0.1)
plot(boruta.ampaus, cex.axis=.75, las=2, xlab=&quot;&quot;, ylab = &quot;&quot;, cex = .75, 
     col = c(&quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,  &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,&quot;grey90&quot;,&quot;grey90&quot;,&quot;grey90&quot;))
abline(v = 3.5, lty = &quot;dashed&quot;)
mtext(&quot;Predictors&quot;, 1, line = 8, at = 7, cex = 1)
mtext(&quot;Control&quot;, 1, line = 8, at = 2, cex = 1)
mtext(&quot;Importance&quot;, 2, line = 2.5, at = 2.5, cex = 1, las = 0)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-153-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-154-1.png" width="672" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-achen1982interpreting">
<p>Achen, Christopher H. 1982. <em>Interpreting and Using Regression</em>. Vol. 29. Sage.</p>
</div>
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. a Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-bortz2006statistik">
<p>Bortz, Jürgen. 2006. <em>Statistik: Für Human-Und Sozialwissenschaftler</em>. Springer-Verlag.</p>
</div>
<div id="ref-bowerman1990linear">
<p>Bowerman, Bruce L, and Richard T O’Connell. 1990. <em>Linear Statistical Models: An Applied Approach</em>. Boston: PWS-Kent.</p>
</div>
<div id="ref-crawley2005statistics">
<p>Crawley, Michael J. 2005. <em>Statistics: An Introduction Using R. 2005</em>. Chichester, West Sussex: John Wiley &amp; Sons.</p>
</div>
<div id="ref-crawley2012r">
<p>———. 2012. <em>The R Book</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-faraway2002practical">
<p>Faraway, Julian J. 2002. <em>Practical Regression and Anova Using R.</em> University of Bath.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-green1991many">
<p>Green, Samuel B. 1991. “How Many Subjects Does It Take to Do a Regression Analysis.” <em>Multivariate Behavioral Research</em> 26 (3). Taylor &amp; Francis: 499–510.</p>
</div>
<div id="ref-gries2009statistics">
<p>Gries, Stefan Th. 2009. <em>Statistics for Linguistics Using R: A Practical Introduction</em>. Berlin &amp; New York: Mouton de Gruyter.</p>
</div>
<div id="ref-menard1995applied">
<p>Menard, Scott. 1995. <em>Applied Logistic Regression Analysis: Sage University Series on Quantitative Applications in the Social Sciences</em>. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-myers1990classical">
<p>Myers, Raymond H. 1990. <em>Classical and Modern Regression with Applications</em>. Vol. 2. Duxbury Press Belmont, CA.</p>
</div>
<div id="ref-szmrecsanyi2006morphosyntactic">
<p>Szmrecsanyi, Benedikt. 2006. <em>Morphosyntactic Persistence in Spoken English: A Corpus Study at the Intersection of Variationist Sociolinguistics, Psycholinguistics, and Discourse Analysis</em>. Berlin &amp; New York: Walter de Gruyter.</p>
</div>
<div id="ref-wilcox2009basic">
<p>Wilcox, Rand R. 2009. <em>Basic Statistics: Understanding Conventional Methods and Modern Insights</em>. Oxford University Press.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” <em>Methods in Ecology and Evolution</em> 1 (1): 3–14.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
