<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-01-23" />

<title>Advanced Inferential Statistics: Regression Modelling and Random Forests</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="researchdesigns.html">Research Designs</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="loading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization Techniques</a>
    </li>
    <li>
      <a href="advancedgraphs.html">Advanced Visualization Techniques</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptives.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Interential Statistics</a>
    </li>
    <li>
      <a href="advancedstatz.html">Advanced Interential Statistics</a>
    </li>
    <li>
      <a href="groupingstatz.html">Clustering</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis and Corpus Linguistics</li>
    <li>
      <a href="page-c.html">Network Analysis</a>
    </li>
    <li>
      <a href="page-c.html">Topic Modeling</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
    <li>
      <a href="corplingantconcexcel.html">Corpus Linguistics with AntConc, TextPad and Excel</a>
    </li>
    <li>
      <a href="available.html">Available Software</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Advanced Inferential Statistics: Regression Modelling and Random Forests</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-01-23</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">1</span> Multiple Linear Regression</h1>
<p>In contrast to simple linear regression, which estiamtes the effect of a single predictor, multiple linear regression estiamtes the effect of various predictor (cf. equation ()). A multiple linear regression can thus test the effects of various predictors simultaneously.</p>
<span class="math display">\[\begin{equation}

f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon

\end{equation}\]</span>
<p>There exists a wealth of literture focusing on multiple linear regressions and the concepts it is based on. For insatnce, there are <span class="citation">(Achen 1982)</span>, <span class="citation">(Bortz 2006)</span>, <span class="citation">(Crawley 2005)</span>, <span class="citation">(Faraway 2002)</span>, <span class="citation">(A. Field, Miles, and Field 2012)</span> (my personal favorite), and <span class="citation">(Wilcox 2009)</span> to name just a few. Introductions to regression modeling in <code>R</code> are <span class="citation">(Baayen 2008)</span>, <span class="citation">(Crawley 2012)</span>, or <span class="citation">(Gries 2009)</span>.</p>
<p>Eine weitere Anmerkung vorweg: Die modelldiagnostischen Verfahren werden teilweise identisch sein mit denen, die im Kapitel zur einfachen linearen Regression besprochen wurden und sie werden daher nur dann ausgiebiger erläutert, insofern dies nicht bereits geschehen ist.</p>
<p>Eine letzte Anmerkung betrifft die Stichprobengröße, die notwendig ist um eine Regression zu rechnen. Obwohl die Angabe, dass 25 Datenpunkte pro Gruppe ausreichen weit verbreitet ist, ist diese Angabe nicht korrekt, da sich die benötigte Stichprobengröße nach der Größe des Effekts, der bestimmt werden soll, und nach der Anzahl der untersuchten Variablen richtet. Gehen viele unabhängige Variablen in die Regression ein und die Effektstärke der zu testenden Variable(n) ist sehr klein, dann kann man von einer Mindestgröße der Stichprobe von 600 Datenpunkten ausgehen. <span class="citation">(A. Field, Miles, and Field 2012)</span> (273-275) geben zur Mindestgröße der benötigten Stichprobe Daumenregeln an die Hand (k = Anzahl der Prädikatoren; kategorische Prädikatoren mit mehr als 2 Levels sollten in Dummy-variablen transformiert werden):</p>
<ul>
<li>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</li>
<li>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</li>
<li>Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen. \end{itemize}</li>
</ul>
<p>%Grafik  einfügen. XXX</p>
<p>Sie werden im <code>R</code>-code sehen, dass hierzu eine Funktion existiert, die testet, ob die Stichprobe für die Untersuchung angemessen war.</p>
<p>Hinsichtlich der Modellanpassung wird nur auf step-wise step-down Prozeduren, die auf dem AIC (Akaike information criterion) beruhen, eingegangen werden. Es gibt eine Vielzahl von möglichen Prozeduren, die genutzt werden können forced entry, stepwise, hierarchical) und innerhalb dieser Prozeduren gibt es Unterklassen, sodass eine Diskussion den Rahmen dieser Sektion sprengen würde.</p>
<div id="example-gifts-and-availability" class="section level2">
<h2><span class="header-section-number">1.1</span> Example: Gifts and Availability</h2>
<p>In diesem Beispiel werden wir untersuchen, ob der Geldbetrag, den Männer für Geschenke ausgeben, mit der Attraktivität und dem Beziehungsstatus der Frauen, für die Geschenke gekauft wurden, korreliert. Das Beispiel ist  entnommen. Wir werden nun das Beispiel in  implementieren und leeren dazu, wie üblich, den gegenwärtigen Workspace, installieren und initialisieren/aktivieren notwendige Pakete und laden zusätzliche Funktionen.</p>
<pre class="r"><code># entfernen aller objekte aus dem aktuellen workspace
rm(list=ls(all=T))
# installieren der notwendigen pakete
# (falls nicht schon geschehen)
# (um die befehle zu aktivieren # entfernen)
#install.packages(&quot;rms&quot;)
#install.packages(&quot;glmulti&quot;)
#install.packages(&quot;lmtest&quot;)
#install.packages(&quot;MASS&quot;)
#install.packages(&quot;QuantPsyc&quot;)
#install.packages(&quot;car&quot;)
#install.packages(&quot;ggplot2&quot;)
# pakete initialisieren
#library(rms)
#library(glmulti)
#library(lmtest)
#library(MASS)
library(car)</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## 
## Attaching package: &#39;car&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:carData&#39;:
## 
##     Adler, Blackmore, Guyer, UN, Vocab</code></pre>
<pre class="r"><code>library(QuantPsyc)</code></pre>
<pre><code>## Loading required package: boot</code></pre>
<pre><code>## 
## Attaching package: &#39;boot&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     logit</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## 
## Attaching package: &#39;QuantPsyc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     norm</code></pre>
<pre class="r"><code>library(boot)
library(ggplot2)
source(&quot;rscripts/multiplot_ggplot2.r&quot;)
source(&quot;rscripts/mlinr.summary.r&quot;)
source(&quot;rscripts/SampleSizeMLR.r&quot;)
source(&quot;rscripts/ExpR.r&quot;)
# optionen festlegen
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)</code></pre>
<p>Nachdem wir die notwendigen Pakete usw. in <code>R</code> eingelesen haben, können wir nun die Daten laden und uns einen ersten Eindruck über deren Struktur und Eigenschaften verschaffen.</p>
<pre class="r"><code># daten laden
mlrdata &lt;- read.delim(&quot;data/mlrdata.txt&quot;, header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code># struktur der daten betrachten
str(mlrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code># zusammenfassung der daten betrachten
summary(mlrdata)</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p>Wir haben nun den Datensatz eingelesen und seine Struktur betrachtet. Im nächsten Schritt werden wir die Daten visualisieren, um einen Eindruck der Daten und der Verteilungen der Variablen zu gewinnen. Wir werden vier Grafiken erstellen und diese dann in einem Fenster darstellen.</p>
<pre class="r"><code>ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = T, aes(fill = factor(status))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Status&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(attraction, money)) +
geom_boxplot(notch = T, aes(fill = factor(attraction))) +
scale_fill_brewer() +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE) +
ggtitle(&quot;Attraction&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(x = money)) +
geom_histogram(aes(y=..density..),
binwidth = 10,
colour = &quot;black&quot;, fill = &quot;white&quot;) +
geom_density(alpha=.2, fill = &quot;#FF6666&quot;) # Overlay with transparent density plot</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mlrdata, aes(status, money)) +
geom_boxplot(notch = F, aes(fill = factor(status))) +
scale_fill_brewer(palette=&quot;Paired&quot;) +
facet_wrap(~ attraction, nrow = 1) +
theme_bw() + # backgroud white(inactive to default grey)
labs(x = &quot;&quot;) +
labs(y = &quot;Money spent on present (Euro)&quot;) +
coord_cartesian(ylim = c(0, 250)) +
guides(fill = FALSE)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>

<p>Die Grafik im oberen linken Panel scheint anzudeuten, dass Männer mehr Geld für Frauen ausgeben, die Single sind, allerdings relativiert sich dieser Eindruck, denn die Grafik im unteren rechten Panel deutet darauf hin, dass Männer nur dann mehr Geld für ein Geschenk ausgeben, wenn die Frau Single ist UND sie an ihr interessiert sind. Den der Beziehungsstatus hat keinen Einfluss auf das Geld für Geschenke für Frauen, an denen Männer nicht interessiert sind. Die Grafik im oberen rechten Panel weist darauf hin, dass Männer substantiell mehr Geld für Geschenke für Frauen ausgeben, an denen sie interessiert sind.</p>
<p>Gehen wir nun dazu über mit der Regression zu beginnen. Im ersten Schritt erzeugen wir vier Baselinemodelle: Zwei minimale Modelle, die nur den Gesamtmittelwert (Intercept) als Prädiktor beinhalten und zwei gesättigte Modelle (saturated models), die alle möglichen Prädikatoren und Interaktionen beinhalten.</p>
<pre class="r"><code># generieren der minimalen baselinemodelle, die nur den
# intercept (mittelwert) als unabh. variable beinhalten
m0.mlr = lm(money ~ 1, data = mlrdata) # baseline model
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)

summary(m0.mlr)  # inspect model</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -87.45 -38.54  -6.65  33.20 112.61 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 48.6 on 99 degrees of freedom</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m0.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -87.45  -38.54   -6.65   33.20  112.61  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2359)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance: 233562  on 99  degrees of freedom
## AIC: 1063
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>#############################
# generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -45.08  -14.26    0.46   11.93   44.14  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 360)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance:  34558  on 96  degrees of freedom
## AIC: 878.3
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Nachdem wir die Baselinemodelle generiert haben, werden wir nun mit dem Modellanpassung (model fitting)beginnen. Modellanpassung bezeichnet den Prozess mit dem man zu demjenigen Modell gelangt, dass das Maximum an Varianz mit einem Minimum an Variablen erklärt. Das zugrunde liegende Prinzip ist daher das <em>Parsimonie-</em> oder <em>Sparsamkeitsprinzip</em>, welches im Englischen häufig als Ockham’s Rasiermesser bezeichnet wird.</p>
<p>Wir werden einen automatischen step-wise step-down Prozess bei der Modellanpassung nutzen, der dasjenige Modell mit dem niedrigsten AIC (Akaike information criterion) Wert sucht. Das AIC berechnet sich nach Formel () und ist ein Maß der Sparsamkeit, dass einen Wert dafür bildet, wie viel Varianz mit wie vielen Variablen erklärt werden kann <span class="citation">(cf. A. Field, Miles, and Field 2012, 318)</span>. Um so niedriger der AIC-Wert, umso besser die Balance zwischen erklärter Varianz und der Anzahl der dafür nötigen Variablen. Die AIC-Werte können nun zwischen Modellen verglichen werden, die auf die selben Datenpunkte angepasst sind (<span class="math inline">\(LL\)</span> steht für LogLikelihood und <span class="math inline">\(k\)</span> für die Anzahl der unabhängigen Variablen im Modell).</p>
<span class="math display">\[\begin{equation}

-2LL + 2k
\label{eq:aic}

\end{equation}\]</span>
<p>We will not begin fitting the model.</p>
<pre class="r"><code># automatisches modelfitting
# kriterium: AIC (um so kleiner umso besser)
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<pre class="r"><code># minimales adequates modell generieren
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ (status + attraction)^2, family = gaussian, data = mlrdata)

# zusammenfassugn der modellergebnisse betrachten
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<p>Basierend auf dem Modell mit dem kleinsten AIC-Wert haben wir das minimale adäquate Modell (minimal adequate model) generiert und anschließend haben wir die Zusammenfassung der Ergebnisse des Modells auswerfen lassen. Im Folgenden werden wir den Output, d.h. die Zusammenfassung der Ergebnisse des minimalen adäquaten Modells beleuchten und die verschiedenen Konzepte erläutern.</p>
<p>Das erste Objekt, was die Zusammenfassung berichtet ist der <em>Call</em>, d.h. die Formel des des minimalen adäquaten Modells. Daran anschließend wird die Verteilung der Residuen, also der Unterschiede zwischen den vorhergesagten und beobachteten Werten, berichtet. Dann folgt das wichtigste Element der Modellzusammenfassung: Die Tabelle mit den Koeffizienten der Prädikatoren des Modells (dies sind die Koeffizienten der Fixed Effects). Wir werden uns mit dieser Tabelle später genauer beschäftigen. Nach der Tabelle folgen die Modellstatistiken, die Aufschluss darüber geben, wie gut das Modell die Daten modelliert, d.h. wie gut das Modell den beobachteten Daten entspricht. Der Unterschied zwischen diesen Werten und der Tabelle mit den Koeffizienten besteht darin, dass die Modellstatistiken über die Gesamtgüte des Modells berichten, während die Tabelle mit den Koeffizienten nur etwas über die individuellen Faktoren aussagt.</p>
<p>Der multiple R<sup>2</sup>-Wert gibt an, wie viel Varianz das Modell erklärt. Ein Wert von 0 würde bedeuten, dass das Modell gar keine Varianz erklärt, während ein Wert von 1 bedeuten würde, dass das Modell 100 percent der Varianz erklärt und somit die Vorhersage des Modells genau den beobachteten Daten entspricht. Dies bedeutet, dass, wenn man den R<span class="math inline">\(^{2}\)</span>-Wert mit 100 multipliziert, man den Prozentwert der Varianz erhält, den das Modell erklärt. In unserem Fall sagt der multiple R<span class="math inline">\(^{2}\)</span>-Wert von 0.852 also aus, dass unser minimales adäquates Modell 85.2 percent der Varianz erklärt. Modelle, die einen multiplen R<span class="math inline">\(^{2}\)</span>-Wert von <span class="math inline">\(ge\)</span>.05 haben, gelten als substantiell signifikant (substantially significant) <span class="citation">(Szmrecsanyi 2006)</span> 55). Manche gehen soweit zu sagen, dass Modelle mindestens einen <span class="math inline">\(R^{2}\)</span>-Wert von <span class="math inline">\(\ge\)</span>.05 haben müssen, aber dies ist problematisch, da es durchaus vorkommen kann, dass man an sehr schwachen (aber signifikanten) Effekten interessiert ist, die aber zu einem sehr kleinen <span class="math inline">\(R^{2}\)</span>-Wert führen. Wichtiger ist, dass das Modell insgesamt signifikant ist, da dies aussagt, dass das Modell zu signifikant besseren Vorhersagen kommt, als es durch Zufall der Fall wäre.</p>
<p>Der angepasste <span class="math inline">\(R^{2}\)</span>-Wert (adjusted <span class="math inline">\(R^{2}\)</span>) berücksichtigt die Anzahl der Prädikatoren. Darüber hinaus gibt der angepasste <span class="math inline">\(R^{2}\)</span>-Wert darüber Aufschluss, wie gut sich das Modell eignet, um Aussagen über die Population (und nicht nur über die Stichprobe) zu tätigen. Wenn der Unterschied zwischen dem multiplen <span class="math inline">\(R^{2}\)</span>-Wert und dem angepassten <span class="math inline">\(R^{2}\)</span>-Wert sehr gering ist, dann bedeutet dies, dass sich das Modell dazu eignet Aussagen über die Population als Ganzes zu machen. Wenn der Unterschied allerdings relativ groß ist, dann bedeutet dies, dass das Modell instabil ist und die Datenstruktur, auf die das Modell angepasst wurde, eine suboptimale Verteilung aufweist, z.B. wegen Ausreißern. In anderen Worten bedeutet der Unterschied, dass wenn die Regression auf die Population anstatt der Stichprobe angewandt worden wäre, dann würde sie .5 perecnt weniger Varianz (85.2-84.7) erklären.</p>
<p>Kommen wir nun zu der Tabelle mit den Koeffizienten zurück. Alle Haupteffekte und eine Interaktion zwischen “<em>status</em>” und “<em>attraction</em>” sind signifikant. Eine Interaktion besteht dann, wenn die Korrelation zwischen einer unabhängigen und der abhängigen variable von einer anderen unabhängigen variable beeinflusst wird. In unserem Szenario geben Männer nur dann mehr Geld für ein Geschenk für eine Frau aus, wenn sie an ihr (a) interessiert sind und (b) sie Single ist. Die Korrelation zwischen “<em>money</em>” und “<em>attraction</em>” wird also von einer anderen Variable “<em>status</em>” beeinflusst. Wir haben es also mit einer Interaktion zwischen “<em>attraction</em>” und “<em>status</em>” zu tun.</p>
<p>Hinsichtlich der Interpretation dieser Ergebnisse ist festzuhalten, dass man Haupteffekte, die an Interaktionen beteiligt sind, nicht interpretieren sollte, da nicht klar ist, wie sich der Anteil an erklärter Varianz zwischen dem Haupteffekten und den Interaktionen aufteilt. Zusätzlich ist festzuhalten, dass, insofern nur Haupteffekte signifikant sind, die Koeffizienten die Korrelation zwischen der abhängigen und der unabhängigen Variable abbilden, wenn die anderen Variablen einen Wert von 0 oder das jeweilige Baseline-Level annehmen.</p>
<p>Bevor wir die Tabelle mit den Koeffizienten weiter interpretieren, werden wir noch die Konfidenzintervalle berechnen und das Baselinemodell mit dem minimalen adäquaten Modell vergleichen, um zu schauen, ob das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell.</p>
<pre class="r"><code>confint(m2.mlr)       # extract confidence intervals of the coeficients</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre class="r"><code>anova(m0.mlr, m2.mlr) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m0.mlr, m2.mlr, type = &quot;III&quot;) # compare baseline- and minimal adequate model</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Vergleich der Modelle zeigt eindeutig, dass das minimale adäquate Modell zu signifikant besseren Vorhersagen kommt als das Baselinemodell. Wir werden nun mit der Modelldiagnose fortfahren, indem wir schauen, ob Datenpunkte entfernt werden sollten, da sie die Passgenauigkeit des Modells (modelfit) überproportional verschlechtern.</p>
<pre class="r"><code># suche nach problematischen datenpunkten
# erzeugen diagnostischer grafiken
par(mfrow = c(3, 2))
plot(m2.mlr)
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;)</code></pre>
<pre><code>## [1] 52 83</code></pre>
<pre class="r"><code># Cooks D plot
# D-werte &gt; 4/(n-k-1) sind problematisch
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
plot(m2.mlr, which=4, cook.levels = cutoff)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>

<p>The graphs indicate that data points 52, 64, and 83 may be problematic. We will tehrefore statistically evaluate whether these data points need to be removed. In order to find out which data points require removal, we extract the influence measure statistics and add them to out data set.</p>
<pre class="r"><code>infl &lt;- influence.measures(m2.mlr)                   # extarct influence statistics
mydata &lt;- data.frame(mlrdata, infl[[1]], infl[[2]])  # add infl. statistics to data
head(mydata)</code></pre>
<pre><code>##         status    attraction money                  dfb.1_
## 1 Relationship NotInterested 86.33  0.00000000000000236805
## 2 Relationship NotInterested 45.58  0.00000000000000022805
## 3 Relationship NotInterested 68.43 -0.00000000000000091891
## 4 Relationship NotInterested 52.93 -0.00000000000000016896
## 5 Relationship NotInterested 61.86  0.00000000000000011789
## 6 Relationship NotInterested 48.47 -0.00000000000000004889
##                   dfb.sttS dfb.atNI  dfb.sS.N    dffit  cov.r     cook.d
## 1 -0.000000000000001067658  0.27414 -0.193850  0.38770 0.9358 0.03658407
## 2 -0.000000000000000396634 -0.04569  0.032306 -0.06461 1.0817 0.00105355
## 3  0.000000000000001134168  0.13140 -0.092911  0.18582 1.0491 0.00864788
## 4  0.000000000000000269812  0.01111 -0.007854  0.01571 1.0860 0.00006233
## 5 -0.000000000000000001814  0.08021 -0.056718  0.11344 1.0722 0.00324023
## 6  0.000000000000000015629 -0.02334  0.016507 -0.03301 1.0850 0.00027528
##    hat dfb.1_.1 dfb.sttS.1 dfb.atNI.1 dfb.sS.N.1 dffit.1 cov.r.1 cook.d.1
## 1 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 2 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 3 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 4 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 5 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 6 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
##   hat.1
## 1 FALSE
## 2 FALSE
## 3 FALSE
## 4 FALSE
## 5 FALSE
## 6 FALSE</code></pre>
<pre class="r"><code># zu einflussreiche datenpunkte erkennen
remove &lt;- apply(infl$is.inf, 1, function(x) {
ifelse(x == TRUE, return(&quot;remove&quot;), return(&quot;keep&quot;)) } )

# informationen zu den zu einflussreichen datenpunkten
# zum datensatz hinzuaddieren
mlrdata &lt;- data.frame(mlrdata, remove)

# zeilenzahl des alten datensatzes anzeigen
nrow(mydata)</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>mlrdata &lt;- mlrdata[mlrdata$remove == &quot;keep&quot;, ]

# zeilenzahl des neuen datensatzes anzeigen
nrow(mlrdata)</code></pre>
<pre><code>## [1] 98</code></pre>
<p>Die Zeilenzahl weist darauf hin, dass zwei potentielle Problemfälle entfernt wurden, da deren Werte inakzeptabel waren, während einer der Punkte im Modell verbleiben durfte. Da wir es nun mit einem veränderten Datensatz zu tun haben, müssen wir die bisherigen Schritte wiederholen. Die einzelnen wiederholten Schritte werden nun nicht weiter erläutert, insofern die Erläuterungen mit den bereits oben ausgeführten weitgehend identisch wäre.</p>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -76.00 -38.05  -6.39  33.15 105.66 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 46.9 on 97 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -76.00  -38.05   -6.39   33.15  105.66  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2198)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance: 213227  on 97  degrees of freedom
## AIC: 1035
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code># generieren der saturated models, die alle
# unabh. variablen und interaktionen beinhalten
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian, data = mlrdata)
# ergebnisse betrachten
summary(m1.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre class="r"><code># ergebnisse betrachten
summary(m1.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -35.76  -13.51   -0.99   10.60   38.77  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 323.5)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance:  30411  on 94  degrees of freedom
## AIC: 850.4
## 
## Number of Fisher Scoring iterations: 2</code></pre>
</div>
<div id="automatic-model-fitting" class="section level2">
<h2><span class="header-section-number">1.2</span> Automatic Model Fitting</h2>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="outlier-detection" class="section level2">
<h2><span class="header-section-number">1.3</span> Outlier Detection</h2>
<p>In a next step, we cerate diagnostic plots in order to check whether there are potentially problematic data points.</p>
<pre><code>## 84 88 
## 82 86</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>

<p>Although the diagnosic plots indicate that additional points may be problematic, but these data points deviate substantially less from the trend than was the case with the data points that have already been removed. To make sure that retaining the data points that are deemed potentially problematic by the diagnostoc plots, is acceptable, we extarct diagnostoic statistics and add them to the data.</p>
<p>We can now use these diagnostic statistics to create more precise diagnostic plots.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>

<p>The new diagnistic plots do not indicate outliers that require removal. With respect to such data points the following parameters should be considered:</p>
<ul>
<li><p>Data points with standardised residuals &gt; 3.29 should be removed <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>If more than 1 percent of data points have standardized residuals exceeding values <span class="math inline">\(\ge\)</span> 2.58, then the errorrate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field 2012, 269)</span>.</p></li>
<li><p>If more than 5 percent of data points have standardized residuals exceeding values <span class="math inline">\(\ge\)</span> 1.96, then the errorrate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>In addition, data points with Cook’s D-values <span class="math inline">\(\ge\)</span> 1 should be removed <span class="citation">(A. Field, Miles, and Field 2012, 269)</span></p></li>
<li><p>Also, data points with leverage values <span class="math inline">\(3(k + 1)/n\)</span> (k = Number of predictors, N = Number of cases in model) should be removed <span class="citation">(A. Field, Miles, and Field 2012, 270)</span></p></li>
<li><p>There should not be (any) autocorrelation among predictors. This means that independent variables cannot be correlated with itself (for instance, because data points come from the same subject). If there is autocorrelation among predictots, then a Repeated Measures Design or a (hierarchical) mixed-effects model should be implemented instead.</p></li>
<li><p>Predictors cannot substantiatlly correlate with each other (multicollinearity). If a model contains perdictors that have variance inflation factors (VIF) <span class="math inline">\(\ge\)</span> 10 the model is completely unreliable <span class="citation">(Myers 1990)</span> and predictors causing such VIFs should be removed. Indeed, even VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi 2006, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick 2010)</span> proposes that variables with VIFs exceeding 3 should be removed!</p></li>
<li><p>Data points with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard 1995)</span>.</p></li>
<li><p>The mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and O’Connell 1990)</span>.</p></li>
</ul>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">1.4</span> Model Diagnostics</h2>
<pre><code>## integer(0)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968   0.596
##  Alternative hypothesis: rho != 0</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre><code>## [1] 2.307</code></pre>
<p>Except for the mean VIF value (2.307) which should not exceed 1, all diagnostics are acceptable. We will now test whether the sample size is sufficient for our model. With respect to the minimal sample size and based on <span class="citation">(Green 1991)</span>, <span class="citation">(A. Field, Miles, and Field 2012, 273–74)</span> offer the following rules of thumb (k = number of predictors; categorical predictors with more than two levels shuld be recoded as dummy variables):</p>
<ul>
<li><p>Ist man nur an dem allgemeinen Modell-fit interessiert (ein Fall, der mir persönlich noch nie vorgekommen ist), sollte die Stichprobe mindestens 50 + k umfassen.</p></li>
<li><p>Wenn man nur am Einfluss spezifischer Variablen interessiert ist, sollte die Stichprobe mindestens 104 + k umfassen.</p></li>
<li><p>Wenn man an beidem interessiert ist, sollte man den je höheren Wert nehmen.</p></li>
</ul>
<p>Zusätzlich werden wir prüfen, wie groß der Wert für <code>R</code> basierend auf einer Zufallsstichprobe wäre, um abschätzen zu können, wie groß die Wahrscheinlichkeit eines <span class="math inline">\(\beta\)</span>-Fehlers bei der vorliegenden Stichprobengröße ist <span class="citation">(vgl. A. Field, Miles, and Field 2012, 274)</span>. Bei <span class="math inline">\(\beta\)</span>-Fehlern handelt es sich um die Annahme, ein Prädikator ist nicht signifikant, obwohl er tatsächlich einen signifikanten Einfluss hat (siehe Sektion ). Die Prüfgröße schwankt zwischen 0 und 1. Umso kleiner der Wert ist, umso besser. Wenn der Wert <span class="math inline">\(\ge\)</span> 1 liegt, dann gibt es Grund zur Sorge und es sollte eine größere Stichprobe gezogen werden.</p>
</div>
<div id="evaluation-of-sample-size" class="section level2">
<h2><span class="header-section-number">1.5</span> Evaluation of Sample Size</h2>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<p>Die Funktion <code>smplesz</code> teilt mit, dass die Stichprobengröße nicht optimal ist und 9 Datenpunkte fehlen, um der Anforderung von <span class="citation">(Green 1991)</span> zu genügen. Die Wahrscheinlichkeit einen <span class="math inline">\(\beta\)</span>-Fehler zu begehen ist hingegen sehr klein (0.0309). Als letzten Schritt tabellarisieren wir die Ergebnisse und fassen diese anschließend in Textform zusammen.</p>
<pre class="r"><code># ergebnisse der mlr betrachten
mlr.summary(m2.mlr, m2.glm, ia = T)</code></pre>
<pre><code>## Waiting for profiling to be done...
## Waiting for profiling to be done...</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%) CI(97.5%)
## (Intercept)                             99.15          92.1    106.21
## statusSingle                            55.85    2    45.78     65.93
## attractionNotInterested                -47.66 1.96   -57.63    -37.69
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71    -45.21
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                                                          
##                                               Std. Error      t value
## (Intercept)                                          3.6        27.56
## statusSingle                                        5.14        10.87
## attractionNotInterested                             5.09        -9.37
## statusSingle:attractionNotInterested                7.27        -8.18
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                          F-statistic: 188.36 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>

<p>Zusätzlich werden die Ergebnisse von multiplen linearen Regressionen schriftlich wie folgt zusammengefasst:</p>
<p>(Falls signifikante Interaktionen vorliegen, sollten die Haupteffekte der Prädikatoren, die an der/n Interaktion/en beteiligt sind, nicht interpretiert werden. Sie werden hier dennoch interpretiert, um zu verdeutlichen, wie die Ergebnisse einer multiplen linearen Regression verschriftlicht werden können.)</p>
<p>Eine multiple lineare Regression wurde mit AIC-basierter (Akaike’s Information Criterion) step-wise step-down Prozedur auf die Daten angepasst, um zum finalen minimalen adäquaten Modell zu gelangen. Während der Modelldiagnose wurden zwei Datenpunkte als Ausreißer ermittelt und aus dem Datensatz entfernt. Weitere modelldiagnostischen Grafiken und zusätzliche statistische Modelldiagnosen ergaben nach dem Entfernen der Ausreißer keine weiteren Auffälligkeiten.</p>
<p>Das finale minimale adäquate Modell basiert auf 98 Datenpunkten und korreliert hoch signifikant mit dem Datensatz (Multipler <span class="math inline">\(R^{2}\)</span>: .857, Angepasster <span class="math inline">\(R^{2}\)</span>: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p<span class="math inline">\(&lt;.001***\)</span>). Das finale minimale adäquate Modell enthält sowohl  und  als signifikante Haupteffekte. Der Status von Geschenk-empfängern korreliert hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.14, <span class="math inline">\(t\)</span>-Wert: 10.87, p<span class="math inline">\(&lt;.001***\)</span>). Dies zeigt, dass wenn eine Person single ist, ihr Geschenk {55,85} mehr wert ist, verglichen mit dem Fall, dass sie in einer Beziehung ist (in diesem Fall ist das Geschenk {99.15}, wenn der Schenker nicht an der Beschenkten interessiert ist. Der Faktor  korreliert ebenfalls hoch signifikant positiv mit dem Geldbetrag, der für ihre Geschenke ausgegeben wird (SE: 5.09, <span class="math inline">\(t\)</span>-Wert: -9.37, p<span class="math inline">\(&lt;.001***\)</span>). Falls der Schenkende nicht an der Beschenkten interessiert ist, dann gibt er {-47.66} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er sie attraktiv findet (vorausgesetzt die Beschenkte ist in einer Beziehung). Schließlich weist das finale minimale adäquate Modell eine hoch signifikante Interaktion zwischen  und  nach (SE: 7.27, <span class="math inline">\(t\)</span>-Wert: -8.18, p<span class="math inline">\(&lt;\)</span>.001***): Wenn die Beschenkte ein Single ist, aber der Schenker nicht an ihr interessiert ist, dann gibt der Schenker {59,46} weniger für ein Geschenk aus, verglichen mit dem Fall, dass er an der Beschenkten interessiert ist (vgl. Figure ).</p>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.6</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Download the data set called <code>exdatamlr</code> from <code>http://martinschweinberger.de/docs/data/exdatamlr.txt</code> and apply what you have learned by implementing a multiple linear regression model so that you can answer how movement (move) and food intake (food) affect weight (given the data at hand).</li>
</ol>
</div>
</div>
<div id="multiple-linear-regression-1" class="section level1">
<h1><span class="header-section-number">2</span> Multiple Linear Regression</h1>
<pre class="r"><code># pakete initialisieren
library(car)
library(QuantPsyc)
library(boot)
library(ggplot2)
# load functions
source(&quot;rscripts/multiplot_ggplot2.R&quot;)
source(&quot;rscripts/mlinr.summary.r&quot;)
source(&quot;rscripts/SampleSizeMLR.r&quot;)
source(&quot;rscripts/ExpR.r&quot;)
# optionen festlegen
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)
# daten laden
mlrdata &lt;- read.delim(&quot;data/mlrdata.txt&quot;, header = TRUE)
# ersten zeilen der daten betrachten
head(mlrdata)</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code># struktur der daten betrachten
str(mlrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code># zusammenfassung der daten betrachten
summary(mlrdata)</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -87.45 -38.54  -6.65  33.20 112.61 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 48.6 on 99 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -87.45  -38.54   -6.65   33.20  112.61  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.38       4.86    18.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2359)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance: 233562  on 99  degrees of freedom
## AIC: 1063
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -45.08  -14.26    0.46   11.93   44.14  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 360)
## 
##     Null deviance: 233562  on 99  degrees of freedom
## Residual deviance:  34558  on 96  degrees of freedom
## AIC: 878.3
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## Start:  AIC=592.5
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           34558 593
## - status:attraction  1     24947 59505 645</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 57.7  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -63.2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.79   26.13
## statusSingle                            57.69       5.37   10.75
## attractionNotInterested                -47.66       5.37   -8.88
## statusSingle:attractionNotInterested   -63.18       7.59   -8.32
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000038 ***
## statusSingle:attractionNotInterested    0.000000000000581 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.847 
## F-statistic:  184 on 3 and 96 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           91.62 106.69
## statusSingle                          47.04  68.34
## attractionNotInterested              -58.31 -37.01
## statusSingle:attractionNotInterested -78.24 -48.11</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     99 233562                                         
## 2     96  34558  3    199005 184 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 781016  1     331 &lt;0.0000000000000002 ***
## Residuals    34558 96                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## [1] 52 83</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre><code>##         status    attraction money                  dfb.1_
## 1 Relationship NotInterested 86.33  0.00000000000000236805
## 2 Relationship NotInterested 45.58  0.00000000000000022805
## 3 Relationship NotInterested 68.43 -0.00000000000000091891
## 4 Relationship NotInterested 52.93 -0.00000000000000016896
## 5 Relationship NotInterested 61.86  0.00000000000000011789
## 6 Relationship NotInterested 48.47 -0.00000000000000004889
##                   dfb.sttS dfb.atNI  dfb.sS.N    dffit  cov.r     cook.d
## 1 -0.000000000000001067658  0.27414 -0.193850  0.38770 0.9358 0.03658407
## 2 -0.000000000000000396634 -0.04569  0.032306 -0.06461 1.0817 0.00105355
## 3  0.000000000000001134168  0.13140 -0.092911  0.18582 1.0491 0.00864788
## 4  0.000000000000000269812  0.01111 -0.007854  0.01571 1.0860 0.00006233
## 5 -0.000000000000000001814  0.08021 -0.056718  0.11344 1.0722 0.00324023
## 6  0.000000000000000015629 -0.02334  0.016507 -0.03301 1.0850 0.00027528
##    hat dfb.1_.1 dfb.sttS.1 dfb.atNI.1 dfb.sS.N.1 dffit.1 cov.r.1 cook.d.1
## 1 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 2 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 3 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 4 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 5 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
## 6 0.04    FALSE      FALSE      FALSE      FALSE   FALSE   FALSE    FALSE
##   hat.1
## 1 FALSE
## 2 FALSE
## 3 FALSE
## 4 FALSE
## 5 FALSE
## 6 FALSE</code></pre>
<pre><code>## [1] 100</code></pre>
<pre><code>## [1] 98</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -76.00 -38.05  -6.39  33.15 105.66 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 46.9 on 97 degrees of freedom</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ 1, family = gaussian, data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -76.00  -38.05   -6.39   33.15  105.66  
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    88.12       4.74    18.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 2198)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance: 213227  on 97  degrees of freedom
## AIC: 1035
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>## 
## Call:
## glm(formula = money ~ status * attraction, family = gaussian, 
##     data = mlrdata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -35.76  -13.51   -0.99   10.60   38.77  
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 323.5)
## 
##     Null deviance: 213227  on 97  degrees of freedom
## Residual deviance:  30411  on 94  degrees of freedom
## AIC: 850.4
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre><code>## Start:  AIC=570.3
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS AIC
## &lt;none&gt;                           30411 570
## - status:attraction  1     21647 52058 621</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                 99.2  
##                         statusSingle  
##                                 55.9  
##              attractionNotInterested  
##                                -47.7  
## statusSingle:attractionNotInterested  
##                                -59.5</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76 -13.51  -0.99  10.60  38.77 
## 
## Coefficients:
##                                      Estimate Std. Error t value
## (Intercept)                             99.15       3.60   27.56
## statusSingle                            55.85       5.14   10.87
## attractionNotInterested                -47.66       5.09   -9.37
## statusSingle:attractionNotInterested   -59.46       7.27   -8.18
##                                                  Pr(&gt;|t|)    
## (Intercept)                          &lt; 0.0000000000000002 ***
## statusSingle                         &lt; 0.0000000000000002 ***
## attractionNotInterested                 0.000000000000004 ***
## statusSingle:attractionNotInterested    0.000000000001338 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18 on 94 degrees of freedom
## Multiple R-squared:  0.857,  Adjusted R-squared:  0.853 
## F-statistic:  188 on 3 and 94 DF,  p-value: &lt;0.0000000000000002</code></pre>
<pre><code>##                                       2.5 % 97.5 %
## (Intercept)                           92.01 106.30
## statusSingle                          45.65  66.06
## attractionNotInterested              -57.76 -37.56
## statusSingle:attractionNotInterested -73.89 -45.03</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq   F              Pr(&gt;F)    
## 1     97 213227                                         
## 2     94  30411  3    182816 188 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value              Pr(&gt;F)    
## (Intercept) 760953  1     346 &lt;0.0000000000000002 ***
## Residuals    30411 94                                
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 84 88 
## 82 86</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre><code>## integer(0)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## [1] 6.122</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1        -0.01433         1.968    0.65
##  Alternative hypothesis: rho != 0</code></pre>
<pre><code>##            status        attraction status:attraction 
##              2.00              1.96              2.96</code></pre>
<pre><code>##            status        attraction status:attraction 
##            0.5000            0.5102            0.3378</code></pre>
<pre><code>## [1] 2.307</code></pre>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%) CI(97.5%)
## (Intercept)                             99.15          92.1    106.21
## statusSingle                            55.85    2    45.78     65.93
## attractionNotInterested                -47.66 1.96   -57.63    -37.69
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71    -45.21
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                                                          
##                                               Std. Error      t value
## (Intercept)                                          3.6        27.56
## statusSingle                                        5.14        10.87
## attractionNotInterested                             5.09        -9.37
## statusSingle:attractionNotInterested                7.27        -8.18
## Model statistics                                                     
## Number of cases in model                                             
## Residual Standard Error on 94 DF                                     
## Multiple R2                                                          
## Adjusted R2                                                          
## AIC                                                                  
## BIC                                                                  
## F-statistic                          F-statistic: 188.36 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>
</div>
<div id="linear-mixed-effects-regression-models" class="section level1">
<h1><span class="header-section-number">3</span> Linear Mixed-Effects Regression Models </h1>
<p>The following focuses on an extension of ordinary multiple regressions: mixed-effects regression models.</p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. having only fixed-effecst measn that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristsi. In such cases, the data is consiederd hierarchical and statistical models should incororate such structiral features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope, while mixed effects models have intercepts for each level of a random effect. If the randon effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and or slope for each speaker.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p><em>Random Effects</em> have two parameters: the intercept (the point where the regression line cross the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models have only 1 intercept and one slope (left panel of the Figure above) while mixed-effects models can have various <em>random intercepts</em> (center left panel ) or various <em>random slopes</em> (center right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the follwoing, we will onyl focus on models with random interecpts becasue this is the by far more common method and because including both random incetrcepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>caption{Scatterplots mit einer Regressionsgeraden (mitte) und Random Intencepts (rechts)} label{fig:mem01}</p>
<p>The left panel merely shows the data while the center panel includes the regression line for a regression that estimates Weight basedon Height. The right panel shows the regression line and, in addition, random incercepts each each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple rgeression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field 2012)</span>. We test whteher including random effects is warranted by comparing a model, that bases its estiamtes of the dependend variable solely on the base intercept (the mean), with a model, that bases its estiamtes of the dependend variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in <code>R</code> we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load neccessary <code>R</code> packages, specify oprions, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(RLRsim)
#library(car)
#library(QuantPsyc)
#library(boot)
library(nlme)
library(lme4)
#library(ez)
library(ggplot2)
# set options
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      # supress scientific notation
options(stringsAsFactors = F)              # do not convert strings into factors
mydata &lt;- read.delim(&quot;data/lmemdata.txt&quot;, header = TRUE) # read in data
mydata$date &lt;- as.numeric(mydata$date)     # convert date into a numeric variable
head(mydata); nrow(mydata)                 # inspect updated data set</code></pre>
<pre><code>##   date         genre    text  pptw region
## 1 1736 SCIENCE_OTHER   albin 166.0  north
## 2 1711 EDUC_TREATISE    anon 139.9  north
## 3 1808  LETTERS_PRIV  austen 130.8  north
## 4 1878 EDUC_TREATISE    bain 151.3  north
## 5 1743 EDUC_TREATISE barclay 145.7  north
## 6 1908 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (<code>date</code>), the genre of the text (<code>genre</code>), the name of the text (<code>text</code>), the relative frequency of prepositions in the text (<code>pptw</code>), and the region in which the text was written (<code>region</code>). We now plot the data to get a first impression of its structure.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderattely increased over time while the boxplots in the lower left panel show show that the gernres differ quite substantailly with respect to their median frequencies of preositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre><code>##     date         genre    text  pptw region
## 1 109.87 SCIENCE_OTHER   albin 166.0  north
## 2  84.87 EDUC_TREATISE    anon 139.9  north
## 3 181.87  LETTERS_PRIV  austen 130.8  north
## 4 251.87 EDUC_TREATISE    bain 151.3  north
## 5 116.87 EDUC_TREATISE barclay 145.7  north
## 6 281.87 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  5 variables:
##  $ date  : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ genre : chr  &quot;SCIENCE_OTHER&quot; &quot;EDUC_TREATISE&quot; &quot;LETTERS_PRIV&quot; &quot;EDUC_TREATISE&quot; ...
##  $ text  : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ pptw  : num  166 140 131 151 146 ...
##  $ region: chr  &quot;north&quot; &quot;north&quot; &quot;north&quot; &quot;north&quot; ...</code></pre>
<pre><code>## [[1]]
## [1] 220.9
## 
## [[2]]
## [1] 0.000000000000000000000000000000000000000000000001082</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer1: pptw ~ (1 | genre) + 1
## m0.lmer2: pptw ~ (1 | region) + 1
## m0.lmer3: pptw ~ (1 | genre/region) + 1
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.lmer1  3 4502 4515  -2248     4496                                     
## m0.lmer2  3 4719 4731  -2356     4713     0      0                   1    
## m0.lmer3  4 4501 4518  -2246     4493   220      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 
##  simulated finite sample distribution of RLRT.
##  
##  (p-value based on 10000 simulated values)
## 
## data:  
## RLRT = 220, p-value &lt;0.0000000000000002</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m1.lme     2  5 4496 4517  -2243 1 vs 2   10.12  0.0063</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4496 4517  -2243
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.05
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       3.453    14.97
## 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.95     3.183 505   42.09  0.0000
## date          0.02     0.007 505    2.70  0.0071
##  Correlation: 
##      (Intr)
## date 0.003 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.74687 -0.66308  0.01827  0.64043  3.62269 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1770.7  &lt;.0001
## date            1   505     7.3  0.0071</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer: pptw ~ (1 | genre/region) + 1
## m1.lmer: pptw ~ (1 | genre/region) + date
##         Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
## m0.lmer  4 4501 4518  -2246     4493                           
## m1.lmer  5 4496 4517  -2243     4486  7.03      1      0.008 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.713505 133.95499 140.19647
## date          0.004896   0.01787   0.03083
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept))  8.19 12.05 17.73
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 1.172 3.453 10.17
## 
##  Within-group standard error:
## lower  est. upper 
## 14.07 14.97 15.93</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-42-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-2.png" width="672" /></p>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m1.lme     1  5 4496 4517  -2243                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   42.75  0.0002</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4483 4569  -2222
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.14
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       4.183    13.89
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | genre 
##  Parameter estimates:
##             BIBLE   BIOGRAPHY_OTHER        DIARY_PRIV     EDUC_TREATISE 
##            1.0000            0.3582            0.8994            0.7324 
##           FICTION    HANDBOOK_OTHER           HISTORY               LAW 
##            0.8895            1.1417            1.0185            0.7591 
##  LETTERS_NON-PRIV      LETTERS_PRIV        PHILOSOPHY PROCEEDINGS_TRIAL 
##            1.2641            1.2302            0.7753            1.2262 
##    RELIG_TREATISE     SCIENCE_OTHER            SERMON        TRAVELOGUE 
##            1.0108            0.8293            0.9821            1.0663 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 134.01     3.209 505   41.76  0.0000
## date          0.02     0.006 505    3.36  0.0008
##  Correlation: 
##      (Intr)
## date 0.002 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.29018 -0.67307  0.03261  0.64633  3.08450 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1743.6  &lt;.0001
## date            1   505    11.3  0.0008</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   52.87  &lt;.0001</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.719320 134.01179 140.30426
## date          0.008414   0.02022   0.03203
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept)) 8.253 12.14 17.87
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 2.092 4.183 8.363
## 
##  Variance function:
##                    lower   est.  upper
## BIOGRAPHY_OTHER   0.2233 0.3582 0.5747
## DIARY_PRIV        0.6532 0.8994 1.2385
## EDUC_TREATISE     0.5210 0.7324 1.0295
## FICTION           0.6426 0.8895 1.2312
## HANDBOOK_OTHER    0.8170 1.1417 1.5955
## HISTORY           0.7583 1.0185 1.3682
## LAW               0.5499 0.7591 1.0480
## LETTERS_NON-PRIV  0.9974 1.2641 1.6020
## LETTERS_PRIV      0.9907 1.2302 1.5276
## PHILOSOPHY        0.4907 0.7753 1.2250
## PROCEEDINGS_TRIAL 0.8344 1.2262 1.8019
## RELIG_TREATISE    0.6776 1.0108 1.5078
## SCIENCE_OTHER     0.5702 0.8293 1.2063
## SERMON            0.7351 0.9821 1.3121
## TRAVELOGUE        0.7574 1.0663 1.5012
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.62 13.89 16.61</code></pre>
<pre><code>## [1] &quot;Pearson&#39;s r =  0.148&quot;</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000005159</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-42-3.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-4.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-5.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-6.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-7.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-42-8.png" width="672" /></p>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
</div>
</div>
<div id="multiple-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">4</span> Multiple Binomial Logistic Regression</h1>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  7 variables:
##  $ file.speaker.id: chr  &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; ...
##  $ text.id        : chr  &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; ...
##  $ spk.ref        : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ...
##  $ sex            : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ age            : Factor w/ 2 levels &quot;young&quot;,&quot;old&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ethnicity      : Factor w/ 2 levels &quot;Pakeha&quot;,&quot;Maori&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ suf.eh         : num  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<pre><code>##  file.speaker.id      text.id            spk.ref              sex       
##  Length:25821       Length:25821       Length:25821       female:15852  
##  Class :character   Class :character   Class :character   male  : 9969  
##  Mode  :character   Mode  :character   Mode  :character                 
##                                                                         
##                                                                         
##                                                                         
##     age         ethnicity         suf.eh     
##  young:19150   Pakeha:20024   Min.   :0.000  
##  old  : 6671   Maori : 5797   1st Qu.:0.000  
##                               Median :0.000  
##                               Mean   :0.337  
##                               3rd Qu.:1.000  
##                               Max.   :1.000</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-43-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-43-2.png" width="672" /></p>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age * sex * ethnicity, family = binomial, 
##     data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.095  -0.913  -0.780   1.283   1.868  
## 
## Coefficients:
##                               Estimate Std. Error z value
## (Intercept)                    -0.6594     0.0207  -31.79
## ageold                         -0.7966     0.0563  -14.15
## sexmale                         0.4150     0.0337   12.32
## ethnicityMaori                  0.0639     0.0555    1.15
## ageold:sexmale                  0.0070     0.0852    0.08
## ageold:ethnicityMaori          -0.1599     0.1025   -1.56
## sexmale:ethnicityMaori         -0.0169     0.0819   -0.21
## ageold:sexmale:ethnicityMaori   0.0709     0.1470    0.48
##                                          Pr(&gt;|z|)    
## (Intercept)                   &lt;0.0000000000000002 ***
## ageold                        &lt;0.0000000000000002 ***
## sexmale                       &lt;0.0000000000000002 ***
## ethnicityMaori                               0.25    
## ageold:sexmale                               0.93    
## ageold:ethnicityMaori                        0.12    
## sexmale:ethnicityMaori                       0.84    
## ageold:sexmale:ethnicityMaori                0.63    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25813  degrees of freedom
## AIC: 32152
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age * sex * ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25813      32136                     
## 2     25814      32136 -1   -0.233     0.63</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + 
##     sex:ethnicity, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.099  -0.914  -0.784   1.284   1.861  
## 
## Coefficients:
##                        Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.65800    0.02053  -32.05 &lt;0.0000000000000002 ***
## ageold                 -0.80705    0.05211  -15.49 &lt;0.0000000000000002 ***
## sexmale                 0.41124    0.03277   12.55 &lt;0.0000000000000002 ***
## ethnicityMaori          0.05377    0.05142    1.05               0.296    
## ageold:sexmale          0.03083    0.06943    0.44               0.657    
## ageold:ethnicityMaori  -0.12538    0.07346   -1.71               0.088 .  
## sexmale:ethnicityMaori  0.00513    0.06800    0.08               0.940    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25814  degrees of freedom
## AIC: 32150
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25814      32136                     
## 2     25815      32136 -1 -0.00569     0.94</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity, 
##     family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.098  -0.913  -0.784   1.284   1.860  
## 
## Coefficients:
##                       Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.6583     0.0201  -32.82 &lt;0.0000000000000002 ***
## ageold                 -0.8077     0.0515  -15.69 &lt;0.0000000000000002 ***
## sexmale                 0.4121     0.0307   13.43 &lt;0.0000000000000002 ***
## ethnicityMaori          0.0561     0.0408    1.38               0.169    
## ageold:sexmale          0.0321     0.0674    0.48               0.634    
## ageold:ethnicityMaori  -0.1252     0.0734   -1.71               0.088 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25815  degrees of freedom
## AIC: 32148
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity + age:ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25815      32136                     
## 2     25816      32136 -1   -0.226     0.63</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity + age:ethnicity, 
##     family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.099  -0.912  -0.779   1.282   1.854  
## 
## Coefficients:
##                       Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)            -0.6609     0.0194  -34.14 &lt;0.0000000000000002 ***
## ageold                 -0.7937     0.0423  -18.79 &lt;0.0000000000000002 ***
## sexmale                 0.4187     0.0273   15.32 &lt;0.0000000000000002 ***
## ethnicityMaori          0.0555     0.0408    1.36               0.174    
## ageold:ethnicityMaori  -0.1225     0.0732   -1.67               0.094 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32136  on 25816  degrees of freedom
## AIC: 32146
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity + age:ethnicity
## Model 2: suf.eh ~ age + sex + ethnicity
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1     25816      32136                       
## 2     25817      32139 -1    -2.81    0.094 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex + ethnicity, family = binomial, 
##     data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.086  -0.915  -0.768   1.279   1.840  
## 
## Coefficients:
##                Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)     -0.6549     0.0190  -34.45 &lt;0.0000000000000002 ***
## ageold          -0.8350     0.0346  -24.11 &lt;0.0000000000000002 ***
## sexmale          0.4191     0.0273   15.34 &lt;0.0000000000000002 ***
## ethnicityMaori   0.0173     0.0339    0.51                0.61    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32139  on 25817  degrees of freedom
## AIC: 32147
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ age + sex + ethnicity
## Model 2: suf.eh ~ age + sex
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25817      32139                     
## 2     25818      32140 -1   -0.261     0.61</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ age + sex, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.081  -0.916  -0.770   1.278   1.837  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6525     0.0184   -35.4 &lt;0.0000000000000002 ***
## ageold       -0.8305     0.0335   -24.8 &lt;0.0000000000000002 ***
## sexmale       0.4201     0.0273    15.4 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 32140  on 25818  degrees of freedom
## AIC: 32146
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = suf.eh ~ age + sex, data = mydata, x = T, y = T, 
##      linear.predictors = T)
##  
##                         Model Likelihood    Discrimination    Rank Discrim.    
##                               Ratio Test           Indexes          Indexes    
##  Obs         25821    LR chi2     868.21    R2       0.046    C       0.602    
##   0          17114    d.f.             2    g        0.432    Dxy     0.203    
##   1           8707    Pr(&gt; chi2) &lt;0.0001    gr       1.541    gamma   0.302    
##  max |deriv| 3e-10                          gp       0.091    tau-a   0.091    
##                                             Brier    0.216                     
##  
##            Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept -0.6525 0.0184 -35.39 &lt;0.0001 
##  age=old   -0.8305 0.0335 -24.78 &lt;0.0001 
##  sex=male   0.4201 0.0273  15.42 &lt;0.0001 
## </code></pre>
<pre><code>##                 Wald Statistics          Response: suf.eh 
## 
##  Factor     Chi-Square d.f. P     
##  age        614.0      1    &lt;.0001
##  sex        237.7      1    &lt;.0001
##  TOTAL      802.6      2    &lt;.0001</code></pre>
<pre><code>## 
##      Backwards Step-down - Original Model
## 
##  Deleted               Chi-Sq d.f. P      Residual d.f. P      AIC  
##  age * sex             0.01   1    0.9346 0.01     1    0.9346 -1.99
##  sex * ethnicity       0.05   1    0.8239 0.06     2    0.9723 -3.94
##  age * sex * ethnicity 0.41   1    0.5230 0.46     3    0.9267 -5.54
##  ethnicity             1.85   1    0.1735 2.32     4    0.6778 -5.68
##  age * ethnicity       1.21   1    0.2711 3.53     5    0.6192 -6.47
## 
## Approximate Estimates after Deleting Factors
## 
##              Coef    S.E. Wald Z P
## Intercept -0.6524 0.01843 -35.39 0
## age=old   -0.8301 0.03353 -24.76 0
## sex=male   0.4199 0.02725  15.41 0
## 
## Factors in Final Model
## 
## [1] age sex</code></pre>
<pre><code>##           index.orig training    test optimism index.corrected   n
## Dxy           0.2032   0.2043  0.2036   0.0007          0.2025 200
## R2            0.0458   0.0462  0.0457   0.0005          0.0454 200
## Intercept     0.0000   0.0000 -0.0021   0.0021         -0.0021 200
## Slope         1.0000   1.0000  0.9960   0.0040          0.9960 200
## Emax          0.0000   0.0000  0.0012   0.0012          0.0012 200
## D             0.0336   0.0339  0.0335   0.0003          0.0332 200
## U            -0.0001  -0.0001  0.0000  -0.0001          0.0000 200
## Q             0.0337   0.0339  0.0335   0.0004          0.0332 200
## B             0.2163   0.2162  0.2163  -0.0001          0.2164 200
## g             0.4323   0.4351  0.4328   0.0023          0.4300 200
## gp            0.0910   0.0915  0.0911   0.0004          0.0906 200
## 
## Factors Retained in Backwards Elimination
## 
##  age sex ethnicity age * sex age * ethnicity sex * ethnicity
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *             *                         *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *               *              
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                                                  
##  *   *   *                                                  
##  *   *                                                      
##  *   *             *                         *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *             *                                        
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *                   *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *         *                                        
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                                                  
##  *   *                       *                              
##  *   *                       *                              
##  *   *   *                                                  
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *               *              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                       *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *                                                  
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                       *              
##  *   *                       *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                       *                              
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *             *                                        
##  *   *                                                      
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                       *              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *               *              
##  *   *                       *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *                                       *              
##  *   *   *                   *                              
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  *   *   *         *         *               *              
##  *   *                                                      
##  *   *                                                      
##  *   *                       *                              
##  *   *   *         *                                        
##  *   *                                                      
##  *   *                                                      
##  *   *                                                      
##  age * sex * ethnicity
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##  *                    
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
##  *                    
##                       
##                       
##                       
## 
## Frequencies of Numbers of Factors Retained
## 
##   2   3   4   5   6   7 
## 135  30  21   7   4   3</code></pre>
<pre><code>## 
## Best penalty:
## 
##  penalty    df
##      0.8 1.999
## 
##  penalty    df   aic   bic aic.c
##     0.00 2.000 864.2 847.9 864.2
##     0.05 2.000 864.2 847.9 864.2
##     0.10 2.000 864.2 847.9 864.2
##     0.15 2.000 864.2 847.9 864.2
##     0.20 2.000 864.2 847.9 864.2
##     0.25 2.000 864.2 847.9 864.2
##     0.30 2.000 864.2 847.9 864.2
##     0.35 2.000 864.2 847.9 864.2
##     0.40 2.000 864.2 847.9 864.2
##     0.45 2.000 864.2 847.9 864.2
##     0.50 2.000 864.2 847.9 864.2
##     0.55 1.999 864.2 847.9 864.2
##     0.60 1.999 864.2 847.9 864.2
##     0.65 1.999 864.2 847.9 864.2
##     0.70 1.999 864.2 847.9 864.2
##     0.75 1.999 864.2 847.9 864.2
##     0.80 1.999 864.2 847.9 864.2</code></pre>
<pre><code>## [1] 868.2</code></pre>
<pre><code>## [1] 2</code></pre>
<pre><code>## [1] 0</code></pre>
<pre><code>## Pseudo R^2 for logistic regression
## Hosmer and Lemeshow R^2   0.026 
## Cox and Snell R^2         0.033 
## Nagelkerke R^2            0.046</code></pre>
<pre><code>##               2.5 %  97.5 %
## (Intercept) -0.6887 -0.6164
## ageold      -0.8965 -0.7651
## sexmale      0.3667  0.4735</code></pre>
<pre><code>## (Intercept)      ageold     sexmale 
##      0.5207      0.4358      1.5221</code></pre>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 0.5022 0.5399
## ageold      0.4080 0.4653
## sexmale     1.4430 1.6057</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: suf.eh ~ 1
## Model 2: suf.eh ~ age + sex
##   Resid. Df Resid. Dev Df Deviance            Pr(&gt;Chi)    
## 1     25820      33008                                    
## 2     25818      32140  2      868 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>##   file.speaker.id no.eh eh text.id spk.ref    sex   age ethnicity
## 1   &lt;S1A-001#1:F&gt;    95 56  S1A001       F female young    Pakeha
## 2   &lt;S1A-001#1:M&gt;    97 75  S1A001       M   male young    Pakeha
## 3   &lt;S1A-002#1:B&gt;    99 45  S1A002       B female young    Pakeha
## 4   &lt;S1A-002#1:Q&gt;    86 51  S1A002       Q female young    Pakeha
## 5   &lt;S1A-003#1:B&gt;    58 50  S1A003       B   male young    Pakeha
## 6   &lt;S1A-003#1:M&gt;   119 84  S1A003       M   male young    Pakeha</code></pre>
<pre><code>## [1] 66.28</code></pre>
<pre><code>## [1] 66.28</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-43-3.png" width="672" /></p>
<pre><code>##  ageold sexmale 
##   1.005   1.005</code></pre>
<pre><code>##  ageold sexmale 
##  0.9952  0.9952</code></pre>
<pre><code>## [1] 1.005</code></pre>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh    dfb.1_
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0 -0.001211
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1  0.001432
##    dfb.agld  dfb.sxml    dffit cov.r     cook.d       hat dfb.1_.1
## 1  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 2 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
## 3  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 4  0.003762 -0.007929 -0.01071     1 0.00003231 0.0001223    FALSE
## 5 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
## 6 -0.004449  0.009375  0.01266     1 0.00005142 0.0001223    FALSE
##   dfb.agld.1 dfb.sxml.1 dffit.1 cov.r.1 cook.d.1 hat.1
## 1      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 2      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 3      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 4      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 5      FALSE      FALSE   FALSE   FALSE    FALSE FALSE
## 6      FALSE      FALSE   FALSE   FALSE    FALSE FALSE</code></pre>
<pre><code>## [1] &quot;Sample size sufficient&quot;</code></pre>
<pre><code>##                             Estimate VIF OddsRatio CI(2.5%) CI(97.5%)
## (Intercept)                    -0.65          0.52      0.5      0.54
## ageold                         -0.83   1      0.44     0.41      0.47
## sexmale                         0.42   1      1.52     1.44      1.61
## Model statistics                                                     
## Number of cases in model                                             
## Observed misses                                                      
## Observed successes                                                   
## Null deviance                                                        
## Residual deviance                                                    
## R2 (Nagelkerke)                                                      
## R2 (Hosmer &amp; Lemeshow)                                               
## R2 (Cox &amp; Snell)                                                     
## C                                                                    
## Somers&#39; Dxy                                                          
## AIC                                                                  
## Prediction accuracy                                                  
## Model Likelihood Ratio Test                                          
##                                     Std. Error z value   Pr(&gt;|z|)
## (Intercept)                               0.02  -35.39          0
## ageold                                    0.03  -24.78          0
## sexmale                                   0.03   15.42          0
## Model statistics                                                 
## Number of cases in model                                         
## Observed misses                                               0 :
## Observed successes                                            1 :
## Null deviance                                                    
## Residual deviance                                                
## R2 (Nagelkerke)                                                  
## R2 (Hosmer &amp; Lemeshow)                                           
## R2 (Cox &amp; Snell)                                                 
## C                                                                
## Somers&#39; Dxy                                                      
## AIC                                                              
## Prediction accuracy                                              
## Model Likelihood Ratio Test Model L.R.: 868.21   df: 2 p-value: 0
##                                 Significance
## (Intercept)                      p &lt; .001***
## ageold                           p &lt; .001***
## sexmale                          p &lt; .001***
## Model statistics                       Value
## Number of cases in model               25821
## Observed misses                        17114
## Observed successes                      8707
## Null deviance                       33007.75
## Residual deviance                   32139.54
## R2 (Nagelkerke)                        0.046
## R2 (Hosmer &amp; Lemeshow)                 0.026
## R2 (Cox &amp; Snell)                       0.033
## C                                      0.602
## Somers&#39; Dxy                            0.203
## AIC                                 32145.54
## Prediction accuracy                   66.28%
## Model Likelihood Ratio Test sig: p &lt; .001***</code></pre>
<div id="model-fit-parameters" class="section level2">
<h2><span class="header-section-number">4.1</span> Model Fit Parameters</h2>
<div id="r2-hosmer-lemeshow" class="section level3">
<h3><span class="header-section-number">4.1.1</span> R2 (Hosmer &amp; Lemeshow)</h3>
<p>“Rt is the proportional reduction in the absolute value of the log-likelihood measure and as such it is a measure of how much the badness of fit improves as a result of the inclusionof the predictor variables. It can vary between 0 (indicating that the predictors are useless at predicting the outcome variable) and 1 (indicating that the model predicts the outcome variable perfectly)” (<span class="citation">(A. Field, Miles, and Field 2012, 317)</span>).</p>
</div>
<div id="r2-cox-snell" class="section level3">
<h3><span class="header-section-number">4.1.2</span> R2 (Cox &amp; Snell)</h3>
<p>“Cox and Snell’s R~s (1989) is based on the deviance of the model (-2LL(new») and the deviance of the baseline model (-2LL(baseline), and the sample size, n […]. However, this statistic never reaches its theoretical maximum of 1.</p>
</div>
<div id="r2-nagelkerke" class="section level3">
<h3><span class="header-section-number">4.1.3</span> R2 (Nagelkerke)</h3>
<p>Since R2 (Cox &amp; Snell) never reaches its theoretical maximum of 1, Nagelkerke (1991) suggested Nagelkerke’s R^2. (Field, Miles &amp; Field 2012:317-318).</p>
</div>
<div id="somers-dxy" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Somers’ Dxy</h3>
<p>Somers’ Dxy is a rank correlation between predicted probabilities and observed responses ranges between 0 (randomness) and 1 (perfect prediction). (cf. <span class="citation">(Baayen 2008, 204)</span>).</p>
</div>
<div id="c" class="section level3">
<h3><span class="header-section-number">4.1.5</span> C</h3>
<p>C is an index of concordance between the predicted probability and the observed response. When C takes the value 0.5, the predictions are random, when it is 1, prediction is perfect. A value above 0.8 indicates that the model may have some real predictive capacity (cf. <span class="citation">(Baayen 2008, 204)</span>).</p>
</div>
<div id="akaike-information-criteria-aic" class="section level3">
<h3><span class="header-section-number">4.1.6</span> Akaike information criteria (AIC)</h3>
<p>Akaike information criteria (AlC = -2LL + 2k) provide a value that reflects a ratio between the number of predictors in the model and the variance that is explained by these predictors. Changes in AIC can serve as a measure of whether the inclusion of a variable leads to a significant incerase in the amount of variance that is explained by the model. “You can think of this as the price you pay for something: you get a better value of R2, but you pay a higher price, and was that higher price worth it? These information criteria help you to decide.model. The BIC is the same as the AIC but adjusts the penalty included in the AlC (i.e., 2k) by the number of cases: BlC = -2LL + 2k x log(n) in which n is the number of cases in the model” (<span class="citation">(A. Field, Miles, and Field 2012, 318)</span>).</p>
</div>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">5</span> Mixed Effects Binomial Logistic Regression</h1>
<pre><code>##   file.speaker.id text.id spk.ref  sex   age ethnicity suf.eh
## 1   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 2   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 3   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 4   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      0
## 5   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1
## 6   &lt;S1A-001#1:M&gt;  S1A001       M male young    Pakeha      1</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  7 variables:
##  $ file.speaker.id: chr  &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; &quot;&lt;S1A-001#1:M&gt;&quot; ...
##  $ text.id        : chr  &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; &quot;S1A001&quot; ...
##  $ spk.ref        : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ...
##  $ sex            : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ age            : Factor w/ 2 levels &quot;young&quot;,&quot;old&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ethnicity      : Factor w/ 2 levels &quot;Pakeha&quot;,&quot;Maori&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ suf.eh         : num  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<pre><code>##  file.speaker.id      text.id            spk.ref              sex       
##  Length:25821       Length:25821       Length:25821       female:15852  
##  Class :character   Class :character   Class :character   male  : 9969  
##  Mode  :character   Mode  :character   Mode  :character                 
##                                                                         
##                                                                         
##                                                                         
##     age         ethnicity         suf.eh     
##  young:19150   Pakeha:20024   Min.   :0.000  
##  old  : 6671   Maori : 5797   1st Qu.:0.000  
##                               Median :0.000  
##                               Mean   :0.337  
##                               3rd Qu.:1.000  
##                               Max.   :1.000</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-44-1.png" width="672" /><img src="advancedstatz_files/figure-html/unnamed-chunk-44-2.png" width="672" /></p>
<pre><code>## , ,  = female,  = Pakeha
## 
##    
##     young  old
##   0  6820 1930
##   1  3527  450
## 
## , ,  = male,  = Pakeha
## 
##    
##     young  old
##   0  3237 1125
##   1  2535  400
## 
## , ,  = female,  = Maori
## 
##    
##     young  old
##   0  1063 1218
##   1   586  258
## 
## , ,  = male,  = Maori
## 
##    
##     young  old
##   0   759  962
##   1   623  328</code></pre>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">5.1</span> Model Building</h2>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = suf.eh ~ 1, data = mydata, x = T, y = T)
##  
##                        Model Likelihood    Discrimination    Rank Discrim.    
##                              Ratio Test           Indexes          Indexes    
##  Obs         25821    LR chi2      0.00    R2       0.000    C       0.500    
##   0          17114    d.f.            0    g        0.000    Dxy     0.000    
##   1           8707    Pr(&gt; chi2) 1.0000    gr       1.000    gamma   0.000    
##  max |deriv|     0                         gp       0.000    tau-a   0.000    
##                                            Brier    0.223                     
##  
##            Coef   
##  Intercept -0.6758
## </code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + 1
##    Data: mydata
## REML criterion at convergence: 4489
## Random effects:
##  Groups       Name        Std.Dev.
##  region:genre (Intercept)  4.36   
##  genre        (Intercept) 12.54   
##  Residual                 15.02   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## Fixed Effects:
## (Intercept)  
##         134</code></pre>
<pre><code>## [1] 32479</code></pre>
<pre><code>## [1] 33010</code></pre>
<pre><code>## 
## Call:
## glm(formula = suf.eh ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -0.907  -0.907  -0.907   1.474   1.474  
## 
## Coefficients:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6758     0.0132   -51.3 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33008  on 25820  degrees of freedom
## Residual deviance: 33008  on 25820  degrees of freedom
## AIC: 33010
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: suf.eh ~ (1 | file.speaker.id)
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##    32479    32495   -16237    32475    25819 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -1.059 -0.741 -0.614  1.193  2.368 
## 
## Random effects:
##  Groups          Name        Variance Std.Dev.
##  file.speaker.id (Intercept) 0.158    0.398   
## Number of obs: 25821, groups:  file.speaker.id, 203
## 
## Fixed effects:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -0.6866     0.0315   -21.8 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">5.2</span> Model Fitting</h2>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m3.glmer: suf.eh ~ age + sex + ethnicity + (1 | file.speaker.id)
## m4.glmer: suf.eh ~ age + sex + ethnicity + age:sex + (1 | file.speaker.id)
## m5.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + (1 | 
## m5.glmer:     file.speaker.id)
## m6.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m6.glmer:     (1 | file.speaker.id)
## m7.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m7.glmer:     age:sex:ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance  Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                  
## m1.glmer  3 32302 32327 -16148    32296 178.65      1 &lt;0.0000000000000002
## m2.glmer  4 32148 32180 -16070    32140 156.50      1 &lt;0.0000000000000002
## m3.glmer  5 32149 32190 -16070    32139   0.26      1               0.609
## m4.glmer  6 32151 32200 -16070    32139   0.12      1               0.728
## m5.glmer  7 32150 32207 -16068    32136   2.91      1               0.088
## m6.glmer  8 32152 32218 -16068    32136   0.01      1               0.940
## m7.glmer  9 32154 32227 -16068    32136   0.23      1               0.629
##             
## m0.glmer    
## m1.glmer ***
## m2.glmer ***
## m3.glmer    
## m4.glmer    
## m5.glmer .  
## m6.glmer    
## m7.glmer    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                 
## m1.glmer  3 32302 32327 -16148    32296   179      1 &lt;0.0000000000000002
##             
## m0.glmer    
## m1.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m1.glmer  3 32302 32327 -16148    32296                                 
## m2.glmer  4 32148 32180 -16070    32140   156      1 &lt;0.0000000000000002
##             
## m1.glmer    
## m2.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m3.glmer: suf.eh ~ age + sex + ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m3.glmer  5 32149 32190 -16070    32139  0.26      1       0.61</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m4.glmer: suf.eh ~ age + sex + ethnicity + age:sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m4.glmer  6 32151 32200 -16070    32139  0.38      2       0.83</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m5.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + (1 | 
## m5.glmer:     file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m5.glmer  7 32150 32207 -16068    32136  3.29      3       0.35</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m6.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m6.glmer:     (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m6.glmer  8 32152 32218 -16068    32136   3.3      4       0.51</code></pre>
<pre><code>## Data: mydata
## Models:
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
## m7.glmer: suf.eh ~ age + sex + ethnicity + age:sex + age:ethnicity + sex:ethnicity + 
## m7.glmer:     age:sex:ethnicity + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m2.glmer  4 32148 32180 -16070    32140                        
## m7.glmer  9 32154 32227 -16068    32136  3.53      5       0.62</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## mlr.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##           Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer   2 32479 32495 -16237    32475                                 
## mlr.glmer  4 32148 32180 -16070    32140   335      2 &lt;0.0000000000000002
##              
## m0.glmer     
## mlr.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: suf.eh ~ age + sex + (1 | file.speaker.id)
##    Data: mydata
##      AIC      BIC   logLik deviance df.resid 
##    32148    32180   -16070    32140    25817 
## Random effects:
##  Groups          Name        Std.Dev.
##  file.speaker.id (Intercept) 0       
## Number of obs: 25821, groups:  file.speaker.id, 203
## Fixed Effects:
## (Intercept)       ageold      sexmale  
##      -0.652       -0.831        0.420</code></pre>
<pre><code>## Analysis of Variance Table
##     Df Sum Sq Mean Sq F value
## age  1    565     565     565
## sex  1    238     238     238</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.glmer: suf.eh ~ 1 + (1 | file.speaker.id)
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer  2 32479 32495 -16237    32475                                 
## m1.glmer  3 32302 32327 -16148    32296   179      1 &lt;0.0000000000000002
##             
## m0.glmer    
## m1.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## Data: mydata
## Models:
## m1.glmer: suf.eh ~ age + (1 | file.speaker.id)
## m2.glmer: suf.eh ~ age + sex + (1 | file.speaker.id)
##          Df   AIC   BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m1.glmer  3 32302 32327 -16148    32296                                 
## m2.glmer  4 32148 32180 -16070    32140   156      1 &lt;0.0000000000000002
##             
## m1.glmer    
## m2.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">5.3</span> Extracting Model Fit Parameters</h2>
<p>We now create a lmr object equivalent to the final minimal adequate model but without the random effect.</p>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  coef(mlr.lrm) and fixef(mlr.lmer)
## t = Inf, df = 1, p-value &lt;0.0000000000000002
## alternative hypothesis: true correlation is not equal to 0
## sample estimates:
## cor 
##   1</code></pre>
<pre><code>##          C        Dxy          n    Missing 
##     0.6181     0.2361 25821.0000     0.0000</code></pre>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">5.4</span> Model Diagnostics</h2>
<pre class="r"><code># model diagnostics: plot fitted against residuals
plot(mlr.glmer)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r"><code># plot residuals against fitted
plot(mlr.glmer, form = resid(., type = &quot;response&quot;) ~ fitted(.) | file.speaker.id, abline = 0, cex = .5,id = 0.05, adj = -0.3)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: examining residuals (Pinheiro &amp; Bates 2000:175)
plot(mlr.glmer, file.speaker.id ~ resid(.), abline = 0 , cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r"><code># summarize final model
meblrm.summary(m0.glm, m1.glm, m0.glmer, mlr.glmer, dpvar=mydata$suf.eh)</code></pre>
<pre><code>##                                    Group(s) Variance Std. Dev.         
## Random Effect(s)            file.speaker.id        0         0         
## Fixed Effect(s)                    Estimate      VIF OddsRatio CI(2.5%)
## (Intercept)                           -0.65               0.52      0.5
## ageold                                -0.83        1      0.44     0.41
## sexmale                                0.42        1      1.52     1.44
## Model statistics                                                       
## Number of Groups                                                       
## Number of cases in model                                               
## Observed misses                                                        
## Observed successes                                                     
## Residual deviance                                                      
## R2 (Nagelkerke)                                                        
## R2 (Hosmer &amp; Lemeshow)                                                 
## R2 (Cox &amp; Snell)                                                       
## C                                                                      
## Somers&#39; Dxy                                                            
## AIC                                                                    
## BIC                                                                    
## Prediction accuracy                                                    
## Model Likelihood Ratio Test                                            
##                                               L.R. X2      DF         Pr
## Random Effect(s)                               533.06       1          0
## Fixed Effect(s)             CI(97.5%)      Std. Error z value   Pr(&gt;|z|)
## (Intercept)                      0.54            0.02  -35.39          0
## ageold                           0.47            0.03  -24.78          0
## sexmale                          1.61            0.03   15.42          0
## Model statistics                                                        
## Number of Groups                                                        
## Number of cases in model                                                
## Observed misses                                                         
## Observed successes                                                      
## Residual deviance                                                       
## R2 (Nagelkerke)                                                         
## R2 (Hosmer &amp; Lemeshow)                                                  
## R2 (Cox &amp; Snell)                                                        
## C                                                                       
## Somers&#39; Dxy                                                             
## AIC                                                                     
## BIC                                                                     
## Prediction accuracy                                                     
## Model Likelihood Ratio Test           L.R. X2: 868.21   DF: 3 p-value: 0
##                                 Significance
## Random Effect(s)                 p &lt; .001***
## Fixed Effect(s)                 Significance
## (Intercept)                      p &lt; .001***
## ageold                           p &lt; .001***
## sexmale                          p &lt; .001***
## Model statistics                       Value
## Number of Groups                         203
## Number of cases in model               25821
## Observed misses                        17114
## Observed successes                      8707
## Residual deviance                   32139.54
## R2 (Nagelkerke)                        0.046
## R2 (Hosmer &amp; Lemeshow)                 0.026
## R2 (Cox &amp; Snell)                       0.033
## C                                      0.602
## Somers&#39; Dxy                            0.203
## AIC                                 32147.54
## BIC                                 32180.18
## Prediction accuracy                   66.28%
## Model Likelihood Ratio Test sig: p &lt; .001***</code></pre>
</div>
</div>
<div id="conditional-inference-trees" class="section level1">
<h1><span class="header-section-number">6</span> Conditional Inference Trees</h1>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  15 variables:
##  $ Age             : chr  &quot;26-40&quot; &quot;26-40&quot; &quot;26-40&quot; &quot;17-25&quot; ...
##  $ Adjective       : chr  &quot;good&quot; &quot;good&quot; &quot;good&quot; &quot;nice&quot; ...
##  $ FileSpeaker     : chr  &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-001:1$B&gt;&quot; &quot;&lt;S1A-003:1$B&gt;&quot; ...
##  $ Function        : chr  &quot;Attributive&quot; &quot;Attributive&quot; &quot;Predicative&quot; &quot;Attributive&quot; ...
##  $ Priming         : chr  &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Occupation      : chr  &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; &quot;AcademicManagerialProfessionals&quot; ...
##  $ ConversationType: chr  &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; &quot;SameSex&quot; ...
##  $ AudienceSize    : chr  &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;MultipleInterlocutors&quot; &quot;Dyad&quot; ...
##  $ very            : int  0 0 0 1 0 1 0 1 0 0 ...
##  $ really          : int  0 0 0 0 0 0 0 0 1 1 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : chr  &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; &quot;NotGradable&quot; ...
##  $ SemanticCategory: chr  &quot;Value&quot; &quot;Value&quot; &quot;Value&quot; &quot;HumanPropensity&quot; ...
##  $ Emotionality    : chr  &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;PositiveEmotional&quot; &quot;NonEmotional&quot; ...</code></pre>
<pre><code>##  [1] &quot;Age&quot;              &quot;Adjective&quot;        &quot;Function&quot;        
##  [4] &quot;Priming&quot;          &quot;Gender&quot;           &quot;ConversationType&quot;
##  [7] &quot;AudienceSize&quot;     &quot;really&quot;           &quot;Freq&quot;            
## [10] &quot;Gradabilty&quot;       &quot;SemanticCategory&quot; &quot;Emotionality&quot;</code></pre>
<pre><code>## &#39;data.frame&#39;:    314 obs. of  12 variables:
##  $ Age             : Factor w/ 3 levels &quot;17-25&quot;,&quot;26-40&quot;,..: 2 2 2 1 3 3 3 3 1 1 ...
##  $ Adjective       : Factor w/ 6 levels &quot;bad&quot;,&quot;funny&quot;,..: 3 3 3 5 6 6 3 6 6 6 ...
##  $ Function        : Factor w/ 2 levels &quot;Attributive&quot;,..: 1 1 2 1 2 2 1 2 1 1 ...
##  $ Priming         : Factor w/ 2 levels &quot;NoPrime&quot;,&quot;Prime&quot;: 1 1 1 1 1 1 1 1 1 2 ...
##  $ Gender          : Factor w/ 2 levels &quot;Men&quot;,&quot;Women&quot;: 1 1 1 1 1 1 2 2 1 1 ...
##  $ ConversationType: Factor w/ 2 levels &quot;MixedSex&quot;,&quot;SameSex&quot;: 2 2 2 2 2 1 1 1 1 1 ...
##  $ AudienceSize    : Factor w/ 2 levels &quot;Dyad&quot;,&quot;MultipleInterlocutors&quot;: 2 2 2 1 1 2 2 2 2 2 ...
##  $ really          : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 2 2 ...
##  $ Freq            : num  27.848 27.848 27.848 7.293 0.617 ...
##  $ Gradabilty      : Factor w/ 3 levels &quot;GradabilityUndetermined&quot;,..: 3 3 3 3 3 3 3 1 1 3 ...
##  $ SemanticCategory: Factor w/ 5 levels &quot;Dimension&quot;,&quot;HumanPropensity&quot;,..: 5 5 5 2 5 5 5 2 1 4 ...
##  $ Emotionality    : Factor w/ 3 levels &quot;NegativeEmotional&quot;,..: 3 3 3 2 2 3 3 1 2 2 ...</code></pre>
<pre><code>## png 
##   2</code></pre>
<pre><code>## [1] 100</code></pre>
<pre><code>## [1] 41.08</code></pre>
</div>
<div id="random-forests" class="section level1">
<h1><span class="header-section-number">7</span> Random Forests</h1>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Example 1:</h2>
<pre class="r"><code># prepare data
rfd &lt;- reallyaus
# convert really into a factor
rfd$really &lt;- as.factor(rfd$really)
# start with random forest
# set seed
set.seed(222)
# partition data for evaluating rf 
id &lt;- sample(2, nrow(rfd), replace = T, prob = c(.7, .3))
train &lt;- rfd[id == 1, ]
test &lt;- rfd[id == 2,]
# load library
library(randomForest)
# create initial model
reallyaus_rf1 &lt;- randomForest(really~., data = train)
# inspect model
print(reallyaus_rf1)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 41.47%
## Confusion matrix:
##    0  1 class.error
## 0 79 44      0.3577
## 1 46 48      0.4894</code></pre>
<pre class="r"><code># inspect attibutes
attributes(reallyaus_rf1)</code></pre>
<pre><code>## $names
##  [1] &quot;call&quot;            &quot;type&quot;            &quot;predicted&quot;      
##  [4] &quot;err.rate&quot;        &quot;confusion&quot;       &quot;votes&quot;          
##  [7] &quot;oob.times&quot;       &quot;classes&quot;         &quot;importance&quot;     
## [10] &quot;importanceSD&quot;    &quot;localImportance&quot; &quot;proximity&quot;      
## [13] &quot;ntree&quot;           &quot;mtry&quot;            &quot;forest&quot;         
## [16] &quot;y&quot;               &quot;test&quot;            &quot;inbag&quot;          
## [19] &quot;terms&quot;          
## 
## $class
## [1] &quot;randomForest.formula&quot; &quot;randomForest&quot;</code></pre>
<pre class="r"><code># start model evaluation
# install package
#source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(); library(Biobase)
#install.packages(&quot;Biobase&quot;, repos=c(&quot;http://rstudio.org/_packages&quot;, &quot;http://cran.rstudio.com&quot;, 
#                                      &quot;http://cran.rstudio.com/&quot;, dependencies=TRUE))
#install.packages(&quot;dimRed&quot;, dependencies = TRUE)
#install.packages(&#39;caret&#39;, dependencies = TRUE)

# load caret library
library(caret) # because initially caret did not work, the libraries above had to be installed
# extract prediction for training data
ptrain1 &lt;- predict(reallyaus_rf1, train)
# inspect predictions
head(ptrain1); head(train$really)</code></pre>
<pre><code>## 2 3 4 7 8 9 
## 0 0 0 0 0 1 
## Levels: 0 1</code></pre>
<pre><code>## [1] 0 0 0 0 0 1
## Levels: 0 1</code></pre>
<pre class="r"><code># create confusionMatrix
confusionMatrix(ptrain1, train$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 116  13
##          1   7  81
##                                              
##                Accuracy : 0.908              
##                  95% CI : (0.861, 0.943)     
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.811              
##  Mcnemar&#39;s Test P-Value : 0.264              
##                                              
##             Sensitivity : 0.943              
##             Specificity : 0.862              
##          Pos Pred Value : 0.899              
##          Neg Pred Value : 0.920              
##              Prevalence : 0.567              
##          Detection Rate : 0.535              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.902              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest1 &lt;- predict(reallyaus_rf1, test)
# create confusionMatrix
confusionMatrix(ptest1, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 44 16
##          1 18 19
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.249         
##  Mcnemar&#39;s Test P-Value : 0.864         
##                                         
##             Sensitivity : 0.710         
##             Specificity : 0.543         
##          Pos Pred Value : 0.733         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.454         
##    Detection Prevalence : 0.619         
##       Balanced Accuracy : 0.626         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># determine errorrate of random forest model
plot(reallyaus_rf1, main = &quot;&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<pre class="r"><code># tune model
reallyaus_rf2 &lt;- tuneRF(train[, !colnames(train)== &quot;really&quot;], train[, colnames(train)== &quot;really&quot;], 
                        stepFactor = .5, # for most values 6 appears to be optimal
                        plot = T,
                        ntreeTry = 200,
                        trace = T,
                        improve = .05
)</code></pre>
<pre><code>## mtry = 3  OOB error = 42.4% 
## Searching left ...
## mtry = 6     OOB error = 42.4% 
## 0 0.05 
## Searching right ...
## mtry = 1     OOB error = 43.32% 
## -0.02174 0.05</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<pre class="r"><code># create improved model
reallyaus_rf2 &lt;- randomForest(really~., data = train, 
                              ntree = 200,
                              ntry = 6,
                              importance= T,
                              proximity = T)
# inspect model
print(reallyaus_rf2)</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = really ~ ., data = train, ntree = 200,      ntry = 6, importance = T, proximity = T) 
##                Type of random forest: classification
##                      Number of trees: 200
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 40.09%
## Confusion matrix:
##    0  1 class.error
## 0 86 37      0.3008
## 1 50 44      0.5319</code></pre>
<pre class="r"><code># predict based on improved model
ptrain2 &lt;- predict(reallyaus_rf2, train)
# create confusionMatrix
confusionMatrix(ptrain2, train$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 114  15
##          1   9  79
##                                              
##                Accuracy : 0.889              
##                  95% CI : (0.84, 0.928)      
##     No Information Rate : 0.567              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.773              
##  Mcnemar&#39;s Test P-Value : 0.307              
##                                              
##             Sensitivity : 0.927              
##             Specificity : 0.840              
##          Pos Pred Value : 0.884              
##          Neg Pred Value : 0.898              
##              Prevalence : 0.567              
##          Detection Rate : 0.525              
##    Detection Prevalence : 0.594              
##       Balanced Accuracy : 0.884              
##                                              
##        &#39;Positive&#39; Class : 0                  
## </code></pre>
<pre class="r"><code># extract prediction for test data
ptest2 &lt;- predict(reallyaus_rf2, test)
# create confusionMatrix
confusionMatrix(ptest2, test$really)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 45 17
##          1 17 18
##                                         
##                Accuracy : 0.649         
##                  95% CI : (0.546, 0.744)
##     No Information Rate : 0.639         
##     P-Value [Acc &gt; NIR] : 0.462         
##                                         
##                   Kappa : 0.24          
##  Mcnemar&#39;s Test P-Value : 1.000         
##                                         
##             Sensitivity : 0.726         
##             Specificity : 0.514         
##          Pos Pred Value : 0.726         
##          Neg Pred Value : 0.514         
##              Prevalence : 0.639         
##          Detection Rate : 0.464         
##    Detection Prevalence : 0.639         
##       Balanced Accuracy : 0.620         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<pre class="r"><code># inspect number of nodes for trees
hist(treesize(reallyaus_rf2), main = &quot;&quot;, col = &quot;lightgray&quot;)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-55-2.png" width="672" /></p>
<pre class="r"><code># check variable importance
varImpPlot(reallyaus_rf2, main = &quot;&quot;, pch = 20) </code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<pre class="r"><code># left plot (Accuracy): how much accuracy decreases if factor is left out
# left plot (Gini/Pureness): how much more unpure (ambigious) the distributions become if fector is left out
# extract variable importance values
#importance(reallyaus_rf2)

#which variables have been used in the trees
varUsed(reallyaus_rf2)</code></pre>
<pre><code>##  [1]  817  826  894  745  672  902  831 2114  461 1129  853</code></pre>
<pre class="r"><code># partial dependence plot
partialPlot(reallyaus_rf2, train, Freq, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, ConversationType, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Function, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, SemanticCategory, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<pre class="r"><code>partialPlot(reallyaus_rf2, train, Gender, 1)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<pre class="r"><code># extract tree
getTree(reallyaus_rf2, 1, labelVar = T)</code></pre>
<pre><code>##    left daughter right daughter        split var split point status
## 1              2              3       Gradabilty      3.0000      1
## 2              4              5 SemanticCategory      1.0000      1
## 3              6              7          Priming      1.0000      1
## 4              8              9     AudienceSize      1.0000      1
## 5             10             11           Gender      1.0000      1
## 6             12             13        Adjective     22.0000      1
## 7             14             15              Age      1.0000      1
## 8              0              0             &lt;NA&gt;      0.0000     -1
## 9              0              0             &lt;NA&gt;      0.0000     -1
## 10             0              0             &lt;NA&gt;      0.0000     -1
## 11            16             17         Function      1.0000      1
## 12            18             19        Adjective      2.0000      1
## 13            20             21             Freq      1.2295      1
## 14            22             23     Emotionality      2.0000      1
## 15             0              0             &lt;NA&gt;      0.0000     -1
## 16             0              0             &lt;NA&gt;      0.0000     -1
## 17            24             25        Adjective      8.0000      1
## 18            26             27              Age      3.0000      1
## 19            28             29        Adjective      4.0000      1
## 20            30             31         Function      1.0000      1
## 21            32             33     AudienceSize      1.0000      1
## 22            34             35             Freq      2.8177      1
## 23            36             37             Freq     11.6575      1
## 24             0              0             &lt;NA&gt;      0.0000     -1
## 25            38             39       Gradabilty      1.0000      1
## 26             0              0             &lt;NA&gt;      0.0000     -1
## 27             0              0             &lt;NA&gt;      0.0000     -1
## 28            40             41              Age      1.0000      1
## 29            42             43 ConversationType      1.0000      1
## 30            44             45     Emotionality      1.0000      1
## 31            46             47     AudienceSize      1.0000      1
## 32            48             49              Age      2.0000      1
## 33            50             51 SemanticCategory      2.0000      1
## 34             0              0             &lt;NA&gt;      0.0000     -1
## 35            52             53             Freq      5.7459      1
## 36            54             55     Emotionality      1.0000      1
## 37            56             57     AudienceSize      1.0000      1
## 38             0              0             &lt;NA&gt;      0.0000     -1
## 39            58             59             Freq      0.6844      1
## 40            60             61 ConversationType      1.0000      1
## 41            62             63     AudienceSize      1.0000      1
## 42             0              0             &lt;NA&gt;      0.0000     -1
## 43            64             65     AudienceSize      1.0000      1
## 44            66             67           Gender      1.0000      1
## 45            68             69     Emotionality      2.0000      1
## 46            70             71             Freq      0.7032      1
## 47            72             73 SemanticCategory      3.0000      1
## 48            74             75 ConversationType      1.0000      1
## 49             0              0             &lt;NA&gt;      0.0000     -1
## 50            76             77     Emotionality      2.0000      1
## 51             0              0             &lt;NA&gt;      0.0000     -1
## 52             0              0             &lt;NA&gt;      0.0000     -1
## 53             0              0             &lt;NA&gt;      0.0000     -1
## 54            78             79     AudienceSize      1.0000      1
## 55             0              0             &lt;NA&gt;      0.0000     -1
## 56             0              0             &lt;NA&gt;      0.0000     -1
## 57             0              0             &lt;NA&gt;      0.0000     -1
## 58             0              0             &lt;NA&gt;      0.0000     -1
## 59             0              0             &lt;NA&gt;      0.0000     -1
## 60             0              0             &lt;NA&gt;      0.0000     -1
## 61             0              0             &lt;NA&gt;      0.0000     -1
## 62             0              0             &lt;NA&gt;      0.0000     -1
## 63             0              0             &lt;NA&gt;      0.0000     -1
## 64            80             81           Gender      1.0000      1
## 65             0              0             &lt;NA&gt;      0.0000     -1
## 66             0              0             &lt;NA&gt;      0.0000     -1
## 67             0              0             &lt;NA&gt;      0.0000     -1
## 68            82             83 ConversationType      1.0000      1
## 69             0              0             &lt;NA&gt;      0.0000     -1
## 70             0              0             &lt;NA&gt;      0.0000     -1
## 71            84             85              Age      1.0000      1
## 72             0              0             &lt;NA&gt;      0.0000     -1
## 73             0              0             &lt;NA&gt;      0.0000     -1
## 74             0              0             &lt;NA&gt;      0.0000     -1
## 75             0              0             &lt;NA&gt;      0.0000     -1
## 76             0              0             &lt;NA&gt;      0.0000     -1
## 77             0              0             &lt;NA&gt;      0.0000     -1
## 78             0              0             &lt;NA&gt;      0.0000     -1
## 79            86             87 SemanticCategory      2.0000      1
## 80            88             89         Function      1.0000      1
## 81             0              0             &lt;NA&gt;      0.0000     -1
## 82            90             91             Freq      0.9945      1
## 83             0              0             &lt;NA&gt;      0.0000     -1
## 84            92             93           Gender      1.0000      1
## 85            94             95 SemanticCategory      8.0000      1
## 86             0              0             &lt;NA&gt;      0.0000     -1
## 87            96             97             Freq      1.6575      1
## 88             0              0             &lt;NA&gt;      0.0000     -1
## 89             0              0             &lt;NA&gt;      0.0000     -1
## 90            98             99 SemanticCategory      1.0000      1
## 91             0              0             &lt;NA&gt;      0.0000     -1
## 92             0              0             &lt;NA&gt;      0.0000     -1
## 93             0              0             &lt;NA&gt;      0.0000     -1
## 94             0              0             &lt;NA&gt;      0.0000     -1
## 95             0              0             &lt;NA&gt;      0.0000     -1
## 96             0              0             &lt;NA&gt;      0.0000     -1
## 97             0              0             &lt;NA&gt;      0.0000     -1
## 98             0              0             &lt;NA&gt;      0.0000     -1
## 99             0              0             &lt;NA&gt;      0.0000     -1
##    prediction
## 1        &lt;NA&gt;
## 2        &lt;NA&gt;
## 3        &lt;NA&gt;
## 4        &lt;NA&gt;
## 5        &lt;NA&gt;
## 6        &lt;NA&gt;
## 7        &lt;NA&gt;
## 8           1
## 9           0
## 10          0
## 11       &lt;NA&gt;
## 12       &lt;NA&gt;
## 13       &lt;NA&gt;
## 14       &lt;NA&gt;
## 15          1
## 16          0
## 17       &lt;NA&gt;
## 18       &lt;NA&gt;
## 19       &lt;NA&gt;
## 20       &lt;NA&gt;
## 21       &lt;NA&gt;
## 22       &lt;NA&gt;
## 23       &lt;NA&gt;
## 24          0
## 25       &lt;NA&gt;
## 26          1
## 27          0
## 28       &lt;NA&gt;
## 29       &lt;NA&gt;
## 30       &lt;NA&gt;
## 31       &lt;NA&gt;
## 32       &lt;NA&gt;
## 33       &lt;NA&gt;
## 34          1
## 35       &lt;NA&gt;
## 36       &lt;NA&gt;
## 37       &lt;NA&gt;
## 38          0
## 39       &lt;NA&gt;
## 40       &lt;NA&gt;
## 41       &lt;NA&gt;
## 42          1
## 43       &lt;NA&gt;
## 44       &lt;NA&gt;
## 45       &lt;NA&gt;
## 46       &lt;NA&gt;
## 47       &lt;NA&gt;
## 48       &lt;NA&gt;
## 49          0
## 50       &lt;NA&gt;
## 51          0
## 52          0
## 53          1
## 54       &lt;NA&gt;
## 55          0
## 56          1
## 57          0
## 58          0
## 59          0
## 60          1
## 61          1
## 62          1
## 63          0
## 64       &lt;NA&gt;
## 65          1
## 66          0
## 67          1
## 68       &lt;NA&gt;
## 69          0
## 70          0
## 71       &lt;NA&gt;
## 72          1
## 73          0
## 74          0
## 75          1
## 76          1
## 77          0
## 78          0
## 79       &lt;NA&gt;
## 80       &lt;NA&gt;
## 81          0
## 82       &lt;NA&gt;
## 83          0
## 84       &lt;NA&gt;
## 85       &lt;NA&gt;
## 86          0
## 87       &lt;NA&gt;
## 88          0
## 89          0
## 90       &lt;NA&gt;
## 91          0
## 92          0
## 93          1
## 94          0
## 95          1
## 96          0
## 97          1
## 98          1
## 99          1</code></pre>
<pre class="r"><code># mds plot
MDSplot(reallyaus_rf2, test$really)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
</div>
<div id="example-2" class="section level2">
<h2><span class="header-section-number">7.2</span> Example 2:</h2>
<pre><code>##              Age        Adjective         Function          Priming 
##            0.001            0.005            0.012            0.000 
##           Gender ConversationType     AudienceSize             Freq 
##            0.002            0.003            0.002            0.011 
##       Gradabilty SemanticCategory     Emotionality 
##            0.000            0.004            0.001</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<pre class="r"><code># load library
library(Hmisc)
# evaluate random forst
reallyaus.rf.pred &lt;- unlist(treeresponse(reallyaus.rf))[c(FALSE,TRUE)]
somers2(reallyaus.rf.pred, as.numeric(rfd$really) - 1)</code></pre>
<pre><code>##        C      Dxy        n  Missing 
##   0.8069   0.6138 314.0000   0.0000</code></pre>
<pre class="r"><code>##     C         Dxy           n     Missing 
##0.8119422   0.6238843 314.0000000   0.0000000 </code></pre>
</div>
<div id="example-3" class="section level2">
<h2><span class="header-section-number">7.3</span> Example 3:</h2>
<pre class="r"><code>#                     RANDOM FOREST III
# load library
library(party)
# create data
randomforestdata &lt;- reallyaus

cf1 &lt;- cforest(really ~ . , data= randomforestdata, control=cforest_unbiased(mtry=2,ntree=100)) # fit the random forest
varimp(cf1) # get variable importance, based on mean decrease in accuracy</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0013913        0.0169565        0.0082609        0.0008696 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0053043        0.0046087        0.0040870        0.0253043 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0031304        0.0032174        0.0097391</code></pre>
<pre class="r"><code>varimp(cf1, conditional=TRUE) # conditional=True, adjusts for correlations between predict</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##       0.00034783       0.00834783       0.00582609      -0.00191304 
##           Gender ConversationType     AudienceSize             Freq 
##       0.00295652       0.00069565       0.00252174       0.01139130 
##       Gradabilty SemanticCategory     Emotionality 
##       0.00008696       0.00008696       0.00086957</code></pre>
<pre class="r"><code>varimpAUC(cf1)  # more robust towards class imbalance.</code></pre>
<pre><code>##              Age        Adjective         Function          Priming 
##        0.0056743        0.0319284        0.0116915        0.0006288 
##           Gender ConversationType     AudienceSize             Freq 
##        0.0108261        0.0076496        0.0093993        0.0415649 
##       Gradabilty SemanticCategory     Emotionality 
##        0.0085987        0.0060204        0.0077188</code></pre>
<pre class="r"><code>par(mar = c(5, 8, 4, 2) + 0.1)
plot(y = 1:length(varimpAUC(cf1)), x = varimpAUC(cf1)[order(varimpAUC(cf1))], 
     axes = F, ann = F, pch = 20, xlim = c(-0.01, 0.05), main = &quot;Predictor Importance&quot;)
axis(1, at = seq(-0.01, 0.05, 0.005), seq(-0.01, 0.05, 0.005))
axis(2, at = 1:length(varimpAUC(cf1)), names(varimpAUC(cf1))[order(varimpAUC(cf1))], las = 2)
grid()
box()</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
</div>
</div>
<div id="boruta" class="section level1">
<h1><span class="header-section-number">8</span> Boruta</h1>
<pre class="r"><code># load library
library(Boruta)
# create dada for boruta
borutadata &lt;- reallyaus
# run 1
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 6.009 secs.
##  3 attributes confirmed important: Adjective, Freq, Function;
##  3 attributes confirmed unimportant: Age, Priming,
## SemanticCategory;
##  5 tentative attributes left: AudienceSize, ConversationType,
## Emotionality, Gender, Gradabilty;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq
## &lt;environment: 0x000000002f7da990&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .5)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<pre class="r"><code># remove superfluous variables
borutadata$Emotionality &lt;- NULL
borutadata$Priming &lt;- NULL
borutadata$Age &lt;- NULL
borutadata$SemanticCategory &lt;- NULL
# run2
boruta.ampaus &lt;- Boruta(really~.,data=borutadata)
print(boruta.ampaus)</code></pre>
<pre><code>## Boruta performed 99 iterations in 5.27 secs.
##  4 attributes confirmed important: Adjective, Freq, Function,
## Gradabilty;
##  No attributes deemed unimportant.
##  3 tentative attributes left: AudienceSize, ConversationType,
## Gender;</code></pre>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x000000000cf70f90&gt;</code></pre>
<pre class="r"><code>plot(boruta.ampaus, cex = .75)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<pre class="r"><code>getConfirmedFormula(boruta.ampaus)</code></pre>
<pre><code>## really ~ Adjective + Function + Freq + Gradabilty
## &lt;environment: 0x000000000ac2a2b0&gt;</code></pre>
<pre class="r"><code>par(mar = c(10, 8, 4, 2) + 0.1)
plot(boruta.ampaus, cex.axis=.75, las=2, xlab=&quot;&quot;, ylab = &quot;&quot;, cex = .75, 
     col = c(&quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,  &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;, &quot;grey50&quot;,&quot;grey90&quot;,&quot;grey90&quot;,&quot;grey90&quot;))
abline(v = 3.5, lty = &quot;dashed&quot;)
mtext(&quot;Predictors&quot;, 1, line = 8, at = 7, cex = 1)
mtext(&quot;Control&quot;, 1, line = 8, at = 2, cex = 1)
mtext(&quot;Importance&quot;, 2, line = 2.5, at = 2.5, cex = 1, las = 0)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<pre class="r"><code>par(mar = c(5, 4, 4, 2) + 0.1)</code></pre>
<pre class="r"><code>plotImpHistory(boruta.ampaus)</code></pre>
<p><img src="advancedstatz_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-achen1982interpreting">
<p>Achen, Christopher H. 1982. <em>Interpreting and Using Regression</em>. Vol. 29. Sage.</p>
</div>
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. a Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-bortz2006statistik">
<p>Bortz, Jürgen. 2006. <em>Statistik: Für Human-Und Sozialwissenschaftler</em>. Springer-Verlag.</p>
</div>
<div id="ref-bowerman1990linear">
<p>Bowerman, Bruce L, and Richard T O’Connell. 1990. <em>Linear Statistical Models: An Applied Approach</em>. Boston: PWS-Kent.</p>
</div>
<div id="ref-crawley2005statistics">
<p>Crawley, Michael J. 2005. <em>Statistics: An Introduction Using R. 2005</em>. Chichester, West Sussex: John Wiley &amp; Sons.</p>
</div>
<div id="ref-crawley2012r">
<p>———. 2012. <em>The R Book</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-faraway2002practical">
<p>Faraway, Julian J. 2002. <em>Practical Regression and Anova Using R.</em> University of Bath.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-green1991many">
<p>Green, Samuel B. 1991. “How Many Subjects Does It Take to Do a Regression Analysis.” <em>Multivariate Behavioral Research</em> 26 (3). Taylor &amp; Francis: 499–510.</p>
</div>
<div id="ref-gries2009statistics">
<p>Gries, Stefan Th. 2009. <em>Statistics for Linguistics Using R: A Practical Introduction</em>. Berlin &amp; New York: Mouton de Gruyter.</p>
</div>
<div id="ref-menard1995applied">
<p>Menard, Scott. 1995. <em>Applied Logistic Regression Analysis: Sage University Series on Quantitative Applications in the Social Sciences</em>. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-myers1990classical">
<p>Myers, Raymond H. 1990. <em>Classical and Modern Regression with Applications</em>. Vol. 2. Duxbury Press Belmont, CA.</p>
</div>
<div id="ref-szmrecsanyi2006morphosyntactic">
<p>Szmrecsanyi, Benedikt. 2006. <em>Morphosyntactic Persistence in Spoken English: A Corpus Study at the Intersection of Variationist Sociolinguistics, Psycholinguistics, and Discourse Analysis</em>. Berlin &amp; New York: Walter de Gruyter.</p>
</div>
<div id="ref-wilcox2009basic">
<p>Wilcox, Rand R. 2009. <em>Basic Statistics: Understanding Conventional Methods and Modern Insights</em>. Oxford University Press.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” <em>Methods in Ecology and Evolution</em> 1 (1): 3–14.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
