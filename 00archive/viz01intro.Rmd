---
title: "Introduction to data visualization with R"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction

This tutorial introduces data visualization with R while the following tutorials show how different types of data can be displayed using various types of visualizations. When it comes to data visualization, R offers a myriad of options and ways to show and summarize data which makes R an incredibly flexible tool that offers full control over the distinct layers of plots.

Before addressing practical issues, rather general questions relating to what needs to be kept in mind when visualizing data, e.g. axes labelling, are discussed. In addition, the section discusses pros and cons of different types of graphs (scatter plots, line graphs, bar plots, histograms, pie charts, box plots and many more).

The practical part presents the code used to set up graphs so that they can be recreated and also discusses potential problems that you may encounter when setting up a graph. 

As there exists a multitude of different ways to visualize data, this section can only highlight the most common types of visualization. Each type of visualization (or graph or plot) is briefly introduced followed by code which produces the type of visualization in R. This section focuses on using R when dealing with plots because R is extremely flexible when it comes to creating graphics. R is flexible in the sense that one can produce not only a huge variety of different types of visualization in R but also to modify these visualizations to match one's individual needs. In addition, a major advantage of using R consists in the fact that the code can be store, distributed, and run very easily. This means that R represents a framework for creating graphs that enables sustainable, reproducible, and transparent procedures. 

**Basics of visualization**

Before turning to the practical issues relating to creating graphs, a few words on what one has to keep in mind when visualizing data are in order. On a very general level, graphs should be used to inform the reader about properties and relationships between variables. This implies that...

* graphs, including axes, must be labelled properly to allow the reader to understand the visualization with ease. 

* visualizations should not use more dimensions than the data has that is visualized.

* all elements within a graph should be unambiguous.

* variable scales should be portrayed accurately (for instance, lines - which imply continuity - should not be used for categorically scaled variables).

* graphs should be as intuitive as possible.

**Visualization using R**

A few words on different frameworks for creating graphics in R are in order. There are three frameworks in which to create graphics in R. The *basic* framework, the *lattice* framework, and the *ggplot* or *tidyverse* framework. 

The *basic* framework is the oldest of the three and is included in the "base"-package that is automatically activated when entering R. The idea behind the "base" environment is that the creation of graphics is seen in analogy to a painter who paints on an empty canvass. Each line or element is added to the graph consecutively which oftentimes leads to code that is very comprehensible but also very long.

The *lattice* environment was a follow-up to the *base* package and it complemented it insofar as it made it much easier to display various variables and variable levels simultaneously. The philosophy of the lattice-package is quite different from the philosophy of *base*: whereas everything had to be specified in *base*, the graphs created in the *lattice* environment require only very little code but are therefore very easily created when one is satisfied with the design but vey labour intensive when it comes to customizing graphs. However, *lattice* is very handy when summarizing relationships between multiple variable and variable levels.

The *ggplot* environment was written by Hadley Wickham and it combines the positive aspects of both the *base* and the *lattice* package. It was first publicized in the *gplot* and *ggplot1* packages but the latter was soon repackaged and improved in the now most widely used package for data visualization: the *ggplot2* package. The *ggplot* environment implements a philosophy of graphic design described in builds on *The Grammar of Graphics* by Leland Wilkinson [@wilkinson2012grammar].

The philosophy of *ggplot2* is to consider graphics as consisting out of basic elements (called *aesthetics* and they include, for instance, the data set to be plotted and the axes) and layers that overlayed onto the aesthetics. The idea of the *ggplot2* package can be summarized as taking "care of many of the fiddly details that make plotting a hassle (like drawing legends) as well as providing a powerful model of graphics that makes it easy to produce complex multi-layered graphics."

Thus, ggplots typically start with the function call (ggplot) followed by the specification of the data, then the aesthetics (aes), and then a specification of the type of plot that is created (geom_line for line graphs, geom_box for boxplots, geom_bar for bargraphs, , geom_text for text, etc.). In addition, ggplot allows to specify all elements that the graph consists of (e.g. the theme and axes)

In the following, we will start to create a couple of graphs in the *base* environment (and a very brief example of how create visualizations in the *lattice* framework) but we will then concentrate on how to create *ggplot* graphs.

**Preparation and session set up**

As all visualizations in this tutorial rely on R, it is necessary to install R and RStudio. If these programs (or, in the case of R, environments) are not already installed on your machine, please search for them in your favourite search engine and add the term "download". Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).

In addition, certain *packages* need to be installed from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).

```{r prep1, echo=T, eval = F, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)
# install libraries
install.packages(c("lattice", "ggplot2", "dplyr", "likert", 
                   "scales", "vcd", "tm", "wordcloud", 
                   "stringr", "SnowballC", "tidyr"))
```

Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.

**Activating packages and loading the data**

Before turning to the practical creation of graphs, we will load the packages for the following tutorials and then briefly look at the structures of the data set we will be working with. The data set is stored as "lmmdata" but we change the name to "vizdata". The data set contains 537 observations of  5 variables: Date, Genre, Text, Prepositions, and Region. Date refers to the date when the text was written (Date), the genre of the text (Genre), the name of the text (Text), the relative frequency of prepositions in the text (Prepositions), and the region in which the text was written (Region). 

```{r prep2, echo=T, eval = T, message=FALSE, warning=FALSE}
# activate packages
library(knitr)
library(lattice)             
library(ggplot2)               
library(dplyr)
library(likert)                         
library(scales)
library(vcd)    
library(tm)
library(wordcloud)
library(stringr)
library(SnowballC)
library(tidyr)
# load data
vizdata <- read.delim("https://slcladal.github.io/data/lmmdata.txt", header = TRUE)
```

We have now activated  the packages that we will need for the vizualizations and loaded the data. Next, we inspect the data and its structure by using the "str()" and the "summary()" command. 

```{r prep3, echo=T, eval = T, message=FALSE, warning=FALSE}
# inspect data
str(vizdata); summary(vizdata)
```

The "str()" function shows that the data is a data frame containing 537 data points (or observations) and 5 variables. Also, the output of the "str()" function informs us that "Date" is an integer, "Genre" and "Text" are factors (with 16 and 271 levels respectively),  that "Prepositions" is a numeric variable, and "Region" is another factor (with 2 levels). 

The output of "summary()" function shows that the earliest text was written in 1150 and the latest text in 1913. The most common genre is "PrivateLetter" with 136 texts and the lowest relative freqeuncy of prepositions in a text is 63.97 while the highest relative frequency is 195.86 prepositions per 1,000 words in a text. Also, 237 texts were written in northern regions whereas 300 were written in southern regions. 

In a table, the first rows of the data look like this:

```{r data2, echo = F, eval=T, message=FALSE, warning=FALSE}
library(knitr)
kable(head(vizdata), caption = "First 6 rows of the data")
```

The following sections introduce different types of vizualizations and show how they can be created.

# How to cite this tutorial {-}

Schweinberger, Martin. 2020. *Introduction to data visualization with R*. Brisbane: The University of Queensland. url: https://slcladal.github.io/viz01intro.html.

# References
