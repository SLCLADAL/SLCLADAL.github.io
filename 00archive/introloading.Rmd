---
title: "Loading and Exporting Data"
author: "UQ SLC Digital Team"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction

This tutorial focuses on how to import data into R and how to export results from "R". In addition, we will have a look at how to set the "workspace" and why this makes sense when working in R. The entire code for the sections below can be downloaded [here](https://slcladal.github.io/rscripts/classificationscript.r).  

# Preparation and session set up

As all caluculations and visualizations in this tutorial rely on R, it is necessary to install R and RStudio. If these programms (or, in the case of R, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term "download". Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).

In addition, certain *packages* need to be installed from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the libraries by running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).

```{r prep1, echo=T, eval = F, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options("scipen" = 100, "digits" = 4) # supress math annotation
# install libraries
install.packages(c("cluster", "factoextra", "cluster", 
                   "seriation", "pvclust", "ape", "vcd", 
                   "exact2x2", "factoextra", "seriation", 
                   "NbClust", "pvclust"))
```

Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.

# Setting the workspace

When you are not working within an R project which automatically assumes that the folder, in which the project is located, is the working directory, it is useful to define the working directory ("work space") at the beginning of each session.

Defining the working directory means that you specify the path to a folder that serves as the default location, so that you do not have to specify the entire path to the objects or folders you are working with all the time. Instead of having to type, for example,  "D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io/mydata.txt" you would only have to type "mydata.txt" if "SLCLADAL.github.io" is defined as the working directory. 

Therefore, if you do not work within an R project (Rproj), the working directory should be specified manually by you (the user) which is done by specifying a path in the "setwd()" function (as shown below). In the present case, you may want to specify the folder that contains the materials for this tutorial. Before defining a working directory, it can be useful to check what is defined as the present working directory. To get the present working directory, you can use the command "getwd()" as shown below (). 


```{r echo=T, eval = F, message=FALSE, warning=FALSE}
# Set workspace
#setwd("D:\\StatisticsForLinguists")
# show workspace
getwd ()
```

From now on, we no longer need to specify the entire path to the files, just the name of the object we want to load.

# Importing Data

This section deals with importing and exporting data. 

## Importing tables from Excel

The most common way to load data is to load tabulated data - often data that were created in some type of spread sheet software (e.g. OpenOffice Calc or Microsoft Excel). We will therefore start with importing a single file containing tabulated data. 
To read spreadsheets directly from Microsoft Excel, you must first install and enable the "xlsx package". To install this package enter the command "install.packages("xlsx")" and press "Enter". The package "xlsx" can then be activated by the command "library(xlsx)".

```{r echo=F, eval = T, message=FALSE, warning=FALSE}
library(xlsx)
```

```{r echo=T, eval = F, message=FALSE, warning=FALSE}
install.packages("xlsx")
library(xlsx)
```

In a next step, we can either define the path to the data or explicitly define the path within the function "read.xlsx". Both options are shown below.

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
# define path to data
path <- "data/testdata1.xlsx"
# load data with defined path
mydata <- read.xlsx(path, 1)
# load data without pre-defining the path
mydata <- read.xlsx("data/testdata1.xlsx", 1)
```

Another way to import data is to navigate to the data using a GUI or Browser interface which is done by using the "chose.files()" command within the "read.xlsx" function.

```{r choosexlsx, echo=T, eval = F, message=FALSE, warning=FALSE}
mydata <- read.xlsx(choose.files(), 1)
```

To have a look at the entire data set, we can simply type the name of the object containing the data. In our case we called the object "mydata". So enter "mydataxlsx" into the "R" GUI and "R" will show you the loaded data. 

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
mydata
```

The command "summary(mydata)" summarizes the data set.

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
summary(mydata)
```

We can get an overview of the structure of the data with the command "str(mydata)". 

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
str(mydata)
```

The command "head(mydata)" outputs the first six lines or elements of a data object. 

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
head(mydata)
```


You import data into "R" so that "R" will then have this data available and you can edit it in "R". 

## Importing plain text tables

Tables are often stored not as spread sheets but as plain text files (, i.e. files with the file extension .txt). This is done to save space and also because it can be "tidier".

As the interactive way to load plain text tables is the most common way to load data into "R" among people who do not have much experience with "R", we will elaborate a little bit on this function. 

The function we use to load plain text tables is "read.table()" (or, as we will see later on, "read.delim()"). When we use the "chose.files()" function within the "read.table()" function, "R" opens a navigation window that allows us to browse to the data we want to load. In plain text files, tables are tap-stop-separated by default. To interactively open a tap-stop-separated .txt file, you need to enter the following command in R: 

```{r echo=T, eval = F, message=FALSE, warning=FALSE}
mydata <- read.table(choose.files(), header = T, sep = "\t", quote = "", comment.char = "")
```


The command (or the function to be precise) contains a number of arguments, which we should briefly discuss here. To get help on functions, enter the command "?package name" in "R" (of course, the name of the function must be used instead of the sequence "package name"). 

Now to our argument: first we define a name for the data, "mydata", to which we assign the result of the function "read.table" with the sequence "<-". 

Then, we use the function "read.table" which requires only the path to the data which we include by browsing to the data due to "choose.files()". In the case above, we also explicity define the following arguments: "header", "sep", "quote", and "comment.char". 

"choose.files()" tells "R" that we are interactively navigating to the file via a browser. "choose.files()" can also be replaced by the exact path to the file (e.g., "D:\\MyProjects\\RorLinguists/testdata1.txt"). In this case, "R" reads the file directly from the specified source. If we use a Windows machine, the direct path is specified with double backslashes for directories (instead of simple backslashes or forwardslashes that we use on a Mac) and simple forwardslashes for individual files. The "header" argument is needed to indicate whether the table has header that define the variables in the table. If the data has header, we set "header = TRUE" or "header = T", for short.

The "sep" argument is very important because it indicates how the data points in the driven file are separated. In most cases, the data points will be tab separated, but there are also comma-separated files (.csv).

The "\t" indicates that the data points are tab-separated, whereas "sep =" "" would indicate that the data points are separated by spaces and "sep =", "" would indicate that the data points passed through Commas are separated. The argument "quote" informs "R" that certain characters delineate quotes. The argument "comment.char" informs "R" that certain characters are not to be read as normal characters, but are programming comments.

## Loading more than one file: loading corpus data
To load many files at once, as we typically do when we load a corpus, requires different functions but it works very similar to the way individual files are loaded. In such cases, it does make sense however, to specify the path rather than browsing to the directory of the corpus.

```{r echo=T, message=FALSE, warning=FALSE}
# define path to corpus
corpuspath <- "D:\\Uni\\UQ\\LADAL\\SLCLADAL.github.io\\data\\testcorpus"
```

After we have specified the path, we can now create a list of all the files that are in that directory

```{r echo=T, message=FALSE, warning=FALSE}
# define files to load
corpus.files = list.files(path = corpuspath, pattern = NULL, all.files = T,
  full.names = T, recursive = T, ignore.case = T, include.dirs = T)
```


Now, we loop over the files in the list and scan the content, i.e. we load the corpus into "R".

```{r echo=T, message=FALSE, warning=FALSE}
# load corpus and start processing
corpus <- lapply(corpus.files, function(x) {
  x <- scan(x, what = "char", sep = "", quote = "", quiet = T, skipNul = T)
  x <- paste(x, sep = " ", collapse = " ")
  } )
```

To load the corpus, we have used two basic fiunctions, "scan()" and "paste()". The "scan()" function load the data while the "paste()" function conmbines the individual words of each file into a single object. 

We can inspect the corpus files with "corpus[1]" which shows us the first corpus file. 

```{r echo=T, message=FALSE, warning=FALSE}
# inspect first file
corpus[[1]]
```


Another way to inspect the corpus is "str(corpus)" which tells us about the structure of the corpus.   

```{r echo=T, message=FALSE, warning=FALSE}
# inspect corpus structure
str(corpus)
```

The last way to inspect corpus data that we will discuss here is to use the "summary()" function which gives us a summary of the structure of the corpus.  

```{r echo=T, message=FALSE, warning=FALSE}
# inspect corpus
summary(corpus)
```


# Exporting data

The following section shows how data can be exported from "R" and can then be stored on your computer. The most common way to export data from "R" is to save a tab-separated, plain text file (i.e. a file with the extension .txt). To export the data that was processed or generated in "R" we typically use the "write.table()" function. This function needs the following arguments: The first argument "file" is the object to be saved. "file" does not have to be written out, but should be mentioned first. The second argument "path" is the indication where "R" should save the file. Since we set the workspace, we only have to tell "R" which name we want to give to the object to be stored. Again, the argument does not have to be named. The following arguments, sep, col.names, and row.names, are the delimiter (either tab, comma, or space), and whether there are rows or column names in the object.

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
# define path to data
testdatawords <- paste(as.vector(unlist(corpus)), sep = " ", collapse = " ")
testdatawords <- gsub("[^[:alpha:][:space:]]*", "", testdatawords)
testdatawords <- as.vector(unlist(strsplit(testdatawords, " ")))
testdatawords <- table(testdatawords)[order(table(testdatawords), decreasing = T)]
head(testdatawords)
```

The data we want to output is a table called "testdatawords" which contains the words from the corpus and their frequencies in decending order.

```{r echo=T, eval = T, message=FALSE, warning=FALSE}
# define path to data
outpath <- "data/testdatawords.txt"
# save data to pc
write.table(testdatawords, file = outpath, sep = "\t", col.names = TRUE, row.names = F, quote = F)
```

To save data directly as a Microsoft Excel file you must first activate the package "xlsx" and then apply the "write.xlsx" command:

```{r echo=T, eval = F, message=FALSE, warning=FALSE}
library(xlsx)
write.xlsx (testdatawords, "data/testdatawords.xlsx")
```

There are many other ways to read and write data - and especially the tidyverse functions can be intersting to explore as they are less prone to changing features of data (such as converting factors to character variables). However, the functions explored above should give you some idea of how to get started.


```{r uq2, echo=F, fig.cap="", out.width = '100%'}
knitr::include_graphics("images/uq2.jpg")
```

