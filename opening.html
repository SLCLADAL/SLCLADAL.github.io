<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />
<link rel="icon" 
      type="image/x-icon" 
      href="favicon.ico" />


<meta name="author" content="" />


<title>LADAL Opening</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>


<!-- added by SKC for LADAL Style -->
<link rel="stylesheet" href="styles.css">
</head>

<body>


<div class="container-fluid main-container">





<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li>
  <a href="news.html">NEWS</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="comp.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="repro.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="intror.html">Getting started</a>
    </li>
    <li>
      <a href="string.html">String Processing</a>
    </li>
    <li>
      <a href="regex.html">Regular Expressions</a>
    </li>
    <li>
      <a href="table.html">Handling tables in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="dviz.html">Data Visualization with R</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="dstats.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="tree.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="clust.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="lexsim.html">Introduction to Lexical Similarity</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li>
      <a href="pwr.html">Power Analysis</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="net.html">Network Analysis</a>
    </li>
    <li>
      <a href="coll.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="vc.html">Phonetics: Creating Vowel Charts with Praat and R</a>
    </li>
    <li>
      <a href="litsty.html">Computational Literary Stylistics with R</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Useful How-To Tutorials</li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
    <li>
      <a href="gutenberg.html">Downloading Texts from Project Gutenberg</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES | CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">LADAL Opening</h1>

</div>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130562131-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130562131-1');
</script>

<p><img src="https://slcladal.github.io/images/LadalPurple.png" width="40%" style="float:right; padding:10px" /></p>
<p><br></p>
<p>The <strong>LADAL Opening</strong> event will consist of weekly presentations from eminent figures in linguistics, data science, and computational humanities and will cover a wide range of topics related to LADAL-relevant issues!</p>
<p>The first event of the LADAL Opening is a presentation by <a href="http://www.stgries.info/">Stefan Th. Gries</a> on MuPADRF (<em>Multifactorial Prediction and Deviation Analysis Using Regression/Random Forests</em>) on <strong>June 3, 2021, 5pm Brisbane time</strong> The event will take place on Zoom (the Zoom link will be announced here, on Twitter (@slcladal), and via our collaborators).</p>
<p>See below for the full list of presentations that are part of the LADAL Opening.</p>
<p><br> <br></p>
<hr />
<div id="upcoming-presentations" class="section level1 unnumbered">
<h1>UPCOMING PRESENTATIONS</h1>
<hr />
<div id="june-3-stefan-gries" class="section level2 unnumbered">
<h2>June 3: Stefan Gries</h2>
<details>
<p><summary><strong>MuPADRF (<em>Multifactorial Prediction and Deviation Analysis Using Regression/Random Forests</em>)</strong></p>
<p><strong><a href="https://languages-cultures.uq.edu.au/event/session/6575">Register here!</a></strong></p>
<p><strong>Abstract</strong></p>
<p><img src="https://slcladal.github.io/images/STG.jpg" width="45%" style="float:right; padding:10px" /></p>
<p>In this talk, I will give a brief and relatively practical introduction to an approach called MuPDAR(F) (for <em>Multifactorial Prediction and Deviation Analysis using Regressions/Random Forests</em>) that I developed (see <span class="citation">Gries and Deshors (<a href="#ref-gries2014using" role="doc-biblioref">2014</a>)</span>, <span class="citation">Gries and Adelman (<a href="#ref-gries2014subject" role="doc-biblioref">2014</a>)</span> for the first applications). The main part of the talk involves using a version of the data in <span class="citation">Gries and Adelman (<a href="#ref-gries2014subject" role="doc-biblioref">2014</a>)</span> to exemplify how this protocol works and how it can be done in R. Second, I will discuss a few recent extensions proposed in <span class="citation">Gries and Deshors (<a href="#ref-gries2020theresmore" role="doc-biblioref">2020</a>)</span> and <span class="citation">Gries (<a href="#ref-griestamupdar" role="doc-biblioref">n.d.</a>)</span>, which have to do with</p>
<ol style="list-style-type: lower-roman">
<li><p>how to deal with situations with more than two linguistic choices,</p></li>
<li><p>how predictions are made, and</p></li>
<li><p>how deviations are quantified.</p></li>
</ol>
<p>Finally, I will briefly comment on exploring individual variation among the target speakers (based on <span class="citation">Gries and Wulff (<a href="#ref-gries2021examining" role="doc-biblioref">2021</a>)</span>).</p>
<p></summary></p>
<p><strong>About Stefan</strong></p>
<p>Stefan Th. Gries is full professor at the University of California, Santa Barbara (UCSB), as well as Honorary Liebig-Professor and Chair of English Linguistics at the Justus-Liebig-Universität Giessen. Stefan has held several prestigious visiting professorships at top universities and, methodologically, he is a quantitative corpus linguist at the intersection of corpus linguistics, cognitive linguistics, and computational linguistics. Stefan has applied a variety of different statistical methods to investigate a wide range of linguistic topics and much of his work involves the open-source software R. Stefan has produced more than 200 publications (articles, chapters, books, and edited volumes), he is an active member of various editorial boards as well as academic societies.</p>
<br><br>
</details>
</div>
<div id="june-10-martin-schweinberger-michael-haugh" class="section level2 unnumbered">
<h2>June 10: Martin Schweinberger &amp; Michael Haugh</h2>
<details>
<p><summary><strong>The Australian Text Analytics Platform (ATAP) and the Language Technology and Data Analysis Laboratory (LADAL) - building computational humanities infrastructures: experiences, problems, and potentials</strong></p>
<p><img src="https://slcladal.github.io/images/LadalGrey.png" width="35%" style="float:right; padding:10px" /></p>
<p><strong>Abstract</strong></p>
<p>This talk introduces the <em>Language Technology and Data Analysis Laboratory</em> (LADAL) which is a computational humanities resource infrastructure maintained by the School of Languages and Cultures at the University of Queensland. The talk will also provide information about its relations to the Australian Text Analytics Platform (ATAP) which represents an effort to promote text analytics in Australia and to make resources for using text analytics available to a wider community of researchers.</p>
<p></summary></p>
<p><strong>About Martin</strong></p>
<p><img src="https://slcladal.github.io/images/martinsface.jpg" width="20%" style="float:right; padding:10px" /></p>
<p>Martin is a language data scientist with a PhD in English linguistics who has specialized in corpus linguistics and quantitative, computational analyses of language data. Martin is currently an Associate Professor in the AcqVA-Aurora Center at the Arctic University of Norway in Tromsø and he holds a additional appointment as Postdoctoral Research Fellow in Language Technology at the University of Queensland, Australia where he has been establishing the Language Technology and Data Analysis Laboratory (LADAL).</p>
<p><br><br></p>
<p><strong>About Michael</strong></p>
<p><img src="https://slcladal.github.io/images/michael.jpg" width="20%" style="float:right; padding:10px" /></p>
<p>Michael is Professor of Linguistics and a Fellow of the Australian Academy of the Humanities. His research interests lie primarily in the field of pragmatics, the science of language-in-use. He works with recordings and transcriptions of naturally occurring spoken interactions, as well as data from digitally-mediated forms of communication across a number of languages. An area of emerging importance in his view is the role that language corpora can play in the humanities and social sciences more broadly. He has been involved in the establishment of the <a href="http://www.ausnc.org.au">Australian National Corpus</a> and the Language Technology and Data Analytics Lab, and is currently leading the establishment of a national language data commons.</p>
<br><br>
</details>
</div>
<div id="june-18-felicity-meakins" class="section level2 unnumbered">
<h2>June 18: Felicity Meakins</h2>
<details>
<p><summary><strong>Field-based methods for collecting quantitative data</strong></p>
<p><img src="https://slcladal.github.io/images/felicity.png" width="45%" style="float:right; padding:10px" /></p>
<p><strong>Abstract</strong></p>
<p>Shana Poplack has set benchmarks for the development of corpora since the early 1980s. Poplack (2015, p. 921) maintains that the “gold standard remains the (standard sociolinguistic-style) … corpus”. The aim of producing corpora using these principles is to avoid the ‘cherry picking’ approach which dominates much of the theoretical literature. Poplack and her team have created the Ottawa-Hull Corpus which consists of 3.5 million words of informal speech data. This corpus is enormous and beyond the capabilities of a single linguist in a small language community. This talk offers suggestions for corpus development in the field that follow Poplack’s principles, but also shows where compromises can be made. I discuss the method developed during the Gurindji Kriol project called ‘peer elicitation’. It supplements Poplack’s gold standard of naturally occurring speech with semi-formal elicitation to ensure sufficient data for quantitative analyses. </summary></p>
<p><br><br></p>
<p><strong>About Felicity</strong></p>
<p><img src="https://slcladal.github.io/images/felicity.jpeg" width="25%" style="float:right; padding:10px" /></p>
<p>Felicity Meakins is an ARC Future Fellow in Linguistics at the University of Queensland and a CI in the ARC Centre of Excellence for the Dynamics of Language. She is a field linguist who specialises in the documentation of Australian Indigenous languages in the Victoria River District of the Northern Territory and the effect of English on Indigenous languages. She has worked as a community linguist as well as an academic over the past 20 years, facilitating language revitalisation programs, consulting on Native Title claims and conducting research into Indigenous languages. She has compiled a number of dictionaries and grammars of traditional Indigenous languages and has written numerous papers on language change in Australia.</p>
</details>
</div>
<div id="june-27-gerold-schneider" class="section level2 unnumbered">
<h2>June 27: Gerold Schneider</h2>
<details>
<p><summary><strong>Text Crunching Center (TCC): Data-driven methods for linguists, social science and digital humanities</strong></p>
<p><strong>Abstract</strong></p>
<p><img src="https://slcladal.github.io/images/ttclogo.png" width="25%" style="float:right; padding:10px" /></p>
<p>This talk introduces the Text Crunching Centre (TCC) which is a Computational Linguistics and Digital Humanities service hosted at the University of Zurich, and a collaboration partner of LADAL. We present a selection of our case studies using text analytics, from cognitive linguistics, social, political and historical studies. We show how stylistics, document classification, topic modelling, conceptual maps, distributional semantics and eye-tracking can offer new perspectives. Our case studies include language and age, learner language, the history of medicine, democratisation, religion, and attitudes to migration. We conclude with an outlook to the future of text analytics.</summary></p>
<p><br><br></p>
<p><strong>About Gerold</strong></p>
<p><img src="https://slcladal.github.io/images/gerold.jpg" width="25%" style="float:right; padding:10px" /></p>
<p>Gerold Schneider is a Senior Lecturer, researcher and computing scientist at the department of Computational Linguistics at the University of Zurich, Switzerland. His doctoral degree is on large-scale dependency parsing, his habilitation on using computational models for corpus linguistics. His research interests include corpus linguistics, statistical approaches, Digital Humanities, text mining and language modeling. He has published over 100 articles on these topics. He has published a book on <a href="https://dlf.uzh.ch/openbooks/statisticsforlinguists/">statistics for linguists</a> <span class="citation">(Schneider and Lauber <a href="#ref-schneider2019statistics" role="doc-biblioref">2019</a>)</span>, and a book on digital humanities is under way. His Google scholar page can be accessed <a href="https://scholar.google.com/citations?user=l_8L7NYAAAAJ">here</a>.</p>
</details>
</div>
<div id="july-1-monika-bednarek" class="section level2 unnumbered">
<h2>July 1: Monika Bednarek</h2>
<p><strong>Corpus-based media linguistics: A case study of linguistic diversity in Australian television</strong></p>
</div>
<div id="july-8-natalia-levshina" class="section level2 unnumbered">
<h2>July 8: Natalia Levshina</h2>
<p><strong>Bayesian versus Frequentist Approaches in Statistics (preliminary title)</strong></p>
</div>
<div id="july-15-myrte-vos" class="section level2 unnumbered">
<h2>July 15: Myrte Vos</h2>
<p><strong>Gathering data and creating online experiments with jsPsych (preliminary title)</strong></p>
</div>
<div id="july-22-julie-toohey-amanda-miotto" class="section level2 unnumbered">
<h2>July 22: Julie Toohey &amp; Amanda Miotto</h2>
<p><strong>Reproducible research, Open Science, and Pre-Publication (preliminary title)</strong></p>
</div>
<div id="july-28-vincent-deluca-toms-voits-jason-rothman" class="section level2 unnumbered">
<h2>July 28: Vincent DeLuca, Toms Voits, &amp; Jason Rothman</h2>
<p><strong>Neurocognitve effects of bilingual experience</strong></p>
</div>
<div id="august-2-simon-musgrave-matttias-allard" class="section level2 unnumbered">
<h2>August 2: Simon Musgrave &amp; Matttias Allard</h2>
<p><strong>Starting to work with networks</strong></p>
</div>
<div id="august-12-janet-wiles-ben-foley" class="section level2 unnumbered">
<h2>August 12: Janet Wiles &amp; Ben Foley</h2>
<p><strong>(Semi-)Automated speech recognition using ELPIS (preliminary title)</strong></p>
</div>
<div id="august-19-mikko-laitinen" class="section level2 unnumbered">
<h2>August 19: Mikko Laitinen</h2>
<p><strong>Establishing Computational Humanities Infrastructures in Finland (preliminary title)</strong></p>
</div>
<div id="september-2-peter-crosthwaite" class="section level2 unnumbered">
<h2>September 2: Peter Crosthwaite</h2>
<details>
<p><summary><strong>Data-driven learning for younger learners: Boosting schoolgirls’ knowledge of passive voice constructions for STEM education</strong></summary></p>
<p><img src="https://slcladal.github.io/images/peter.jpg" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Abstract</strong></p>
<p>This paper explores how corpus technology and DDL pedagogy can support secondary schoolgirls’ reporting of an observed science experiment through a written research report, focusing particularly on how corpora were used to develop receptive and productive knowledge of passive voice constructions. A pre-test of the grammaticality of passive constructions was conducted, alongside a diagnostic pre-instruction written report requiring the retelling of an observed science experiment were collected from 60 Year 9-10 girls at a high school in Australia. During a full 10-week term, students were given guided individual homework tasks and short in-class pair/group DDL activities focusing on passive voice constructions, using freely available online corpus applications such as SketchEngine. Following this treatment, a post-test was conducted while an additional written research report was collected. Questionnaire and interview data was also collected to determine the perceptions of younger female learners and their teachers regarding their engagement with corpora and DDL for improving knowledge and use of passive constructions over time. The data suggest the DDL treatment resulted in increased knowledge of the grammaticality of passive voice constructions, while students were more likely to include such constructions in their written reports while increasing the accuracy of their use. Qualitative stakeholder perceptions of improved disciplinary linguistic knowledge, increased data management skills, and positive engagement with “science” were also found in the survey/interview data, although a number of challenges at the technical and conceptual levels for DDL still remain.</p>
<p><strong>About Peter</strong></p>
<p>Peter is Senior Lecturer in the School of Languages and Cultures at UQ (since 2017), having formerly been an assistant professor at the Centre for Applied English Studies (CAES), University of Hong Kong (since 2014). His areas of research and supervisory expertise include corpus linguistics and the use of corpora for language learning (known as <em>data-driven learning</em>), as well as English for General and Specific Academic Purposes. I am the author of the monograph <em><a href="https://benjamins.com/catalog/scl.93">Learning the language of Dentistry: Disciplinary corpora in the teaching of English for specific academic purposes</a></em> as part of Benjamins’ Studies in Corpus Linguistics series (with Lisa Cheung, published 2019), as well as the edited volumes <em><a href="https://www.routledge.com/Data-Driven-Learning-for-the-Next-Generation-Corpora-and-DDL-for-Pre-tertiary/Crosthwaite/p/book/9781138388017">Data Driven Learning for the Next Generation: Corpora and DDL for Pre-tertiary Learners</a></em> (published 2019) and <em><a href="https://www.routledge.com/Referring-in-a-Second-Language-Studies-on-Reference-to-Person-in-a-Multilingual/Ryan-Crosthwaite/p/book/9780367208943">Referring in a second language: Reference to person in a multilingual world</a></em> (with Jonathon Ryan, published 2020) with Routledge. I am also currently serving as the corpus linguistics section editor for <a href="https://www.degruyter.com/journal/key/OPLI/html">Open Linguistics</a> (ISI-ESCI) - an open access linguistics journal from De Gruyter, as well as on the editorial board of Applied Corpus Linguistics, a new journal covering the direct applications of corpora to teaching and learning.</p>
<br><br>
</details>
</div>
<div id="september-9-laura-janda" class="section level2 unnumbered">
<h2>September 9: Laura Janda</h2>
<details>
<p><summary><strong>Strategic targeting of rich inflectional morphology for linguistic analysis and L2 acquisition</strong></summary></p>
<p><img src="https://slcladal.github.io/images/laura.png" width="30%" style="float:right; padding:10px" /></p>
<p><strong>Abstract</strong></p>
<p>Many languages have rich inflectional morphology signaling grammatical categories such as case, number, tense, etc. Rich morphology presents a challenge for L2 learners because even a basic vocabulary of a few thousand words can entail mastery of over 100,000 word forms. However, only a handful of the potential forms of a given word occur frequently, while the remainder are rare. Access to digital corpora makes it possible to determine which forms of any given word are of highest frequency, as well as what grammatical and collocational contexts motivate those few frequent forms, facilitating strategically focused language learning tools. Corpus analysis of the frequency distributions of inflectional forms provide linguists with added insights into the function of languages. The results achieved primarily by using correspondence analysis of Russian material are potentially portable to any language with rich inflectional morphology.</p>
<p><strong>About Laura</strong></p>
<p>In the Cold War era, Laura Janda combined study of Slavic linguistics at Princeton and UCLA with US-government-funded adventures as an exchange student behind the Iron Curtain in countries that have since changed their names: USSR, Czechoslovakia, and Yugoslavia. After over two decades at the University of Rochester and UNC-Chapel Hill, she moved to the University of Tromsø in 2008. Laura Janda was an early adopter of Cognitive Linguistics in the 1980s and has explored quantitative methods since 2007. Her research focuses primarily on the morphology of Slavic languages, with various admixtures (North Saami, conlangs, political discourse).</p>
<br><br>
</details>
</div>
<div id="september-13-gregor-wiedemann" class="section level2 unnumbered">
<h2>September 13: Gregor Wiedemann</h2>
<details>
<p><summary><strong>Text classification for automatic detection of hate speech, counter speech, and protest events</strong></summary></p>
<p><img src="https://slcladal.github.io/images/people_gregor.jpg" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Abstract</strong></p>
<p>Social sciences have opened up to text mining, i.e., a set of methods to automatically identify semantic structures in large document collections. However, the methods have often been limited to a statistical analysis of textual data, strongly limiting the scope of possible research questions. The more complex concepts central to the social sciences such as arguments, frames, narratives and claims still are mainly studied using manual content analyses in which the knowledge needed to apply a category (i.e. to “code”) is verbally described in a codebook and implicit in the coder’s own background knowledge. Supervised machine learning provides an approach to scale-up this coding process to large datasets. Recent advantages in neural network-based natural language processing allow for pretraining language models that can transfer semantic knowledge from unsupervised text collections to specific automatic coding problems. With deep learning models such as BERT automatic coding of context-sensitive semantics with substantially lowered efforts in training data generation comes within reach to content analysis. The talk will introduce to the applied usage of these technologies along with two interdisciplinary research projects studying hate speech and counter speech in German Facebook postings, and information extraction for the analysis of the coverage of protest events in local news media.</p>
<p><strong>About Gregor</strong></p>
<p>Dr. Gregor Wiedemann is working as Senior Researcher Computational Social Science at the Leibniz Institute for Media Research │ Hans Bredow Institute (HBI). Since September 2020, he heads the Media Research Methods Lab (MRML). His current work focuses on the development of methods and applications of natural language processing and text mining for empirical social and media research. Gregor Wiedemann studied political science and computer science in Leipzig and Miami, USA. In 2016 he received his doctorate from the Department of Computer Science at the University of Leipzig for his thesis on automation of discourse and content analysis using text mining and machine learning methods. Afterwards he worked as a postdoc in the NLP group of Computer Science Department at the University of Hamburg. Among other things, the resulting works are concerned with unsupervised information extraction to support investigative research in unknown document collections (see newsleak.io) and with the detection of hate and counter-speech in social media.</p>
<br><br>
</details>
</div>
<div id="september-21-terttu-nevalainen-turo-hiltunen-aatu-liimatta" class="section level2 unnumbered">
<h2>September 21: Terttu Nevalainen, Turo Hiltunen &amp; Aatu Liimatta</h2>
<p><strong>Case studies from VARIENG (preliminary title)</strong></p>
</div>
<div id="september-27-laurence-anthony" class="section level2 unnumbered">
<h2>September 27: Laurence Anthony</h2>
<p><strong>AntConc 4.0 (preliminary title)</strong></p>
</div>
<div id="october-2-guillaume-desagulier" class="section level2 unnumbered">
<h2>October 2: Guillaume Desagulier</h2>
<p><strong>Doing diachronic linguistics with distributional semantic models in R</strong></p>
</div>
<div id="october-15-tanja-säily" class="section level2 unnumbered">
<h2>October 15: Tanja Säily</h2>
<details>
<p><summary><strong>Analysing 18th-century publications and publishing networks (preliminary title)</strong></summary></p>
<p><strong>About Tanja</strong></p>
<p><img src="https://slcladal.github.io/images/tanja.png" width="30%" style="float:right; padding:10px" /></p>
<p>Tanja Säily is a tenure-track assistant professor in English language at the University of Helsinki. Her research interests include corpus linguistics, digital humanities, historical sociolinguistics, and linguistic productivity. She is also interested in the social embedding of language variation and change in general, including gendered styles in the history of English and extralinguistic factors influencing language change. Her overarching aim is to develop new ways of understanding language variation and change, often in collaboration with experts from other fields. Her current project combines historical sociolinguistics, intellectual history, book history and data science to analyse eighteenth-century publications and publishing networks.</p>
<br><br>
</details>
</div>
<div id="october-18-stéphane-guillou" class="section level2 unnumbered">
<h2>October 18: Stéphane Guillou</h2>
<details>
<p><summary><strong>Git and GitHub/Gitlab for versioning and collaborating</strong></summary></p>
<p><strong>Abstract</strong></p>
<p>Git is a tool for versioning of and collaborating on any text-based file. Widely used in software development, it is now adopted in many different settings, from document versioning to data analysis management. It is also at the centre of major platforms like GitHub and GitLab, used by millions to share and collaborate on code and documents. In this workshop, you will learn about:</p>
<ul>
<li><p>The main commands used in a git workflow</p></li>
<li><p>How to publish your work online</p></li>
<li><p>How to collaborate on a GitHub repository</p></li>
</ul>
<p>If you would like to follow along, please do the following before attending:</p>
<ul>
<li><p>Install Git on your computer (here are <a href="https://gitlab.com/stragu/DSH/-/blob/master/Git/installation.md">OS-specific instructions</a>)</p></li>
<li><p>Create a <a href="https://github.com/">GitHub</a> account (or <a href="https://gitlab.com/">GitLab</a> if you want an alternative)</p></li>
</ul>
<p><strong>About Stéphane</strong></p>
<p>Stéphane has worked for the last 10 years at the University of Queensland (UQ). After completing a master’s degree in plants science and ecology in France, he worked in research around the topic of sustainable agriculture. In 2018, a drastic move to a Technology Trainer position at the Library allowed him to share data analysis best practice skills, and promote Open Source tools for research. He is motivated by the principles of Open Science and the opportunities an increasingly collaborative research ecosystem offers.</p>
<br><br>
</details>
</div>
<div id="october-29joseph-flanagan" class="section level2 unnumbered">
<h2>October 29:Joseph Flanagan</h2>
<p><strong>How to Make your Research Reproducible</strong></p>
<hr />
</div>
</div>
<div id="past-presentations" class="section level1 unnumbered">
<h1>PAST PRESENTATIONS</h1>
<hr />
<hr />
<p><a href="#announcements">Back to top</a></p>
<p><a href="https://slcladal.github.io/index.html">Back to HOME</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-griestamupdar">
<p>Gries, Stefan Th. n.d. “MuPDAR for Corpus-Based Learner and Variety Studies: Two (More) Suggestions for Improvement.” In <em>Tba</em>, edited by Martin Hilpert and Susanne Flach, ???–??? ? ?</p>
</div>
<div id="ref-gries2014subject">
<p>Gries, Stefan Th, and Allison S Adelman. 2014. “Subject Realization in Japanese Conversation by Native and Non-Native Speakers: Exemplifying a New Paradigm for Learner Corpus Research.” In <em>Yearbook of Corpus Linguistics and Pragmatics 2014</em>, 35–54. Springer.</p>
</div>
<div id="ref-gries2014using">
<p>Gries, Stefan Th, and Sandra C Deshors. 2014. “Using Regressions to Explore Deviations Between Corpus Data and a Standard/Target: Two Suggestions.” <em>Corpora</em> 9 (1): 109–36.</p>
</div>
<div id="ref-gries2020theresmore">
<p>———. 2020. “There’s More to Alternations Than the Main Diagonal of a 2×2 Confusion Matrix: Improvements of Mupdar and Other Classificatory Alternation Studies.” <em>ICAME Journal</em> 44: 69–96.</p>
</div>
<div id="ref-gries2021examining">
<p>Gries, Stefan Th, and Stefanie Wulff. 2021. “Examining Individual Variation in Learner Production Data: A Few Programmatic Pointers for Corpus-Based Analyses Using the Example of Adverbial Clause Ordering.” <em>Applied Psycholinguistics</em> 42 (2): 279–99.</p>
</div>
<div id="ref-schneider2019statistics">
<p>Schneider, Gerold, and Max Lauber. 2019. “Introduction to Statistics for Linguists.” Pressbooks. <a href="https://dlf.uzh.ch/openbooks/statisticsforlinguists/">https://dlf.uzh.ch/openbooks/statisticsforlinguists/</a>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>
</html>
