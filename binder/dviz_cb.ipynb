{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *Data Visualization with R*](https://ladal.edu.au/dviz.html). \n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "We set up our session by activating the packages we need for this tutorial. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# activate packages\n",
                "library(dplyr)\n",
                "library(stringr)\n",
                "library(ggplot2)\n",
                "library(ggridges)\n",
                "library(likert)\n",
                "library(vcd)\n",
                "library(tm)\n",
                "library(wordcloud)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have initiated the session by executing the code shown above, you are good to go.\n",
                "\n",
                "If you are using this notebook on your own computer and you have not already installed the R packages listed above, you need to install them. You can install them by replacing the `library` command with `install.packages` and putting the name of the package into quotation marks like this: `install.packages(\"dplyr\")`. Then, you simply run this command and R will install the package you specified.\n",
                "\n",
                "\n",
                "# Load data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load data\n",
                "pdat  <- base::readRDS(url(\"https://slcladal.github.io/data/pvd.rda\", \"rb\"))\n",
                "# inspect data\n",
                "head(pdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "## Using your own data\n",
                "\n",
                "While the tutorial uses data from the LADAL website, you can also use your own data. You can see below what you need to do to upload and use your own data.\n",
                "\n",
                "The code chunk below allows you to upload two files from your own computer. To be able to load your own data, you need to click on the folder symbol to the left of the screen:\n",
                "\n",
                "![Binder Folder Symbol](https://slcladal.github.io/images/binderfolder.JPG)\n",
                "\n",
                "\n",
                "Then on the upload symbol.\n",
                "\n",
                "![Binder Upload Symbol](https://slcladal.github.io/images/binderupload.JPG)\n",
                "\n",
                "Next, upload the files you want to analyze and then the respective files names in the file argument of the scan function. When you then execute the code (like to code chunk below, you will upload your own data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mytable1 <- openxlsx::read.xlsx(\"testdata1.xlsx\", sheet = 1)\n",
                "# inspect\n",
                "mytable1\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Keep in mind though that you need to adapt the names of the texts in the code chunks below so that the code below work on your own texts!**\n",
                "\n",
                "***\n",
                "\n",
                "Next, we create vectors with custom colors. You can also check out the colors that are available in R  [here](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf) and the palettes or sets of colors  [here](https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clrs5 <- c(\"indianred4\", \"gray30\", \"darkblue\", \"orange\", \"gray80\")\n",
                "clrs3 <- c(\"indianred4\", \"gray30\", \"darkblue\")\n",
                "clrs2 <- c(\"orange\", \"gray80\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now turn to creating graphs.\n",
                "\n",
                "# Dot and Scatter Plots\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create simple scatter plot using the pdat data\n",
                "ggplot(pdat,  \n",
                "       # define axes\n",
                "       aes(x= Date,        \n",
                "           y= Prepositions)) + \n",
                "  # define plot type\n",
                "  geom_point()                  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can change the basic outlook by modifying the theme (in this case to the black-and-white theme).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(pdat,    \n",
                "       # define axes\n",
                "       aes(x=Date,             \n",
                "           y= Prepositions, \n",
                "           # define to color by Species\n",
                "           color = GenreRedux)) + \n",
                "  # define plot type\n",
                "  geom_point() +   \n",
                "  # define theme  as black and white (bw)\n",
                "  theme_bw()                   \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now specify the symbols in the scatter plot.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create scatter plot colored by genre\n",
                "ggplot(pdat, aes(Date, Prepositions, color = GenreRedux, shape = GenreRedux)) +\n",
                "  geom_point() +\n",
                "  guides(shape=guide_legend(override.aes=list(fill=NA))) +\n",
                "  scale_shape_manual(name = \"Genre\", \n",
                "                     breaks = names(table(pdat$GenreRedux)), \n",
                "                     values = 1:5) +\n",
                "  scale_color_manual(name = \"Genre\", \n",
                "                     breaks = names(table(pdat$GenreRedux)), \n",
                "                     values = clrs5) +\n",
                "  theme_bw() +\n",
                "  theme(legend.position=\"top\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extensions of dot plots\n",
                "\n",
                "In addition, we can add regression lines with error bars by Species and, if we want to show separate windows for the plots, we can use the \"facet_grid\" or \"facet_wrap\" function and define by which variable we want to create different panels.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create scatter plot colored by genre in different panels\n",
                "ggplot(pdat, aes(Date, Prepositions,  color = Genre)) +\n",
                "  facet_wrap(vars(Genre), ncol = 4) +\n",
                "  geom_point() + \n",
                "  geom_smooth(method = \"lm\", se = F) +\n",
                "  theme_bw() +\n",
                "  theme(legend.title = element_blank(), \n",
                "        axis.text.x = element_text(size=8, angle=90))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we only want to show the lines, we simply drop the \"geom_point\" function.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create scatter plot colored by genre in different panels\n",
                "ggplot(pdat, aes(x=Date, y= Prepositions,  color = Genre)) +\n",
                "  facet_wrap(vars(Genre), ncol = 4) +\n",
                "  geom_smooth(method = \"lm\", se = F) +\n",
                "  theme_bw() +\n",
                "  theme(legend.title = element_blank(), \n",
                "        axis.text.x = element_text(size=8, angle=90))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Another option is to plot density layers instead of plotting the data points.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create scatter density plot\n",
                "ggplot(pdat, aes(x=Date, y= Prepositions,  color = GenreRedux)) +\n",
                "    facet_wrap(vars(GenreRedux), ncol = 5) +\n",
                "  theme_bw() +                  \n",
                "  geom_density_2d() +\n",
                "  theme(legend.position = \"top\",\n",
                "        legend.title = element_blank(), \n",
                "        axis.text.x = element_text(size=8, angle=90))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Although these are not scatterplots, plots with dot-symbols are very flexible and can be extended to show properties of the distribution of values. One way to create such a plot is to plot means as dot-symbols and add error bars to provide information about the underlying distribution. The plot below illustrates such a plot and additionally shows how plots can be further customized.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# scatter plot with error bars\n",
                "ggplot(pdat, aes(x=reorder(Genre, Prepositions, mean), y= Prepositions,  group = Genre)) +                 \n",
                "  stat_summary(fun = mean, geom = \"point\", aes(group= Genre)) +          \n",
                "  stat_summary(fun.data = mean_cl_boot,       \n",
                "               # add error bars\n",
                "               geom = \"errorbar\", width = 0.2) + \n",
                "  # def. y-axis range\n",
                "  coord_cartesian(ylim = c(100, 200)) +              \n",
                "  # def. font size\n",
                "  theme_bw(base_size = 15) +         \n",
                "  # def. x- and y-axis\n",
                "  theme(axis.text.x = element_text(size=10, angle = 90),  \n",
                "        axis.text.y = element_text(size=10, face=\"plain\")) + \n",
                "  # def. axes labels\n",
                "  labs(x = \"Genre\", y = \"Prepositions (Frequency)\") +     \n",
                "  # def. to col.\n",
                "  scale_color_manual(guide = FALSE)          \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Balloon plots are an extension of scatter plots that are typically used to display data that represents\n",
                "* two categorical variables\n",
                "* one numeric variable.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ballon plot\n",
                "pdat %>%\n",
                "  dplyr::mutate(DateRedux = factor(DateRedux)) %>%\n",
                "  dplyr::group_by(DateRedux, GenreRedux) %>%\n",
                "  dplyr::summarise(Prepositions = mean(Prepositions)) %>%\n",
                "  ggplot(aes(DateRedux, 100, \n",
                "             size = Prepositions,\n",
                "             fill = GenreRedux)) +\n",
                "  facet_grid(vars(GenreRedux)) +\n",
                "  geom_point(shape = 21) +\n",
                "  scale_size_area(max_size = 15) +\n",
                "  coord_cartesian(ylim = c(50, 150)) +\n",
                "  theme_bw() +\n",
                "  theme(axis.title.y=element_blank(),\n",
                "        axis.text.y=element_blank(),\n",
                "        axis.ticks.y=element_blank()) +\n",
                "  scale_fill_discrete(guide = \"none\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Density Plots\n",
                "\n",
                "Another way to visualize the distribution of the data with respect to numeric variables are density plots or Kernel Density Plots. Density plots smooth the data using so-called kernel smoothing to even out the distribution of frequencies along the lines of a numeric or interval variable. The peaks of density plots help display where values are concentrated over the interval. To show the relationship between the variable and the density plot, we will first create a scatter plot and then create a density plot of the variable displayed on the x-axis of the scatter plot.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create dot plot\n",
                "ggplot(pdat, aes(x = Date, y = Prepositions, color=Region)) +  \n",
                "  geom_point() +  \n",
                "  scale_color_manual(values = clrs2) + \n",
                "  theme(legend.position=c(0,1), legend.justification=c(0,1)) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now create a marginal density plot of Date (x-axis) to show when texts from the north and south were particularly common.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create dot plot\n",
                "ggplot(pdat, aes(Date, fill=Region)) +  \n",
                "  geom_density(alpha=.5) +  \n",
                "  scale_fill_manual(values = clrs2) + \n",
                "  theme(legend.position=c(0,1), legend.justification=c(0,1)) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The density plot shows that the texts differ substantially with respect to where they were written as the distribution of texts written in southern Britain continues way into the 19^th^ century while we only have texts written in north until about 1800. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create dot plot\n",
                "ggplot(pdat, aes(Date, Prepositions)) +  \n",
                "  geom_density2d_filled()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Line Graphs\n",
                "\n",
                "Line graphs are used when we have numeric values that are linked (in one way or another) because they come from the same speaker or genre as in our case). \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pdat %>%\n",
                "  dplyr::group_by(DateRedux, GenreRedux) %>%\n",
                "  dplyr::summarise(Frequency = mean(Prepositions)) %>%\n",
                "  ggplot(aes(x=DateRedux, y= Frequency, group= GenreRedux, color = GenreRedux)) +\n",
                "  # add geom layer with lines\n",
                "  geom_line()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Smoothed line graphs\n",
                "\n",
                "Another very useful function when creating line graphs with \"ggplot\" is \"geom_smooth\" which *smoothes* the lines to be drawn. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(pdat, aes(x=Date, y= Prepositions, group= GenreRedux, color = GenreRedux)) +\n",
                "  # add geom layer with lines\n",
                "  geom_smooth()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As this smoothed line graph is extremely useful, we will customize it to show how to modify your graph.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define aesthetics\n",
                "ggplot(pdat, aes(x=Date, y= Prepositions,  color = GenreRedux, linetype = GenreRedux)) +\n",
                "  # add geom layer with lines\n",
                "  geom_smooth(se = F) +  \n",
                "  # legend without background color\n",
                "  guides(color=guide_legend(override.aes=list(fill=NA))) +  \n",
                "  # def. legend position\n",
                "  theme(legend.position=\"top\") +  \n",
                "  # def. linetype\n",
                "  scale_linetype_manual(values=c(\"twodash\", \"dashed\", \"dotdash\", \"dotted\", \"solid\"), \n",
                "                        # def. legend header\n",
                "                        name=c(\"Genre\"),\n",
                "                        # def. linetypes\n",
                "                        breaks = names(table(pdat$GenreRedux)),\n",
                "                        # def. labels\n",
                "                        labels = names(table(pdat$GenreRedux))) + \n",
                "  # def. col.\n",
                "  scale_colour_manual(values=clrs5,\n",
                "                      # define legend header\n",
                "                      name=c(\"Genre\"),\n",
                "                      # define elements\n",
                "                      breaks=names(table(pdat$GenreRedux)),  \n",
                "                      # define labels\n",
                "                      labels = names(table(pdat$GenreRedux))) +\n",
                "  # add x-axis label\n",
                "  labs(x = \"Year\") +      \n",
                "  # customize x-axis tick positions\n",
                "  scale_x_continuous(breaks=seq(1100, 1900, 100), \n",
                "                     # add labels to x-axis tick pos.\n",
                "                     labels=seq(1100, 1900, 100)) +\n",
                "  # add y-axis label\n",
                "  scale_y_continuous(name=\"Relative frequency \\n(per 1,000 words)\",  \n",
                "                     # customize tick y-axis\n",
                "                     limits=c(100, 200)) + \n",
                "  # define theme  as black and white\n",
                "  theme_bw(base_size = 10)  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Although the code for the customized smoothed line graph is much longer and requires addition specifications, it is a very nice way to portrait the development over time.\n",
                "\n",
                "## Ribbon plots\n",
                "\n",
                "Ribbon plots show an area, typically between minimum and maximum values. In addition, ribbon plots commonly also show the mean as depicted below.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create dot plot\n",
                "pdat %>%\n",
                "  dplyr::mutate(DateRedux = as.numeric(DateRedux)) %>%\n",
                "  dplyr::group_by(DateRedux) %>%\n",
                "  dplyr::summarise(Mean = mean(Prepositions),\n",
                "                   Min = min(Prepositions),\n",
                "                   Max = max(Prepositions)) %>%\n",
                "  ggplot(aes(x = DateRedux, y = Mean)) +  \n",
                "  geom_ribbon(aes(ymin = Min, ymax = Max), fill = \"gray80\") +\n",
                "  geom_line() +\n",
                "  scale_x_continuous(labels = names(table(pdat$DateRedux)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Line graphs for Likert data\n",
                "\n",
                "A special case of line graphs is used when dealing with Likert-scaled variables. In such cases, the line graph displays the density of cumulative frequencies of responses. The difference between the cumulative frequencies of responses displays differences in preferences. We will only focus on how to create such graphs using the \"ggplot\" environment here as it has an inbuilt function (\"ecdf\") which is designed to handle such data.\n",
                "\n",
                "In a first step, we create a data set which consists of a Likert-scaled variable. The fictitious data created here consists of rating of students from three courses about how satisfied they were with their language-learning course. The response to the Likert item is numeric so that \"strongly disagree/very dissatisfied\" would get the lowest and \"strongly agree/very satisfied\" the highest numeric value. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ldat <- base::readRDS(url(\"https://slcladal.github.io/data/lid.rda\", \"rb\"))\n",
                "# inspect data\n",
                "head(ldat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have data resembling a Likert-scaled item from a questionnaire, we will display the data in a cumulative line graph.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create cumulative density plot\n",
                "ggplot(ldat,aes(x = Satisfaction, color = Course)) + \n",
                "  geom_step(aes(y = ..y..), stat = \"ecdf\") +\n",
                "  labs(y = \"Cumulative Density\") + \n",
                "  scale_x_discrete(limits = 1:5, breaks = 1:5,\n",
                "        labels=c(\"very dissatisfied\", \"dissatisfied\", \"neutral\", \"satisfied\", \"very satisfied\")) + \n",
                "  scale_colour_manual(values = clrs3)  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The satisfaction of the German course was the lowest as the red line shows the highest density (frequency of responses) of \"very dissatisfied\" and \"dissatisfied\" ratings. The students in our fictitious data set were most satisfied with the Chinese course as the blue line is the lowest for \"very dissatisfied\" and \"dissatisfied\" ratings while the difference between the courses shrinks for \"satisfied\" and \"very satisfied\". The Japanese language course is in-between the German and the Chinese course.  \n",
                "\n",
                "\n",
                "# Pie charts\n",
                "\n",
                "Most commonly, the data for visualization comes from tables of absolute frequencies associated with a categorical or nominal variable. The default way to visualize such frequency tables are pie charts and bar plots. \n",
                "\n",
                "In a first step, we modify the original data to get counts and percentages. The data represents the number of documents per time period and the percentage of those documents across all time periods.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create bar plot data\n",
                "bdat <- pdat %>%\n",
                "  dplyr::mutate(DateRedux = factor(DateRedux)) %>%\n",
                "  group_by(DateRedux) %>%\n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1))\n",
                "# inspect data\n",
                "head(bdat) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In ggplot, we create pie charts by using the `geom_bar` and then define `coord_polar(\"y\", start=0). In contrast to base R, the labeling is not as easy as in base R. To place the labels where they make sense, we will add another variable to the data called \"Position\".\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "piedata <- bdat %>%\n",
                "  dplyr::arrange(desc(DateRedux)) %>%\n",
                "  dplyr::mutate(Position = cumsum(Percent)- 0.5*Percent)\n",
                "# inspect data\n",
                "head(piedata) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have specified the position, we can include it into the pie chart.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create pie chart\n",
                "ggplot(piedata,  aes(\"\", Percent, fill = DateRedux)) + \n",
                "  geom_bar(stat=\"identity\", width=1, color = \"white\") +\n",
                "  coord_polar(\"y\", start=0) +\n",
                "  scale_fill_manual(values = clrs5) +\n",
                "  theme_void() +\n",
                "  geom_text(aes(y = Position, label = Percent), color = \"white\", size=6)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Histograms\n",
                "\n",
                "Histograms summarize numeric variables by showing their distribution across bins. \n",
                "\n",
                "Using `ggplot`, we specify the variable we want to summarize in the aesthetics and use the `geom_histogram` function to generate a histogram.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(pdat, aes(Prepositions)) +\n",
                "  geom_histogram()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can simply add information about a second variable by specifying this variable as the basis for the coloring of the bars (which we do by specify the `fill` argument). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(pdat, aes(Prepositions, fill = Region)) +\n",
                "  geom_histogram()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Bar plots\n",
                "\n",
                "Like pie charts, bar plot display frequency information across categorical variable levels. \n",
                "\n",
                "The creation of barplots in ggplot works just like other types of visualizations in this framework. We first define the data and the aesthetics and then use the `geom_bar` to create a barplot.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# bar plot\n",
                "ggplot(bdat, aes(DateRedux, Percent, fill = DateRedux)) +\n",
                "  geom_bar(stat=\"identity\") +          # determine type of plot\n",
                "  theme_bw() +                         # use black & white theme\n",
                "  # add and define text\n",
                "  geom_text(aes(y = Percent-5, label = Percent), color = \"white\", size=3) + \n",
                "  # add colors\n",
                "  scale_fill_manual(values = clrs5) +\n",
                "  # suppress legend\n",
                "  theme(legend.position=\"none\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compared with the pie chart, it is much easier to grasp the relative size and order of the percentage values which shows that pie charts are unfit to show relationships between elements in a graph and, as a general rule of thumb, should be avoided.\n",
                "\n",
                "Bar plot can be grouped to add another layer of information which is particularly useful when dealing with frequency counts across multiple categorical variables. To create grouped bar plots, we plot `Region` while including `DateRedux` as the `fill` argument. Also, we use the command `position=position_dodge()`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# bar plot\n",
                "ggplot(pdat, aes(Region, fill = DateRedux)) + \n",
                "  geom_bar(position = position_dodge(), stat = \"count\") +  \n",
                "  theme_bw() +\n",
                "  scale_fill_manual(values = clrs5)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we leave out the `position=position_dodge()` argument, we get a stacked bar plot as shown below.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# bar plot\n",
                "ggplot(pdat, aes(DateRedux, fill = GenreRedux)) + \n",
                "  geom_bar(stat=\"count\") +  \n",
                "  theme_bw() +\n",
                "  scale_fill_manual(values = clrs5)    \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One issue to consider when using stacked bar plots is the number of variable levels: when dealing with many variable levels, stacked bar plots tend to become rather confusing. This can be solved by either collapsing infrequent variable levels or choose a colour palette that reflects some other inherent piece of information such as *formality* (e.g. blue) versus *informality* (e.g. red).\n",
                "\n",
                "Stacked bar plots can also be normalized so that changes in percentages become visible. This is done by exchanging `position=position_dodge()` with `position=\"fill\"`. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# bar plot\n",
                "ggplot(pdat, aes(DateRedux, fill = GenreRedux)) + \n",
                "  geom_bar(stat=\"count\", position=\"fill\") +  \n",
                "  theme_bw() +\n",
                "  scale_fill_manual(values = clrs5) +\n",
                "  labs(y = \"Probability\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bar plots for Likert data\n",
                "\n",
                "Another and very interesting way to display such data is by using the Likert package. In a first step, we need to activate the package, clean the data, and extract a subset for the data visualization example.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdat <- base::readRDS(url(\"https://slcladal.github.io/data/sdd.rda\", \"rb\"))\n",
                "# inspect data\n",
                "head(sdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see, we need to clean and adapt the column names. To do this, we will \n",
                "\n",
                "* add an identifier which shows which question we are dealing with (e.g. Q 1: question text)\n",
                "* remove the dots between words with spaces\n",
                "* add a question mark at the end of questions\n",
                "* remove superfluous white spaces\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# clean column names\n",
                "colnames(sdat)[3:ncol(sdat)] <- paste0(\"Q \", str_pad(1:10, 2, \"left\", \"0\"), \": \", colnames(sdat)[3:ncol(sdat)]) %>%\n",
                "  stringr::str_replace_all(\"\\\\.\", \" \") %>%\n",
                "  stringr::str_squish() %>%\n",
                "  stringr::str_replace_all(\"$\", \"?\")\n",
                "# inspect column names\n",
                "colnames(sdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, that we have nice column names, we will replace the numeric values (1 to 5) with labels ranging from *disagree* to *agree* and convert our data into a data frame.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lbs <- c(\"disagree\", \"somewhat disagree\", \"neither agree nor disagree\",  \"somewhat agree\", \"agree\")\n",
                "survey <- sdat %>%\n",
                "  dplyr::mutate_if(is.character, factor) %>%\n",
                "  dplyr::mutate_if(is.numeric, factor, levels = 1:5, labels = lbs) %>%\n",
                "  as.data.frame() %>%\n",
                "  .[complete.cases(.),]\n",
                "# inspect data\n",
                "head(survey)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can use the `plot` and the `likert` function to visualize the survey data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate plot\n",
                "plot(likert(survey[,3:12]), ordered = F, wrap= 60)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "An additional and very helpful feature is that the `likert` package enables grouping the data as shown below. The display columns 3 to 8 and use column 1 for grouping.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create plot\n",
                "plot(likert(survey[,3:8], grouping = survey[,1]))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Ridge Plots\n",
                "\n",
                "A very nice option to display frequency information about levels of a categorical variable are ridge plots. To generate ridge plots, we can use the `ggridges` package written by [Claus Wilke](https://github.com/clauswilke).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create ridge plot\n",
                "pdat %>%\n",
                "  ggplot(aes(x = Prepositions, y = GenreRedux, fill = GenreRedux)) +\n",
                "  geom_density_ridges() +\n",
                "  theme_ridges() + \n",
                "  theme(legend.position = \"none\") + \n",
                "  labs(y = \"\", x = \"Density of the relative frequency of prepostions\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can easily replace the density displays by histograms which only requires to define the `stat` argument and the bin width.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create ridge plot\n",
                "pdat %>%\n",
                "  ggplot(aes(x = Prepositions, y = GenreRedux, fill = GenreRedux)) +\n",
                "  geom_density_ridges(alpha=0.6, stat=\"binline\", bins=20) +\n",
                "  theme_ridges() + \n",
                "  theme(legend.position = \"none\") + \n",
                "  labs(y = \"\", x = \"Histograms of the relative frequency of prepostions\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Boxplots\n",
                "\n",
                "Boxplots, or Box-and-Whisker Plots, are exploratory graphics first created by John W. Tukey and they show the relationships between categorical and numeric variables. They are very useful because they not only provide measures of central tendency (the median which is the line in the middle of the box) but they also offer information about the distribution of the data. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create boxplot\n",
                "ggplot(pdat, aes(DateRedux, Prepositions, color = GenreRedux)) +                 \n",
                "  geom_boxplot(fill=clrs5, \n",
                "               color=\"black\") \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Another interesting feature of boxplots is that they allow us to visually get an idea whether categories differ significantly. Because if add \"notch = T\" and the notches of the boxplots do not overlap, then this is a very strong indication that the categories actually differ significantly (see below). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create boxplot\n",
                "ggplot(pdat, aes(DateRedux, Prepositions, color = GenreRedux)) +                 \n",
                "  geom_boxplot(outlier.colour=\"red\", \n",
                "               outlier.shape=2, \n",
                "               outlier.size=5, \n",
                "               notch=T, \n",
                "               fill=clrs5, \n",
                "               color=\"black\") \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Violin plots\n",
                "\n",
                "An alternative to boxplots which display the distribution within the data even more accurately are violin plots. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(pdat, aes(DateRedux, Prepositions, fill = DateRedux)) +  \n",
                "  geom_violin(trim = FALSE, alpha = .5) +  \n",
                "  scale_fill_manual(values = clrs5) +\n",
                "  theme_bw() +\n",
                "  theme(legend.position = \"none\")         \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Word clouds\n",
                "\n",
                "Word clouds visualize word frequencies of either single corpus or different corpora. Although word clouds are rarely used in academic publications, they are a common way to display language data and the topics of texts - which may be thought of as their semantic content. To exemplify how to use word clouds, we are going to have a look at rally speeches of Hillary Clinton and Donald Trump that were given during their 2016 campaigns. In a first step, we load and process the data as the relevant packages are already loaded.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load and process speeches by clinton\n",
                "clinton <- base::readRDS(url(\"https://slcladal.github.io/data/Clinton.rda\", \"rb\")) %>% paste0(collapse = \" \")\n",
                "# load and process speeches by trump\n",
                "trump <- base::readRDS(url(\"https://slcladal.github.io/data/Trump.rda\", \"rb\")) %>%  paste0(collapse = \" \")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After loading the data, we need to clean it.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# clean texts\n",
                "docs <- Corpus(VectorSource(c(clinton, trump))) %>%\n",
                "  # clean text data\n",
                "  tm::tm_map(removePunctuation) %>%\n",
                "  tm::tm_map(removeNumbers) %>%\n",
                "  tm::tm_map(tolower)  %>%\n",
                "  tm::tm_map(removeWords, stopwords(\"english\")) %>%\n",
                "  tm::tm_map(stripWhitespace) %>%\n",
                "  tm::tm_map(PlainTextDocument)\n",
                "# create term document matrix\n",
                "tdm <- TermDocumentMatrix(docs) %>%\n",
                "  as.matrix()\n",
                "colnames(tdm) <- c(\"Clinton\",\"Trump\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we normalize the absolute frequencies of the terms in the document by converting them into relative frequencies.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# calculate rel. freq.\n",
                "tdm[, 1] <- as.vector(unlist(sapply(tdm[, 1], function(x) round(x/colSums(tdm)[1]*1000, 0) )))\n",
                "# calculate rel. freq.\n",
                "tdm[, 2] <- as.vector(unlist(sapply(tdm[, 2], function(x) round(x/colSums(tdm)[2]*1000, 0) )))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After processing the data, we can now create word clouds. However, there are different word clouds: \n",
                "\n",
                "* (Common) word clouds\n",
                "* Comparative clouds\n",
                "* Commonality clouds\n",
                "\n",
                "Common or simple word clouds simply show the frequency of word types while comparative word clouds show which word types are particularly overrepresented in one sub-corpus compared to another sub-corpus. Commonality word clouds show words that are shared and are thus particularly indistinctive for different sub-corpora.\n",
                "\n",
                "Let us first inspect a common word cloud of the corpus.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create word cloud\n",
                "wordcloud(docs, max.words = 100, \n",
                "          colors = brewer.pal(6, \"BrBG\"), \n",
                "          random.order = FALSE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The common word cloud shows the frequencies of words regardless of who used them. In contrast, the comparative cloud shown below highlights words that differ most with respect to their frequencies in the sub-corpora under investigation.  \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create comparison cloud\n",
                "comparison.cloud(tdm, \n",
                "                 max.words = 100, \n",
                "                 random.order = FALSE, \n",
                "                 colors = c(\"blue\", \"red\"), \n",
                "                 title.bg.colors=\"white\",\n",
                "                 bg.color = \"black\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The opposite of comparative clouds are commonality clouds which highlight words that use with similar relative frequencies in the sub-corpora under investigation and that are therefore particularly indistinctive.  \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create commonality cloud\n",
                "commonality.cloud(tdm, \n",
                "                  max.words = 100, \n",
                "                  random.order = FALSE, \n",
                "          colors = brewer.pal(6, \"Spectral\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "At first, I thought that word clouds are simply a fancy but not very helpful way to inspect language data but I have to admit that word clouds really surprised me as they do appear to possess potential to provide an idea of what groups of people are talking about. The comparative word cloud shows that the Trump uses a lot of contractions (\"'re\", \"'ll\", etc.) and stresses concepts linked to the future (*going*) thereby stressing his vision of the US (*great*). In Contrast, Clinton did not use contractions but talked about *Americans*, *work*, the *economy*, and *women*.\n",
                "\n",
                "\n",
                "# Association plots\n",
                "\n",
                "Another plot type that is related to bar plots is the association plot. Association plots are similar to bar plots in that they display difference as bars above or below a line (as shown above). However, association plots show the difference between the observed and expected frequencies rather than differences as deviations from a reference. Therefore, they are often used when graphically representing tables with absolute frequencies. We use the already loaded *vcd* package to create association plots. \n",
                "\n",
                "We also modify the reduced pdat as association plots work on matrices rather than data frames or tibbles. In addition, we will drop more genres as to avoid overlap in the y-axis labels later on.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# reduce data\n",
                "assocdata <- pdat %>%\n",
                "  droplevels() %>%\n",
                "  dplyr::mutate(GenreRedux <- as.character(GenreRedux),\n",
                "                GenreRedux = dplyr::case_when(GenreRedux == \"Conversational\" ~ \"Conv.\",\n",
                "                                              GenreRedux == \"Religious\" ~ \"Relig.\",\n",
                "                                              TRUE ~ GenreRedux)) %>%\n",
                "  dplyr::group_by(GenreRedux, DateRedux) %>%\n",
                "  dplyr::summarise(Prepositions = round(mean(Prepositions), 0)) %>%\n",
                "  tidyr::spread(DateRedux, Prepositions)\n",
                "# create matrix \n",
                "assocmx <- as.matrix(assocdata[,2:6])\n",
                "attr(assocmx, \"dimnames\")[1] <- as.vector(assocdata[,1])\n",
                "# inspect data\n",
                "head(assocmx)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Association plots are created by using the `assoc` function which takes a table (or a similar format such as a matrix or a data frame) as their argument. In addition, we specify `shade` as `T` in order to color code the bars in the association plot and to add a legend.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create association plot\n",
                "assoc(assocmx, shade=TRUE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The bars above the line indicate that the observed frequency is higher than expected, bars under the line indicate frequencies that are lower than expected. Darker shades of blue and red coloring suggest that there are significant differences between the observed and the expected frequencies. In the present example, this means that the frequencies of prepositions differ significantly across genres and periods. *However(!) as shown in the table above, this result is an artifact because the first period does not contain any data points for conversational or legal texts!*\n",
                "\n",
                "\n",
                "\n",
                "# Mosaic plots\n",
                "\n",
                "Another plot which is useful to graphically depict the relationship of categorical variables is the mosaic plot. The size of the boxes in a mosaic plot indicate how frequent that subcategory is and the colors show whether or not the category differs from the value that is expected if given the overall distribution in the table. In addition, the hue of the color shows how great the difference between observed and expected is and thus indicates whether the respective subcategory deviates significantly from the expected frequency. Boxes that are gray suggest the absence of significant differences. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a mosaic plot\n",
                "mosaic(assocmx, shade=T, legend=TRUE)  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " \n",
                "According to the mosaic plot above, there are some potentially significant differences in the first and second period. This, however, is still likely to be caused by the absence of data points from conversational or legal texts in the first period. Also, the absence of boxes for these text types in the first period indicate that there is a potential problem - something that was not visible in the mosaic plot!\n",
                "\n",
                "# Heat maps\n",
                "\n",
                "Heat maps are similar to mosaic plots in that they display frequency information and use color-coding to indicate high and low values. Heat maps also work on matrices but they are much more powerful and versatile that mosaic plots. \n",
                "\n",
                "Heat maps are a very popular way to display frequency information and various packages have been written to create or customize heatmaps (for example the packages \"ComplexHeatmap\", \"dendextend\", \"d3heatmap\", \"pheatmap\") which means that many aspects of heatmaps can be modified. In this example, we will only use the most basic function to create a heat map.\n",
                "\n",
                "We again modify the data and create a matrix from the original pdat. In addition, we scale the frequencies. This is not necessary in the present case but when dealing with variables which differ in their mean and variance because they reflect different variables, scaling will normalize such variables and render their values comparable. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create data\n",
                "heatdata <- pdat %>%\n",
                "  dplyr::group_by(DateRedux, GenreRedux) %>%\n",
                "  dplyr::summarise(Prepositions = mean(Prepositions)) %>%\n",
                "  tidyr::spread(DateRedux, Prepositions)\n",
                "# create matrix \n",
                "heatmx <- as.matrix(heatdata[,2:5])\n",
                "attr(heatmx, \"dimnames\")[1] <- as.vector(heatdata[,1])\n",
                "heatmx <- scale(heatmx) %>%\n",
                "  round(., 2)\n",
                "# inspect data\n",
                "head(heatmx) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have created a data matrix, we can create a simple heat map.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create heat map\n",
                "heatmap(heatmx, scale = \"none\", cexCol = 1, cexRow = 1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The dendrogram on the top shows that documents from 1600 and 1700 as well as documents from 1800 and 1900 are grouped together and thus are more similar with respect to their preposition frequencies. The dendrogram on the left indicates that we have two categories of documents: the genres to towards the bottom tend to have fewer prepositions (indicated by the light colours) while the documents to the top tend to have more prepositions (thus the darker hues). Legal texts (genre = Law) have notably higher rates of prepositions as is derivable from the dark red colour of such texts.  \n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/dviz.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
