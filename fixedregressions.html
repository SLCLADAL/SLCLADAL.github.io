<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-11-22" />

<title>Fixed-Effects Regression Models</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Visualizing Data with R</a>
    </li>
    <li>
      <a href="maps.html">Geo-Spatial Data Visualization in R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="textanalysis.html">Introduction</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Fixed-Effects Regression Models</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-11-22</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces fixed-effects regression modeling using “R”. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/fixedregressionsrscript.r">here</a>.</p>
<p>Regression models are among the most widely used methods in data analysis because they are:</p>
<ul>
<li>multivariate and can thus incorporate many predictors in a single model (which allows to test the impact of one predictor while all other predictors in the model remain controlled)</li>
<li>extremely flexible and and can be fitted to different types of predictors and dependend variables</li>
<li>provide output that can be easily interpreted</li>
<li>conceptually relative simple and not overly complex from a mathematical perspective</li>
</ul>
<p>Fixed-effects regression models are simple additive models which means that the predicted values represent the intercept value plus the effects of the individual predictors while mixed-effects models are based on more complex matrix multiplications where predicted values represent the product of the random effect multiplied by the intercept values plus the effects of the fixed effects. “R” offers a various ready-made functions with which implemneting different types of regression models is very easy.</p>
<p>In the following, we will go over the most relevant and frequently used types of regression models: * multiple linear regression * multiple binomial logistic regression * ordinal regression * Poissant regression * robust regression</p>
<p>The major difference between these types of models is that they take different types of dependent variables: linear regressions take numeric , logistic regressions take nominal variables, ordinal regressions take ordinal variables, and Poissant regressions take dependent variables that reflect counts of (rare) events. Robust regression, in contrast, is a simple multiple linear regression that is able to handle outliers due to a weighing procedure.</p>
</div>
<div id="preparation-and-session-set-up" class="section level1">
<h1><span class="header-section-number">2</span> Preparation and session set up</h1>
<p>As all caluculations and visualizations in this tutorial rely on “R”, it is necessary to install “R”, “RStudio”, and “Tinn-R”. If these programms (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the librariesby running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;boot&quot;, &quot;car&quot;, &quot;caret&quot;, &quot;effects&quot;, &quot;foreign&quot;, &quot;ggplot2&quot;, 
                   &quot;Hmisc&quot;, &quot;knitr&quot;, &quot;MASS&quot;, &quot;mlogit&quot;, &quot;msm&quot;, &quot;QuantPsyc&quot;, 
                   &quot;reshape2&quot;, &quot;rms&quot;, &quot;sandwich&quot;, &quot;sfsmisc&quot;, &quot;sjPlot&quot;, &quot;vcd&quot;, &quot;visreg&quot;))</code></pre>
<p>Once you have installed “R”, “R-Studio”, “Tinn-R”, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">3</span> Multiple Linear Regression</h1>
<p>In contrast to simple linear regression, which estimates the effect of a single predictor, multiple linear regression estimates the effect of various predictor (cf. equation ()). A multiple linear regression can thus test the effects of various predictors simultaneously.</p>
<span class="math display">\[\begin{equation}

f_{(x)} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i+1} + \dots + \beta_{n}x_{i+n} + \epsilon

\end{equation}\]</span>
<p>There exists a wealth of literature focusing on multiple linear regressions and the concepts it is based on. For instance, there are <span class="citation">(Achen <a href="#ref-achen1982interpreting">1982</a>)</span>, <span class="citation">(Bortz <a href="#ref-bortz2006statistik">2006</a>)</span>, <span class="citation">(Crawley <a href="#ref-crawley2005statistics">2005</a>)</span>, <span class="citation">(Faraway <a href="#ref-faraway2002practical">2002</a>)</span>, <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span> (my personal favourite), and <span class="citation">(Wilcox <a href="#ref-wilcox2009basic">2009</a>)</span> to name just a few. Introductions to regression modelling in “R” are <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>)</span>, <span class="citation">(Crawley <a href="#ref-crawley2012r">2012</a>)</span>, or <span class="citation">(Gries <a href="#ref-gries2009statistics">2009</a>)</span>.</p>
<p>The model diagnostics we are dealing with here are partly identical to the diagnostic methods discussed in the section on simple linear regression. Because of this overlap, diagnostics will only be described in more detail if they have not been described in the section on simple linear regression.</p>
<p>A brief note on minimum necessary sample or data set size appears necessary here. Although there appears to be a general assumption that 25 data points per group are sufficient, this is not necessarily correct (it is merely a general rule of thumb that is actually often incorrect). Such rules of thumb are inadequate because the required sample size depends on the number of variables in a given model, the size of the effect and the variance of the effect. If a model contains many variables, then this requires a larger sample size than a model which only uses very few predictors. Also, to detect an effect with a very minor effect size, one needs a substantially larger sample compared to cases where the effect is very strong. In fact, when dealing with small effects, model require a minimum of 600 cases to reliably detect these effects. Finally, effects that very robust and do not vary much require a much smaller sample size compared with effects that are spurious and vary substantially. Since the sample size depends on the effect size and variance as well as the number of variables, there is no final one-size-fits-all answer to what the best sample size is.</p>
<p>Another, slightly better but still incorrect, rule of thumb is that the more data, the better. This is not correct because models based on too many cases are prone for overfitting and thus report correlations as being significant that are not. However, given that there are procedures that can correct for overfitting, larger data sets are still preferable to data sets that are simply too small to warrant reliable results. In conclusion, it remains true that the sample size depends on the effect under investigation.</p>
<p>Despite there being no ultimate rule of thumb, <span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span> 273-275), based on <span class="citation">Green (<a href="#ref-green1991many">1991</a>)</span>, provide data-driven suggestions for the minimal size of data required for regression models that aim to find medium sized effects (k = number of predictors; categorical variables with more than two levels should be transformed into dummy variables):</p>
<ul>
<li>If one is merely interested in the overall model fit (something I have not encountered), then the sample size should be at least 50 + k (k = number of predictors in model).</li>
<li>If one is only interested in the effect of specific variables, then the sample size should be at least 104 + k (k = number of predictors in model).</li>
<li>If one is only interested in both model fit and the effect of specific variables, then the sample size should be at least the higher value of 50 + k or 104 + k (k = number of predictors in model).</li>
</ul>
<p>You will see in the “R”-code below that there is already a function that tests whether the sample size is sufficient.</p>
<div id="example-gifts-and-availability" class="section level2">
<h2><span class="header-section-number">3.1</span> Example: Gifts and Availability</h2>
<p>The example we will go through here is taken from <span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span>. In this example, the research question is if the money that men spend on presents for women depends on the women’s attractiveness and their relationship status. To answer this research question, we will implement a multiple linear regression and start by preparing the “R”-session (cleaning the workspace, setting options necessary, installing and activating necessary packages, and loading functions).</p>
<pre class="r"><code># load libraries
library(boot)
library(car)
library(caret)
library(effects)
library(foreign)
library(ggplot2)
library(Hmisc)
library(knitr)
library(MASS)
library(mlogit)
library(msm)
library(plyr)
library(QuantPsyc)
library(reshape2)
library(rms)
library(sandwich)
library(sfsmisc)
library(sjPlot)
library(vcd)
library(visreg)
# load functions
source(&quot;rscripts/blr.summary.R&quot;)
source(&quot;rscripts/multiplot_ggplot2.r&quot;)
source(&quot;rscripts/mlinr.summary.r&quot;)
source(&quot;rscripts/SampleSizeMLR.r&quot;)
source(&quot;rscripts/ExpR.r&quot;)</code></pre>
<p>After preparing the session, we can now load the data and inspect its structure and properties.</p>
<pre class="r"><code># load data
mlrdata &lt;- read.delim(&quot;https://slcladal.github.io/data/mlrdata.txt&quot;, header = TRUE)
head(mlrdata)    # inspect first 6 lines</code></pre>
<pre><code>##         status    attraction money
## 1 Relationship NotInterested 86.33
## 2 Relationship NotInterested 45.58
## 3 Relationship NotInterested 68.43
## 4 Relationship NotInterested 52.93
## 5 Relationship NotInterested 61.86
## 6 Relationship NotInterested 48.47</code></pre>
<pre class="r"><code>str(mlrdata)     # inspect structure</code></pre>
<pre><code>## &#39;data.frame&#39;:    100 obs. of  3 variables:
##  $ status    : Factor w/ 2 levels &quot;Relationship&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ attraction: Factor w/ 2 levels &quot;Interested&quot;,&quot;NotInterested&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ money     : num  86.3 45.6 68.4 52.9 61.9 ...</code></pre>
<pre class="r"><code>summary(mlrdata) # summarize data</code></pre>
<pre><code>##           status           attraction     money       
##  Relationship:50   Interested   :50   Min.   :  0.93  
##  Single      :50   NotInterested:50   1st Qu.: 49.84  
##                                       Median : 81.73  
##                                       Mean   : 88.38  
##                                       3rd Qu.:121.57  
##                                       Max.   :200.99</code></pre>
<p>The data set consist of three variables stored in three columns. The first column contains the relationship status of the women, the second whether the man is interested in the woman, and the third column represents the money spend on the present. The data set represents 100 cases and the mean amount of money spend on a present is 88.38 dollars. In a next step, we visualize the data to get a more detailed impression of the relationships between variables.</p>
<pre class="r"><code># create plots
p1 &lt;- ggplot(mlrdata, aes(status, money)) +   # data + x/y-axes
  geom_boxplot(fill=c(&quot;grey30&quot;, &quot;grey70&quot;)) + # def. col.
  theme_set(theme_bw(base_size = 8))+   # black and white theme
  labs(x = &quot;&quot;) +                        # x-axis label
  labs(y = &quot;Money spent on present (AUD)&quot;, cex = .75) +   # y-axis label
  coord_cartesian(ylim = c(0, 250)) +   # y-axis range
  guides(fill = FALSE) +                # no legend
  ggtitle(&quot;Status&quot;)                     # title
# plot 2
p2 &lt;- ggplot(mlrdata, aes(attraction, money)) +
  geom_boxplot(fill=c(&quot;grey30&quot;, &quot;grey70&quot;)) +
  theme_set(theme_bw(base_size = 8))+
  labs(x = &quot;&quot;) +                              # x-axis label
  labs(y = &quot;Money spent on present (AUD)&quot;) +  # y-axis label
  coord_cartesian(ylim = c(0, 250)) +
  guides(fill = FALSE) +
  ggtitle(&quot;Attraction&quot;)
# plot 3
p3 &lt;- ggplot(mlrdata, aes(x = money)) +
  geom_histogram(aes(y=..density..),    # add density statistic
                 binwidth = 10,         # def. bin width
                 colour = &quot;black&quot;,      # def. bar edge colour
                 fill = &quot;white&quot;) +      # def. bar col.
    theme_bw() +                        # black-white theme
  geom_density(alpha=.2, fill = &quot;gray50&quot;) + # def. col. of overlay
    labs(x = &quot;Money spent on present (AUD)&quot;) +
  labs(y = &quot;Density of frequency&quot;)
# plot 4
p4 &lt;- ggplot(mlrdata, aes(status, money)) +
  geom_boxplot(notch = F, aes(fill = factor(status))) + # create boxplot
  scale_fill_manual(values = c(&quot;grey30&quot;, &quot;grey70&quot;)) +   # def. col. palette
  facet_wrap(~ attraction, nrow = 1) +  # separate panels for attraction
  theme_set(theme_bw(base_size = 8)) +
  labs(x = &quot;&quot;) +
  labs(y = &quot;Money spent on present (AUD)&quot;) +
  coord_cartesian(ylim = c(0, 250)) +
  guides(fill = FALSE)
# show plots
multiplot(p1, p3, p2, p4, cols = 2)</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr3-1.png" width="672" /></p>
<p>The upper left figure consists of a boxplot which shows how much money was spent based on the relationship status of the moan. The figure suggests that men spend more on women who are not in a relationship. The next figure shows the relationship between the money spend on presents and whether or not the men were interested in the women.</p>
<p>The boxplot in the upper right panel suggests that men spend substantially more on women if the men are interested in them. The next figure depicts the distribution of the amounts of money spend on women. In addition, the figure indicates the existence of two outliers (dots in the boxplot)</p>
<p>The histogram in the lower left panel shows that, although the mean amount of money spent on presents is 88.38 dollars, the distribution peaks around 50 dollars indicating that on average, men spend about 50 dollars on presents. Finally, we will plot the amount of money spend on presents against relationship status by attraction in order to check whether the money spent on presents is affected by an interaction between attraction and relationship status.</p>
<p>The boxplot in the lower right panel confirms the existence of an interaction (a non-additive term) as men only spend more money on single women if the men are interested in the women. If men are not interested in the women, then the relationship has no effect as they spend an equal amount of money on the women regardless of whether they are in a relationship or not.</p>
<p>We will now start to implement the regression model. In a first step, we create two saturated base-line models that contain all possible predictors (main effects and interactions). The two models are identical but one is generated with the “lm” and the other with the “glm” function as these functions offer different model parameters in their output.</p>
<pre class="r"><code>m1.mlr = lm(                      # generate lm regression object
  money ~ 1 + attraction*status,  # def. rgression formula (1 = intercept)
  data = mlrdata)                 # def. data
m1.glm = glm(                     # generate glm regression object
  money ~ 1 + attraction*status,  # def. rgression formula (1 = intercept)
  family = gaussian,              # def. linkage function
  data = mlrdata)                 # def. data</code></pre>
<p>After generating the saturated base-line models we can now start with the model fitting. Model fitting refers to a process that aims at find the model that explains a maximum of variance with a minimum of predictors <span class="citation">(cf. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 318)</span>. Model fitting is therefore based on the <em>principle of parsimony</em> which is related to Occam’s razor according to which explanations that require fewer assumptions are more likely to be true.</p>
</div>
<div id="automatic-model-fitting-and-why-you-should-not-use-it" class="section level2">
<h2><span class="header-section-number">3.2</span> Automatic Model Fitting and Why You Should Not Use It</h2>
<p>In this section, we will use a step-wise step-down procedure that uses decreases in AIC (Akaike information criterion) as the criterion to minimize the model in a step-wise manner. This procedure aims at finding the model with the lowest AIC values by evaluating - step-by-step - whether the removal of a predictor (term) leads to a lower AIC value.</p>
<p>We use this method here just so that you know it exists and how to implement it but you should rather avoid using automated model fitting. The reason for avoiding automated model fitting is that the algorithsm only checks if the AIC has decreased but not if the model is stable or reliable. Thus, automated model fitting has the problem that you can never be sure that the way that lead you to the final model is reliable and that all models were indeed stable. Imagine you want to climb down from a roof top and you have a ladder. The problem is that you do not know if and how many steps are broken. This is similar to using automated model fitting. In other sections, we will explore better methods to fit models (manual step-wise step-up and step-down procedures, for example).</p>
<p>The AIC is calculated using the equation below. The lower the AIC value, the better the balance between explained variance and the number of predictors. AIC values can and should only be compared for models that are fit on the same dataset with the same (number of) cases (<span class="math inline">\(LL\)</span> stands for LogLikelihood and <span class="math inline">\(k\)</span> represents the number of predictors in the model).</p>
<span class="math display">\[\begin{equation}

-2LL + 2k
\label{eq:aic}

\end{equation}\]</span>
<p>Interactions are evaluated first and only if all interactions have been removed would the procedure start removing main effects. Other model fitting procedures (forced entry, step-wise step up, hierarchical) are discussed during the implementation of other regression models. We cannot discuss all procedures here as model fitting is rather complex and a discussion of even the most common procedures would to lengthy and time consuming at this point. It is important to note though that there is not perfect model fitting procedure and automated approaches should be handled with care as they are likely to ignore violations of model parameters that can be detected during manual - but time consuming - model fitting procedures. As a general rule of thumb, it is advisable to fit models as carefully and deliberately as possible. We will now begin to fit the model.</p>
<pre class="r"><code># automated AIC based model fitting
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=592.52
## money ~ 1 + attraction * status
## 
##                     Df Sum of Sq   RSS    AIC
## &lt;none&gt;                           34558 592.52
## - attraction:status  1     24947 59505 644.86</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ 1 + attraction * status, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                99.15  
##              attractionNotInterested  
##                               -47.66  
##                         statusSingle  
##                                57.69  
## attractionNotInterested:statusSingle  
##                               -63.18</code></pre>
<p>The automated model fitting procedure informs us that removing predictors ahs not caused a decrease in the AIC. The saturated model is thus also the final minimal adequate model. We will now inspect the final minimal model and go over the model report.</p>
<pre class="r"><code>m2.mlr = lm(                       # generate lm regression object
  money ~ (status + attraction)^2, # def. regression formula
  data = mlrdata)                  # def. data
m2.glm = glm(                      # generate glm regression object
  money ~ (status + attraction)^2, # def. regression formula
  family = gaussian,               # def. linkage function
  data = mlrdata)                  # def. data
# inspect final minimal model
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.08 -14.26   0.46  11.93  44.14 
## 
## Coefficients:
##                                      Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)                            99.155      3.795  26.131  &lt; 2e-16
## statusSingle                           57.693      5.366  10.751  &lt; 2e-16
## attractionNotInterested               -47.663      5.366  -8.882 3.75e-14
## statusSingle:attractionNotInterested  -63.179      7.589  -8.325 5.81e-13
##                                         
## (Intercept)                          ***
## statusSingle                         ***
## attractionNotInterested              ***
## statusSingle:attractionNotInterested ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18.97 on 96 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.8474 
## F-statistic: 184.3 on 3 and 96 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The first element of the report is called <em>Call</em> and it reports the regression formula of the model. Then, the report provides the residual distribution (the range, median and quartiles of the residuals) which allows drawing inferences about the distribution of differences between observed and expected values. If the residuals are distributed unevenly, then this is a strong indicator that the model is unstable and unreliable because mathematical assumptions on which the model is based are violated.</p>
<p>Next, the model summary reports the most important part: a table with model statistics of the fixed-effects structure of the model. The table contains the estimates (coefficients of the predictors), standard errors, t-values, and the p-values which show whether a predictor significantly correlates with the dependent variable that the model investigates.</p>
<p>All main effects (status and attraction) as well as the interaction between status and attraction is reported as being significantly correlated with the dependent variable (money). An interaction occurs if a correlation between the dependent variable and a predictor is affect by another predictor.</p>
<p>The top most term is called intercept and has a value of 99.15 which represents the base estimate to which all other estimates refer. To exemplify what this means, let us consider what the model would predict a man would spend on a present for a women who is single but the man is not attracted to her: The amount he would spend (based on the model would be 99.15 dollars (the intercept) plus 57.69 dollars (because she is single) minus 47.66 dollars (because he is not interested in her) minus 63.18 dollars because of the interaction between status and attraction.</p>
<pre class="r"><code>#intercept  Single  NotInterested  Single:NotInterested
99.15     + 57.69  + 0           + 0     # 156.8 single + interested</code></pre>
<pre><code>## [1] 156.84</code></pre>
<pre class="r"><code>99.15     + 57.69  - 47.66       - 63.18 # 46.00 single + not interested</code></pre>
<pre><code>## [1] 46</code></pre>
<pre class="r"><code>99.15     - 0      + 0           - 0     # 99.15 relationship + interested</code></pre>
<pre><code>## [1] 99.15</code></pre>
<pre class="r"><code>99.15     - 0      - 47.66       - 0     # 51.49 relationship + not interested</code></pre>
<pre><code>## [1] 51.49</code></pre>
<p>Interestingly, the model predicts that a man would invest even less money in a woman that he is not interested in if she were single compared to being in a relationship! We can derive the same results easier using the “predict” function.</p>
<pre class="r"><code># make prediction based on the model for original data
prediction &lt;- predict(m2.mlr, newdata = mlrdata)
# inspect predictions
table(round(prediction,2))</code></pre>
<pre><code>## 
##  46.01  51.49  99.15 156.85 
##     25     25     25     25</code></pre>
<p>Below the table of coefficient, the summary reports model statistics that provide information about how well the model performs. The difference between the values and the values in the coefficients table is that the model statistics refer to the model as a whole rather than focusing on individual predictors.</p>
<p>The multiple R<sup>2</sup>-value is a measure of how much variance the model explains. A multiple R<sup>2</sup>-value of 0 would inform us that the model does not explain any variance while a value of .852 mean that the model explains 85.2 percent of the variance. A value of 1 would inform us that the model explains 100 percent of the variance and that the predictions of the model match the observed values perfectly. Multiplying the multiple R<sup>2</sup>-value thus provides the percentage of explained variance. Models that have a multiple R<sup>2</sup>-value equal or higher than .05 are deemed substantially significant <span class="citation">(cf Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 55)</span>. It has been claimed that models should explain a minimum of 5 percent of variance but this is problematic as itis not uncommon for models to have very low explanatory power while still performing significantly and systematically better than chance. In addition, the total amount of variance is negligible in cases where one is interested in very weak but significant effects. It is much more important for model to perform significantly better than minimal base-line models because if this is not the case, then the model does not have any predictive and therefore no explanatory power.</p>
<p>The adjusted R<sup>2</sup>-value considers the amount of explained variance in light of the number of predictors in the model (it is thus somewhat similar to the AIC and BIC) and informs about how well the model would perform if it were applied to the population that the sample is drawn from. Ideally, the difference between multiple and adjusted R<sup>2</sup>-value should be very small as this means that the model is not overfitted. If, however, the difference between multiple and adjusted R<sup>2</sup>-value is substantial, then this would strongly suggest that the model is instable and overfitted to the data while being inadequate for drawing inferences about the population. Differences between multiple and adjusted R<sup>2</sup>-values indicate that the data contains outliers that cause the distribution of the data on which the model is based to differ from the distributions that the model mathematically requires to provide reliable estimates. The difference between multiple and adjusted R<sup>2</sup>-value in our model is very small (85.2-84.7=.05) and should not cause concern.</p>
<p>Before continuing, we will calculate the confidence intervals of the coefficients.</p>
<pre class="r"><code># extract confidence intervals of the coefficients
confint(m2.mlr)</code></pre>
<pre><code>##                                          2.5 %    97.5 %
## (Intercept)                           91.62258 106.68702
## statusSingle                          47.04063  68.34497
## attractionNotInterested              -58.31497 -37.01063
## statusSingle:attractionNotInterested -78.24324 -48.11436</code></pre>
<pre class="r"><code># create and compare baseline- and minimal adequate model
m0.mlr &lt;- lm(money ~1, data = mlrdata)
anova(m0.mlr, m2.mlr)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     99 233562                                  
## 2     96  34558  3    199005 184.28 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Now, we compare the final minimal adequate model to the base-line model to test whether then final model significantly outperforms the baseline model.</p>
<pre class="r"><code># compare baseline- and minimal adequate model
Anova(m0.mlr, m2.mlr, type = &quot;III&quot;)</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value    Pr(&gt;F)    
## (Intercept) 781016  1  2169.6 &lt; 2.2e-16 ***
## Residuals    34558 96                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The comparison between the two model confirms that the minimal adequate model performs significantly better (makes significantly more accurate estimates of the outcome variable) compared with the baseline model.</p>
</div>
<div id="outlier-detection" class="section level2">
<h2><span class="header-section-number">3.3</span> Outlier Detection</h2>
<p>After implementing the multiple regression, we now need to look for outliers and perform the model diagnostics by testing whether removing data points disproportionately decreases model fit. To begin with, we generate diagnostic plots.</p>
<pre class="r"><code># start plotting
par(mfrow = c(1, 4)) # display plots in 3 rows/2 columns
plot(m2.mlr)         # plot fitted values</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr11-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1)) # restore original settings</code></pre>
<pre class="r"><code># determine a cutoff for data points that have D-values higher than 4/(n-k-1)
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
# start plotting
par(mfrow = c(1, 2))           # display plots in 3 rows/2 columns
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;) # create qq-plot</code></pre>
<pre><code>## [1] 52 83</code></pre>
<pre class="r"><code>plot(m2.mlr, which=4, cook.levels = cutoff) # plot cook*s distance</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr12-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original settings</code></pre>
<p>The graphs indicate that data points 52, 64, and 83 may be problematic. We will therefore statistically evaluate whether these data points need to be removed. In order to find out which data points require removal, we extract the influence measure statistics and add them to out data set.</p>
<pre class="r"><code># extract influence statistics
infl &lt;- influence.measures(m2.mlr)
# add infl. statistics to data
mlrdata &lt;- data.frame(mlrdata, infl[[1]], infl[[2]])
# annotate too influential data points
remove &lt;- apply(infl$is.inf, 1, function(x) {
  ifelse(x == TRUE, return(&quot;remove&quot;), return(&quot;keep&quot;)) } )
# add annotation to data
mlrdata &lt;- data.frame(mlrdata, remove)
# number of rows before removing outliers
nrow(mlrdata)</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code># remove outliers
mlrdata &lt;- mlrdata[mlrdata$remove == &quot;keep&quot;, ]
# number of rows after removing outliers
nrow(mlrdata)</code></pre>
<pre><code>## [1] 98</code></pre>
<p>The difference in row in the data set before and after removing data points indicate that two data points which represented outliers have been removed.</p>
</div>
<div id="rerun-regression" class="section level2">
<h2><span class="header-section-number">3.4</span> Rerun Regression</h2>
<p>As we have a different data set now, we need to rerun the regression analysis. As the steps are identical to the regression analysis performed above, the steps will not be described in greater detail.</p>
<pre class="r"><code># recreate regression models on new data
m0.mlr = lm(money ~ 1, data = mlrdata)
m0.glm = glm(money ~ 1, family = gaussian, data = mlrdata)
m1.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m1.glm = glm(money ~ status * attraction, family = gaussian,
             data = mlrdata)
# automated AIC based model fitting
step(m1.mlr, direction = &quot;both&quot;)</code></pre>
<pre><code>## Start:  AIC=570.29
## money ~ (status + attraction)^2
## 
##                     Df Sum of Sq   RSS    AIC
## &lt;none&gt;                           30411 570.29
## - status:attraction  1     21647 52058 620.96</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Coefficients:
##                          (Intercept)  
##                                99.15  
##                         statusSingle  
##                                55.85  
##              attractionNotInterested  
##                               -47.66  
## statusSingle:attractionNotInterested  
##                               -59.46</code></pre>
<pre class="r"><code># create new final models
m2.mlr = lm(money ~ (status + attraction)^2, data = mlrdata)
m2.glm = glm(money ~ status * attraction, family = gaussian,
             data = mlrdata)
# inspect final minimal model
summary(m2.mlr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = money ~ (status + attraction)^2, data = mlrdata)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -35.764 -13.505  -0.989  10.599  38.772 
## 
## Coefficients:
##                                      Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)                            99.155      3.597  27.563  &lt; 2e-16
## statusSingle                           55.854      5.140  10.866  &lt; 2e-16
## attractionNotInterested               -47.663      5.087  -9.369 4.04e-15
## statusSingle:attractionNotInterested  -59.461      7.269  -8.180 1.34e-12
##                                         
## (Intercept)                          ***
## statusSingle                         ***
## attractionNotInterested              ***
## statusSingle:attractionNotInterested ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 17.99 on 94 degrees of freedom
## Multiple R-squared:  0.8574, Adjusted R-squared:  0.8528 
## F-statistic: 188.4 on 3 and 94 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># extract confidence intervals of the coefficients
confint(m2.mlr)</code></pre>
<pre><code>##                                          2.5 %    97.5 %
## (Intercept)                           92.01216 106.29744
## statusSingle                          45.64764  66.05943
## attractionNotInterested              -57.76402 -37.56158
## statusSingle:attractionNotInterested -73.89468 -45.02805</code></pre>
<pre class="r"><code># compare baseline with final model
anova(m0.mlr, m2.mlr)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: money ~ 1
## Model 2: money ~ (status + attraction)^2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     97 213227                                  
## 2     94  30411  3    182816 188.36 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># compare baseline with final model
Anova(m0.mlr, m2.mlr, type = &quot;III&quot;)</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: money
##             Sum Sq Df F value    Pr(&gt;F)    
## (Intercept) 760953  1  2352.1 &lt; 2.2e-16 ***
## Residuals    30411 94                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="additional-model-diagnostics" class="section level2">
<h2><span class="header-section-number">3.5</span> Additional Model Diagnostics</h2>
<p>After rerunning the regression analysis on the updated data set, we again create diagnostic plots in order to check whether there are potentially problematic data points.</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2)) # display plots in 2 rows/2 columns
plot(m2.mlr)         # plot fitted values</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr19-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1)) # restore original settings</code></pre>
<pre class="r"><code># determine a cutoff for data points that have
# D-values higher than 4/(n-k-1)
cutoff &lt;- 4/((nrow(mlrdata)-length(m2.mlr$coefficients)-2))
# start plotting
par(mfrow = c(1, 2))           # display plots in 1 row/2 columns
qqPlot(m2.mlr, main=&quot;QQ Plot&quot;) # create qq-plot</code></pre>
<pre><code>## 84 88 
## 82 86</code></pre>
<pre class="r"><code>plot(m2.mlr, which=4, cook.levels = cutoff) # plot cook*s distance</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr20-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))           # restore original settings</code></pre>
<p>Although the diagnostic plots indicate that additional points may be problematic, but these data points deviate substantially less from the trend than was the case with the data points that have already been removed. To make sure that retaining the data points that are deemed potentially problematic by the diagnostic plots, is acceptable, we extract diagnostic statistics and add them to the data.</p>
<pre class="r"><code># add model diagnostics to the data
mlrdata$residuals &lt;- resid(m2.mlr)
mlrdata$standardized.residuals &lt;- rstandard(m2.mlr)
mlrdata$studentized.residuals &lt;- rstudent(m2.mlr)
mlrdata$cooks.distance &lt;- cooks.distance(m2.mlr)
mlrdata$dffit &lt;- dffits(m2.mlr)
mlrdata$leverage &lt;- hatvalues(m2.mlr)
mlrdata$covariance.ratios &lt;- covratio(m2.mlr)
mlrdata$fitted &lt;- m2.mlr$fitted.values</code></pre>
<p>We can now use these diagnostic statistics to create more precise diagnostic plots.</p>
<pre class="r"><code># plot 5
p5 &lt;- ggplot(mlrdata,
             aes(studentized.residuals)) +
  theme(legend.position = &quot;none&quot;) +
  theme_set(theme_bw(base_size = 8))+
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour=&quot;black&quot;,
                 fill=&quot;white&quot;) +
  labs(x = &quot;Studentized Residual&quot;, y = &quot;Density&quot;) +
  stat_function(fun = dnorm,
                args = list(mean = mean(mlrdata$studentized.residuals, na.rm = TRUE),
                            sd = sd(mlrdata$studentized.residuals, na.rm = TRUE)),
                colour = &quot;red&quot;, size = 1)
# plot 6
p6 &lt;- ggplot(mlrdata, aes(fitted, studentized.residuals)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;)+
    theme_set(theme_bw(base_size = 8))+
  labs(x = &quot;Fitted Values&quot;,
       y = &quot;Studentized Residual&quot;)
# plot 7
p7 &lt;- qplot(sample = mlrdata$studentized.residuals, stat=&quot;qq&quot;) +
    theme_set(theme_bw(base_size = 8))+
  labs(x = &quot;Theoretical Values&quot;,
       y = &quot;Observed Values&quot;)
multiplot(p5, p6, p7, cols = 3)</code></pre>
<p><img src="fixedregressions_files/figure-html/mlr22-1.png" width="672" /></p>
<p>The new diagnostic plots do not indicate outliers that require removal. With respect to such data points the following parameters should be considered:</p>
<ul>
<li><p>Data points with standardised residuals &gt; 3.29 should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>If more than 1 percent of data points have standardized residuals exceeding values &gt; 2.58, then the error rate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span>.</p></li>
<li><p>If more than 5 percent of data points have standardized residuals exceeding values &gt; 1.96, then the error rate of the model is inacceptable <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>In addition, data points with Cook’s D-values &gt; 1 should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 269)</span></p></li>
<li><p>Also, data points with leverage values <span class="math inline">\(3(k + 1)/n\)</span> (k = Number of predictors, N = Number of cases in model) should be removed <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 270)</span></p></li>
<li><p>There should not be (any) autocorrelation among predictors. This means that independent variables cannot be correlated with itself (for instance, because data points come from the same subject). If there is autocorrelation among predictors, then a Repeated Measures Design or a (hierarchical) mixed-effects model should be implemented instead.</p></li>
<li><p>Predictors cannot substantially correlate with each other (multicollinearity). If a model contains predictors that have variance inflation factors (VIF) &gt; 10 the model is completely unreliable <span class="citation">(Myers <a href="#ref-myers1990classical">1990</a>)</span> and predictors causing such VIFs should be removed. Indeed, even VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol">2010</a>)</span> proposes that variables with VIFs exceeding 3 should be removed!</p></li>
<li><p>Data points with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard <a href="#ref-menard1995applied">1995</a>)</span>.</p></li>
<li><p>The mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and O’Connell <a href="#ref-bowerman1990linear">1990</a>)</span>.</p></li>
</ul>
<pre class="r"><code># 1: optimal = 0
# (aufgelistete datenpunkte sollten entfernt werden)
which(mlrdata$standardized.residuals &gt; 3.29)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 2: optimal = 1
# (listed data points should be removed)
stdres_258 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 2.58, 1, 0) } ))
(sum(stdres_258) / length(stdres_258)) * 100</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># 3: optimal = 5
# (listed data points should be removed)
stdres_196 &lt;- as.vector(sapply(mlrdata$standardized.residuals, function(x) {
ifelse(sqrt((x^2)) &gt; 1.96, 1, 0) } ))
(sum(stdres_196) / length(stdres_196)) * 100</code></pre>
<pre><code>## [1] 6.122449</code></pre>
<pre class="r"><code># 4: optimal = 0
# (listed data points should be removed)
which(mlrdata$cooks.distance &gt; 1)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 5: optimal = 0
# (data points should be removed if cooks distance is close to 1)
which(mlrdata$leverage &gt;= (3*mean(mlrdata$leverage)))</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code># 6: checking autocorrelation:
# Durbin-Watson test (optimal: grosser p-wert)
dwt(m2.mlr)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1     -0.01433247      1.968042   0.624
##  Alternative hypothesis: rho != 0</code></pre>
<pre class="r"><code># 7: test multicolliniarity 1
vif(m2.mlr)</code></pre>
<pre><code>##                         statusSingle              attractionNotInterested 
##                                 2.00                                 1.96 
## statusSingle:attractionNotInterested 
##                                 2.96</code></pre>
<pre class="r"><code># 8: test multicolliniarity 2
1/vif(m2.mlr)</code></pre>
<pre><code>##                         statusSingle              attractionNotInterested 
##                            0.5000000                            0.5102041 
## statusSingle:attractionNotInterested 
##                            0.3378378</code></pre>
<pre class="r"><code># 9: mean vif should not exceed 1
mean(vif(m2.mlr))</code></pre>
<pre><code>## [1] 2.306667</code></pre>
<p>Except for the mean VIF value (2.307) which should not exceed 1, all diagnostics are acceptable. We will now test whether the sample size is sufficient for our model. With respect to the minimal sample size and based on <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>, <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 273–74)</span> offer the following rules of thumb (k = number of predictors; categorical predictors with more than two levels should be recoded as dummy variables):</p>
</div>
<div id="evaluation-of-sample-size" class="section level2">
<h2><span class="header-section-number">3.6</span> Evaluation of Sample Size</h2>
<p>After performing the diagnostics, we will now test whether the sample size is adequate and what the values of “R” would be based on a random distribution in order to be able to estimate how likely a <span class="math inline">\(\beta\)</span>-error is given the present sample size <span class="citation">(cf. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 274)</span>. Beta errors (or <span class="math inline">\(\beta\)</span>-errors) refer to the erroneous assumption that a predictor is not significant (based on the analysis and given the sample) although it does have an effect in the population. In other words, <span class="math inline">\(\beta\)</span>-error means to overlook a significant effect because of weaknesses of the analysis. The test statistics ranges between 0 and 1 where lower values are better. If the values approximate 1, then there is serious concern as the model is not reliable given the sample size. In such cases, unfortunately, the best option is to increase the sample size.</p>
<pre class="r"><code># check if sample size is sufficient
smplesz(m2.mlr)</code></pre>
<pre><code>## [1] &quot;Sample too small: please increase your sample by  9  data points&quot;</code></pre>
<pre class="r"><code># check beta-error likelihood
expR(m2.mlr)</code></pre>
<pre><code>## [1] &quot;Based on the sample size expect a false positive correlation of 0.0309 between the predictors and the predicted&quot;</code></pre>
<p>The function “smplesz” reports that the sample size is insufficient by 9 data points according to <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>. The likelihood of <span class="math inline">\(\beta\)</span>-errors, however, is very small (0.0309). As a last step, we summarize the results of the regression analysis.</p>
<pre class="r"><code># tabulate regression results
mlrsummary &lt;- mlr.summary(m2.mlr, m2.glm, ia = T)
# remove columns with confidence intervals
mlrsummary[,-c(4:5)]</code></pre>
<pre><code>##                                      Estimate  VIF CI(2.5%)      t value
## (Intercept)                             99.15          92.1        27.56
## statusSingle                            55.85    2    45.78        10.87
## attractionNotInterested                -47.66 1.96   -57.63        -9.37
## statusSingle:attractionNotInterested   -59.46 2.96   -73.71        -8.18
## Model statistics                                                        
## Number of cases in model                                                
## Residual Standard Error on 94 DF                                        
## Multiple R2                                                             
## Adjusted R2                                                             
## AIC                                                                     
## BIC                                                                     
## F-statistic                                                 DF: 3 and 94
##                                        Pr(&gt;|t|) Significance
## (Intercept)                                   0  p &lt; .001***
## statusSingle                                  0  p &lt; .001***
## attractionNotInterested                       0  p &lt; .001***
## statusSingle:attractionNotInterested          0  p &lt; .001***
## Model statistics                                       Value
## Number of cases in model                                  98
## Residual Standard Error on 94 DF                       17.99
## Multiple R2                                            0.857
## Adjusted R2                                            0.853
## AIC                                                    850.4
## BIC                                                   863.32
## F-statistic                          p-value: 0  p &lt; .001***</code></pre>
<p>Although <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span> suggest that the main effects of the predictors involved in the interaction should not be interpreted, they are interpreted here to illustrate how the results of a multiple linear regression can be reported. Accordingly, the results of the regression analysis performed above can be summarized as follows:</p>
<p>A multiple linear regression was fitted to the data in a step-wise step-down, AIC-based (Akaike’s Information Criterion) procedure to the data and arrived at a final minimal model. During the model diagnostics, two outliers were detected and removed. Further diagnostics did not find other issues after the removal.</p>
<p>The final minimal adequate regression model is based on 98 data points and performs highly significantly better than a minimal baseline model (Multiple R<sup>2</sup>: .857, Adjusted R<sup>2</sup>: .853, F-statistic (3, 94): 154.4, AIC: 850.4, BIC: 863.32, p&lt;.001<span class="math inline">\(***\)</span>). The final minimal adequate regression model reports <em>attraction</em> and <em>status</em> as significant main effects. The relationship status of women correlates highly significantly and positively with the amount of money spend on the women’s presents (SE: 5.14, t-value: 10.87, p&lt;.001<span class="math inline">\(***\)</span>). This shows that men spend 156.8 dollars on presents are single while they spend 99,15 dollars if the women are in a relationship. Whether men are attracted to women also correlates highly significantly and positively with the money they spend on women (SE: 5.09, t-values: -9.37, p&lt;.001<span class="math inline">\(***\)</span>). If men are not interested in women, they spend 47.66 dollar less on a present for women compared with women the men are interested in.</p>
<p>Furthermore, the final minimal adequate regression model reports a highly significant interaction between relationship <em>status</em> and <em>attraction</em> (SE: 7.27, t-value: -8.18, p&lt;.001<span class="math inline">\(***\)</span>): If women are single but man are not interested in them, men spend 59.46 dollars less on their presents compared to all other constellations.</p>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">3.7</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Download the data “exdatamlr” from “<a href="https://slcladal.github.io/data/exdatamlr.txt" class="uri">https://slcladal.github.io/data/exdatamlr.txt</a>” and apply what you have learned by implementing a multiple linear regression model so that you can answer how movement (move) and food intake (food) affect weight (given the data at hand).</li>
</ol>
</div>
</div>
<div id="multiple-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">4</span> Multiple Binomial Logistic Regression</h1>
<p>Logistic regression is a multivariate analysis technique that builds on and is very similar in terms of its implementation to linear regression but logistic regressions take dependent variables that represent nominal rather than numeric scaling <span class="citation">(Harrell Jr <a href="#ref-harrell2015regression">2015</a>)</span>. The difference requires that the linear regression must be modified in certain ways to avoid producing non-sensical outcomes. The most fundamental difference between logistic and linear regressions is that logistic regression work on the probabilities of an outcome (the likelihood), rather than the outcome itself. In addition, the likelihoods on which the logistic regression works must be logged (logarithmized) in order to avoid produce predictions that produce values greater than 1 (instance occurs) and 0 (instance does not occur).</p>
<p>To understand what this mean, we will use a very simple example. In this example, we want to see whether the height of men affect their likelihood of being in a relationship. The data we use represents a data set consisting of two variables: height and relationship.</p>
<table>
<caption>Example data set representing the height and relationship status of a sample of men.</caption>
<thead>
<tr class="header">
<th align="right">bodyheight</th>
<th align="right">relationship</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">163.4544</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">165.9073</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">169.3760</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">171.5621</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">171.6197</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">173.5545</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">174.2074</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">174.9611</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">175.1703</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">176.0026</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">177.3602</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">177.4000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">177.5261</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">178.6551</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">180.8053</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">183.8197</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">186.1655</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">187.4334</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">187.6755</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">202.7913</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p><img src="fixedregressions_files/figure-html/blm2-1.png" width="672" /></p>
<p>The left panel of the Figure above shows that a linear model would predict values for the relationship status, which represents a factor (0 = Not in Relationship and 1 = In Relationship), that are non-sensical because 1.1 does not make sense if the only options are 0 OR 1. The logistic function shown in the right panel of the Figure above solves this problem by working on the logged probabilities of an outcome rather than on the actual outcome.</p>
<div id="example-1-eh-in-kiwi-english" class="section level2">
<h2><span class="header-section-number">4.1</span> Example 1: EH in Kiwi English</h2>
<p>To exemplify hot to implement a logistic regression in “R” <span class="citation">(see Agresti <a href="#ref-agresti1996introduction">1996</a>, <span class="citation">Agresti and Kateri (<a href="#ref-agresti2011categorical">2011</a>)</span> for very good and thorough introductions to this topic)</span>, we will analyse the use of the discourse particle <em>eh</em> in New Zealand English and test which factors correlate with its occurrence. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender, ethnicity, and age of that speaker and whether or not the speech unit contained an <em>eh</em>. To begin with, we clean the current work space, set option, install and activate relevant packages, load customized functions, and load the example data set.</p>
<pre class="r"><code># load data
blrdata &lt;- read.table(&quot;data/blrdata.txt&quot;,
                      comment.char = &quot;&quot;,  # data does not contain comments
                      quote = &quot;&quot;,         # data does not contain quotes
                      sep = &quot;\t&quot;,         # data is tab separetd
                      header = T)         # variables have headers
# inspect data
str(blrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    25821 obs. of  5 variables:
##  $ ID       : Factor w/ 203 levels &quot;&lt;S1A-001#F&gt;&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ Gender   : Factor w/ 2 levels &quot;Men&quot;,&quot;Women&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Age      : Factor w/ 2 levels &quot;Old&quot;,&quot;Young&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ Ethnicity: Factor w/ 2 levels &quot;Maori&quot;,&quot;Pakeha&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ EH       : int  0 1 0 0 1 1 0 0 0 1 ...</code></pre>
<p>The summary of the data show that the data set contains 25,821 observations of five variables. The variable “ID” contains strings that represent a combination file and speaker of a speech unit. The second variable represents the gender, the third the age, and the fourth the ethnicity of speakers. The fifth variable represents whether or not a speech unit contained the discourse particle <em>EH</em>. The first six lines of the data set are shown in the Table below.</p>
<table>
<caption>First six line of the blrdata data set.</caption>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">Ethnicity</th>
<th align="right">EH</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Next, we factorize the variables in our data set. In other words, we specify that the strings represent variable levels and define new reference levels because as a default “R” will use the variable level which first occurs in alphabet ordering as the reference level for each variable, we redefine the variable levels for Age and Ethnicity.</p>
<pre class="r"><code>vrs &lt;- c(&quot;Age&quot;, &quot;Gender&quot;, &quot;Ethnicity&quot;, &quot;ID&quot;)  # define variables to be factorized
fctr &lt;- which(colnames(blrdata) %in% vrs)     # define vector with variables
blrdata[,fctr] &lt;- lapply(blrdata[,fctr], factor) # factorize variables
blrdata$Age &lt;- relevel(blrdata$Age, &quot;Young&quot;) # relevel Age (Young = Reference)
blrdata$Ethnicity &lt;- relevel(                # relevel Ethnicity
  blrdata$Ethnicity, &quot;Pakeha&quot;) # define Pakeha as Reference level)</code></pre>
<p>After preparing the data, we will now plot the data to get an overview of potential relationships between variables.</p>
<pre class="r"><code>ggplot(blrdata, aes(Age, EH, color = Gender)) +
  facet_wrap(~Ethnicity) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
  labs(x = &quot;&quot;, y = &quot;Observed Probabilty of eh&quot;) +
  scale_color_manual(values = c(&quot;gray20&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="fixedregressions_files/figure-html/blm6-1.png" width="672" /></p>
<p>With respect to main effects, the Figure above indicates that men use <em>eh</em> more frequently than women, that young speakers sue it more frequently compared with old speakers, and that speakers that are descendants of European settlers (Pakeha) use <em>eh</em> more frequently compared with Maori (the native inhabitants of New Zealand).</p>
<p>The plots in the lower panels do not indicate significant interactions between use of <em>EH</em> and the Age, Gender, and Ethnicity of speakers. In a next step, we will start building the logistic regression model.</p>
</div>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">4.2</span> Model Building</h2>
<p>As a first step, we need to define contrasts and add a distance matrix to the options. Contrasts define what and how variable levels should be compared and therefore influences how the results of the regression analysis are presented.</p>
<pre class="r"><code># set contrasts
options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;))
# create distance matrix
blrdata.dist &lt;- datadist(blrdata)
# include distance matrix in options
options(datadist = &quot;blrdata.dist&quot;)</code></pre>
<p>Next, we generate two minimal models that predict the use of <em>eh</em> solely based on the intercept.</p>
<pre class="r"><code># baseline glm model
m0.glm = glm(EH ~ 1, family = binomial, data = blrdata)
# baseline lrm model
m0.lrm = lrm(EH ~ 1, data = blrdata, x = T, y = T)</code></pre>
<p>A few words on “glm” vs “lrm”: Baayen (2008:196-197) states that “lrm” should be the function of choice in cases where each row contains exactly 1 success OR failure (1 or 0) while “glm” is preferable if there are two columns holding the number of successes and the number of failures respectively. I have tried it both ways and both functions work fine if each row contains exactly 1 success OR failure but only glm can handle the latter case.</p>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">4.3</span> Model fitting</h2>
<p>We will now start with the model fitting procedure. In the present case, we will use a manual step-wise step-up procedure during which predictors are added to the model if they significantly improve the model fit. In addition, we will perform diagnostics as we fit the model ateach step of the model fitting process rather than after the fitting.</p>
<p>We will test two things in particular: whether the data has incomplete information or complete separation and if the model suffers from multicollinearity.</p>
<p>Incomplete information or complete separation means that the data does not contain all combinations of the predictor or the dependent variable. This is important because if the data does not contain cases of all combinations, the model will assume that it has found a perfect predictor. In such cases the model overestimates the effect of that that predictor and the results of that model are no longer reliable. For example, if “EH” was only used by young speakers in the data, the model would jump on that fact and say “Ha! If there is an old speaker, that means that that speaker will never ever and under no circumstances say”EH&quot; - I can therefore ignore all other factors!&quot;</p>
<p>Multicollinearity means that predictors correlate and have shared variance. This means that whichever predictor is included first will take all the variance that it can explain and the remaining part of the variable that is shared will not be attributed to the other predictor. This may lead to reporting that a factor is not significant because all of the variance it can explain is already accounted for. However, if the other predictor were included first, then the orginal predictor would be returned as insignificant. This means that- depending on the order in which predictors are added - the results of the regression can differ dramatically and the model is therefore not reliable. Multicollinearity is actually a very comon problem and theer are various ways to deal with it but it cannot be ignored (at least in regression analyses).</p>
<p>We will start by adding “Age” to the minimal adequate model.</p>
<pre class="r"><code># check incomplete information
ifelse(min(ftable(blrdata$Age, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code># add age to the model
m1.glm = glm(EH ~ Age, family = binomial, data = blrdata)
# check multicollinearity (vifs should have values of 3 or lower for main effects)
ifelse(max(vif(m1.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code># check if adding Age significantly improves model fit
anova(m1.glm, m0.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age
## Model 2: EH ~ 1
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1     25819      32377                          
## 2     25820      33008 -1  -630.89 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As the data does not contain incomplete information, the vif values are below 3, and adding “Age” has significantly imporved the mdel fit (the p-value of the anova is lower than .05). We therefore proceed with “Age” included.</p>
<p>We continue by adding “Gender”. We add a second ANOVA test to see if including Gender affects the significance of other predictors in the model. If this were the case - if adding Gender woudl cause Age to become insignificant - then we could change the ordering in which we include predictors into our model.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Gender, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m2.glm &lt;- update(m1.glm, . ~ . +Gender)
ifelse(max(vif(m2.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m2.glm, m1.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender
## Model 2: EH ~ Age
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1     25818      32140                          
## 2     25819      32377 -1  -237.32 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m2.glm, test = &quot;LR&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II tests)
## 
## Response: EH
##        LR Chisq Df Pr(&gt;Chisq)    
## Age      668.64  1  &lt; 2.2e-16 ***
## Gender   237.32  1  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Again, including “Gender” significantly improves model fit and the data does not contain incomplete information or complete separation. Also, including “Gender” does not affect the significance of “Age”. Now, we include “Ethnicity”.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Ethnicity, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m3.glm &lt;- update(m2.glm, . ~ . +Ethnicity)
ifelse(max(vif(m3.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m3.glm, m2.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25817      32139                     
## 2     25818      32140 -1 -0.26101   0.6094</code></pre>
<p>Since adding “Ethnicity” does not significantly imporve the mdoel fit, we do not need to test if its inclusion affects the significance of other predictors. We continue without “Ethnicity” and include the interaction between “Age” and “Gender”.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Age, blrdata$Gender, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m4.glm &lt;- update(m2.glm, . ~ . +Age*Gender)
ifelse(max(vif(m4.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m4.glm, m2.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Age:Gender
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25817      32139                     
## 2     25818      32140 -1 -0.12424   0.7245</code></pre>
<p>The interaction between Age and Gender is not significant which means that men and women do not behave differently with respect to their use of “EH” as they age. Also, the data does not contain incomplete information and the model does not suffer from multicollinerity - the predictors are not collinear. We can now include if there is a significant interaction between “Age” and “Ethnicity”.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Age, blrdata$Ethnicity, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m5.glm &lt;- update(m2.glm, . ~ . +Age*Ethnicity)
ifelse(max(vif(m5.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m5.glm, m2.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Age:Ethnicity
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25816      32136                     
## 2     25818      32140 -2  -3.0686   0.2156</code></pre>
<p>Again, no incomplete information or multicollinearity and no significant interaction. Now, we test if there exists a significant interaction between “Gender” and “Ethnicity”.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Gender, blrdata$Ethnicity, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m6.glm &lt;- update(m2.glm, . ~ . +Gender*Ethnicity)
ifelse(max(vif(m6.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m6.glm, m2.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Gender:Ethnicity
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25816      32139                     
## 2     25818      32140 -2 -0.27225   0.8727</code></pre>
<p>As the interaction between “Gender” and “Ethnicity” is not significant, we continue without it. In a final step, we include the three-way interaction between “Age”, “Gender”, and “Ethnicity”.</p>
<pre class="r"><code>ifelse(min(ftable(blrdata$Age, blrdata$Gender, blrdata$Ethnicity, blrdata$EH)) == 0, &quot;not possible&quot;, &quot;possible&quot;)</code></pre>
<pre><code>## [1] &quot;possible&quot;</code></pre>
<pre class="r"><code>m7.glm &lt;- update(m2.glm, . ~ . +Gender*Ethnicity)
ifelse(max(vif(m7.glm)) &lt;= 3,  &quot;vifs ok&quot;, &quot;WARNING: high vifs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;vifs ok&quot;</code></pre>
<pre class="r"><code>anova(m7.glm, m2.glm, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ Age + Gender + Ethnicity + Gender:Ethnicity
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1     25816      32139                     
## 2     25818      32140 -2 -0.27225   0.8727</code></pre>
<p>We have found our final minimal adequate model because the 3-way interaction is also insignificant. As we have now arrived at the final minimal adequate model (m2.glm), we generate a final minimal model using the “lrm” model.</p>
<pre class="r"><code>m2.lrm &lt;- lrm(EH ~ Age+Gender, data = blrdata, x = T, y = T, linear.predictors = T)
m2.lrm</code></pre>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = EH ~ Age + Gender, data = blrdata, x = T, y = T, 
##      linear.predictors = T)
##  
##                        Model Likelihood     Discrimination    Rank Discrim.    
##                           Ratio Test           Indexes           Indexes       
##  Obs         25821    LR chi2     868.21    R2       0.046    C       0.602    
##   0          17114    d.f.             2    g        0.432    Dxy     0.203    
##   1           8707    Pr(&gt; chi2) &lt;0.0001    gr       1.541    gamma   0.302    
##  max |deriv| 3e-10                          gp       0.091    tau-a   0.091    
##                                             Brier    0.216                     
##  
##               Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept    -0.2324 0.0223 -10.44 &lt;0.0001 
##  Age=Old      -0.8305 0.0335 -24.78 &lt;0.0001 
##  Gender=Women -0.4201 0.0273 -15.42 &lt;0.0001 
## </code></pre>
<pre class="r"><code>anova(m2.lrm)</code></pre>
<pre><code>##                 Wald Statistics          Response: EH 
## 
##  Factor     Chi-Square d.f. P     
##  Age        614.04     1    &lt;.0001
##  Gender     237.65     1    &lt;.0001
##  TOTAL      802.65     2    &lt;.0001</code></pre>
<p>After fitting the model, we validate the model to avoid arriving at a final minimal model that is overfitted to the data at hand.</p>
</div>
<div id="model-validation" class="section level2">
<h2><span class="header-section-number">4.4</span> Model Validation</h2>
<p>To validate a model, you can apply the “validate” function and apply it to a saturated model. The output of the “validate” function shows how often predictors are retained if the sample is re-selected with the same size but with placing back drawn data points. The execution of the function requires some patience as it is rather computationally expensive and it is, tehrefore, commented out below.</p>
<pre class="r"><code># model validation (remove # to activate: output too long for website)
m7.lrm &lt;- lrm(EH ~ (Age+Gender+Ethnicity)^3, data = blrdata, x = T, y = T, linear.predictors = T)
#validate(m7.lrm, bw = T, B = 200)</code></pre>
<p>The “validate” function shows that retaining two predictors (Age and Gender) is the best option and thereby confirms our final minimal adequate model as the best minimal model. In addition, we check whether we need to include a penalty for data points because they have too strong of an impact of the model fit. To see whether a penalty is warranted, we apply the “pentrace” function to the final minimal adequate model.</p>
<pre class="r"><code>pentrace(m2.lrm, seq(0, 0.8, by = 0.05)) # determine penalty</code></pre>
<pre><code>## 
## Best penalty:
## 
##  penalty       df
##      0.8 1.999254
## 
##  penalty       df      aic      bic    aic.c
##     0.00 2.000000 864.2138 847.8959 864.2133
##     0.05 1.999953 864.2139 847.8964 864.2134
##     0.10 1.999907 864.2140 847.8969 864.2135
##     0.15 1.999860 864.2141 847.8973 864.2136
##     0.20 1.999813 864.2142 847.8978 864.2137
##     0.25 1.999767 864.2143 847.8983 864.2138
##     0.30 1.999720 864.2143 847.8987 864.2139
##     0.35 1.999674 864.2144 847.8992 864.2140
##     0.40 1.999627 864.2145 847.8997 864.2140
##     0.45 1.999580 864.2146 847.9001 864.2141
##     0.50 1.999534 864.2147 847.9006 864.2142
##     0.55 1.999487 864.2148 847.9011 864.2143
##     0.60 1.999440 864.2148 847.9015 864.2144
##     0.65 1.999394 864.2149 847.9020 864.2144
##     0.70 1.999347 864.2150 847.9024 864.2145
##     0.75 1.999301 864.2151 847.9029 864.2146
##     0.80 1.999254 864.2151 847.9033 864.2147</code></pre>
<p>The values are so similar that a penalty is unnecessary. In a next step, we rename the final models.</p>
<pre class="r"><code>lr.glm &lt;- m2.glm  # rename final minimal adeqaute glm model
lr.lrm &lt;- m2.lrm  # rename final minimal adeqaute lrm model</code></pre>
<p>Now, we calculate a Model Likelihood Ratio Test to check if the final model performs significantly better than the initial minimal base-line model. The result of this test is provided as a default if we call a summary of the lrm object.</p>
<pre class="r"><code>modelChi &lt;- lr.glm$null.deviance - lr.glm$deviance
chidf &lt;- lr.glm$df.null - lr.glm$df.residual
chisq.prob &lt;- 1 - pchisq(modelChi, chidf)
modelChi; chidf; chisq.prob</code></pre>
<pre><code>## [1] 868.2138</code></pre>
<pre><code>## [1] 2</code></pre>
<pre><code>## [1] 0</code></pre>
<p>The code above provides three values: a <span class="math inline">\(\chi\)</span><sup>2</sup>, the degrees of freedom, and a p-value. The p-value is lower than .05 and the results of the Model Likelihood Ratio Test therefore confirm that the final minimal adequate model performs significantly better than the initial minimal base-line model. Another way to extract the model likelihood test statistics is to use an ANOVA to compare the final minimal adequate model to the minimal base-line model.</p>
<p>A handier way to get thses statistics is by performing an ANOVA on the final minimal model which, if used this way, is identical to a Model Likelihood Ratio test.</p>
<pre class="r"><code>anova(m0.glm, lr.glm, test = &quot;Chi&quot;) # Model Likelihood Ratio Test</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: EH ~ 1
## Model 2: EH ~ Age + Gender
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1     25820      33008                          
## 2     25818      32140  2   868.21 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>In a next step, we calculate pseudo-R<sup>2</sup> values which represent the amount of residual variance that is explained by the final minimal adequate model. We cannot use the ordinary R<sup>2</sup> because the model works on the logged likelihoods rather than the values of the dependent variable.</p>
<pre class="r"><code># calculate pseudo R^2
# number of cases
ncases &lt;- length(fitted(lr.glm))
R2.hl &lt;- modelChi/lr.glm$null.deviance
R.cs &lt;- 1 - exp ((lr.glm$deviance - lr.glm$null.deviance)/ncases)
R.n &lt;- R.cs /( 1- ( exp (-(lr.glm$null.deviance/ ncases))))
# function for extracting pseudo-R^2
logisticPseudoR2s &lt;- function(LogModel) {
  dev &lt;- LogModel$deviance
    nullDev &lt;- LogModel$null.deviance
    modelN &lt;-  length(LogModel$fitted.values)
    R.l &lt;-  1 -  dev / nullDev
    R.cs &lt;- 1- exp ( -(nullDev - dev) / modelN)
    R.n &lt;- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
    cat(&quot;Pseudo R^2 for logistic regression\n&quot;)
    cat(&quot;Hosmer and Lemeshow R^2  &quot;, round(R.l, 3), &quot;\n&quot;)
    cat(&quot;Cox and Snell R^2        &quot;, round(R.cs, 3), &quot;\n&quot;)
    cat(&quot;Nagelkerke R^2           &quot;, round(R.n, 3),    &quot;\n&quot;) }
logisticPseudoR2s(lr.glm)</code></pre>
<pre><code>## Pseudo R^2 for logistic regression
## Hosmer and Lemeshow R^2   0.026 
## Cox and Snell R^2         0.033 
## Nagelkerke R^2            0.046</code></pre>
<p>The low pseudo-R<sup>2</sup> values show that our model has very low explanatory power as it only accounts for approximately 2.6 to 4.6 percent of the variance in the logged likelihoods (to get the percentages, you simply multiply the pseudo-R<sup>2</sup> values by 100). Next, we extract the confidence intervals for the coefficients of the model.</p>
<pre class="r"><code># extract the confidence intervals for the coefficients
confint(lr.glm)</code></pre>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) -0.2760509 -0.1887787
## AgeOld      -0.8964864 -0.7650958
## GenderWomen -0.4735310 -0.3667038</code></pre>
<p>Despite having low explanatory and predictive power, the age of speakers and their gender are significant as the confidence intervals of the coefficients do not overlap with 0.</p>
</div>
<div id="effect-size" class="section level2">
<h2><span class="header-section-number">4.5</span> Effect Size</h2>
<p>In a next step, we compute odds ratios and their confidence intervals. Odds Ratios represent a common measure of effect size and can be used to compare effect sizes across models. Odds ratios rang between 0 and infinity. Values of 1 indicate that there is no effect. The further away the values are from 1, the stronger the effect. If the values are lower than 1, then the variable level correlates negatively with the occurrence of the outcome (the likelihood decreases) while values above 1 indicate a positive correlation and show that the variable level causes an increase in the likelihood of the outcome (the occurrence of EH).</p>
<pre class="r"><code>exp(lr.glm$coefficients) # odds ratios</code></pre>
<pre><code>## (Intercept)      AgeOld GenderWomen 
##   0.7926425   0.4358154   0.6569723</code></pre>
<pre class="r"><code>exp(confint(lr.glm))     # confidence intervals of the coefficients</code></pre>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 0.7587743 0.8279697
## AgeOld      0.4080007 0.4652893
## GenderWomen 0.6227993 0.6930149</code></pre>
<p>The odds ratios confirm that older speakers use <em>EH</em> significantly less often compared with younger speakers and that women use <em>EH</em> less frequently than men as the confidence intervals of the odds rations do not overlap with 1. In a next step, we calculate the prediction accuracy of the model.</p>
</div>
<div id="accuracy" class="section level2">
<h2><span class="header-section-number">4.6</span> Accuracy</h2>
<p>In order to calculate the prediction accuracy of the model, we rearrange the data so that it does not reflect one speech unit per row but the number of speech units with <em>EH</em> and the number of speech units without <em>EH</em> per speaker! Thus, we transform the data into a per speaker rather than a per speech-unit format.</p>
<pre class="r"><code>blrdata_byspeaker &lt;- table(blrdata$ID, blrdata$EH)
blrdata_byspeaker &lt;- data.frame(rownames(blrdata_byspeaker), blrdata_byspeaker[, 1], blrdata_byspeaker[, 2])
names(blrdata_byspeaker) &lt;- c(&quot;ID&quot;, &quot;NOEH&quot;, &quot;EH&quot;)
rownames(blrdata_byspeaker) &lt;- 1:length(blrdata_byspeaker[,1])

blrdata_byspeaker &lt;- plyr::join(blrdata_byspeaker,  # join by-speaker data and biodata
                          blrdata, by = &quot;ID&quot;, # join by ID
                          type = &quot;left&quot;,      # only speakers for which bio data is provided
                          match = &quot;first&quot;)    #
blrdata_byspeaker$EH &lt;- NULL                  # remove EH column</code></pre>
<table>
<caption>First six rows of the by-speaker data.</caption>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="right">NOEH</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">Ethnicity</th>
<th align="right">EH</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><S1A-001#F></td>
<td align="right">95</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-001#M></td>
<td align="right">97</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-002#B></td>
<td align="right">99</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><S1A-002#Q></td>
<td align="right">86</td>
<td align="left">Women</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left"><S1A-003#B></td>
<td align="right">58</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><S1A-003#M></td>
<td align="right">119</td>
<td align="left">Men</td>
<td align="left">Young</td>
<td align="left">Pakeha</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code># use by.spk data to fit another model which we will use to test the accuracy of the model
lr.glm.spk &lt;- glm(cbind(EH, NOEH) ~ Age*Gender + Ethnicity + Age:Ethnicity, data = blrdata_byspeaker, family = binomial)
correct &lt;- sum(blrdata_byspeaker$EH * (predict(lr.glm.spk, type = &quot;response&quot;) &gt;= 0.5)) + sum(blrdata_byspeaker$NOEH * (predict(lr.glm.spk, type=&quot;response&quot;) &lt; 0.5))
tot &lt;- sum(blrdata_byspeaker$EH) + sum(blrdata_byspeaker$NOEH)
predict.acc &lt;- (correct/tot)*100
predict.acc</code></pre>
<pre><code>## [1] 99.60424</code></pre>
<p>The models predicts 99.6 of cases accurately which appears to be a satisfactory result but in order to evaluate the prediction accuracy, we need to compare it to the accuracy of the minimal base-line model.</p>
<pre class="r"><code># extract prediction accuracy
lr.glm.spk.base &lt;- glm(cbind(EH, NOEH) ~ 1, data = blrdata_byspeaker, family = binomial)
correct.b &lt;- sum(blrdata_byspeaker$EH * (predict(lr.glm.spk.base, type = &quot;response&quot;) &gt;= 0.5)) + sum(blrdata_byspeaker$NOEH * (predict(lr.glm.spk.base, type=&quot;response&quot;) &lt; 0.5))
tot.b &lt;- sum(blrdata_byspeaker$EH) + sum(blrdata_byspeaker$NOEH)
predict.acc.base &lt;- (correct.b/tot.b)*100
# inspect prediction accuracy
predict.acc.base</code></pre>
<pre><code>## [1] 99.60424</code></pre>
<p>Both, the final-minimal and the minimal base-line model have the same prediction accuracy. This is interesting and we need to determine why this is the case. We will extract the predictions based on both models to find out why the predictions are identical.</p>
<pre class="r"><code># compare preictions of final and base line model
which(lr.glm.spk$fitted &gt; .5)</code></pre>
<pre><code>## named integer(0)</code></pre>
<pre class="r"><code>which(lr.glm.spk.base$fitted &gt; .5)</code></pre>
<pre><code>## named integer(0)</code></pre>
<p>The reason why both models arrive at the same predictions is that because both models always predict an absence of EH.</p>
<pre class="r"><code># create variable with contains the prediction of the model
blrdata$Prediction &lt;- predict(lr.glm, blrdata, type = &quot;response&quot;)
blrdata$Prediction &lt;- ifelse(blrdata$Prediction &gt; .5, 1, 0)
# convert predicted and observed into factors with the same levels
blrdata$Prediction &lt;- factor(blrdata$Prediction, levels = c(&quot;0&quot;, &quot;1&quot;))
blrdata$EH &lt;- factor(blrdata$EH, levels = c(&quot;0&quot;, &quot;1&quot;))
# create a confusion matrix with compares observed against predicted values
caret::confusionMatrix(blrdata$Prediction, blrdata$EH)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction     0     1
##          0 17114  8707
##          1     0     0
##                                          
##                Accuracy : 0.6628         
##                  95% CI : (0.657, 0.6686)
##     No Information Rate : 0.6628         
##     P-Value [Acc &gt; NIR] : 0.5029         
##                                          
##                   Kappa : 0              
##  Mcnemar&#39;s Test P-Value : &lt;2e-16         
##                                          
##             Sensitivity : 1.0000         
##             Specificity : 0.0000         
##          Pos Pred Value : 0.6628         
##          Neg Pred Value :    NaN         
##              Prevalence : 0.6628         
##          Detection Rate : 0.6628         
##    Detection Prevalence : 1.0000         
##       Balanced Accuracy : 0.5000         
##                                          
##        &#39;Positive&#39; Class : 0              
## </code></pre>
<p>We can now plot the effects using the visreg package <span class="citation">(cf. <span class="citeproc-not-found" data-reference-id="Breheny2013"><strong>???</strong></span>)</span></p>
<pre class="r"><code># create plot
par(mfrow = c(1, 2))
visreg(lr.glm, &quot;Age&quot;, xlab = &quot;Age&quot;,
       ylab = &quot;Logged Odds (EH)&quot;,
       ylim = c(-3, 0))
visreg(lr.glm, &quot;Gender&quot;, xlab = &quot;Gender&quot;,
       ylab = &quot;Logged Odds (EH)&quot;,
       ylim = c(-3, 0))</code></pre>
<p><img src="fixedregressions_files/figure-html/blm32-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>A more intuitive way to visualze results id to plot the predicted values against the observed values.</p>
<pre class="r"><code># extract predicted probabilities
blrdata$Predicted &lt;- predict(lr.glm, blrdata, type = &quot;response&quot;)
# plot
ggplot(blrdata, aes(Age, Predicted, color = Gender)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
    ylim(0, .75) +
  labs(x = &quot;&quot;, y = &quot;Predicted Probabilty of eh&quot;) +
  scale_color_manual(values = c(&quot;gray20&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="fixedregressions_files/figure-html/blm32b-1.png" width="672" /></p>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">4.7</span> Model Diagnostics</h2>
<p>We are now in a position to perform model diagnostics and test if the model violates distributional requirements. In a first step, we test for the existence of multicollinearity.</p>
<div id="multicollinearity" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Multicollinearity</h3>
<p>To check whether the final minimal model contains predictors that correlate with each other, we extract variance inflation factors (VIF). If a model contains predictors that have variance inflation factors (VIF) &gt; 10 the model is completely unreliable and cannot claim the multicollinearity is absent <span class="citation">(Myers <a href="#ref-myers1990classical">1990</a>)</span>. Predictors causing such VIFs should be removed. Indeed, predictors with VIF values greater than 4 are usually already problematic but, for large data sets, even VIFs greater than 2 can lead inflated standard errors (Jaeger 2013:<a href="http://wiki.bcs.rochester.edu/HlpLab/LSA2013Regression?action=AttachFile&amp;do=view&amp;target=LSA13-Lecture6-CommonIssuesAndSolutions.pdf" class="uri">http://wiki.bcs.rochester.edu/HlpLab/LSA2013Regression?action=AttachFile&amp;do=view&amp;target=LSA13-Lecture6-CommonIssuesAndSolutions.pdf</a>). Also, VIFs of 2.5 can be problematic <span class="citation">(Szmrecsanyi <a href="#ref-szmrecsanyi2006morphosyntactic">2006</a>, 215)</span> and <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol">2010</a>)</span> proposes that variables with VIFs exceeding 3 should be removed.</p>
<pre class="r"><code>vif(lr.glm)</code></pre>
<pre><code>##      AgeOld GenderWomen 
##    1.004815    1.004815</code></pre>
<p>In addition, predictors with 1/VIF values <span class="math inline">\(&lt;\)</span> .1 must be removed (data points with values above .2 are considered problematic) <span class="citation">(Menard <a href="#ref-menard1995applied">1995</a>)</span> and the mean value of VIFs should be <span class="math inline">\(&lt;\)</span> 1 <span class="citation">(Bowerman and O’Connell <a href="#ref-bowerman1990linear">1990</a>)</span>.</p>
<pre class="r"><code>mean(vif(lr.glm))</code></pre>
<pre><code>## [1] 1.004815</code></pre>
</div>
<div id="outlier-detection-1" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Outlier detection</h3>
<p>In order to detect potential outliers, we will calculate diagnostic parameters and add these to our data set.</p>
<pre class="r"><code>infl &lt;- influence.measures(lr.glm) # calculate influence statistics
blrdata &lt;- data.frame(blrdata, infl[[1]], infl[[2]]) # add influence statistics</code></pre>
<p>In a next step, we use these diagnostic parameters to check if there are data points which should be removed as they unduly affect the model fit.</p>
</div>
<div id="sample-size" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Sample Size</h3>
<p>We now check whether the sample size is sufficient for our analysis <span class="citation">(Green <a href="#ref-green1991many">1991</a>)</span>. * if you are interested in the overall model: 50 + 8k (k = number of predictors) * if you are interested in individual predictors: 104 + k * if you are interested in both: take the higher value!</p>
<pre class="r"><code># function to evaluate sample size
smplesz &lt;- function(x) {
  ifelse((length(x$fitted) &lt; (104 + ncol(summary(x)$coefficients)-1)) == TRUE,
    return(
      paste(&quot;Sample too small: please increase your sample by &quot;,
      104 + ncol(summary(x)$coefficients)-1 - length(x$fitted),
      &quot; data points&quot;, collapse = &quot;&quot;)),
    return(&quot;Sample size sufficient&quot;)) }
# apply unction to model
smplesz(lr.glm)</code></pre>
<pre><code>## [1] &quot;Sample size sufficient&quot;</code></pre>
<p>According to rule of thumb provided in <span class="citation">Green (<a href="#ref-green1991many">1991</a>)</span>, the sample size is sufficient for our analysis.</p>
</div>
</div>
<div id="summarizing-results" class="section level2">
<h2><span class="header-section-number">4.8</span> Summarizing Results</h2>
<p>As a final step, we summarize our findings in tabulated form.</p>
<pre class="r"><code>blrmsummary &lt;- blrm.summary(lr.glm, lr.lrm, predict.acc) # summarize regression analysis
kable(blrmsummary[, -c(4:5)], caption = &quot;Summary of the final minimal adequate binomial logistic fixed-effects regression model which was fitted to predictors of eh in New Zealand English.&quot;)</code></pre>
<table>
<caption>Summary of the final minimal adequate binomial logistic fixed-effects regression model which was fitted to predictors of eh in New Zealand English.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Estimate</th>
<th align="left">VIF</th>
<th align="left">OddsRatio</th>
<th align="left">Std. Error</th>
<th align="left">z value</th>
<th align="left">Pr(&gt;|z|)</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td align="left">-0.23</td>
<td align="left"></td>
<td align="left">0.79</td>
<td align="left">0.02</td>
<td align="left">-10.44</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>AgeOld</td>
<td align="left">-0.83</td>
<td align="left">1</td>
<td align="left">0.44</td>
<td align="left">0.03</td>
<td align="left">-24.78</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td>GenderWomen</td>
<td align="left">-0.42</td>
<td align="left">1</td>
<td align="left">0.66</td>
<td align="left">0.03</td>
<td align="left">-15.42</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>Model statistics</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">Value</td>
</tr>
<tr class="odd">
<td>Number of cases in model</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">25821</td>
</tr>
<tr class="even">
<td>Observed misses</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0 :</td>
<td align="left">17114</td>
</tr>
<tr class="odd">
<td>Observed successes</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">1 :</td>
<td align="left">8707</td>
</tr>
<tr class="even">
<td>Null deviance</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">33007.75</td>
</tr>
<tr class="odd">
<td>Residual deviance</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">32139.54</td>
</tr>
<tr class="even">
<td>R2 (Nagelkerke)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.046</td>
</tr>
<tr class="odd">
<td>R2 (Hosmer &amp; Lemeshow)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.026</td>
</tr>
<tr class="even">
<td>R2 (Cox &amp; Snell)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.033</td>
</tr>
<tr class="odd">
<td>C</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.602</td>
</tr>
<tr class="even">
<td>Somers’ Dxy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.203</td>
</tr>
<tr class="odd">
<td>AIC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">32145.54</td>
</tr>
<tr class="even">
<td>Prediction accuracy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">99.6%</td>
</tr>
<tr class="odd">
<td>Model Likelihood Ratio Test</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">Model L.R.: 868.21</td>
<td align="left">df: 2</td>
<td align="left">p-value: 0</td>
<td align="left">sig: p &lt; .001***</td>
</tr>
</tbody>
</table>
<p><strong>R2 (Hosmer &amp; Lemeshow)</strong></p>
<p>“Rt is the proportional reduction in the absolute value of the log-likelihood measure and as such it is a measure of how much the badness of fit improves as a result of the inclusion of the predictor variables. It can vary between 0 (indicating that the predictors are useless at predicting the outcome variable) and 1 (indicating that the model predicts the outcome variable perfectly)” (<span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span> 317).</p>
<p><strong>R2 (Cox &amp; Snell)</strong></p>
<p>“Cox and Snell’s R~s (1989) is based on the deviance of the model (-2LL(new») and the deviance of the baseline model (-2LL(baseline), and the sample size, n […]. However, this statistic never reaches its theoretical maximum of 1.</p>
<p><strong>R2 (Nagelkerke)</strong></p>
<p>Since R2 (Cox &amp; Snell) never reaches its theoretical maximum of 1, Nagelkerke (1991) suggested Nagelkerke’s R^2. (Field, Miles &amp; Field 2012:317-318).</p>
<p><strong>Somers’ Dxy</strong></p>
<p>Somers’ Dxy is a rank correlation between predicted probabilities and observed responses ranges between 0 (randomness) and 1 (perfect prediction). Somers Dxy should have a value higher than .5 for the model to be meaningful (cf. <span class="citation">Baayen (<a href="#ref-baayen2008analyzing">2008</a>)</span> 204).</p>
<p><strong>C</strong> C is an index of concordance between the predicted probability and the observed response. When C takes the value 0.5, the predictions are random, when it is 1, prediction is perfect. A value above 0.8 indicates that the model may have some real predictive capacity (cf. <span class="citation">Baayen (<a href="#ref-baayen2008analyzing">2008</a>)</span> 204).</p>
<p><strong>Akaike information criteria (AIC)</strong></p>
<p>Akaike information criteria (AlC = -2LL + 2k) provide a value that reflects a ratio between the number of predictors in the model and the variance that is explained by these predictors. Changes in AIC can serve as a measure of whether the inclusion of a variable leads to a significant increase in the amount of variance that is explained by the model. “You can think of this as the price you pay for something: you get a better value of R<sup>2</sup>, but you pay a higher price, and was that higher price worth it? These information criteria help you to decide. The BIC is the same as the AIC but adjusts the penalty included in the AlC (i.e., 2k) by the number of cases: BlC = -2LL + 2k x log(n) in which n is the number of cases in the model” (<span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span> 318).</p>
</div>
</div>
<div id="ordinal-regression" class="section level1">
<h1><span class="header-section-number">5</span> Ordinal Regression</h1>
<p>Ordinal regression is very similar to multiple linear regression but takes an ordinal dependent variable <span class="citation">(Agresti <a href="#ref-agresti2010analysis">2010</a>)</span>. For this reason, ordinal regression is one of the key methods in analyzing Likert data.</p>
<pre class="r"><code># load data
ordata &lt;- read.delim(&quot;https://slcladal.github.io/data/ordinaldata.txt&quot;, sep = &quot;\t&quot;, header = T)
colnames(ordata) &lt;- c(&quot;Recommend&quot;, &quot;Internal&quot;, &quot;Exchange&quot;, &quot;FinalScore&quot;)
# inspect data
head(ordata); nrow(ordata)</code></pre>
<pre><code>##         Recommend Internal Exchange FinalScore
## 1     very likely        0        0       3.26
## 2 somewhat likely        1        0       3.21
## 3        unlikely        1        1       3.94
## 4 somewhat likely        0        0       2.81
## 5 somewhat likely        0        0       2.53
## 6        unlikely        0        1       2.59</code></pre>
<pre><code>## [1] 400</code></pre>
<pre class="r"><code>#
ordata$Recommend &lt;- factor(ordata$Recommend, 
                           levels=c(&quot;unlikely&quot;, 
                                    &quot;somewhat likely&quot;, 
                                    &quot;very likely&quot;),
                           labels=c(&quot;unlikely&quot;, 
                                    &quot;somewhat likely&quot;, 
                                    &quot;very likely&quot;))
# one at a time, table apply, pared, and public
lapply(ordata[, c(&quot;Recommend&quot;, &quot;Internal&quot;, &quot;Exchange&quot;)], table)</code></pre>
<pre><code>## $Recommend
## 
##        unlikely somewhat likely     very likely 
##             220             140              40 
## 
## $Internal
## 
##   0   1 
## 337  63 
## 
## $Exchange
## 
##   0   1 
## 343  57</code></pre>
<pre class="r"><code>## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Exchange + Recommend + Internal, data = ordata))</code></pre>
<pre><code>##                          Internal   0   1
## Exchange Recommend                       
## 0        unlikely                 175  14
##          somewhat likely           98  26
##          very likely               20  10
## 1        unlikely                  25   6
##          somewhat likely           12   4
##          very likely                7   3</code></pre>
<pre class="r"><code>summary(ordata$FinalScore); sd(ordata$FinalScore)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.900   2.720   2.990   2.999   3.270   4.000</code></pre>
<pre><code>## [1] 0.3979409</code></pre>
<pre class="r"><code># visualize data
ggplot(ordata, aes(x = Recommend, y = FinalScore)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) +
  facet_grid(Exchange ~ Internal, margins = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))</code></pre>
<p><img src="fixedregressions_files/figure-html/orr5-1.png" width="672" /></p>
<pre class="r"><code>## fit ordered logit model and store results &#39;m&#39;
m &lt;- polr(Recommend ~ Internal + Exchange + FinalScore, data = ordata, Hess=TRUE)
## view a summary of the model
summary(m)</code></pre>
<pre><code>## Call:
## polr(formula = Recommend ~ Internal + Exchange + FinalScore, 
##     data = ordata, Hess = TRUE)
## 
## Coefficients:
##               Value Std. Error t value
## Internal    1.04769     0.2658  3.9418
## Exchange   -0.05879     0.2979 -0.1974
## FinalScore  0.61594     0.2606  2.3632
## 
## Intercepts:
##                             Value   Std. Error t value
## unlikely|somewhat likely     2.2039  0.7795     2.8272
## somewhat likely|very likely  4.2994  0.8043     5.3453
## 
## Residual Deviance: 717.0249 
## AIC: 727.0249</code></pre>
<pre class="r"><code>## store table
(ctable &lt;- coef(summary(m)))</code></pre>
<pre><code>##                                   Value Std. Error    t value
## Internal                     1.04769010  0.2657894  3.9418050
## Exchange                    -0.05878572  0.2978614 -0.1973593
## FinalScore                   0.61594057  0.2606340  2.3632399
## unlikely|somewhat likely     2.20391473  0.7795455  2.8271792
## somewhat likely|very likely  4.29936315  0.8043267  5.3452947</code></pre>
<pre class="r"><code>## calculate and store p values
p &lt;- pnorm(abs(ctable[, &quot;t value&quot;]), lower.tail = FALSE) * 2

## combined table
(ctable &lt;- cbind(ctable, &quot;p value&quot; = p))</code></pre>
<pre><code>##                                   Value Std. Error    t value      p value
## Internal                     1.04769010  0.2657894  3.9418050 8.087072e-05
## Exchange                    -0.05878572  0.2978614 -0.1973593 8.435464e-01
## FinalScore                   0.61594057  0.2606340  2.3632399 1.811594e-02
## unlikely|somewhat likely     2.20391473  0.7795455  2.8271792 4.696004e-03
## somewhat likely|very likely  4.29936315  0.8043267  5.3452947 9.027008e-08</code></pre>
<pre class="r"><code># default method gives profiled CIs
(ci &lt;- confint(m)) </code></pre>
<pre><code>##                 2.5 %    97.5 %
## Internal    0.5281768 1.5721750
## Exchange   -0.6522060 0.5191384
## FinalScore  0.1076202 1.1309148</code></pre>
<pre class="r"><code># CIs assuming normality
confint.default(m) </code></pre>
<pre><code>##                 2.5 %    97.5 %
## Internal    0.5267524 1.5686278
## Exchange   -0.6425833 0.5250119
## FinalScore  0.1051074 1.1267737</code></pre>
<pre class="r"><code>## odds ratios
exp(coef(m))</code></pre>
<pre><code>##   Internal   Exchange FinalScore 
##  2.8510579  0.9429088  1.8513972</code></pre>
<pre class="r"><code>## OR and CI
exp(cbind(OR = coef(m), ci))</code></pre>
<pre><code>##                   OR     2.5 %   97.5 %
## Internal   2.8510579 1.6958376 4.817114
## Exchange   0.9429088 0.5208954 1.680579
## FinalScore 1.8513972 1.1136247 3.098490</code></pre>
</div>
<div id="poisson-regression" class="section level1">
<h1><span class="header-section-number">6</span> Poisson Regression</h1>
<p>Poisson regressions are used to analyze data where the dependent variable represents counts. However, the tricky thing about Poisson regressions is that the data has to conform to the Poisson distribution which is, accroding to my experience, rarely the case, unfortunately.</p>
<pre class="r"><code># load data
poissondata &lt;- read.delim(&quot;data/posdata.txt&quot;, sep = &quot;\t&quot;, header = T, skipNul = T, quote = &quot;&quot;)
# inspect data
summary(poissondata)</code></pre>
<pre><code>##        Id             Pauses        Language      Alcohol     
##  Min.   :  1.00   Min.   :0.00   English:105   Min.   :33.00  
##  1st Qu.: 50.75   1st Qu.:0.00   German : 50   1st Qu.:45.00  
##  Median :100.50   Median :0.00   Russian: 45   Median :52.00  
##  Mean   :100.50   Mean   :0.63                 Mean   :52.65  
##  3rd Qu.:150.25   3rd Qu.:1.00                 3rd Qu.:59.00  
##  Max.   :200.00   Max.   :6.00                 Max.   :75.00</code></pre>
<p>We will clean the data by factorizing Id which is currentlx considered a numeric variable rather than a factor.</p>
<pre class="r"><code># process data
poissondata &lt;- poissondata %&gt;%
  mutate(Id = factor(Id, levels = 1:200, labels = 1:200))
# inspect data
summary(poissondata); str(poissondata)</code></pre>
<pre><code>##        Id          Pauses        Language      Alcohol     
##  1      :  1   Min.   :0.00   English:105   Min.   :33.00  
##  2      :  1   1st Qu.:0.00   German : 50   1st Qu.:45.00  
##  3      :  1   Median :0.00   Russian: 45   Median :52.00  
##  4      :  1   Mean   :0.63                 Mean   :52.65  
##  5      :  1   3rd Qu.:1.00                 3rd Qu.:59.00  
##  6      :  1   Max.   :6.00                 Max.   :75.00  
##  (Other):194</code></pre>
<pre><code>## &#39;data.frame&#39;:    200 obs. of  4 variables:
##  $ Id      : Factor w/ 200 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 45 108 15 67 153 51 164 133 2 53 ...
##  $ Pauses  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ Language: Factor w/ 3 levels &quot;English&quot;,&quot;German&quot;,..: 2 3 2 2 2 3 2 2 2 2 ...
##  $ Alcohol : int  41 41 44 42 40 42 46 40 33 46 ...</code></pre>
<p>First, we check if the conditions for a Poisson regression are met.</p>
<pre class="r"><code># output the results
gf = goodfit(poissondata$Pauses,type= &quot;poisson&quot;,method= &quot;ML&quot;)
summary(gf)</code></pre>
<pre><code>## 
##   Goodness-of-fit test for poisson distribution
## 
##                       X^2 df     P(&gt; X^2)
## Likelihood Ratio 33.01229  5 3.742341e-06</code></pre>
<p>If the p-values is smaller than .05, then data is not Poisson distributed which means that it differs significantly from a Poisson distribution and is very likely overdispersed. We will check the divergence froma Poisson distribution visually by plotting the observed counts against the expected counts if the data were Poisson distributed.</p>
<pre class="r"><code>plot(gf,main=&quot;Count data vs Poisson distribution&quot;)</code></pre>
<p><img src="fixedregressions_files/figure-html/pr4-1.png" width="672" /></p>
<p>Although the goodfit function reported that the data differs significantly from the Poisson distribution, the fit is rather good. We can use an additional Levene’s test to check if variance homogeity is given.</p>
<pre class="r"><code># check homogeneity
leveneTest(poissondata$Pauses, poissondata$Language, center = mean)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = mean)
##        Df F value    Pr(&gt;F)    
## group   2  17.153 1.357e-07 ***
##       197                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The Levene’s test indicates that variance homogeneity is also violated. Since both the approximation to a Poisson distributuion and variance homogeineity are violated, we should switch either to a quasi-Poisson model or a negative binomial model. However, as we are only intersted in how to implement a Poisson model here, we continue despite the fact that this could not be recommended if we were actually interested in accurate results based on a reliable model.</p>
<p>In a next step, we summarize Progression by inspecting the means and standard deviations of the individual variable levels.</p>
<pre class="r"><code># extract mean and standard devaiation
with(poissondata, tapply(Pauses, Language, function(x) {
  sprintf(&quot;M (SD) = %1.2f (%1.2f)&quot;, mean(x), sd(x))
}))</code></pre>
<pre><code>##                English                 German                Russian 
## &quot;M (SD) = 1.00 (1.28)&quot; &quot;M (SD) = 0.24 (0.52)&quot; &quot;M (SD) = 0.20 (0.40)&quot;</code></pre>
<p>Now, we visualize the data.</p>
<pre class="r"><code># plot data
ggplot(poissondata, aes(Pauses, fill = Language)) +
  geom_histogram(binwidth=.5, position=&quot;dodge&quot;) +
  scale_fill_manual(values=c(&quot;gray30&quot;, &quot;gray50&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="fixedregressions_files/figure-html/pr7-1.png" width="672" /></p>
<pre class="r"><code># calculate poissant regression
m1.poisson &lt;- glm(Pauses ~ Language + Alcohol, family=&quot;poisson&quot;, data=poissondata)
# inspect model
summary(m1.poisson)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Pauses ~ Language + Alcohol, family = &quot;poisson&quot;, 
##     data = poissondata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2043  -0.8436  -0.5106   0.2558   2.6796  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -4.16327    0.66288  -6.281 3.37e-10 ***
## LanguageGerman  -0.71405    0.32001  -2.231  0.02566 *  
## LanguageRussian -1.08386    0.35825  -3.025  0.00248 ** 
## Alcohol          0.07015    0.01060   6.619 3.63e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.67  on 199  degrees of freedom
## Residual deviance: 189.45  on 196  degrees of freedom
## AIC: 373.5
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>In addition to the Estimates for the coefficients, we could also calculate the confidence intervals for the coefficients (LL stands for lwoer limit and UL for upper limit in the table below).</p>
<pre class="r"><code>cov.m1 &lt;- vcovHC(m1.poisson, type=&quot;HC0&quot;)
std.err &lt;- sqrt(diag(cov.m1))
r.est &lt;- cbind(Estimate= coef(m1.poisson), &quot;Robust SE&quot; = std.err,
&quot;Pr(&gt;|z|)&quot; = 2 * pnorm(abs(coef(m1.poisson)/std.err), lower.tail=FALSE),
LL = coef(m1.poisson) - 1.96 * std.err,
UL = coef(m1.poisson) + 1.96 * std.err)
# inspect data
r.est</code></pre>
<pre><code>##                   Estimate  Robust SE     Pr(&gt;|z|)          LL          UL
## (Intercept)     -4.1632653 0.64809429 1.328638e-10 -5.43353007 -2.89300044
## LanguageGerman  -0.7140499 0.29864225 1.680312e-02 -1.29938873 -0.12871111
## LanguageRussian -1.0838591 0.32104816 7.354745e-04 -1.71311353 -0.45460476
## Alcohol          0.0701524 0.01043516 1.783975e-11  0.04969947  0.09060532</code></pre>
<pre class="r"><code>with(m1.poisson, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))</code></pre>
<pre><code>##      res.deviance  df         p
## [1,]     189.4496 196 0.6182274</code></pre>
<pre class="r"><code>## update m1 model dropping prog
m2.poisson &lt;- update(m1.poisson, . ~ . - Language)
## test model differences with chi square test
anova(m2.poisson, m1.poisson, test=&quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Pauses ~ Alcohol
## Model 2: Pauses ~ Language + Alcohol
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1       198     204.02                          
## 2       196     189.45  2   14.572 0.0006852 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>s &lt;- deltamethod(list(~ exp(x1), ~ exp(x2), ~ exp(x3), ~ exp(x4)), 
                                                coef(m1.poisson), cov.m1)

## exponentiate old estimates dropping the p values
rexp.est &lt;- exp(r.est[, -3])
## replace SEs with estimates for exponentiated coefficients
rexp.est[, &quot;Robust SE&quot;] &lt;- s

rexp.est</code></pre>
<pre><code>##                   Estimate  Robust SE         LL         UL
## (Intercept)     0.01555668 0.01008219 0.00436765 0.05540971
## LanguageGerman  0.48965711 0.14623230 0.27269844 0.87922793
## LanguageRussian 0.33828750 0.10860658 0.18030354 0.63469878
## Alcohol         1.07267164 0.01119351 1.05095521 1.09483681</code></pre>
<pre class="r"><code># extract predicted values
(s1 &lt;- data.frame(Alcohol = mean(poissondata$Alcohol),
  Language = factor(1:3, levels = 1:3, labels = names(table(poissondata$Language)))))</code></pre>
<pre><code>##   Alcohol Language
## 1  52.645  English
## 2  52.645   German
## 3  52.645  Russian</code></pre>
<pre class="r"><code>predict(m1.poisson, s1, type=&quot;response&quot;, se.fit=TRUE)</code></pre>
<pre><code>## $fit
##         1         2         3 
## 0.6249446 0.3060086 0.2114109 
## 
## $se.fit
##          1          2          3 
## 0.08628117 0.08833706 0.07050108 
## 
## $residual.scale
## [1] 1</code></pre>
<pre class="r"><code>## calculate and store predicted values
poissondata$Predicted &lt;- predict(m1.poisson, type=&quot;response&quot;)

## order by program and then by math
poissondata &lt;- poissondata[with(poissondata, order(Language, Alcohol)), ]</code></pre>
<pre class="r"><code>## create the plot
ggplot(poissondata, aes(x = Alcohol, y = Predicted, colour = Language)) +
  geom_point(aes(y = Pauses), alpha=.5, 
             position=position_jitter(h=.2)) +
  geom_line(size = 1) +
  labs(x = &quot;Alcohol (ml)&quot;, y = &quot;Expected number of pauses&quot;) +
  scale_color_manual(values=c(&quot;gray30&quot;, &quot;gray50&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="fixedregressions_files/figure-html/pr15-1.png" width="672" /></p>
</div>
<div id="robust-regression" class="section level1">
<h1><span class="header-section-number">7</span> Robust Regression</h1>
<p>Robust regressions are linear regressions with added weights <span class="citation">(Rousseeuw and Leroy <a href="#ref-rousseeuw2005robust">2005</a>)</span> and are thus used when a linear model is unduely affected by outliers but the data ponts should not be removed.</p>
<pre class="r"><code># load data
robustdata &lt;- read.delim(&quot;https://slcladal.github.io/data/robustdata.txt&quot;, sep = &quot;\t&quot;, header = T)
# inspect data
summary(robustdata)</code></pre>
<pre><code>##       sid           state        crime            murder      
##  Min.   : 1.0   ak     : 1   Min.   :  82.0   Min.   : 1.600  
##  1st Qu.:13.5   al     : 1   1st Qu.: 326.5   1st Qu.: 3.900  
##  Median :26.0   ar     : 1   Median : 515.0   Median : 6.800  
##  Mean   :26.0   az     : 1   Mean   : 612.8   Mean   : 8.727  
##  3rd Qu.:38.5   ca     : 1   3rd Qu.: 773.0   3rd Qu.:10.350  
##  Max.   :51.0   co     : 1   Max.   :2922.0   Max.   :78.500  
##                 (Other):45                                    
##     pctmetro         pctwhite         pcths          poverty     
##  Min.   : 24.00   Min.   :31.80   Min.   :64.30   Min.   : 8.00  
##  1st Qu.: 49.55   1st Qu.:79.35   1st Qu.:73.50   1st Qu.:10.70  
##  Median : 69.80   Median :87.60   Median :76.70   Median :13.10  
##  Mean   : 67.39   Mean   :84.12   Mean   :76.22   Mean   :14.26  
##  3rd Qu.: 83.95   3rd Qu.:92.60   3rd Qu.:80.10   3rd Qu.:17.40  
##  Max.   :100.00   Max.   :98.50   Max.   :86.60   Max.   :26.40  
##                                                                  
##      single     
##  Min.   : 8.40  
##  1st Qu.:10.05  
##  Median :10.90  
##  Mean   :11.33  
##  3rd Qu.:12.05  
##  Max.   :22.10  
## </code></pre>
<pre class="r"><code># create model
slm &lt;- lm(crime ~ poverty + single, data = robustdata)
# inspect model
summary(slm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = crime ~ poverty + single, data = robustdata)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -811.14 -114.27  -22.44  121.86  689.82 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1368.189    187.205  -7.308 2.48e-09 ***
## poverty         6.787      8.989   0.755    0.454    
## single        166.373     19.423   8.566 3.12e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 243.6 on 48 degrees of freedom
## Multiple R-squared:  0.7072, Adjusted R-squared:  0.695 
## F-statistic: 57.96 on 2 and 48 DF,  p-value: 1.578e-13</code></pre>
<p>We now check whether the model is well fitted using diagnostic plots.</p>
<pre class="r"><code># create model diagnost plots
opar &lt;- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(slm, las = 1)</code></pre>
<p><img src="fixedregressions_files/figure-html/rr3-1.png" width="672" /></p>
<pre class="r"><code>par(opar)</code></pre>
<p>The diagnostic plots indicate that there is an outlier in the data (data point 51). Therefore, we need to evaluate if the outlier severely affects the fit of the model.</p>
<pre class="r"><code>robustdata[c(9, 25, 51), 1:2]</code></pre>
<pre><code>##    sid state
## 9    9    fl
## 25  25    ms
## 51  51    dc</code></pre>
<pre class="r"><code>d1 &lt;- cooks.distance(slm)
r &lt;- stdres(slm)
a &lt;- cbind(robustdata, d1, r)
a[d1 &gt; 4/51, ]</code></pre>
<pre><code>##    sid state crime murder pctmetro pctwhite pcths poverty single        d1
## 1    1    ak   761    9.0     41.8     75.2  86.6     9.1   14.3 0.1254750
## 9    9    fl  1206    8.9     93.0     83.5  74.4    17.8   10.6 0.1425891
## 25  25    ms   434   13.5     30.7     63.3  64.3    24.7   14.7 0.6138721
## 51  51    dc  2922   78.5    100.0     31.8  73.1    26.4   22.1 2.6362519
##            r
## 1  -1.397418
## 9   2.902663
## 25 -3.562990
## 51  2.616447</code></pre>
<pre class="r"><code>rabs &lt;- abs(r)
a &lt;- cbind(robustdata, d1, r, rabs)
asorted &lt;- a[order(-rabs), ]
asorted[1:10, ]</code></pre>
<pre><code>##    sid state crime murder pctmetro pctwhite pcths poverty single
## 25  25    ms   434   13.5     30.7     63.3  64.3    24.7   14.7
## 9    9    fl  1206    8.9     93.0     83.5  74.4    17.8   10.6
## 51  51    dc  2922   78.5    100.0     31.8  73.1    26.4   22.1
## 46  46    vt   114    3.6     27.0     98.4  80.8    10.0   11.0
## 26  26    mt   178    3.0     24.0     92.6  81.0    14.9   10.8
## 21  21    me   126    1.6     35.7     98.5  78.8    10.7   10.6
## 1    1    ak   761    9.0     41.8     75.2  86.6     9.1   14.3
## 31  31    nj   627    5.3    100.0     80.8  76.7    10.9    9.6
## 14  14    il   960   11.4     84.0     81.0  76.2    13.6   11.5
## 20  20    md   998   12.7     92.8     68.9  78.4     9.7   12.0
##            d1         r     rabs
## 25 0.61387212 -3.562990 3.562990
## 9  0.14258909  2.902663 2.902663
## 51 2.63625193  2.616447 2.616447
## 46 0.04271548 -1.742409 1.742409
## 26 0.01675501 -1.460885 1.460885
## 21 0.02233128 -1.426741 1.426741
## 1  0.12547500 -1.397418 1.397418
## 31 0.02229184  1.354149 1.354149
## 14 0.01265689  1.338192 1.338192
## 20 0.03569623  1.287087 1.287087</code></pre>
<pre class="r"><code># create robust regression model
rmodel &lt;- rlm(crime ~ poverty + single, data = robustdata)
# inspect model
summary(rmodel)</code></pre>
<pre><code>## 
## Call: rlm(formula = crime ~ poverty + single, data = robustdata)
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -846.09 -125.80  -16.49  119.15  679.94 
## 
## Coefficients:
##             Value      Std. Error t value   
## (Intercept) -1423.0373   167.5899    -8.4912
## poverty         8.8677     8.0467     1.1020
## single        168.9858    17.3878     9.7186
## 
## Residual standard error: 181.8 on 48 degrees of freedom</code></pre>
<pre class="r"><code>hweights &lt;- data.frame(state = robustdata$state, resid = rmodel$resid, weight = rmodel$w)
hweights2 &lt;- hweights[order(rmodel$w), ]
hweights2[1:15, ]</code></pre>
<pre><code>##    state      resid    weight
## 25    ms -846.08536 0.2889618
## 9     fl  679.94327 0.3595480
## 46    vt -410.48310 0.5955740
## 51    dc  376.34468 0.6494131
## 26    mt -356.13760 0.6864625
## 21    me -337.09622 0.7252263
## 31    nj  331.11603 0.7383578
## 14    il  319.10036 0.7661169
## 1     ak -313.15532 0.7807432
## 20    md  307.19142 0.7958154
## 19    ma  291.20817 0.8395172
## 18    la -266.95752 0.9159411
## 2     al  105.40319 1.0000000
## 3     ar   30.53589 1.0000000
## 4     az  -43.25299 1.0000000</code></pre>
<pre class="r"><code>rr.bisquare &lt;- rlm(crime ~ poverty + single, data=robustdata, psi = psi.bisquare)
summary(rr.bisquare)</code></pre>
<pre><code>## 
## Call: rlm(formula = crime ~ poverty + single, data = robustdata, psi = psi.bisquare)
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -905.59 -140.97  -14.98  114.65  668.38 
## 
## Coefficients:
##             Value      Std. Error t value   
## (Intercept) -1535.3338   164.5062    -9.3330
## poverty        11.6903     7.8987     1.4800
## single        175.9303    17.0678    10.3077
## 
## Residual standard error: 202.3 on 48 degrees of freedom</code></pre>
<pre class="r"><code>biweights &lt;- data.frame(state = robustdata$state, 
                        resid = rr.bisquare$resid,
                        weight = rr.bisquare$w)
biweights2 &lt;- biweights[order(rr.bisquare$w), ]
biweights2[1:15, ]</code></pre>
<pre><code>##    state     resid      weight
## 25    ms -905.5931 0.007652565
## 9     fl  668.3844 0.252870542
## 46    vt -402.8031 0.671495418
## 26    mt -360.8997 0.731136908
## 31    nj  345.9780 0.751347695
## 18    la -332.6527 0.768938330
## 21    me -328.6143 0.774103322
## 1     ak -325.8519 0.777662383
## 14    il  313.1466 0.793658594
## 20    md  308.7737 0.799065530
## 19    ma  297.6068 0.812596833
## 51    dc  260.6489 0.854441716
## 50    wy -234.1952 0.881660897
## 5     ca  201.4407 0.911713981
## 10    ga -186.5799 0.924033113</code></pre>
<p>After inspecting the weights, we also want to extract the p-values for the predictors. The p-values have to be calculated separately using the “f.robftest” fucntion from the “sfsmisc” library.</p>
<pre class="r"><code>p_poverty &lt;- f.robftest(rmodel, var = &quot;poverty&quot;)
p_single &lt;- f.robftest(rmodel, var = &quot;single&quot;)
# inspect results
p_poverty; p_single</code></pre>
<pre><code>## 
##  robust F-test (as if non-random weights)
## 
## data:  from rlm(formula = crime ~ poverty + single, data = robustdata)
## F = 1.1691, p-value = 0.285
## alternative hypothesis: true poverty is not equal to 0</code></pre>
<pre><code>## 
##  robust F-test (as if non-random weights)
## 
## data:  from rlm(formula = crime ~ poverty + single, data = robustdata)
## F = 83.124, p-value = 4.77e-12
## alternative hypothesis: true single is not equal to 0</code></pre>
<p>The output shows that poverty is not a significant predictor while single correlates highly significanty with crime.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-achen1982interpreting">
<p>Achen, Christopher H. 1982. <em>Interpreting and Using Regression</em>. Vol. 29. Sage.</p>
</div>
<div id="ref-agresti1996introduction">
<p>Agresti, Alan. 1996. <em>An Introduction to Categorical Data Analysis</em>. Hoboken, NJ: JohnWiley &amp; Sons.</p>
</div>
<div id="ref-agresti2010analysis">
<p>———. 2010. <em>Analysis of Ordinal Categorical Data</em>. Vol. 656. John Wiley &amp; Sons.</p>
</div>
<div id="ref-agresti2011categorical">
<p>Agresti, Alan, and Maria Kateri. 2011. <em>Categorical Data Analysis</em>. Springer.</p>
</div>
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. a Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-bortz2006statistik">
<p>Bortz, Jürgen. 2006. <em>Statistik: Für Human-Und Sozialwissenschaftler</em>. Springer-Verlag.</p>
</div>
<div id="ref-bowerman1990linear">
<p>Bowerman, Bruce L, and Richard T O’Connell. 1990. <em>Linear Statistical Models: An Applied Approach</em>. Boston: PWS-Kent.</p>
</div>
<div id="ref-crawley2005statistics">
<p>Crawley, Michael J. 2005. <em>Statistics: An Introduction Using R. 2005</em>. Chichester, West Sussex: John Wiley &amp; Sons.</p>
</div>
<div id="ref-crawley2012r">
<p>———. 2012. <em>The R Book</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-faraway2002practical">
<p>Faraway, Julian J. 2002. <em>Practical Regression and Anova Using R.</em> University of Bath.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-green1991many">
<p>Green, Samuel B. 1991. “How Many Subjects Does It Take to Do a Regression Analysis.” <em>Multivariate Behavioral Research</em> 26 (3). Taylor &amp; Francis: 499–510.</p>
</div>
<div id="ref-gries2009statistics">
<p>Gries, Stefan Th. 2009. <em>Statistics for Linguistics Using R: A Practical Introduction</em>. Berlin &amp; New York: Mouton de Gruyter.</p>
</div>
<div id="ref-harrell2015regression">
<p>Harrell Jr, Frank E. 2015. <em>Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis</em>. Springer.</p>
</div>
<div id="ref-menard1995applied">
<p>Menard, Scott. 1995. <em>Applied Logistic Regression Analysis: Sage University Series on Quantitative Applications in the Social Sciences</em>. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-myers1990classical">
<p>Myers, Raymond H. 1990. <em>Classical and Modern Regression with Applications</em>. Vol. 2. Duxbury Press Belmont, CA.</p>
</div>
<div id="ref-rousseeuw2005robust">
<p>Rousseeuw, Peter J, and Annick M Leroy. 2005. <em>Robust Regression and Outlier Detection</em>. Vol. 589. John wiley &amp; sons.</p>
</div>
<div id="ref-szmrecsanyi2006morphosyntactic">
<p>Szmrecsanyi, Benedikt. 2006. <em>Morphosyntactic Persistence in Spoken English: A Corpus Study at the Intersection of Variationist Sociolinguistics, Psycholinguistics, and Discourse Analysis</em>. Berlin &amp; New York: Walter de Gruyter.</p>
</div>
<div id="ref-wilcox2009basic">
<p>Wilcox, Rand R. 2009. <em>Basic Statistics: Understanding Conventional Methods and Modern Insights</em>. Oxford University Press.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” <em>Methods in Ecology and Evolution</em> 1 (1): 3–14.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
