<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-01-24" />

<title>Basics of Quantitative Reasoning</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
    <li>
      <a href="researchdesigns.html">Research Designs</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="loading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization Techniques</a>
    </li>
    <li>
      <a href="advancedgraphs.html">Advanced Visualization Techniques</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptives.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Interential Statistics</a>
    </li>
    <li>
      <a href="advancedstatz.html">Advanced Interential Statistics</a>
    </li>
    <li>
      <a href="groupingstatz.html">Clustering</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis and Corpus Linguistics</li>
    <li>
      <a href="page-c.html">Network Analysis</a>
    </li>
    <li>
      <a href="page-c.html">Topic Modeling</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
    <li>
      <a href="corplingantconcexcel.html">Corpus Linguistics with AntConc, TextPad and Excel</a>
    </li>
    <li>
      <a href="available.html">Available Software</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Basics of Quantitative Reasoning</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-01-24</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>Science can be defined as a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe <span class="citation">(Wilson 1999, 58)</span>. One of the most fundamental concepts in that definition is the concept of testable explanations. Another name for such explanations is “hypothesis”. Thus, Edward Wilson’s definition of science can be rephrased (somewhat crudely) as the methodological testing of hypotheses. This goes to show that hypotheses are at the very heart of the scientific endeveor and, in the fowllowing, we will try to understand what hypotheses are, how to formulate them, and what logic underpins hypothesis testing. To begin with, we will focus on a practical example to avoid talking merely about abstract ideas. The example we will look at is the English comparative construction.</p>
</div>
<div id="primer-comparatives-in-english" class="section level1">
<h1><span class="header-section-number">2</span> Primer: Comparatives in English</h1>
<p>In English, the comparative forms of adjectives can be formed according to two strategies: either synthetically/morphologically as in <a href="#1ex">(1)</a> or analytically/periphrastically as in <a href="#2ex">(2)</a>.</p>
<p>As a general rule, the comparative of adjectives that have only one syllable are formed by using the morphological strategy while adjectives that have three or more syllables are formed using the periphrastic strategy. However, in some cases where adjectives consist of two syllables, speakers may choose which strategy they apply. In our example, we want to find out, how to proceed when trying to understand the reasons why a speakers chooses the first strategy in one case and the second strategy in another.</p>
<ol style="list-style-type: decimal">
<li><p>synthetic/morphological comparative {#1ex}<br />
proud <span class="math inline">\(\rightarrow\)</span> prouder</p></li>
<li><p>analytic/periphrastic comparative {#2ex}<br />
proud <span class="math inline">\(\rightarrow\)</span> more proud</p></li>
</ol>
<p>To investigate this phenomenon more closely, we should first determine which variables or factors influence which comparative strategy a speaker uses. To answer whcih factors afffect the comparative choice, we need to have a look at the respective literature. In the literature on the English comparative constructions the follwoing influencing factors ahve been named:</p>
<p><strong>Length of the adjective</strong></p>
<p>Adjectives that consits of a single syllable tend to form the comparative form via the morphological strategy as in () while multisyllabic adjectives tend to form the comparative via the periphrastic strategy as in ().</p>
<ol start="3" style="list-style-type: decimal">
<li><p>synthetic/morphological comparative: cool <span class="math inline">\(\rightarrow\)</span> cooler {#3ex}</p></li>
<li><p>analytic/periphrastic comparative: attractive <span class="math inline">\(\rightarrow\)</span> more attractive {#4ex}</p></li>
</ol>
<p><strong>Syntactic Function</strong></p>
<p>Adjectives in attributive position prefer the morphological strategy, while adjectives in predicative position prefer the the periphrastic strategy.</p>
<ol start="5" style="list-style-type: decimal">
<li><p>“<em>The prouder boy of the two was smiling</em>.” {#5ex}</p></li>
<li><p>“<em>The boy to the left was more proud</em>.” {#6ex}</p></li>
</ol>
<p><strong>Ending</strong></p>
<p>Adjectives which end in –ly or -y prefer the morphological strategy.</p>
<p><strong>Subsequent <em>than</em></strong></p>
<p>If a <em>than</em> follows the comparative, then the adjective prefers the morphological strategy as in ().</p>
<ol start="7" style="list-style-type: decimal">
<li>“<em>This joke is funnier than the other one</em>.” {#7ex}</li>
</ol>
<p>It helps to create an overview table for the variables that have been shown in the literature to significantly affect the choice of the comparative strategy. Both better and worse examples of such overview tables are shown in <span class="citation">(Gries 2009, 27–30)</span>. To answer our example question, we have to define the variables in order to formulate a proper hypothesis in the next step.</p>
<p>An example for such a hypothesis would, for instance, be “<em>If an adjectives has only one syllable, then a typical native speaker will prefer the morphological variant</em>”. The next question then is how to test such a hypothesis and which concepts underly hypothesis testing. And these questions and issues are addressed below.</p>
</div>
<div id="hypotheses" class="section level1">
<h1><span class="header-section-number">3</span> Hypotheses</h1>
<p>Probabaly the most important task in empirical research is hypothesis testing. A proper scientific hypothesis is commonly - but not neccessarily - a general assumption in the form of a statement. Hypotheses are tested by comparing systematic observation with the predictions of the hypothesis. More specifically, in order to test hypothesis one seeks for observations which contradict and are at odds with the hypothesis. If we find such a counter example and we have determined that it is an accurate observation, then the hypothesis is falsified, i.e. is is not correct.</p>
<p>If we proposed the hypothesis “Apples always fall down.” and we find an example of an apple not falling down, then our hypothesis would be falsified.</p>
<blockquote>
<p>Discussion Time!</p>
<p>Can you thnk of cases where apples do not fall down? How would we have to modify our hypothesis to accommodate potential counter-examples?</p>
</blockquote>
<p>The fact that hypothesis must be falsifiable is a defining feature of hypotheses and it means that for a statement to be a hypothesis, it must be falsifiable (which does not mean that it must be false!).</p>
<p>The for trying to falsifying rather than prooving or validating hypothesis, lies in the act that falsification is possible while providing proof for an emirical fact is impossible: If we make only one observation which refutes a hypothesis, the hypothesis is falsified. No matter how many evidence we have for that hypothesis, the hypothesis remains falsified. It is therefore impossible to proove an empirical hypothesis! There are, however, statements that cannot be disproven or falsified - either for technical reasons (@ref(exh3)) or because they are subjectiv (@ref(exh4)).</p>
<ol style="list-style-type: decimal">
<li><p>There are forms of life in the Andromeda galaxy. {#exh3}</p></li>
<li><p>I like chocolate ice cream better than vanilla ice cream. {#exh4}</p></li>
</ol>
<p>Statements that cannot be falsified are called “speculation”. Speculation is nothing bad or somehting worthless - on the contrary! - but they simply fall outside of the realm of empirical science. Exacmples for the creativity and the usefulness of specualtion are, for instance, art, literture, music, and philosophy.</p>
<p>Summing up, hypotheses can be defined as possessing at least four criteria:</p>
<ul>
<li><p>Hypotheses are falsifiziable statements about empirical reality.</p></li>
<li><p>Hypothesen are testable statments about the empirical world.</p></li>
<li><p>Hypothese are unambigious.</p></li>
<li><p>Hypotheses are inherently consistent.</p></li>
</ul>
<p>Universality cannot be considered a defining feature of hypotheses, because it is - striktly speaking - not neccessary. For instance, we could formulate the hypothesis that a certain archeological model is correct, if we find certain artefacts at a specific place in a certain layer of earth. This hypothesis relates to a a very specific singular event but it would still be a falsifiable and testatble statement (and thus a hypothesis).</p>
<div id="types-of-hypotheses" class="section level2">
<h2><span class="header-section-number">3.1</span> Types of Hypotheses</h2>
<p>On a very fiúndamental level, we can differentiate between null-hypotheses (H<span class="math inline">\(_{0}\)</span>), that claim non-existence of either a state of being or a difference, and alternative or test-hypothesis (H<span class="math inline">\(_{1}\)</span>) that claim or postulate the existence of of either a state of being or a difference. Among test-hypotheses, we can furthermore distinguish between undirected hypotheses which claim that one sample is different from another sample, and directed hypotheses which claim that a feature of one sample is bigger, smaller, more frequent, or less frequent, etc. Thus, a hypothesis that group A will perform better in an exam is a diercted testhypothesis while an undirected hypothesis would merely claim that they differ in their test restults. In cotrast, the null-hypothesis would claim that there is no difference between the groups in terms of their performance in that exam.</p>
<p>An additional distinction among hypotheses is the difference between deterministic and probabilistic hypotheses. While we are edaling with a determinitic hypothesis in () because it is a categorical claim, we are dealing with a probabilistic hypothesis in () bcause, here, the hypothesis simply claims that the likelihood of Y is higher if X is the case (but not neccessarily categorically).</p>
<ol start="10" style="list-style-type: decimal">
<li><p>If the length of two words in an English phrase is different, then the shorter word will always preceed the longer word. {#exh1}</p></li>
<li><p>If the length of two words in an English phrase is different, then it is more likely for the shorter word to preceed the longer word than vice versa. {#exh2}</p></li>
</ol>
</div>
<div id="why-testing-the-null-hypothesis" class="section level2">
<h2><span class="header-section-number">3.2</span> Why Testing The Null-Hypothesis?!</h2>
<p>Although it is counter-intuitive, we do not actually test the test-hypothesis but we test the null-hypothesis. This means that hypothesis testing in empirical research typically follows the scheme described below.</p>
<ol style="list-style-type: decimal">
<li><p>Make an observation (e.g. <em>My keys are gone!</em>)</p></li>
<li><p>Deduce a Test-Hypothesis (H<sub>1</sub>) based on observation (e.g. <em>My keys are on the table next to the TV!</em>)</p></li>
<li><p>Formulate Nullhypothesis (H<sub>0</sub>) (e.g. <em>My keys are not on the table next to the TV!</em>)</p></li>
<li><p>Determining the level of significance at which the H<sub>0</sub> is rejected ()</p></li>
<li><p>Formulate potential results: what resulst are possible wnad what do they mean for the H<sub>0</sub> and H<sub>1</sub>? (<em>My keys are not on the table next to the TV!</em>: H<sub>0</sub> cannot be rejected, formulate new H<sub>1</sub>)</p></li>
<li><p>Design experiment/study/research (e.g. <em>I will go over to the TV and see if my keys on the table next to the TV.</em>)</p></li>
<li><p>Conduct experiment/study/research (e.g. <em>Actually go over to the TV and see if my keys on the table next to the TV.</em>)</p></li>
<li><p>Statistical analyse</p></li>
<li><p>Interpretation of the results (e.g. <em>My keys are not on the table next to the TV so I must have lost them elsewhere!</em>)</p></li>
<li><p>In case H<sub>0</sub> could not be rejected: Formulate new H<sub>1</sub>. (e.g. <em>My keys are on the kitchen table!</em>)</p></li>
</ol>
<p>We will now have acloser lok at how to formulate hypotheses and that formulating hypotheses is formulating expected outcomes/explanations in a formal descritption.</p>
<ul>
<li><p>Nullhypothesis (H_{0}) Groups A and B do not differ systematically! (<span class="math inline">\(\mu\)</span>A = <span class="math inline">\(\mu\)</span>B)</p></li>
<li><p>Testhypothesis (H_{1}a) Groups A and B differ systematically! (<span class="math inline">\(\mu\)</span>A <span class="math inline">\(\neq\)</span> <span class="math inline">\(\mu\)</span>B; ungerichtet)</p></li>
<li><p>Testhypothesis (H_{1}b) Group A has significantly better results/higher levels of x compared with group B. (<span class="math inline">\(\mu\)</span>A <span class="math inline">\(&gt;\)</span> <span class="math inline">\(\mu\)</span>B; gerichtet)</p></li>
</ul>
<p>Was bedeutet das nun und was testen wir eigentlich? Wir testen, wie wahrscheinlich es ist, das die Ergebnisse durch Zufall zustande gekommen sind. Ist die Wahrscheinlichkeit hoch (p <span class="math inline">\(\ge\)</span> .05), dass die Ergebnisse zufällig zustande gekommen sind, dann verwerfen wir die H_{0} nicht. Ist die Wahrscheinlichkeit gering (p <span class="math inline">\(&lt;\)</span> .05), dass die Ergebnisse zufällig zustande gekommen sind, dann verwerfen wir die H_{0} und nehmen statt dessen die H_{1} an! Um diese Logik besser zu verstehen, werden wir im Folgenden auf Wahrscheinlichkeiten eingehen und welche Rolle diese in der quantitativen Forschung spielen.</p>
<p>% bearbeiten XXX</p>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">3.3</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Which of the follwoing sentences are hypotheses? Briefly explain your results!</li>
</ol>
<ul>
<li><p>Smoking could have negative effects on one’s health.</p></li>
<li><p>Alcohol is a gateway drug.</p></li>
<li><p>If alcohol is a gateway drug, then it should be criminalized.</p></li>
<li><p>If alcohol is a gateway drug but tabacco is not, then a significantly higher proportion of drug addicts have consumed alcohol compared with the proportion of drug addicts who have smoked before taking drugs.</p></li>
<li><p>Alcohol is a gateway drug, when/if it is illegal.</p></li>
<li><p>Colorless green ideas sleep furiously.</p></li>
<li><p>Nightingales dream in Italian.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>What four characteristics do hypotheses have?</p></li>
<li><p>Come up with (a) three directed hypotheses and (b) three undirected hypotheses.</p></li>
<li><p>Oftentimes, it is not that easy to differentiate between hypotheses and other types of statements. Find a partner and come with statemenst that are not hypotheses and discuss why these statements are not hypotheses.</p></li>
<li><p>Find a partner and come up with statements that can be classified as both hypotheses and non-hypotheses and be prepared to explain your reasoning to the group.</p></li>
</ol>
</div>
</div>
<div id="signifikanz" class="section level1">
<h1><span class="header-section-number">4</span> Significance and Probability</h1>
<p>Hypothesis testing fundamentally builds on probabilites - or more precisely probabilities of error which is an estimation for the likelihood of the H<sub>0</sub> being true given the data. This type of probability is typically providde in the form of p-values. In a more prosaic (and also coarse-grained, imprecise manner), p-values are an estimate of how likely an outcome is a result of chance. We will delve a little deeper into probabilities and how they relate to hypothesis testing below.</p>
<div id="significance-levels" class="section level2">
<h2><span class="header-section-number">4.1</span> Significance Levels</h2>
<p>Before consucting a study, it is adviasble to determine the so-called significance or <span class="math inline">\(\alpha\)</span> level. This <span class="math inline">\(\alpha\)</span> level of significance Signifikanzniveau gibt an, wie hoch bzw. niedrig der p-Wert sein darf ohne dass man davon ausgehen muss, das kein signifikanter Zusammenhang zwischen den untersuchten Variablen vorliegt. Es ist hierbei gebräuchlich zwischen drei Stufen des <span class="math inline">\(\alpha\)</span> Signifikanzniveaus unterscheiden:</p>
<ul>
<li><p>p &lt; .001: <em>highly significant</em> - indicated by three stars (***)</p></li>
<li><p>p &lt; .01: <em>very significant</em> - indicated by two stars (**)</p></li>
<li><p>p &lt; .05: <em>significant</em> - indicated by one star (*)</p></li>
</ul>
<p>Wie bereits gesagt, müssen wir, bevor wir testen, einen Wert festlegen, ab dem wir die Nullhypothese ablehnen, das sogenannte Signifikanzniveau. Es liegt normalerweise bei 5%. Wenn die Irrtumswahrscheinlichkeit kleiner als 5% ist (<span class="math inline">\(p&lt;\)</span>.05), lehnen wir die Nullhypothese ab. Schlussfolgerung: Der Zusammenhang zwischen den Variablen ist statistisch signifikant (WICHTIG: Nur, weil die Nullhypothese abgelehnt werden kann, heißt das nicht, dass H_{1} (oder Testhypothese) bewiesen wurde. Statistik kann Hypothesen NIE beweisen.).</p>
</div>
<div id="probability" class="section level2">
<h2><span class="header-section-number">4.2</span> Probability</h2>
<p>In the following, we will turn to probability and try to understand why probabilty is relevant for testing hypotheses. This is important at this point because statistics, and thus hypothesis testing, fundamentally builds upon probabilies and probability distributions. In order to understand how probability works, we will investaigte what happens when we flip a coin. The first question that we will be addressing is “<em>What is the probablility of getting three Heads when flipping a coin three times?</em>”.</p>
<p>The probablility of getting three heads when flipping a coin three times is .5 to the power of 3: .5<sup>3</sup> = .5 times .5 times .5 = .125. The probability of getting Heads twice when flipping the coin three times is .375. How do we know?</p>
<p>The probability of getting 3 heads in tree tosses is 12.5 percent:</p>
<p>.5<sup>3</sup> = .5 * .5 * .5 = .125</p>
<p>The probability of getting 2 heads in tree tosses is 37.5 percent:</p>
<p>.125 + .125 + .125 = 0.375</p>
<p>But how do we know this? Well, have alook at the table below.</p>
<hr />
<table>
<caption>Probabilities of Heads and Tails in 3 Coin Tosses.</caption>
<thead>
<tr class="header">
<th align="center">1<sup>st</sup> Toss</th>
<th align="center">2<sup>nd</sup> Toss</th>
<th align="center">3<sup>rd</sup> Toss</th>
<th align="center">Heads</th>
<th align="center">Tails</th>
<th align="center">Probabilty</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Head</td>
<td align="center">Head</td>
<td align="center">Head</td>
<td align="center">3</td>
<td align="center">0</td>
<td align="center">0.125</td>
</tr>
<tr class="even">
<td align="center">Head</td>
<td align="center">Head</td>
<td align="center">Tails</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">0.125</td>
</tr>
<tr class="odd">
<td align="center">Head</td>
<td align="center">Tails</td>
<td align="center">Head</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">0.125</td>
</tr>
<tr class="even">
<td align="center">Tails</td>
<td align="center">Head</td>
<td align="center">Head</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">0.125</td>
</tr>
<tr class="odd">
<td align="center">Head</td>
<td align="center">Tails</td>
<td align="center">Tails</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0.125</td>
</tr>
<tr class="even">
<td align="center">Tails</td>
<td align="center">Head</td>
<td align="center">Tails</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0.125</td>
</tr>
<tr class="odd">
<td align="center">Tails</td>
<td align="center">Tails</td>
<td align="center">Head</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0.125</td>
</tr>
<tr class="even">
<td align="center">Tails</td>
<td align="center">Tails</td>
<td align="center">Tails</td>
<td align="center">0</td>
<td align="center">3</td>
<td align="center">0.125</td>
</tr>
</tbody>
</table>
<hr />
<p>Given this table, we are in fact, in a position to calculate the probability of getting 100 heads in 100 coin tosses because we can simply fill in the numbers in the formulas used above: .5<sup>100</sup> = 7.888609 * 10<sup>-31</sup></p>
<p>Okay, let us make a bet..</p>
<ul>
<li><p>If head shows, I win a dollar.</p></li>
<li><p>If tails shows, you win a dollar.</p></li>
</ul>
<p>But given that you know I am cheeky bastard, you do not trust me and calim that I will cheat. But how will you know that I cheat? At which point can you claim that the result is so unlikely that you are (scientifically backed) allowed to claim that I cheat and have manipulated the coin?</p>
<p>So before we actually start with the coin tossing, you operationalize your hypothesis:</p>
<ul>
<li><p>H<sub>0</sub>: The author (I) is not cheating (heads shows just as often as tails).</p></li>
<li><p>H<sub>1</sub>: The author (I) is cheating (heads shows so often that the probability of the author not cheating is lower than 5 percent)</p></li>
</ul>
<p>We now throw the coin and head shows twice. The question now is whther head showing twice is lower than 5 percent.</p>
<p>Wir werfen 3 mal. Kopf fällt 2 mal. Wie wahrscheinlich ist es, dass ich nicht schummele und Kopf trotzdem mehr als 2 mal fällt? (In anderen Worten: Was ist die Wahrscheinlichkeit p, dass ich 2 mal oder mehr gewinne und nicht schummele?) Wenn Sie das Signifikanzniveau bei .05 ansetzen, könnten Sie mich dann als Schummler bezichtigen?\[.2cm]</p>
<p>As you can see in the fourth column, there are three options that lead to heads showing twice (rows 2, 3, and 4). If we add these up (0.125 + 0.125 + 0.125 = 0.375). Also, we need to add the case where head shows 3 times which is another .125 (0.375 + 0.125 = .5), then we find out that the probabilty of heads showing at least twice in three coin tosses is 50 percent and thus 10 times more than the 5-percent threshold that we set initially. Therefore, you cannot claim that I cheated.</p>
<table>
<thead>
<tr class="header">
<th align="center">0 Heads</th>
<th align="center">1 Time Head</th>
<th align="center">2 Times Heads</th>
<th align="center">3 Times Heads</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.125</td>
<td align="center">0.375</td>
<td align="center">0.375</td>
<td align="center">0.125</td>
</tr>
</tbody>
</table>
<p><img src="basicquant_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Calculating the probabilities for three coin tosses is still managable manually but is there an easier way to calculate probabilities? A handier way is have a computer caluculate probabilities and the code below shows how to do that in <code>R</code> - a very powerful and flexible programming environment that has been designed for quantitative analysis (but <code>R</code> can, in fact, do much more - this website, for instance, is programmed in <code>R</code>).</p>
<pre class="r"><code># probabilies of  0, 1, 2 and 3 times head in 3 coin tosses
dbinom(0:3, 3, 0.5)</code></pre>
<pre><code>## [1] 0.125 0.375 0.375 0.125</code></pre>
<pre class="r"><code># probabilies of  2 or 3 times head in 3 coin tosses
sum(dbinom(2:3, 3, 0.5))</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="r"><code># probabily of  100 times head in 100 coin tosses
dbinom(100, 100, 0.5)</code></pre>
<pre><code>## [1] 7.888609e-31</code></pre>
<pre class="r"><code># probabily of  58 to a 100 times head in 100 coin tosses
sum(dbinom(58:100, 100, 0.5))</code></pre>
<pre><code>## [1] 0.06660531</code></pre>
<pre class="r"><code># probabily of  59 to a 100 times head in 100 coin tosses
sum(dbinom(59:100, 100, 0.5))</code></pre>
<pre><code>## [1] 0.04431304</code></pre>
<pre class="r"><code># at which point does the probability of getting head 
# dip below 5 percent in 100 coin tosses?
qbinom(0.05, 100, 0.5, lower.tail=FALSE)</code></pre>
<pre><code>## [1] 58</code></pre>
<p>In our example, we dealing with a directed hypothesis and not with an undirected hypothesis because we claimed in our H<sub>1</sub> that I was cheating and would get more heads than would be expected by chance. For this reason, the test we use is one-tailed. When dealing with undirected hypotheses, you simply claim that the outcome is either higher or lower - in other words the test is two-tailed as you do not know in which direction the effect will manifest itself.</p>
<p>To understand this a more thoroughly, we will consider tossing a coin not merely 3 but 100 times. The Figure below shows the probabilities for the number of heads showing when we toss a coin 100 from 0 occurrences to 100 occurrences.</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The next Figure shows at which number of heads the cumulative probabilities dip below 5 percent for two-tailed hypotheses. According to the graph, if head shows up to 40 or more often than 60 times, the cumulative probability dips below 5 perent. Applied to our initial bet, you could thus claim that I ceated if head shows less than 41 times or more than 60 times (if out hypothesis were two-tailed - which it is not).</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>The Figure below shows at which point the probability of heads showing dips below 5 percent for one-tailed hypotheses. Thus, according to the Figure below, if we toss a coin 100 times and head shows 59 or more often, then you are justified in claiming that I cheated.</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>When compaing the two Figures above, it is notable that the number at which you can claim I cheated differs according to whether the H<sub>1</sub> as one- or two-tailed. When formulating a one-tailed hypothesis, then the number is lower compared with the the number at which you can reject the H<sub>0</sub> if your H<sub>1</sub> is two-tailed. This is actually th reason for why it is preferable to formulare more precise, one-tailed hypotheses ( as then, it is easier for the data to be sufficient to reject the H<sub>0</sub>).</p>
</div>
<div id="the-normal-distribution" class="section level2">
<h2><span class="header-section-number">4.3</span> The Normal Distribution</h2>
<p>It is important to note here that the above described calculation of probabilities does not work for numeric variables that are intervall-scaled. The reason for this is that it is not possible to calculate the probabilities for all possible outcomes of a reaction time experiment. In such cases, we rely on distribution (typically the normal distribution) in order to detremine how likely or probable a certain outcome is. When relying on distributions, we determine whether a certain values falls within or outside of the area of a distribution that accounts for 5 percent of the entire area of the distribution - if it falls within the area that accounts for less tha 5 percent of the total area, then the resul is called statistically significant (see the normal distribution below).</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>The normal distribution (or Gaussian curve or Gaussian distribution) shown in the Figure above has certain characteristics that can be derived mathematically. Some of these characteristcs relate to the area of certain sections of that distribution and the mean, median, and mode are identical (and are at the value of the highest point of the normal distribution).</p>
<p>In addition, 50 percent of the total area under the curve are to left and 50 percent of the right of the mean value. Furthermore, 68 percent of the area are within -1 and +1 standard devaitions from the mean; 95 percent of the area lie between -2 and +2 standard devaitions from the mean; 99.7 percent of the area lie between -3 and +3 standard devaitions from the mean.</p>
<p>In addition, 5 percent of the area lie outside -1.96 and +1.96 standard devaitions from the mean (if these areas are combined) (see the Figure below).</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Finally, 5 percent of the area lies beyond +1.68 standard devaitions from the mean (see the Figure below).</p>
<p><img src="basicquant_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>These properties are extremely useful when determining the likelihood of values or outcomes that reflect certain intervall-scalled variables.</p>
</div>
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">4.4</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>Create a table with the possible outcomes and probabilities of 4 coin tosses (you can consider the table showing the outcomes of three coin tossse above as a guideline).</p></li>
<li><p>How likely is it for heads to show exactly 3 times when tossing a coin 7 times?</p></li>
<li><p>How likely is it for heads to show exactly 2 or 5 times when tossing a coin 7 times?</p></li>
<li><p>How likely is it for heads to show 5 or more times when tossing a coin 7 times?</p></li>
<li><p>How likely is it for heads to show between 3 and 6 times when tossing a coin 7 times?</p></li>
</ol>
</div>
</div>
<div id="what-to-do-with-non-normal-data" class="section level1">
<h1><span class="header-section-number">5</span> What To Do With Non-Normal Data</h1>
<pre><code>## [1] 14.2</code></pre>
<pre><code>## [1] 14.2</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  k1
## W = 0.75258, p-value = 0.03144</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  k2
## W = 0.56501, p-value = 0.0002032</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     9.2     9.6    11.4    14.2    13.7    27.1</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     0.0     0.5     0.7    14.2     1.1    68.7</code></pre>
<pre><code>##  25%  50%  75% 
##  9.6 11.4 13.7</code></pre>
<pre><code>## 25% 50% 75% 
## 0.5 0.7 1.1</code></pre>
<pre><code>## [1]  9.2 27.1</code></pre>
<pre><code>## [1]  0.0 68.7</code></pre>
<pre><code>## [1] 2.2</code></pre>
<pre><code>## [1] 0.4</code></pre>
<pre><code>## [1] 4.1</code></pre>
<pre><code>## [1] 0.6</code></pre>
<pre><code>##   id text.id subfile spk.ref             zone      date    sex   age
## 1  1 S1A-001       1       A northern ireland 1990-1994   male 34-41
## 2  2 S1A-001       1       B northern ireland 1990-1994 female 34-41
## 3  4 S1A-002       1       A northern ireland 2002-2005 female 26-33
## 4  5 S1A-002       1       B northern ireland 2002-2005 female 19-25
## 5  6 S1A-002       1       C northern ireland 2002-2005   male   50+
## 6  7 S1A-002       1       D northern ireland 2002-2005 female   50+
##    reside      relig word.count
## 1 belfast protestant        765
## 2 belfast protestant       1298
## 3 belfast   catholic        391
## 4 belfast   catholic         47
## 5 belfast   catholic        200
## 6 belfast   catholic        464</code></pre>
<p><img src="basicquant_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mydata$word.count
## W = 0.82322, p-value &lt; 2.2e-16</code></pre>
<p><img src="basicquant_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<pre><code>## [1] 617</code></pre>
<pre><code>## [1] 573</code></pre>
<p><img src="basicquant_files/figure-html/unnamed-chunk-22-3.png" width="672" /><img src="basicquant_files/figure-html/unnamed-chunk-22-4.png" width="672" /></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mydata$logwc
## W = 0.90171, p-value &lt; 2.2e-16</code></pre>
<p><img src="basicquant_files/figure-html/unnamed-chunk-22-5.png" width="672" /></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mydata$sqrtwc
## W = 0.96771, p-value = 2.075e-10</code></pre>
</div>
<div id="alpha-and-beta-errors" class="section level1">
<h1><span class="header-section-number">6</span> Alpha and Beta Errors </h1>
<p>Die Frage ist nun, warum man im vorherigen Beispiel nicht einen einfachen <span class="math inline">\(\chi\)</span>^{2}-Test rechnen sollte. Das stärkste Argument dagegen ist hat mit einem sehr gewichtigen Problem zu tun, welches dazu unter anderem geführt hat, dass multivariate Verfahren entwickelt wurden: Dem Ansteigen der Fehlerrate bei wiederholten Tests. Wir haben in Sektion  gesehen, dass wir gewöhnlich ein Signifikanzniveau von 5% annehmen. Dies bedeutet aber auch, dass durchschnittlich bei jedem 20.sten Test, der einen Signifikanzwert von .05 hat eine Fehleinschätzung vorliegt, da durchschnittlich eines von 20 als signifikant  Ergebnissen in Wirklichkeit auf einer zufälligen Verteilung beruht und damit nicht durch die gemessenen Faktoren verursacht wurde. Rechnen wir nun mehrere Tests in Folge, so summieren sich diese Wahrscheinlichkeiten und schon bei 4 Tests, die aufeinander folgen 18.5% wie man mit Formel  leicht errechnen kann (cf. Formel ).</p>
<span class="math display">\[\begin{equation}
1 - .95^{n} = Fehler
\label{eq:inflatederrors}
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
1 - .95^{4} = 1 - 0.814 = 0.185
\label{eq:inflatederrorsbsp}
\end{equation}\]</span>
<p>Wir werden auf dieses Beispiel zurückkommen, aber zuerst werden wir unterschiedliche Arten von Fehlern betrachten.</p>
<p>Man unterscheidet zwischen <span class="math inline">\(\alpha\)</span>- (alpha) und <span class="math inline">\(\beta\)</span>-Fehlern (beta), wobei <span class="math inline">\(\alpha\)</span>-Fehler aussagen, dass ein Zusammenhang besteht, obwohl er in der empirischen Wirklichkeit nicht besteht. Bei <span class="math inline">\(\beta\)</span>-Fehlern wird davon ausgegangen, dass ein Zusammenhang nicht besteht, obwohl er in der empirischen Wirklichkeit vorhanden ist (vgl. Tabelle ).</p>

<p>Zu dem Unterschied zwischen <span class="math inline">\(\alpha\)</span>– und <span class="math inline">\(\beta\)</span>–Fehlern läßt sich sagen, dass generell <span class="math inline">\(\beta\)</span>–Fehler zu bevorzugen sind, da sie lediglich aussagen, dass aufgrund der Datenlage nicht davon ausgegangen werde kann, dass <span class="math inline">\(X\)</span> oder <span class="math inline">\(Y\)</span> der Fall ist, während bei <span class="math inline">\(\alpha\)</span>–Fehlern falsche Aussagen Teil des anerkannten Wissens werden. Als Daumenregel gilt, dass konservativeres und zurückhaltenderes Verhalten wissenschaftstheoretisch weniger problematisch ist und somit eher <span class="math inline">\(\alpha\)</span>– als <span class="math inline">\(\beta\)</span>–Fehler vermieden werden sollten.</p>
<p>Nachdem wir nun geklärt haben, welche Arten von Fehlern es gibt und dass sich Fehler aufsummieren, betrachten wir einen verwandten Begriff:  (Independence).</p>
</div>
<div id="independence" class="section level1">
<h1><span class="header-section-number">7</span> Independence </h1>
<p>Wäre es so, dass sich Fehler immer aufaddieren, dann wäre Statistik nicht möglich, da jeder neue Test alle vorhergehenden Tests berücksichtigen müsste und durch das Aufsummieren der Fehler die Fehlerrate gegen Unendlich tendieren würde. Es kann also nicht so sein, dass sich Fehler immer aufsummieren. Was bestimmt nun, ob sich Fehler aufsummieren oder nicht? Die Antwort lautet: Unabhängigkeit.</p>
<p>Wenn Tests voneinander unabhängig sind, dann summieren sich deren Fehler nicht auf, wenn Sie allerdings miteinander in einem Zusammenhang stehen, dann summieren sich die Fehler. Unabhängigkeit hat in der Statistik allerdings eine von der Alltagssprache abgewandelte Bedeutung: In der Statistik versteht man unter Unabhängigkeit die Unabhängigkeit der Hypothesen. Handelt es sich um Spezifikationen von allgemeineren Hypothesen, so sind die spezifizierten Hypothesen nicht unabhängig von der allgemeinen Hypothese, und sie sind nicht unabhängig von den anderen spezifizierten Hypothesen. In anderen Worten, wenn wir mehrere spezielle Hypothesen im Rahmen einer allgemeineren Hypothese testen, dann sind die Hypothesen streng genommen nicht unabhängig und können nicht so behandelt werden.</p>
<p>Ein verwandtes Phänomen haben wir in Sektion  kennengelernt: Der Grund warum wir nicht einfach einen neuen <span class="math inline">\(\chi\)</span>^{2}-Test rechnen konnten liegt darin, dass erst ein Test durchgeführt würde, bzw. wurde eine Tabelle erstellt unter der Annahme, dass sich die Emotionsmetaphern in unterschiedlichen Registern verschieden Realisiert werden. Der folgende Test baute darauf auf und testete die spezifizierte Hypothese, dass sich zwei bestimmte Metaphernarten in zwei bestimmten Registern unterscheiden würden. Wir haben es also mit zwei Hypothesen zu tun, wobei die zweite Hypothese eine Spezifikation der ersten Hypothese darstellte. Die Hypothesen standen also in einem Zusammenhang und waren nicht unabhängig. Folglich hätten sich die Fehler addiert, wenn wir nicht berücksichtigt hätten, dass nicht nur die Teiltabelle aus den Daten extrahiert wurde, sondern wir eine Teiltabelle einer größeren Tabelle testen wollen.</p>
<p>Ein zweites und vielleicht noch wichtigeres Merkmal von Unabhängigkeit ist, dass unabhängige Variablen nicht miteinander korrelieren dürfen. Tun sie dies dennoch, so spricht man von Multikollinearität (mehr dazu in Sektion ).</p>
</div>
<div id="corrections" class="section level1">
<h1><span class="header-section-number">8</span> Corrections </h1>
<p>Wie kann man nun damit umgehen, dass man mehrere Hypothesen testen möchte? Zum einen kann man multivariate Verfahren verwenden, wie wir in Sektion  sehen werden. Eine andere Methode besteht darin, Korrekturen einzubauen, um so zu garantieren, dass das <span class="math inline">\(\alpha\)</span>–Niveau auch bei wiederholten Tests bei 5% bleibt.</p>
<p>Die bekannteste und wahrscheinlich auch am weitesten verbreitete Korrektur ist die Bonferroni-Korrektur, bei der das <span class="math inline">\(\alpha\)</span>–Niveau durch die Anzahl der Tests geteilt wird. Beispielsweise sollen bei einer Untersuchung 4 Tests durchgeführt werden, dann wird das <span class="math inline">\(\alpha\)</span>–Niveau auf .05/4 = .0125 gesenkt, sodass die Summer der <span class="math inline">\(\alpha\)</span>–Niveaus der vier Tests wieder das gewohnte 5%-Niveau herstellt. Der Nachteil dieser Korrektur ist, dass Sie eher konservativ ist und daher zu einem relativ hohen <span class="math inline">\(\beta\)</span>–Fehlerrate führt.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-gries2009statistics">
<p>Gries, Stefan Th. 2009. <em>Statistics for Linguistics Using R: A Practical Introduction</em>. Berlin &amp; New York: Mouton de Gruyter.</p>
</div>
<div id="ref-wilson1999science">
<p>Wilson, Edward O. 1999. <em>Consilience: The Unity of Knowledge</em>. New York: Vintage.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
