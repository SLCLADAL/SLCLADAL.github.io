<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-11-20" />

<title>Mixed-Effects Regression Models</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Visualizing Data with R</a>
    </li>
    <li>
      <a href="maps.html">Geo-Spatial Data Visualization in R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
    <li>
      <a href="collostructionalanalysis.html">Collostructional Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="textanalysis.html">Introduction</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Mixed-Effects Regression Models</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-11-20</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces mixed-effects regression modeling using “R”. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/mixedregressionsrscript.r">here</a>.</p>
<p>Mixed-effects models are rapidly increasing in use in data analysis because they allow us to incorporate hierarchical ornested data structures. Mixed-effecst models are, of course, an extension of fixed-effects regression models are also multivariate and come in different types.</p>
<p>In contrast to fixed-effects regression models, mixed-effects models are not simple additive models because they are based on complex matrix multiplications where predicted values represent the product of the random effects multiplied by the intercept values plus the estimates of the fixed effects component in the model.</p>
<p>In the following, we will go over the most relevant and frequently used types of mixed-effect regression models, mixed-effects linear regression models and mixed-effects binomial logistic regression models.</p>
<p>The major difference between these types of models is that they take different types of dependent variables. While linear models take numeric dependent variables, logistic models take nominal variables.</p>
</div>
<div id="preparation-and-session-set-up" class="section level1">
<h1><span class="header-section-number">2</span> Preparation and session set up</h1>
<p>As all caluculations and visualizations in this tutorial rely on “R”, it is necessary to install “R”, “RStudio”, and “Tinn-R”. If these programms (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the librariesby running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;RLRsim&quot;, &quot;nlme&quot;, &quot;lme4&quot;, &quot;Hmisc&quot;, &quot;RLRsim&quot;, 
                   &quot;sjPlot&quot;, &quot;visreg&quot;, &quot;mlogit&quot;, &quot;plyr&quot;, &quot;rms&quot;, 
                   &quot;ggplot2&quot;, &quot;effects&quot;, &quot;lme4&quot;, &quot;languageR&quot;, &quot;Hmisc&quot;))</code></pre>
<p>Once you have installed “R”, “R-Studio”, “Tinn-R”, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="linear-mixed-effects-regression-models" class="section level1">
<h1><span class="header-section-number">3</span> Linear Mixed-Effects Regression Models </h1>
<p>The following focuses on an extension of ordinary multiple linear regressions: mixed-effects regression linear regression. Mixed-effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of mixed-effects regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. having only fixed-effects means that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristic. In such cases, the data is considered hierarchical and statistical models should incorporate such structural features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope (as in the left panel in the figure below), while mixed effects models have intercepts for each level of a random effect. If the random effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and or slope for each speaker.</p>
<p><img src="mixedregressions_files/figure-html/lmm1-1.png" width="672" /></p>
<p><em>Random Effects</em> have two parameters: the intercept (the point where the regression line cross the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models have only 1 intercept and one slope (left panel of the Figure above) while mixed-effects models can have various <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/lmm2-1.png" width="672" /></p>
<p>The left panel merely shows the data while the centre panel includes the regression line for a regression that estimates Weight based on Height. The right panel shows the regression line and, in addition, random intercepts each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the depended variable solely on the base intercept (the mean), with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in “R” we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load necessary “R” packages, specify options, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(RLRsim)
library(nlme)
library(lme4)
library(ggplot2)
# load functions
source(&quot;https://slcladal.github.io/rscripts/multiplot_ggplot2.r&quot;)
# set options
# supress scientific notation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      
# do not convert strings into factors
options(stringsAsFactors = F)              
# read in data
mydata &lt;- read.delim(&quot;https://slcladal.github.io/data/lmemdata.txt&quot;, 
                     header = TRUE) 
# convert date into a numeric variable
mydata$date &lt;- as.numeric(mydata$date)     
# inspect updated data set
head(mydata); nrow(mydata)                 </code></pre>
<pre><code>##   date         genre    text  pptw region
## 1 1736 SCIENCE_OTHER   albin 166.0  north
## 2 1711 EDUC_TREATISE    anon 139.9  north
## 3 1808  LETTERS_PRIV  austen 130.8  north
## 4 1878 EDUC_TREATISE    bain 151.3  north
## 5 1743 EDUC_TREATISE barclay 145.7  north
## 6 1908 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (<code>date</code>), the genre of the text (<code>genre</code>), the name of the text (<code>text</code>), the relative frequency of prepositions in the text (<code>pptw</code>), and the region in which the text was written (<code>region</code>). We now plot the data to get a first impression of its structure.</p>
<pre class="r"><code># visualize variables (2 plots per row)
# 3 plots in 1 window
def.par &lt;- par(no.readonly = TRUE)
nf &lt;- layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = T))
plot(mydata$pptw ~ mydata$date, ylab = &quot;Frequency&quot;, xlab = &quot;year of publication&quot;)
abline(lm(mydata$pptw ~ mydata$date), lty = 3, lwd = 2, col = &quot;red&quot;)
# re-set margins to fit the labels
par(mar = c(7.2, 4, 1, 2) + 0.1)
# reorder genre by median
genrebymedian &lt;- with(mydata, reorder(genre, -pptw, median))
#   generate plots
plot(mydata$pptw ~ genrebymedian,
  col = &quot;lightgrey&quot;,
  ylab = &quot;Frequency&quot;,
  xlab = &quot;&quot;,
  las = 2,
  cex.axis = .7,
  cex = .5)
# re-set margins
par(mar = c(5, 4, 1, 2) + 0.1)
x = mydata$pptw
h = hist(mydata$pptw,
    ylim =c(0, 150),
    xlim = c(50, 200),
    xlab = &quot;prepositions per text&quot;,
    col = &quot;lightgrey&quot;,
    main = &quot;&quot;)
xfit &lt;- seq(min(mydata$pptw), max(mydata$pptw), length = 40)
yfit &lt;- dnorm(xfit, mean = mean(mydata$pptw),sd = sd(mydata$pptw))
yfit &lt;- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, lty = 2, lwd=2)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm4-1.png" width="672" /></p>
<pre class="r"><code># restore original graphic&#39;s parameters
par(def.par)</code></pre>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderately increased over time while the boxplots in the lower left panel show that the genres differ quite substantially with respect to their median frequencies of prepositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<pre class="r"><code># plot 8
p8 &lt;- ggplot(mydata, aes(date, pptw)) +
  geom_point() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;)  + 
  theme_set(theme_bw(base_size = 10))
# plot 9
p9 &lt;- ggplot(mydata, aes(region, pptw)) +
  geom_boxplot() +
  labs(x = &quot;Region&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;) # with linear model smoothing!
# include genre (lowess)
multiplot(p8, p9, cols = 2)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm5-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mydata, aes(date, pptw)) +
  geom_point() +
  facet_wrap(~ genre, nrow = 4) +
  geom_smooth(method = &quot;lm&quot;) +
  theme_bw() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  coord_cartesian(ylim = c(0, 220))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm6-1.png" width="672" /></p>
<p>Centering or scaling numeric variables is useful for later interpretation of regression models: if the date variable was not centered, the regression would show the effects of variables at year 0(!). If numeric variables are scaled, other variables are variables are considered relative not to 0 but to the mean of that variable (in this case the mean of years in our data). Centering simply means that the mean of the numeric variable is subtracted from each value.</p>
<pre class="r"><code>mydata$date &lt;- scale(mydata$date, scale = F)
# inspect data
head(mydata); str(mydata)</code></pre>
<pre><code>##     date         genre    text  pptw region
## 1 109.87 SCIENCE_OTHER   albin 166.0  north
## 2  84.87 EDUC_TREATISE    anon 139.9  north
## 3 181.87  LETTERS_PRIV  austen 130.8  north
## 4 251.87 EDUC_TREATISE    bain 151.3  north
## 5 116.87 EDUC_TREATISE barclay 145.7  north
## 6 281.87 EDUC_TREATISE  benson 120.8  north</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  5 variables:
##  $ date  : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ genre : chr  &quot;SCIENCE_OTHER&quot; &quot;EDUC_TREATISE&quot; &quot;LETTERS_PRIV&quot; &quot;EDUC_TREATISE&quot; ...
##  $ text  : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ pptw  : num  166 140 131 151 146 ...
##  $ region: chr  &quot;north&quot; &quot;north&quot; &quot;north&quot; &quot;north&quot; ...</code></pre>
<pre class="r"><code># generate a glm baseline model
m0.glm &lt;- glm(pptw ~ 1, family = gaussian, data = mydata)
# generate a lm base-line model
m0.lm &lt;- lm(pptw ~ 1, data = mydata)
# set up first lme model including only the random effect specifying the random intercepts
m0.lme = lme(pptw ~ 1, random = ~1|genre, data = mydata, method = &quot;ML&quot;)
# set up first lmer model including only the random effect specifying the random intercepts
m0.lmer = lmer(pptw ~ 1 + (1|genre), data = mydata, REML = F)</code></pre>
</div>
<div id="testing-random-effects" class="section level2">
<h2><span class="header-section-number">3.3</span> Testing Random Effects</h2>
<p>As a first step in the modelling process, we now need to determine whether or not including a random effect structure is justified. We do so by comparing the base-line model without random intercepts to the model with random intercepts using a Likelihood Ratio Test. A short word of warning is in order here regarding the specific of the model: we need to set “REML = T” because Relative Estimate Maximum Likelihood (REML) provides better estimates for the random effects part of the model compared with the simpler Maximum Likelihood (ML) specification (cf. Field, Miles &amp; Field 2012:879).</p>
<pre class="r"><code>x2 = -2*logLik(m0.lm, REML = T)+2*logLik(m0.lmer, REML = T)
x2 &lt;- x2 &lt;- x2[[1]]
list(x2, pchisq(x2, df=2, lower.tail=F))</code></pre>
<pre><code>## [[1]]
## [1] 220.9
## 
## [[2]]
## [1] 0.000000000000000000000000000000000000000000000001082</code></pre>
<p>The inclusion of a random effect structure with random intercepts is justified based on the Likelihood Ratio Test.</p>
<p>However, we also want to test which random effects structure is the best. We therefore create several models with different random effect structures and compare these models to see which random effect structure has the highest explanatory power.</p>
<p>We generate a m0.lmer model but using the “lmer” function from the “lme4” package. When we compare models, the REML specification must be FALSE or set to “method =”ML&quot; (Maximum Likelihood) (depending on the function) when we use ANOVAs to compare models (cf. Field, Miles &amp; Field 2012:). This is because “ML” produces more accurate estimates of fixed regression parameters, whereas “REML” produces more accurate estimates of random variances (Twisk 2006). […] Also, if you want to compare models you must use ML&quot; (Field, Miles &amp; Field 2012:879).</p>
<pre class="r"><code>m0.lmer1 &lt;- lmer(pptw ~ (1|genre) + 1, data = mydata, REML = T)
m0.lmer2 &lt;- lmer(pptw ~ (1|region) + 1, data = mydata, REML = T)
m0.lmer3 &lt;- lmer(pptw ~ (1|genre/region) + 1, data = mydata, REML = T)
anova(m0.lmer1, m0.lmer2, m0.lmer3)</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer1: pptw ~ (1 | genre) + 1
## m0.lmer2: pptw ~ (1 | region) + 1
## m0.lmer3: pptw ~ (1 | genre/region) + 1
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.lmer1  3 4502 4515  -2248     4496                                     
## m0.lmer2  3 4719 4731  -2356     4713     0      0                   1    
## m0.lmer3  4 4501 4518  -2246     4493   220      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># the model with the random effect structure (1|genre/region) performs
# significantly better (also it has a much lower AIC and deviance)
# therefore, m0.lmer3 is our new m0 model
m0.lmer &lt;- m0.lmer3
# test if including the random effect is permitted by applying a restricted likelihood ratio test
# WARNING: this test can only take simple random effect (1|genre) but not
# (1|genre/date)
exactRLRT(m0.lmer1)</code></pre>
<pre><code>## 
##  simulated finite sample distribution of RLRT.
##  
##  (p-value based on 10000 simulated values)
## 
## data:  
## RLRT = 220, p-value &lt;0.0000000000000002</code></pre>
<pre class="r"><code># there is another way to compare model with and without random effects: see below!

# create a second model with date as a fixed effect
# m1.lme &lt;- lme(m0.lme, .~. + date) # alternative way to update the model
m1.lme = lme(pptw ~ date, random = ~1|genre/region, data = mydata, method = &quot;ML&quot;)
# set up m1 model but using the lmer function from the lme4 package
m1.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)

# compare the models to see if including date has improved the model
# the difference between the models is the effect (size) of date!
anova(m0.lme, m1.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m1.lme     2  5 4496 4517  -2243 1 vs 2   10.12  0.0063</code></pre>
<pre class="r"><code># m1.lme is the better model (sig. p-value &amp; lower AIC)
# date correlates significantly with pptw (X2(1) = 8.81, p = .003);
# X2 = L.Ratio;
# df = subtract df smaller from df larger model
# inspect results
summary(m1.lme)</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4496 4517  -2243
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.05
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       3.453    14.97
## 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.95     3.183 505   42.09  0.0000
## date          0.02     0.007 505    2.70  0.0071
##  Correlation: 
##      (Intr)
## date 0.003 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.74687 -0.66308  0.01827  0.64043  3.62269 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre class="r"><code># alternative display of the results
anova(m1.lme)</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1770.7  &lt;.0001
## date            1   505     7.3  0.0071</code></pre>
<pre class="r"><code># test if date is significant
anova(m0.lmer, m1.lmer)</code></pre>
<pre><code>## Data: mydata
## Models:
## m0.lmer: pptw ~ (1 | genre/region) + 1
## m1.lmer: pptw ~ (1 | genre/region) + date
##         Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
## m0.lmer  4 4501 4518  -2246     4493                           
## m1.lmer  5 4496 4517  -2243     4486  7.03      1      0.008 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># extract estimates and sd for fixed and random effects
intervals(m1.lme)</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.713505 133.95499 140.19647
## date          0.004896   0.01787   0.03083
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept))  8.19 12.05 17.73
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 1.172 3.453 10.17
## 
##  Within-group standard error:
## lower  est. upper 
## 14.07 14.97 15.93</code></pre>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">3.4</span> Model Diagnostics</h2>
<p>We can now evaluate the goodness of fit of the model and check if mathematical requirements and assumptions have been violated. In a first step, we generate diagnostic plots that focus on the random effect structure.</p>
<pre class="r"><code>plot(m1.lme, genre ~ resid(.), abline = 0 ) # generate diagnostic plots</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm11-1.png" width="672" /></p>
<p>The plot shows that there are some outliers (points outside the boxes) and that the variability within letters is greater than in other genres we therefore examine the genres in isolation standardized residuals versus fitted values (Pinheiro &amp; Bates 2000:175).</p>
<pre class="r"><code>plot(m1.lme, resid(., type = &quot;p&quot;) ~ fitted(.) | genre, id = 0.05, adj = -0.3)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm12-1.png" width="672" /></p>
<p>The plot showing the standardized residuals versus fitted values confirms that there are outliers in the letters because there are obviously differences in the variance, we create a new model which uses weights to compensate heterogeneity of variance (cf. Pinheiro &amp; Bates 2000:177).</p>
<pre class="r"><code>m2.lme &lt;- update(m1.lme, weights = varIdent(form = ~ 1 | genre))
# test if m2.lme is more appropriate for the data than m1.lme
anova(m1.lme, m2.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m1.lme     1  5 4496 4517  -2243                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   42.75  0.0002</code></pre>
<p>The heteroscedastic model (i.e. m2.lme which uses weights to account for unequal variance) is performing significantly better than the homoscedasticity model m1.lme. We therefore inspect the results of the new heteroscedastic model.</p>
<pre class="r"><code>summary(m2.lme)        # inspect results</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: mydata 
##    AIC  BIC logLik
##   4483 4569  -2222
## 
## Random effects:
##  Formula: ~1 | genre
##         (Intercept)
## StdDev:       12.14
## 
##  Formula: ~1 | region %in% genre
##         (Intercept) Residual
## StdDev:       4.183    13.89
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | genre 
##  Parameter estimates:
##             BIBLE   BIOGRAPHY_OTHER        DIARY_PRIV     EDUC_TREATISE 
##            1.0000            0.3582            0.8994            0.7324 
##           FICTION    HANDBOOK_OTHER           HISTORY               LAW 
##            0.8895            1.1417            1.0185            0.7591 
##  LETTERS_NON-PRIV      LETTERS_PRIV        PHILOSOPHY PROCEEDINGS_TRIAL 
##            1.2641            1.2302            0.7753            1.2262 
##    RELIG_TREATISE     SCIENCE_OTHER            SERMON        TRAVELOGUE 
##            1.0108            0.8293            0.9821            1.0663 
## Fixed effects: pptw ~ date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 134.01     3.209 505   41.76  0.0000
## date          0.02     0.006 505    3.36  0.0008
##  Correlation: 
##      (Intr)
## date 0.002 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.29018 -0.67307  0.03261  0.64633  3.08450 
## 
## Number of Observations: 537
## Number of Groups: 
##             genre region %in% genre 
##                16                31</code></pre>
<pre class="r"><code>anova(m2.lme)          # ANOVA display of the results</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1743.6  &lt;.0001
## date            1   505    11.3  0.0008</code></pre>
<pre class="r"><code>anova(m0.lme, m2.lme)  # test if date is significant</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   52.87  &lt;.0001</code></pre>
<pre class="r"><code>intervals(m2.lme)      # extract estimates and sd for fixed and random effects</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.719320 134.01179 140.30426
## date          0.008414   0.02022   0.03203
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: genre 
##                 lower  est. upper
## sd((Intercept)) 8.253 12.14 17.87
##   Level: region 
##                 lower  est. upper
## sd((Intercept)) 2.092 4.183 8.363
## 
##  Variance function:
##                    lower   est.  upper
## BIOGRAPHY_OTHER   0.2233 0.3582 0.5747
## DIARY_PRIV        0.6532 0.8994 1.2385
## EDUC_TREATISE     0.5210 0.7324 1.0295
## FICTION           0.6426 0.8895 1.2312
## HANDBOOK_OTHER    0.8170 1.1417 1.5955
## HISTORY           0.7583 1.0185 1.3682
## LAW               0.5499 0.7591 1.0480
## LETTERS_NON-PRIV  0.9974 1.2641 1.6020
## LETTERS_PRIV      0.9907 1.2302 1.5276
## PHILOSOPHY        0.4907 0.7753 1.2250
## PROCEEDINGS_TRIAL 0.8344 1.2262 1.8019
## RELIG_TREATISE    0.6776 1.0108 1.5078
## SCIENCE_OTHER     0.5702 0.8293 1.2063
## SERMON            0.7351 0.9821 1.3121
## TRAVELOGUE        0.7574 1.0663 1.5012
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.62 13.89 16.61</code></pre>
</div>
<div id="effect-sizes" class="section level2">
<h2><span class="header-section-number">3.5</span> Effect Sizes</h2>
<p>We will now extract effect sizes (in the example: the effect size of date) and calculate normalized effect size measures (this effect size measure works for all fixed effects). To calculate the effect size, take the square root of the squared t-value divided by the t-value squared plus the degrees of freedom:</p>
<p>r = <code>sqrt(t^2^/(t^2^+df))</code>.</p>
<p>A brief word of warning is in order here: only apply this function to main effects not involved in interactions as they are meaningless because the amount of variance explained by main effects involved in interactions is unclear (cf. Field, Miles &amp; Field 2012:641).</p>
<pre class="r"><code>ef.lme &lt;- function(x) {
  df &lt;- summary(x)[[20]][6]
  t &lt;-  summary(x)[[20]][8]
  #df &lt;- summary(x)$tTable[, 3]
  #t &lt;- summary(x)$tTable[, 4]
  r &lt;- sqrt((t^2)/((t^2)+df))
  return(paste(&quot;Pearson&#39;s r = &quot;, round(r, 3)))
  }
ef.lme(m2.lme)</code></pre>
<pre><code>## [1] &quot;Pearson&#39;s r =  0.148&quot;</code></pre>
<p>We now generate another m1 model but we use the “lmer” function from the “lme4” package rather than the “glmer” function.</p>
<pre class="r"><code>m2.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)
summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
<p>We now calculate the variance explained when only a simple random effect is involved. This is done by dividing the variance of the random effect (145.2) by variance of random effect plus residual variance (145.2+224.1) times 100. The results represents the percentage of variance explained by the random effect: <code>(145.2/(145.2+2284.1))*100</code>.</p>
<p>Create lmer with complex random effect structure</p>
<p>An alternative for testing if including the random intercepts is permitted.</p>
<p>WARNING: this method is not as good as applying a restricted likelihood ratio test(!) because the p-value is only an approximation IMPORTANT: the second model is a glm object</p>
<pre class="r"><code>m2.lmer = lmer(pptw ~ (1|genre/region) + date, data = mydata, REML = F)
2*pchisq(2*as.numeric(logLik(m2.lmer)-logLik(m0.glm)), 2, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000005159</code></pre>
</div>
<div id="rerun-model-diagnostics" class="section level2">
<h2><span class="header-section-number">3.6</span> Rerun Model Diagnostics</h2>
<p>Diagnostic plot (Pinheiro &amp; Bates 2000:11, 182) what we wish to see: a cloud of dots in the middle of the window without structure what we do not want to see: a funnel-shaped cloud because this indicates an increase of the errors/residuals with an increase of the predictor(s) (because this would indicate heteroscedasticity) in short: observed values against fitted values (cf. Pinheiro &amp; Bates 2000:182)</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2))           # display plots in 2 rows and 2 columns
plot(m2.lme)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm21-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<pre class="r"><code># diagnostic plot (Pinheiro &amp; Bates 2000:21)
plot(m2.lme, form = resid(., type = &quot;p&quot;) ~ fitted(.) | genre, abline = 0, cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm22-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: residuals of fitted values against observed values (cf. Pinheiro &amp; Bates 2000:182)
qqnorm(m2.lme)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm23-1.png" width="672" /></p>
<pre class="r"><code># normal plot of the estimated date %in% genre random effects
qqnorm(m2.lme, ~ranef(., level = 2), id = 0.05, cex = 0.7, xlim = c(-40, 40))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm24-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: normal plots of the residuals by genre (cf. Pinheiro &amp; Bates 2000:22, 179)
qqnorm(m2.lme, ~resid(.) | genre )</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm25-1.png" width="672" /></p>
<pre class="r"><code># inspect the observed responses versus the within-group fitted values
# (cf. Pinheiro &amp; Bates 2000:178)
plot(m2.lme, pptw ~ fitted(.), id = 0.05, adj = -0.3, xlim = c(80, 220), cex = .8)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm26-1.png" width="672" /></p>
</div>
<div id="reporting-results" class="section level2">
<h2><span class="header-section-number">3.7</span> Reporting Results</h2>
<pre class="r"><code>summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: pptw ~ (1 | genre/region) + date
##    Data: mydata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  region:genre (Intercept)  11.9     3.45   
##  genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  region:genre, 31; genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## date 0.003</code></pre>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression-models" class="section level1">
<h1><span class="header-section-number">4</span> Mixed-Effects Binomial Logistic Regression Models</h1>
<p>We now turn to an extension of binomial logistic regression: mixed-effects binomial logistic regression. As is the case with linear mixed-effects models logistic mixed effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>As is the case with linear mixed-effects models, binomial logistic mixed-effect models are multivariate analysis that treat data points as hierarchical or grouped in some way. In other words, they take into account that the data is nested in the sense that data points are produced by the same speaker or are grouped by some other characteristics. In mixed-models, hierarchical structures are modelled as <em>random effects</em>. If the random effect structure represents speakers then this means that a mixed-model would have a separate intercept and/or slope for each speaker.</p>
<p><em>Random Effects</em> in linear models two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to linear mixed-effects models, random effects differ in the position and the slope of the logistic function that is applied to the likelihood of the dependent variable. <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/blmm1-1.png" width="672" /></p>
<p>The upper left panel merely shows the logistic curve representing the predictions of a fixed-effects logistic regression with a single intercept and slope. The upper right panel shows the logistic curves representing the predictions of a of a mixed-effects logistic regression with random intercepts for each level of a grouping variable. The lower left panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with one intercept but random slopes for each level of a grouping variable. The lower right panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with random intercepts and random slopes for each level of a grouping variable.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the dependent variable solely on the base intercept, with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-discourse-like-in-irish-english" class="section level2">
<h2><span class="header-section-number">4.2</span> Example: Discourse LIKE in Irish English</h2>
<p>In this example we will investigate which factors correlate with the use of <em>final discourse like</em> (e.g. “<em>The weather is shite, like!</em>”) in Irish English. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender (Gender: Men versus Women) and age of that speaker (Age: Old versus Young), whether the interlocutors were of the same or a different gender (ConversationType: SameGender versus MixedGender), and whether another <em>final discourse like</em> had been used up to three speech units before (Priming: NoPrime versus Prime), whether or not the speech unit contained an <em>final discourse like</em> (SUFLike: 1 = yes, 0 = no. To begin with, we clean the current work space, set option, install and activate relevant packages, load customized functions, and load the example data set.</p>
<pre class="r"><code>rm(list=ls(all=T))  # clean current workspace
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)     # set options
library(Hmisc)      # activate library
library(RLRsim)     # activate library
library(sjPlot)     # activate library
library(visreg)     # activate library
library(mlogit)     # activate library
library(plyr)       # activate library
library(rms)        # activate library
library(ggplot2)    # activate library
library(effects)    # activate library
library(lme4)       # activate library
library(languageR)  # activate library
source(&quot;rscripts/multiplot_ggplot2.R&quot;)    # load multiplot function
source(&quot;rscripts/PseudoR2lmerBinomial.R&quot;) # load pseudor2 function
source(&quot;rscripts/meblr.summary.R&quot;)        # load summary function</code></pre>
<p>Next, we load the data and inspect the structure of the data set,</p>
<pre class="r"><code># load data
mblrdata &lt;- read.table(&quot;https://slcladal.github.io/data/mblrdata.txt&quot;, 
                       comment.char = &quot;&quot;,# data does not contain comments
                       quote = &quot;&quot;,       # data does not contain quotes
                       sep = &quot;\t&quot;,       # data is tab separated
                       header = T)       # data has column names
# inspect data structure
str(mblrdata)                               </code></pre>
<pre><code>## &#39;data.frame&#39;:    10170 obs. of  6 variables:
##  $ ID              : chr  &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Age             : chr  &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; ...
##  $ ConversationType: chr  &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; ...
##  $ Priming         : chr  &quot;Prime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ SUFlike         : int  1 0 0 0 0 0 0 0 0 0 ...</code></pre>
<p>As all variables except for the dependent variable (SUFlike) are character strings, we factorize the independent variables.</p>
<pre class="r"><code># def. variables to be factorized
vrs &lt;- c(&quot;ID&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;ConversationType&quot;, &quot;Priming&quot;)
# def. vector with variables
fctr &lt;- which(colnames(mblrdata) %in% vrs)     
# factorize variables
mblrdata[,fctr] &lt;- lapply(mblrdata[,fctr], factor)
# relevel Age (Young = Reference)
mblrdata$Age &lt;- relevel(mblrdata$Age, &quot;Young&quot;) </code></pre>
<p>Before continuing, we check if speakers need to be collapsed because they nest too few data points. As a general rule of thumb, random effects should have a minimum of 20 data points per level.</p>
<pre class="r"><code>plot(table(mblrdata$ID)[order(table(mblrdata$ID), decreasing = T)],
     ylim = c(0,150),
      cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm5-1.png" width="672" /></p>
<p>The plot indicates that the vast majority of speakers represent more than 20 cases. However, we will collapse speakers that represent fewer data points.</p>
<pre class="r"><code>collapsespeaker &lt;- table(mblrdata$ID)[which(table(mblrdata$ID) &lt; 21)]
mblrdata$ID &lt;- ifelse(mblrdata$ID %in% collapsespeaker, &quot;Other&quot;, mblrdata$ID)</code></pre>
<p>After preparing the data, we have a look at the first six lines of the data set.</p>
<pre class="r"><code>library(knitr)    # load library
kable(head(mblrdata), caption = &quot;First six rows of the data set.&quot;)</code></pre>
<table>
<caption>First six rows of the data set.</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">ConversationType</th>
<th align="left">Priming</th>
<th align="right">SUFlike</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">Prime</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We now plot the data to inspect the relationships within the data set.</p>
<pre class="r"><code>p1 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, color = Gender)) +
  scale_fill_brewer() +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;))
p2 &lt;- ggplot(mblrdata, aes(Age, SUFlike, color = Age)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkblue&quot;, &quot;lightblue&quot;))
p3 &lt;- ggplot(mblrdata, aes(ConversationType, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;ConversationType&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;ConversationType&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
p4 &lt;- ggplot(mblrdata, aes(Priming, SUFlike, colour = Priming)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Priming&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Priming&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;grey30&quot;, &quot;grey60&quot;))
p5 &lt;- ggplot(mblrdata, aes(Age, SUFlike, colour = Gender)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= Gender)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
    scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Gender&quot;)
p6 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= ConversationType)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Age&quot;) +
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
# display the plots
multiplot(p1, p3, p5, p2, p4, p6, cols = 2)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm8-1.png" width="672" /></p>
<p>The upper left panel in the Figure above indicates that men sue discourse like more frequently than women. The centre right panel suggests that priming significantly increases the likelihood of discourse like being used. The centre left panel suggests that speakers use discourse like more frequently in mixed-gender conversations. However, the lower right panel indicates an interaction between gender and conversation type as women appear to use discourse like less frequently in same gender conversations while the conversation type does not seem to have an effect on men. After visualizing the data, we will now turn to the model building process.</p>
</div>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">4.3</span> Model Building</h2>
<p>In a first step, we set the options and generate a distance matrix of the data.</p>
<pre class="r"><code># set options
options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;))
mblrdata.dist &lt;- datadist(mblrdata)
options(datadist = &quot;mblrdata.dist&quot;)</code></pre>
<p>In a next step, we generate fixed-effects minimal base-line models and a base-line mixed-model using the “glmer” function with a random intercept for ID (a lmer object of the final minimal adequate model will be created later).</p>
<pre class="r"><code># baseline model glm
m0.glm = glm(SUFlike ~ 1, family = binomial, data = mblrdata) 
# baseline model lrm
m0.lrm = lrm(SUFlike ~ 1, data = mblrdata, x = T, y = T) 
# base-line mixed-model
m0.glmer = glmer(SUFlike ~ (1|ID), data = mblrdata, family = binomial) </code></pre>
</div>
<div id="testing-the-random-effect" class="section level2">
<h2><span class="header-section-number">4.4</span> Testing the Random Effect</h2>
<p>Now, we check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.</p>
<pre class="r"><code>aic.glmer &lt;- AIC(logLik(m0.glmer))
aic.glm &lt;- AIC(logLik(m0.glm))
aic.glmer; aic.glm</code></pre>
<pre><code>## [1] 9193</code></pre>
<pre><code>## [1] 9310</code></pre>
<p>The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, we also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.</p>
<pre class="r"><code># test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) </code></pre>
<pre><code>## [1] 0.000000000000000000000000001273</code></pre>
<pre class="r"><code># sig m0.glmer better than m0.glm</code></pre>
<p>The p-value of the Model Likelihood Ratio Test is lower than .05 which shows that the inclusion of the random-effects structure is warranted. We can now continue with the model fitting process.</p>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">4.5</span> Model Fitting</h2>
<p>The next step is to fit the model which means that we aim to find the “best” model, i.e. the minimal adequate model. In this case, we will use a manual step-wise step-up, forward elimination procedure. Before we begin with the model fitting process we need to add ´control = glmerControl(optimizer = “bobyqa”)´ to avoid unneccesary failures to converge.</p>
<pre class="r"><code>m0.glmer &lt;- glmer(SUFlike ~ 1+ (1|ID), family = binomial, data = mblrdata, control=glmerControl(optimizer=&quot;bobyqa&quot;))</code></pre>
<p>During each step of the fitting procedure, we test whether certain assumptions on which the model relies are violated. To avoid <em>incomplete information</em> (a combination of variables does not occur in the data), we tabulate the variables we intend to include and make sure that all possible combinations are present in the data. Including variables although not all combinations are present in the data would lead to unreliable models that report (vastly) inaccurate results. A special case of incomplete information is <em>complete separation</em> which occurs if one predictor perfectly explains an outcome (in that case the incomplete information would be caused by a level of the dependent variable). In addition, we make sure that the VIFs do not exceed a maximum of 3 as higher values would indicate multicollinearity and thus that the model is unstable. Only once we have confirmed that the incomplete information, complete separation, and <em>multicollinearity</em> are not a major concern, we generate the more saturated model and test whether the inclusion of a predictor leads to a significant reduction in residual deviance. If the predictor explains a significant amount of variance, it is retained in the model while being disregarded in case it does not explain a sufficient quantity of variance.</p>
<pre class="r"><code># add Priming
ifelse(min(ftable(mblrdata$Priming, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m1.glm &lt;- update(m0.glm, .~.+Priming)
m1.glmer &lt;- update(m0.glmer, .~.+Priming)
anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Age
ifelse(min(ftable(mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m2.glm &lt;- update(m1.glm, .~.+Age)
ifelse(max(vif(m2.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m2.glmer &lt;- update(m1.glmer, .~.+Age)
anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;) #mar sig (p=.0.61) BUT BIC inflation  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m2.glmer: SUFlike ~ (1 | ID) + Priming + Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)  
## m1.glmer  3 8688 8710  -4341     8682                          
## m2.glmer  4 8687 8716  -4339     8679  3.44      1      0.064 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Gender
ifelse(min(ftable(mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m3.glm &lt;- update(m1.glm, .~.+Gender)
ifelse(max(vif(m3.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m3.glmer &lt;- update(m1.glmer, .~.+Gender)
anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add ConversationType
ifelse(min(ftable(mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m4.glm &lt;- update(m3.glm, .~.+ConversationType)
ifelse(max(vif(m4.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m4.glmer &lt;- update(m3.glmer, .~.+ConversationType)
anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) # SIG (p&lt;.001***)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># add Priming*Age
ifelse(min(ftable(mblrdata$Priming, mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m5.glm &lt;- update(m4.glm, .~.+Priming*Age)
ifelse(max(vif(m5.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m5.glmer &lt;- update(m4.glmer, .~.+Priming*Age)
anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) # not sig (p=0.6)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m5.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m5.glmer:     Priming:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m4.glmer  5 8560 8596  -4275     8550                        
## m5.glmer  7 8563 8613  -4274     8549  1.03      2        0.6</code></pre>
<pre class="r"><code># add Priming*Gender
ifelse(min(ftable(mblrdata$Priming, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m6.glm &lt;- update(m4.glm, .~.+Priming*Gender)
ifelse(max(vif(m6.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*ConversationType
ifelse(min(ftable(mblrdata$Priming, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m7.glm &lt;- update(m4.glm, .~.+Priming*ConversationType)
ifelse(max(vif(m7.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*Gender
ifelse(min(ftable(mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m8.glm &lt;- update(m4.glm, .~.+Age*Gender)
ifelse(max(vif(m8.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*ConversationType
ifelse(min(ftable(mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m9.glm &lt;- update(m4.glm, .~.+Age*ConversationType)
ifelse(max(vif(m9.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m9.glmer &lt;- update(m4.glmer, .~.+Age*ConversationType)
anova(m9.glmer, m4.glmer, test = &quot;Chi&quot;) # not sig (p=0.3)  </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m9.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m9.glmer:     ConversationType:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m4.glmer  5 8560 8596  -4275     8550                        
## m9.glmer  7 8561 8612  -4274     8547   2.4      2        0.3</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Gender*ConversationType
ifelse(min(ftable(mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m10.glm &lt;- update(m4.glm, .~.+Gender*ConversationType)
ifelse(max(vif(m10.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m11.glm &lt;- update(m4.glm, .~.+Priming*Age*Gender)
ifelse(max(vif(m11.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m12.glm &lt;- update(m4.glm, .~.+Priming*Age*ConversationType)
ifelse(max(vif(m12.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m13.glm &lt;- update(m4.glm, .~.+Priming*Gender*ConversationType)
ifelse(max(vif(m13.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m14.glm &lt;- update(m4.glm, .~.+Age*Gender*ConversationType)
ifelse(max(vif(m14.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>Because the VIFs exceed values of 3 the degree of multicollinearity is unacceptable so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m15.glm &lt;- update(m4.glm, .~.+Priming*Age*Gender*ConversationType)
ifelse(max(vif(m15.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) # VIFs unacceptable</code></pre>
<pre><code>## [1] &quot;VIFs unacceptable&quot;</code></pre>
<p>In a next step, we test which models are the most adequate by comparing all models to get an overview of model parameters. This way it is possible to check which model has the lowest AIC, BIC, and the highest <span class="math inline">\(\chi\)</span><sup>2</sup> value</p>
<pre class="r"><code># comparisons of glmer objects
m1.m0 &lt;- anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) 
m2.m1 &lt;- anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;) 
m3.m1 &lt;- anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) 
m4.m3 &lt;- anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) 
m5.m4 &lt;- anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) 
m9.m4 &lt;- anova(m9.glmer, m4.glmer, test = &quot;Chi&quot;) 
# create a list of the model comparisons
mdlcmp &lt;- list(m1.m0, m2.m1, m3.m1, m4.m3, m5.m4, m9.m4)
# load function for summary
source(&quot;rscripts/ModelFittingSummarySWSU.R&quot;) # for GLMEM (step-wise step-up)
mdlft &lt;- mdl.fttng.swsu(mdlcmp)
mdlft &lt;- mdlft[,-2]
library(knitr)    # load library
kable(mdlft, caption = &quot;Model fitting process summary.&quot;)</code></pre>
<table>
<caption>Model fitting process summary.</caption>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="left">Term Added</th>
<th align="left">Compared to…</th>
<th align="left">DF</th>
<th align="left">AIC</th>
<th align="left">BIC</th>
<th align="left">LogLikelihood</th>
<th align="left">Residual Deviance</th>
<th align="left">X2</th>
<th align="left">X2DF</th>
<th align="left">p-value</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m1.glmer</td>
<td align="left">1+Priming</td>
<td align="left">m0.glmer</td>
<td align="left">3</td>
<td align="left">8688.39</td>
<td align="left">8710.07</td>
<td align="left">-4341.19</td>
<td align="left">8682.39</td>
<td align="left">506.84</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m2.glmer</td>
<td align="left">Age</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8686.95</td>
<td align="left">8715.86</td>
<td align="left">-4339.47</td>
<td align="left">8678.95</td>
<td align="left">3.44</td>
<td align="left">1</td>
<td align="left">0.06373</td>
<td align="left">p &lt; .10(*)</td>
</tr>
<tr class="odd">
<td align="left">m3.glmer</td>
<td align="left">Gender</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8596.76</td>
<td align="left">8625.67</td>
<td align="left">-4294.38</td>
<td align="left">8588.76</td>
<td align="left">93.63</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m4.glmer</td>
<td align="left">ConversationType</td>
<td align="left">m3.glmer</td>
<td align="left">5</td>
<td align="left">8559.57</td>
<td align="left">8595.7</td>
<td align="left">-4274.78</td>
<td align="left">8549.57</td>
<td align="left">39.19</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">m5.glmer</td>
<td align="left">Age+Priming:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">8562.54</td>
<td align="left">8613.13</td>
<td align="left">-4274.27</td>
<td align="left">8548.54</td>
<td align="left">1.03</td>
<td align="left">2</td>
<td align="left">0.59875</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m9.glmer</td>
<td align="left">Age+ConversationType:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">8561.17</td>
<td align="left">8611.76</td>
<td align="left">-4273.58</td>
<td align="left">8547.17</td>
<td align="left">2.4</td>
<td align="left">2</td>
<td align="left">0.30176</td>
<td align="left">n.s.</td>
</tr>
</tbody>
</table>
<p>We now rename our final minimal adequate model, test whether it performs significantly better than the minimal base-line model, and print the regression summary.</p>
<pre class="r"><code>mlr.glmer &lt;- m4.glmer # rename final minimal adequate model
mlr.glm &lt;- m4.glm # rename final minimal adequate fixed-effects model
anova(mlr.glmer, m0.glmer, test = &quot;Chi&quot;) # final model better than base-line model</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## mlr.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##           Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer   2 9193 9208  -4595     9189                                 
## mlr.glmer  5 8560 8596  -4275     8550   640      3 &lt;0.0000000000000002
##              
## m0.glmer     
## mlr.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>print(mlr.glmer, corr = F) # inspect final minimal adequate model</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##    Data: mblrdata
##      AIC      BIC   logLik deviance df.resid 
##     8560     8596    -4275     8550    10165 
## Random effects:
##  Groups Name        Std.Dev.
##  ID     (Intercept) 0.126   
## Number of obs: 10170, groups:  ID, 225
## Fixed Effects:
##                (Intercept)                PrimingPrime  
##                     -0.954                       1.700  
##                GenderWomen  ConversationTypeSameGender  
##                     -0.761                      -0.435</code></pre>
<pre class="r"><code>anova(mlr.glmer)  # ANOVA summary</code></pre>
<pre><code>## Analysis of Variance Table
##                  Df Sum Sq Mean Sq F value
## Priming           1    481     481   480.6
## Gender            1    195     195   195.1
## ConversationType  1     44      44    44.2</code></pre>
<p>To extract the effect sizes of the significant fixed effects, we compare the model with that effect to a model without that effect so that we can ascertain how much variance that effect explains.</p>
<pre class="r"><code>anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) #  Priming effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) # Gender effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) #  ConversationType effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">4.6</span> Extracting Model Fit Parameters</h2>
<p>We now create an “lrm” and “lmer” object that are equivalent to the final minimal adequate model (but the former without the random effect).</p>
<pre class="r"><code>mlr.lrm &lt;- lrm(SUFlike ~ Priming + Gender + ConversationType, data = mblrdata, x = T, y = T)
m1.glm = glm(SUFlike ~ Priming + Gender + ConversationType, family = binomial, data = mblrdata) # baseline model glm
# we now create a lmer object equivalent to the final minimal adequate model
mlr.lmer &lt;- lmer(SUFlike ~ Age + Gender + ConversationType + (1|ID), data = mblrdata, family = binomial)</code></pre>
<p>We now check on the lmer object if the fixed effects of the “lrm” and of the “lmer” model correlate (cf Baayen 2008:281).</p>
<pre class="r"><code>cor.test(coef(mlr.lrm), fixef(mlr.lmer))</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  coef(mlr.lrm) and fixef(mlr.lmer)
## t = 2.7, df = 2, p-value = 0.1
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.5169  0.9975
## sample estimates:
##    cor 
## 0.8827</code></pre>
<p>The fixed effects correlate strongly (.8827) which is a good indicator as it suggests that the coefficient estimates are sufficiently stable. We now activate the “Hmisc” package (if not already active) to extract model fit parameters (cf. Baayen 2008:281).</p>
<pre class="r"><code># load library
library(Hmisc)   
probs = 1/(1+exp(-fitted(mlr.lmer)))
probs = binomial()$linkinv(fitted(mlr.lmer))
somers2(probs, as.numeric(mblrdata$SUFlike))</code></pre>
<pre><code>##          C        Dxy          n    Missing 
##     0.6323     0.2646 10170.0000     0.0000</code></pre>
<p>The model fit parameters indicate a sufficient but not very good fit. The C-value indicates a goodness of fit between predicted and observed responses (occurrences of SUFlike). If the C-value is 0.5, the predictions are random, while the predictions are perfect if the C-value is 1. C-values above 0.8 indicates real predictive capacity (Baayen 2008:204).</p>
<p>Somers’ D<sub>xy</sub> is a value that represents a rank correlation between predicted probabilities and observed responses. Somers’ D<sub>xy</sub> values range between 0, which indicates complete randomness, and 1, which indicates perfect prediction (Baayen 2008:204). This a value of .2646 suggests that the model performs better than chance but not substantially so. We will now perform the model diagnostics.</p>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">4.7</span> Model Diagnostics</h2>
<p>We begin the model diagnostics by generating a diagnostic that plots the fitted or predicted values against the residuals.</p>
<pre class="r"><code>plot(mlr.glmer)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm38-1.png" width="672" /></p>
<pre class="r"><code># plot residuals against fitted
stripParams &lt;- list(cex=.3, lines=1.5)
plot(mlr.glmer, form = resid(., type = &quot;response&quot;) ~ fitted(.) | ID, abline = 0, par.strip.text = stripParams,cex = .3,id = 0.05, adj = -0.3)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm39-1.png" width="672" /></p>
<pre class="r"><code># diagnostic plot: examining residuals (Pinheiro &amp; Bates 2000:175)
plot(mlr.glmer, ID ~ resid(.), abline = 0 , cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm40-1.png" width="672" /></p>
<pre class="r"><code># summarize final model
mblrmtb &lt;- meblrm.summary(m0.glm, m1.glm, m0.glmer, mlr.glmer, dpvar=mblrdata$SUFlike)
mblrmtb &lt;- mblrmtb[, -c(4:5)]
library(knitr)    # load library
kable(mblrmtb, caption = &quot;Results of a Mixed-Effects Binomial Logistic Regression Model.&quot;)</code></pre>
<table>
<caption>Results of a Mixed-Effects Binomial Logistic Regression Model.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Group(s)</th>
<th align="left">Variance</th>
<th align="left">Std. Dev.</th>
<th align="left">L.R. X2</th>
<th align="left">DF</th>
<th align="left">Pr</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Random Effect(s)</td>
<td align="left">ID</td>
<td align="left">0.02</td>
<td align="left">0.13</td>
<td align="left">118.61</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>Fixed Effect(s)</td>
<td align="left">Estimate</td>
<td align="left">VIF</td>
<td align="left">OddsRatio</td>
<td align="left">Std. Error</td>
<td align="left">z value</td>
<td align="left">Pr(&gt;|z|)</td>
<td align="left">Significance</td>
</tr>
<tr class="odd">
<td>(Intercept)</td>
<td align="left">-0.95</td>
<td align="left"></td>
<td align="left">0.39</td>
<td align="left">0.06</td>
<td align="left">-14.93</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>PrimingPrime</td>
<td align="left">1.7</td>
<td align="left">1.01</td>
<td align="left">5.47</td>
<td align="left">0.07</td>
<td align="left">22.85</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td>GenderWomen</td>
<td align="left">-0.76</td>
<td align="left">1.21</td>
<td align="left">0.47</td>
<td align="left">0.08</td>
<td align="left">-9.9</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td>ConversationTypeSameGender</td>
<td align="left">-0.43</td>
<td align="left">1.22</td>
<td align="left">0.65</td>
<td align="left">0.07</td>
<td align="left">-6.65</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td>Model statistics</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">Value</td>
</tr>
<tr class="even">
<td>Number of Groups</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">225</td>
</tr>
<tr class="odd">
<td>Number of cases in model</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">10170</td>
</tr>
<tr class="even">
<td>Observed misses</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8430</td>
</tr>
<tr class="odd">
<td>Observed successes</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">1740</td>
</tr>
<tr class="even">
<td>Residual deviance</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8549.57</td>
</tr>
<tr class="odd">
<td>R2 (Nagelkerke)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.126</td>
</tr>
<tr class="even">
<td>R2 (Hosmer &amp; Lemeshow)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.086</td>
</tr>
<tr class="odd">
<td>R2 (Cox &amp; Snell)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.075</td>
</tr>
<tr class="even">
<td>C</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.708</td>
</tr>
<tr class="odd">
<td>Somers’ Dxy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.416</td>
</tr>
<tr class="even">
<td>AIC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8559.57</td>
</tr>
<tr class="odd">
<td>BIC</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">8595.7</td>
</tr>
<tr class="even">
<td>Prediction accuracy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">82.69%</td>
</tr>
<tr class="odd">
<td>Model Likelihood Ratio Test</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">L.R. X2: 758.28</td>
<td align="left">DF: 4</td>
<td align="left">p-value: 0</td>
<td align="left">sig: p &lt; .001***</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
