<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-11-20" />

<title>Mixed-Effects Regression Models</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Visualizing Data with R</a>
    </li>
    <li>
      <a href="maps.html">Geo-Spatial Data Visualization in R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="textanalysis.html">Introduction</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Mixed-Effects Regression Models</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-11-20</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces mixed-effects regression modelling using “R”. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/mixedregressionsrscript.r">here</a>.</p>
<p>Mixed-effects models are rapidly increasing in use in data analysis because they allow us to incorporate hierarchical or nested data structures. Mixed-effects models are, of course, an extension of fixed-effects regression models and also multivariate and come in different types.</p>
<p>In contrast to fixed-effects regression models, mixed-effects models are not simple additive models because they are based on complex matrix multiplications where predicted values represent the product of the random effects multiplied by the intercept values plus the estimates of the fixed effects component in the model.</p>
<p>In the following, we will go over the most relevant and frequently used types of mixed-effect regression models, mixed-effects linear regression models and mixed-effects binomial logistic regression models.</p>
<p>The major difference between these types of models is that they take different types of dependent variables. While linear models take numeric dependent variables, logistic models take nominal variables.</p>
</div>
<div id="preparation-and-session-set-up" class="section level1">
<h1><span class="header-section-number">2</span> Preparation and session set up</h1>
<p>As all calculations and visualizations in this tutorial rely on “R”, it is necessary to install “R”, “RStudio”, and “Tinn-R”. If these programs (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favourite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the libraries by running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;RLRsim&quot;, &quot;nlme&quot;, &quot;lme4&quot;, &quot;Hmisc&quot;, &quot;RLRsim&quot;, 
                   &quot;sjPlot&quot;, &quot;visreg&quot;, &quot;mlogit&quot;, &quot;plyr&quot;, &quot;rms&quot;, 
                   &quot;ggplot2&quot;, &quot;effects&quot;, &quot;lme4&quot;, &quot;languageR&quot;, &quot;Hmisc&quot;))</code></pre>
<p>Once you have installed “R”, “R-Studio”, “Tinn-R”, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="linear-mixed-effects-regression-models" class="section level1">
<h1><span class="header-section-number">3</span> Linear Mixed-Effects Regression Models </h1>
<p>The following focuses on an extension of ordinary multiple linear regressions: mixed-effects regression linear regression. Mixed-effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of mixed-effects regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. having only fixed-effects means that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristic. In such cases, the data is considered hierarchical and statistical models should incorporate such structural features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope (as in the left panel in the figure below), while mixed effects models have intercepts for each level of a random effect. If the random effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and or slope for each speaker.</p>
<p><img src="mixedregressions_files/figure-html/lmm1-1.png" width="672" /></p>
<p><em>Random Effects</em> have two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models have only 1 intercept and one slope (left panel of the Figure above) while mixed-effects models can have various <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/lmm2-1.png" width="672" /></p>
<p>The left panel merely shows the data while the centre panel includes the regression line for a regression that estimates Weight based on Height. The right panel shows the regression line and, in addition, random intercepts each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the depended variable solely on the base intercept (the mean), with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in “R” we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load necessary “R” packages, specify options, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(car)
library(dplyr)
library(ggplot2)
library(lme4)
library(nlme)
library(RLRsim)
# load functions
source(&quot;https://slcladal.github.io/rscripts/multiplot_ggplot2.r&quot;)
# set options
# supress scientific notation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      
# do not convert strings into factors
options(stringsAsFactors = F)              
# read in data
lmmdata &lt;- read.delim(&quot;https://slcladal.github.io/data/lmmdata.txt&quot;, header = TRUE) %&gt;%
# convert date into a numeric variable
    dplyr::mutate(Date = as.numeric(Date))
# inspect updated data set
head(lmmdata); nrow(lmmdata) </code></pre>
<pre><code>##   Date         Genre    Text Prepositions Region
## 1 1736       Science   albin        166.0  North
## 2 1711     Education    anon        139.9  North
## 3 1808 PrivateLetter  austen        130.8  North
## 4 1878     Education    bain        151.3  North
## 5 1743     Education barclay        145.7  North
## 6 1908     Education  benson        120.8  North</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (<code>Date</code>), the genre of the text (<code>Genre</code>), the name of the text (<code>Text</code>), the relative frequency of prepositions in the text (<code>Prepositions</code>), and the region in which the text was written (<code>Region</code>). We now plot the data to get a first impression of its structure.</p>
<pre class="r"><code># visualize variables (2 plots per row)
# 3 plots in 1 window
def.par &lt;- par(no.readonly = TRUE)
nf &lt;- layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = T))
plot(lmmdata$Prepositions ~ lmmdata$Date, ylab = &quot;Frequency&quot;, xlab = &quot;Year of publication&quot;, ylim = c(0, 200))
abline(lm(lmmdata$Prepositions ~ lmmdata$Date), lty = 3, lwd = 2, col = &quot;red&quot;)
# re-set margins to fit the labels
par(mar = c(7.2, 4, 1, 2) + 0.1)
# reorder Genre by median
Genrebymedian &lt;- with(lmmdata, reorder(Genre, -Prepositions, median))
#   generate plots
plot(lmmdata$Prepositions ~ Genrebymedian,
  col = &quot;lightgrey&quot;,
  ylab = &quot;Frequency&quot;,
  xlab = &quot;&quot;,
  las = 2,
  cex.axis = .7,
  cex = .5,
  ylim = c(0,200))
# re-set margins
par(mar = c(5, 4, 1, 2) + 0.1)
x = lmmdata$Prepositions
h = hist(lmmdata$Prepositions,
    ylim =c(0, 200),
    xlim = c(50, 200),
    xlab = &quot;Prepositions per text&quot;,
    col = &quot;lightgrey&quot;,
    main = &quot;&quot;)
xfit &lt;- seq(min(lmmdata$Prepositions), max(lmmdata$Prepositions), length = 40)
yfit &lt;- dnorm(xfit, mean = mean(lmmdata$Prepositions),sd = sd(lmmdata$Prepositions))
yfit &lt;- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, lty = 2, lwd=2)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm4-1.png" width="672" /></p>
<pre class="r"><code># restore original graphic&#39;s parameters
par(def.par)</code></pre>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderately increased over time while the boxplots in the lower left panel show that the genres differ quite substantially with respect to their median frequencies of prepositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<pre class="r"><code># plot 8
p8 &lt;- ggplot(lmmdata, aes(Date, Prepositions)) +
  geom_point() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;)  + 
  theme_set(theme_bw(base_size = 10))
# plot 9
p9 &lt;- ggplot(lmmdata, aes(Region, Prepositions)) +
  geom_boxplot() +
  labs(x = &quot;Region&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;) # with linear model smoothing!
# include genre (lowess)
multiplot(p8, p9, cols = 2)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm5-1.png" width="672" /></p>
<pre class="r"><code>ggplot(lmmdata, aes(Date, Prepositions)) +
  geom_point() +
  facet_wrap(~ Genre, nrow = 4) +
  geom_smooth(method = &quot;lm&quot;) +
  theme_bw() +
  labs(x = &quot;Year&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  coord_cartesian(ylim = c(0, 220))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm6-1.png" width="672" /></p>
<p>Centring or scaling numeric variables is useful for later interpretation of regression models: if the date variable was not centred, the regression would show the effects of variables at year 0(!). If numeric variables are scaled, other variables are variables are considered relative not to 0 but to the mean of that variable (in this case the mean of years in our data). Centring simply means that the mean of the numeric variable is subtracted from each value.</p>
<pre class="r"><code>lmmdata$Date &lt;- scale(lmmdata$Date, scale = F)
# inspect data
head(lmmdata); str(lmmdata)</code></pre>
<pre><code>##     Date         Genre    Text Prepositions Region
## 1 109.87       Science   albin        166.0  North
## 2  84.87     Education    anon        139.9  North
## 3 181.87 PrivateLetter  austen        130.8  North
## 4 251.87     Education    bain        151.3  North
## 5 116.87     Education barclay        145.7  North
## 6 281.87     Education  benson        120.8  North</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  5 variables:
##  $ Date        : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ Genre       : chr  &quot;Science&quot; &quot;Education&quot; &quot;PrivateLetter&quot; &quot;Education&quot; ...
##  $ Text        : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ Prepositions: num  166 140 131 151 146 ...
##  $ Region      : chr  &quot;North&quot; &quot;North&quot; &quot;North&quot; &quot;North&quot; ...</code></pre>
<p>We now set up four models: two fixed-effects models (one model with the “glm” and another with the “lm” function) and two analogous mixed-effects models with Genre as random effect.</p>
<pre class="r"><code># generate models
m0.glm &lt;- glm(Prepositions ~ 1, family = gaussian, data = lmmdata)
m0.lm &lt;- lm(Prepositions ~ 1, data = lmmdata)
m0.lme = lme(Prepositions ~ 1, random = ~1|Genre, data = lmmdata, method = &quot;ML&quot;)
m0.lmer = lmer(Prepositions ~ 1 + (1|Genre), data = lmmdata, REML = F)</code></pre>
<p>Now that we have created base-line models, we will test whether including a random effect structure is mathematically justified. It is important to note here that we are not going to test if including a random effect structure is theoretically motivated but simply if it causes a decrease in variance.</p>
</div>
<div id="testing-random-effects" class="section level2">
<h2><span class="header-section-number">3.3</span> Testing Random Effects</h2>
<p>As a first step in the modelling process, we now need to determine whether or not including a random effect structure is justified. We do so by comparing the base-line model without random intercepts to the model with random intercepts using a Likelihood Ratio Test. A short word of warning is in order here regarding the specific of the model: we need to set “REML = T” because Relative Estimate Maximum Likelihood (REML) provides better estimates for the random effects part of the model compared with the simpler Maximum Likelihood (ML) specification <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 879)</span>.</p>
<pre class="r"><code>x2 = -2*logLik(m0.lm, REML = T)+2*logLik(m0.lmer, REML = T)
x2 &lt;- x2 &lt;- x2[[1]]
list(x2, pchisq(x2, df=2, lower.tail=F))</code></pre>
<pre><code>## [[1]]
## [1] 220.9
## 
## [[2]]
## [1] 0.000000000000000000000000000000000000000000000001082</code></pre>
<p>The inclusion of a random effect structure with random intercepts is justified based on the Likelihood Ratio Test.</p>
<p>However, we also want to test which random effects structure is the best. We therefore create several models with different random effect structures and compare these models to see which random effect structure has the highest explanatory power.</p>
<p>We generate a m0.lmer model but using the “lmer” function from the “lme4” package. When we compare models, the REML specification must be FALSE or set to “method =”ML&quot; (Maximum Likelihood) (depending on the function) when we use ANOVAs to compare models <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 879)</span>. This is because “ML” produces more accurate estimates of fixed regression parameters, whereas “REML” produces more accurate estimates of random variances <span class="citation">(<span class="citeproc-not-found" data-reference-id="twisk2006multilevel"><strong>???</strong></span>)</span>. […] Also, if you want to compare models you must use ML&quot; <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 879)</span>.</p>
<pre class="r"><code>m0.lmer1 &lt;- lmer(Prepositions ~ (1|Genre) + 1, data = lmmdata, REML = T)
m0.lmer2 &lt;- lmer(Prepositions ~ (1|Region) + 1, data = lmmdata, REML = T)
m0.lmer3 &lt;- lmer(Prepositions ~ (1|Genre/Region) + 1, data = lmmdata, REML = T)
anova(m0.lmer1, m0.lmer2, m0.lmer3)</code></pre>
<pre><code>## Data: lmmdata
## Models:
## m0.lmer1: Prepositions ~ (1 | Genre) + 1
## m0.lmer2: Prepositions ~ (1 | Region) + 1
## m0.lmer3: Prepositions ~ (1 | Genre/Region) + 1
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.lmer1  3 4502 4515  -2248     4496                                     
## m0.lmer2  3 4719 4731  -2356     4713     0      0                   1    
## m0.lmer3  4 4501 4518  -2246     4493   220      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The model with the random effect structure (1|Genre/Region) performs significantly better (also it has a much lower AIC and deviance) and it is thus our new m0 model. In addition, we also want to know if including the random effect is permitted by applying a restricted likelihood ratio test. This can, however, only be done for simple random effects, e.g. (1|Genre), but not for complex random effects such as (1|Genre/Date).</p>
<pre class="r"><code># rename model
m0.lmer &lt;- m0.lmer3
# perform restricted likelihood ratio test
exactRLRT(m0.lmer1)</code></pre>
<pre><code>## 
##  simulated finite sample distribution of RLRT.
##  
##  (p-value based on 10000 simulated values)
## 
## data:  
## RLRT = 220, p-value &lt;0.0000000000000002</code></pre>
<p>There is also another way to compare models with and without random effects (see below) which may be easier for you. Now, we create a second model with “Date” as a fixed effect and another analogous model using the “lmer” function. After that, we compare the models to see if including “Date” has improved the model - the difference between the models is the effect (size) of “Date”!</p>
<pre class="r"><code># create a second model with date as a fixed effect
m1.lme = lme(Prepositions ~ Date, random = ~1|Genre/Region, data = lmmdata, method = &quot;ML&quot;)
# set up m1 model but using the lmer function from the lme4 package
m1.lmer = lmer(Prepositions ~ (1|Genre/Region) + Date, data = lmmdata, REML = F)
# compare the models 
anova(m0.lme, m1.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m1.lme     2  5 4496 4517  -2243 1 vs 2   10.12  0.0063</code></pre>
<p>The model m1.lme is the better model (significant p-value and lower AIC). The significant p-value shows that “Date” correlates significantly with “Prepositions” (<span class="math inline">\(\chi\)</span>^2(1) = 8.81, p = .003); <span class="math inline">\(\chi\)</span>^2 here is the L.Ratio and the degrees of freedom are calculated by subtracting the smaller number of DFs from the larger number of DFs.</p>
<pre class="r"><code># inspect results
summary(m1.lme)</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: lmmdata 
##    AIC  BIC logLik
##   4496 4517  -2243
## 
## Random effects:
##  Formula: ~1 | Genre
##         (Intercept)
## StdDev:       12.05
## 
##  Formula: ~1 | Region %in% Genre
##         (Intercept) Residual
## StdDev:       3.453    14.97
## 
## Fixed effects: Prepositions ~ Date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.95     3.183 505   42.09  0.0000
## Date          0.02     0.007 505    2.70  0.0071
##  Correlation: 
##      (Intr)
## Date 0.003 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.74687 -0.66308  0.01827  0.64043  3.62269 
## 
## Number of Observations: 537
## Number of Groups: 
##             Genre Region %in% Genre 
##                16                31</code></pre>
<pre class="r"><code># alternative display of the results
anova(m1.lme)</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1770.7  &lt;.0001
## Date            1   505     7.3  0.0071</code></pre>
<pre class="r"><code># extract estimates and sd for fixed and random effects
intervals(m1.lme)</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.713506 133.95499 140.19647
## Date          0.004896   0.01787   0.03083
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: Genre 
##                 lower  est. upper
## sd((Intercept)) 8.191 12.05 17.73
##   Level: Region 
##                 lower  est. upper
## sd((Intercept)) 1.174 3.453 10.15
## 
##  Within-group standard error:
## lower  est. upper 
## 14.07 14.97 15.93</code></pre>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">3.4</span> Model Diagnostics</h2>
<p>We can now evaluate the goodness of fit of the model and check if mathematical requirements and assumptions have been violated. In a first step, we generate diagnostic plots that focus on the random effect structure.</p>
<pre class="r"><code>plot(m1.lme, Genre ~ resid(.), abline = 0 ) # generate diagnostic plots</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm11-1.png" width="672" /></p>
<p>The plot shows that there are some outliers (points outside the boxes) and that the variability within letters is greater than in other genres we therefore examine the genres in isolation standardized residuals versus fitted values <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code>plot(m1.lme, resid(., type = &quot;p&quot;) ~ fitted(.) | Genre, id = 0.05, adj = -0.3)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm12-1.png" width="672" /></p>
<p>The plot showing the standardized residuals versus fitted values confirms that there are outliers in the letters because there are obviously differences in the variance, we create a new model which uses weights to compensate heterogeneity of variance <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code>m2.lme &lt;- update(m1.lme, weights = varIdent(form = ~ 1 | Genre))
# test if m2.lme is more appropriate for the data than m1.lme
anova(m1.lme, m2.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m1.lme     1  5 4496 4517  -2243                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   42.75  0.0002</code></pre>
<p>The heteroscedastic model (i.e. m2.lme which uses weights to account for unequal variance) is performing significantly better than the homoscedasticity model m1.lme. We therefore inspect the results of the new heteroscedastic model.</p>
<pre class="r"><code>summary(m2.lme)        # inspect results</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: lmmdata 
##    AIC  BIC logLik
##   4483 4569  -2222
## 
## Random effects:
##  Formula: ~1 | Genre
##         (Intercept)
## StdDev:       12.14
## 
##  Formula: ~1 | Region %in% Genre
##         (Intercept) Residual
## StdDev:       4.183    13.89
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | Genre 
##  Parameter estimates:
##           Bible       Biography           Diary       Education 
##          1.0000          0.3582          0.8994          0.7324 
##         Fiction        Handbook         History             Law 
##          0.8895          1.1417          1.0185          0.7591 
##      Philosophy   PrivateLetter    PublicLetter        Religion 
##          0.7753          1.2302          1.2641          1.0108 
##         Science          Sermon          Travel TrialProceeding 
##          0.8293          0.9821          1.0663          1.2262 
## Fixed effects: Prepositions ~ Date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 134.01     3.209 505   41.77  0.0000
## Date          0.02     0.006 505    3.36  0.0008
##  Correlation: 
##      (Intr)
## Date 0.002 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.29020 -0.67307  0.03261  0.64633  3.08448 
## 
## Number of Observations: 537
## Number of Groups: 
##             Genre Region %in% Genre 
##                16                31</code></pre>
<pre class="r"><code>anova(m2.lme)          # ANOVA display of the results</code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   505  1743.7  &lt;.0001
## Date            1   505    11.3  0.0008</code></pre>
<pre class="r"><code>anova(m0.lme, m2.lme)  # test if date is significant</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m0.lme     1  3 4502 4515  -2248                       
## m2.lme     2 20 4483 4569  -2222 1 vs 2   52.87  &lt;.0001</code></pre>
<pre class="r"><code>intervals(m2.lme)      # extract estimates and sd for fixed and random effects</code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                  lower      est.     upper
## (Intercept) 127.719492 134.01179 140.30409
## Date          0.008413   0.02022   0.03203
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: Genre 
##                 lower  est. upper
## sd((Intercept)) 8.252 12.14 17.87
##   Level: Region 
##                 lower  est. upper
## sd((Intercept)) 2.088 4.183 8.379
## 
##  Variance function:
##                  lower   est.  upper
## Biography       0.2268 0.3582 0.5658
## Diary           0.6628 0.8994 1.2204
## Education       0.5382 0.7324 0.9965
## Fiction         0.6456 0.8895 1.2255
## Handbook        0.8307 1.1417 1.5692
## History         0.7361 1.0185 1.4093
## Law             0.5559 0.7591 1.0366
## Philosophy      0.4937 0.7753 1.2176
## PrivateLetter   1.0187 1.2302 1.4857
## PublicLetter    1.0167 1.2641 1.5717
## Religion        0.6432 1.0108 1.5884
## Science         0.5769 0.8293 1.1921
## Sermon          0.7379 0.9821 1.3070
## Travel          0.7610 1.0663 1.4940
## TrialProceeding 0.8461 1.2262 1.7771
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.98 13.89 16.11</code></pre>
</div>
<div id="effect-sizes" class="section level2">
<h2><span class="header-section-number">3.5</span> Effect Sizes</h2>
<p>We will now extract effect sizes (in the example: the effect size of date) and calculate normalized effect size measures (this effect size measure works for all fixed effects). To calculate the effect size, take the square root of the squared t-value divided by the t-value squared plus the degrees of freedom:</p>
<p>r = <code>sqrt(t^2^/(t^2^+df))</code>.</p>
<p>A brief word of warning is in order here: only apply this function to main effects not involved in interactions as they are meaningless because the amount of variance explained by main effects involved in interactions is unclear <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 641)</span>.</p>
<pre class="r"><code>ef.lme &lt;- function(x) {
  df &lt;- summary(x)[[20]][6]
  t &lt;-  summary(x)[[20]][8]
  #df &lt;- summary(x)$tTable[, 3]
  #t &lt;- summary(x)$tTable[, 4]
  r &lt;- sqrt((t^2)/((t^2)+df))
  return(paste(&quot;Pearson&#39;s r = &quot;, round(r, 3)))
  }
ef.lme(m2.lme)</code></pre>
<pre><code>## [1] &quot;Pearson&#39;s r =  0.148&quot;</code></pre>
<p>We now generate another m1 model but we use the “lmer” function from the “lme4” package rather than the “glmer” function.</p>
<pre class="r"><code>m2.lmer = lmer(Prepositions ~ (1|Genre/Region) + Date, data = lmmdata, REML = F)
summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: Prepositions ~ (1 | Genre/Region) + Date
##    Data: lmmdata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  Region:Genre (Intercept)  11.9     3.45   
##  Genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  Region:Genre, 31; Genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## Date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## Date 0.003</code></pre>
<p>We now calculate the variance explained when only a simple random effect is involved. This is done by dividing the variance of the random effect (145.2) by variance of random effect plus residual variance (145.2+224.1) times 100. The results represents the percentage of variance explained by the random effect: <code>(145.2/(145.2+2284.1))*100</code>.</p>
<p>Create lmer with complex random effect structure</p>
<p>An alternative for testing if including the random intercepts is permitted.</p>
<p>WARNING: this method is not as good as applying a restricted likelihood ratio test(!) because the p-value is only an approximation IMPORTANT: the second model is a glm object</p>
<pre class="r"><code>m2.lmer = lmer(Prepositions ~ (1|Genre/Region) + Date, data = lmmdata, REML = F)
2*pchisq(2*as.numeric(logLik(m2.lmer)-logLik(m0.glm)), 2, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000005159</code></pre>
</div>
<div id="rerun-model-diagnostics" class="section level2">
<h2><span class="header-section-number">3.6</span> Rerun Model Diagnostics</h2>
<p>What we wish to see is a cloud of dots in the middle of the window without structure what we do not want to see: a funnel-shaped cloud because this indicates an increase of the errors/residuals with an increase of the predictor(s) (because this would indicate heteroscedasticity) in short: observed values against fitted values <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2))           # display plots in 2 rows and 2 columns
plot(m2.lme)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm21-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We will now create more diagnostic plots to find potential problems <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># fitted values by Genre
plot(m2.lme, form = resid(., type = &quot;p&quot;) ~ fitted(.) | Genre, abline = 0, cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm22-1.png" width="672" /></p>
<p>Now, we check the residuals of fitted values against observed values <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># residuals of fitted values against observed
qqnorm(m2.lme)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm23-1.png" width="672" /></p>
<pre class="r"><code># normal plot of the estimated date %in% genre random effects
qqnorm(m2.lme, ~ranef(., level = 2), id = 0.05, cex = 0.7, xlim = c(-40, 40))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm24-1.png" width="672" /></p>
<p>Next, we check the residuals by “Genre” <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># residuals by genre
qqnorm(m2.lme, ~resid(.) | Genre )</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm25-1.png" width="672" /></p>
<p>Now, we inspect the observed responses versus the within-group fitted values <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># observed responses versus the within-group fitted values
plot(m2.lme, Prepositions ~ fitted(.), id = 0.05, adj = -0.3, xlim = c(80, 220), cex = .8)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm26-1.png" width="672" /></p>
</div>
<div id="reporting-results" class="section level2">
<h2><span class="header-section-number">3.7</span> Reporting Results</h2>
<pre class="r"><code>summary(m2.lmer)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: Prepositions ~ (1 | Genre/Region) + Date
##    Data: lmmdata
## 
##      AIC      BIC   logLik deviance df.resid 
##     4496     4517    -2243     4486      532 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.747 -0.663  0.018  0.640  3.623 
## 
## Random effects:
##  Groups       Name        Variance Std.Dev.
##  Region:Genre (Intercept)  11.9     3.45   
##  Genre        (Intercept) 145.2    12.05   
##  Residual                 224.1    14.97   
## Number of obs: 537, groups:  Region:Genre, 31; Genre, 16
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 133.9550     3.1768   42.17
## Date          0.0179     0.0066    2.71
## 
## Correlation of Fixed Effects:
##      (Intr)
## Date 0.003</code></pre>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression-models" class="section level1">
<h1><span class="header-section-number">4</span> Mixed-Effects Binomial Logistic Regression Models</h1>
<p>We now turn to an extension of binomial logistic regression: mixed-effects binomial logistic regression. As is the case with linear mixed-effects models logistic mixed effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical data structures.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of regression modelling are that they are prone to producing β-errors (cf. Johnson 2009) and that they require rather large data sets.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>As is the case with linear mixed-effects models, binomial logistic mixed-effect models are multivariate analysis that treat data points as hierarchical or grouped in some way. In other words, they take into account that the data is nested in the sense that data points are produced by the same speaker or are grouped by some other characteristics. In mixed-models, hierarchical structures are modelled as <em>random effects</em>. If the random effect structure represents speakers then this means that a mixed-model would have a separate intercept and/or slope for each speaker.</p>
<p><em>Random Effects</em> in linear models two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to linear mixed-effects models, random effects differ in the position and the slope of the logistic function that is applied to the likelihood of the dependent variable. <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/blmm1-1.png" width="672" /></p>
<p>The upper left panel merely shows the logistic curve representing the predictions of a fixed-effects logistic regression with a single intercept and slope. The upper right panel shows the logistic curves representing the predictions of a of a mixed-effects logistic regression with random intercepts for each level of a grouping variable. The lower left panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with one intercept but random slopes for each level of a grouping variable. The lower right panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with random intercepts and random slopes for each level of a grouping variable.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(vgl. A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the dependent variable solely on the base intercept, with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-discourse-like-in-irish-english" class="section level2">
<h2><span class="header-section-number">4.2</span> Example: Discourse LIKE in Irish English</h2>
<p>In this example we will investigate which factors correlate with the use of <em>final discourse like</em> (e.g. “<em>The weather is shite, like!</em>”) in Irish English. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender (Gender: Men versus Women) and age of that speaker (Age: Old versus Young), whether the interlocutors were of the same or a different gender (ConversationType: SameGender versus MixedGender), and whether another <em>final discourse like</em> had been used up to three speech units before (Priming: NoPrime versus Prime), whether or not the speech unit contained an <em>final discourse like</em> (SUFLike: 1 = yes, 0 = no. To begin with, we clean the current work space, set option, install and activate relevant packages, load customized functions, and load the example data set.</p>
<pre class="r"><code>rm(list=ls(all=T))  # clean current workspace
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)     # set options
library(Hmisc)      # activate library
library(RLRsim)     # activate library
library(sjPlot)     # activate library
library(visreg)     # activate library
library(mlogit)     # activate library
library(plyr)       # activate library
library(rms)        # activate library
library(ggplot2)    # activate library
library(effects)    # activate library
library(lme4)       # activate library
library(languageR)  # activate library
source(&quot;rscripts/multiplot_ggplot2.R&quot;)    # load multiplot function
source(&quot;rscripts/PseudoR2lmerBinomial.R&quot;) # load pseudor2 function
source(&quot;rscripts/meblr.summary.R&quot;)        # load summary function</code></pre>
<p>Next, we load the data and inspect the structure of the data set,</p>
<pre class="r"><code># load data
mblrdata &lt;- read.table(&quot;https://slcladal.github.io/data/mblrdata.txt&quot;, 
                       comment.char = &quot;&quot;,# data does not contain comments
                       quote = &quot;&quot;,       # data does not contain quotes
                       sep = &quot;\t&quot;,       # data is tab separated
                       header = T)       # data has column names
# inspect data structure
str(mblrdata)                               </code></pre>
<pre><code>## &#39;data.frame&#39;:    10170 obs. of  6 variables:
##  $ ID              : chr  &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; &quot;S1A-001$A&quot; ...
##  $ Gender          : chr  &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; &quot;Men&quot; ...
##  $ Age             : chr  &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; &quot;Old&quot; ...
##  $ ConversationType: chr  &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; &quot;SameGender&quot; ...
##  $ Priming         : chr  &quot;Prime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ SUFlike         : int  1 0 0 0 0 0 0 0 0 0 ...</code></pre>
<p>As all variables except for the dependent variable (SUFlike) are character strings, we factorize the independent variables.</p>
<pre class="r"><code># def. variables to be factorized
vrs &lt;- c(&quot;ID&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;ConversationType&quot;, &quot;Priming&quot;)
# def. vector with variables
fctr &lt;- which(colnames(mblrdata) %in% vrs)     
# factorize variables
mblrdata[,fctr] &lt;- lapply(mblrdata[,fctr], factor)
# relevel Age (Young = Reference)
mblrdata$Age &lt;- relevel(mblrdata$Age, &quot;Young&quot;) </code></pre>
<p>Before continuing, we check if speakers need to be collapsed because they nest too few data points. As a general rule of thumb, random effects should have a minimum of 20 data points per level.</p>
<pre class="r"><code>plot(table(mblrdata$ID)[order(table(mblrdata$ID), decreasing = T)],
     ylim = c(0,150), ylab = &quot;Frequency&quot;, cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm5-1.png" width="672" /></p>
<p>The plot indicates that the vast majority of speakers represent more than 20 cases. However, we will collapse speakers that represent fewer data points.</p>
<pre class="r"><code>collapsespeaker &lt;- table(mblrdata$ID)[which(table(mblrdata$ID) &lt; 21)]
mblrdata$ID &lt;- ifelse(mblrdata$ID %in% collapsespeaker, &quot;Other&quot;, mblrdata$ID)</code></pre>
<p>After preparing the data, we have a look at the first six lines of the data set.</p>
<pre class="r"><code>library(knitr)    # load library
kable(head(mblrdata), caption = &quot;First six rows of the data set.&quot;)</code></pre>
<table>
<caption>First six rows of the data set.</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">ConversationType</th>
<th align="left">Priming</th>
<th align="right">SUFlike</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">Prime</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We now plot the data to inspect the relationships within the data set.</p>
<pre class="r"><code>p1 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, color = Gender)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) + 
  scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;))
p2 &lt;- ggplot(mblrdata, aes(Age, SUFlike, color = Age)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkblue&quot;, &quot;lightblue&quot;))
p3 &lt;- ggplot(mblrdata, aes(ConversationType, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;ConversationType&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;ConversationType&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
p4 &lt;- ggplot(mblrdata, aes(Priming, SUFlike, colour = Priming)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  labs(x = &quot;Priming&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Priming&quot;) +
    guides(fill=FALSE, color=FALSE) +              # supress legend
  scale_color_manual(values = c(&quot;grey30&quot;, &quot;grey60&quot;))
p5 &lt;- ggplot(mblrdata, aes(Age, SUFlike, colour = Gender)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= Gender)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
    scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) +
  labs(x = &quot;Age&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Gender&quot;)
p6 &lt;- ggplot(mblrdata, aes(Gender, SUFlike, colour = ConversationType)) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;, aes(group= ConversationType)) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
  labs(x = &quot;Sex&quot;, y = &quot;Mean frequency of discourse like&quot;, colour = &quot;Age&quot;) +
  scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;lightgreen&quot;))
# display the plots
multiplot(p1, p3, p5, p2, p4, p6, cols = 2)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm8-1.png" width="672" /></p>
<p>The upper left panel in the Figure above indicates that men sue discourse like more frequently than women. The centre right panel suggests that priming significantly increases the likelihood of discourse like being used. The centre left panel suggests that speakers use discourse like more frequently in mixed-gender conversations. However, the lower right panel indicates an interaction between gender and conversation type as women appear to use discourse like less frequently in same gender conversations while the conversation type does not seem to have an effect on men. After visualizing the data, we will now turn to the model building process.</p>
</div>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">4.3</span> Model Building</h2>
<p>In a first step, we set the options and generate a distance matrix of the data.</p>
<pre class="r"><code># set options
options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;))
mblrdata.dist &lt;- datadist(mblrdata)
options(datadist = &quot;mblrdata.dist&quot;)</code></pre>
<p>In a next step, we generate fixed-effects minimal base-line models and a base-line mixed-model using the “glmer” function with a random intercept for ID (a lmer object of the final minimal adequate model will be created later).</p>
<pre class="r"><code># baseline model glm
m0.glm = glm(SUFlike ~ 1, family = binomial, data = mblrdata) 
# baseline model lrm
m0.lrm = lrm(SUFlike ~ 1, data = mblrdata, x = T, y = T) 
# base-line mixed-model
m0.glmer = glmer(SUFlike ~ (1|ID), data = mblrdata, family = binomial) </code></pre>
</div>
<div id="testing-the-random-effect" class="section level2">
<h2><span class="header-section-number">4.4</span> Testing the Random Effect</h2>
<p>Now, we check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.</p>
<pre class="r"><code>aic.glmer &lt;- AIC(logLik(m0.glmer))
aic.glm &lt;- AIC(logLik(m0.glm))
aic.glmer; aic.glm</code></pre>
<pre><code>## [1] 9193</code></pre>
<pre><code>## [1] 9310</code></pre>
<p>The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, we also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.</p>
<pre class="r"><code># test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) </code></pre>
<pre><code>## [1] 0.000000000000000000000000001273</code></pre>
<pre class="r"><code># sig m0.glmer better than m0.glm</code></pre>
<p>The p-value of the Model Likelihood Ratio Test is lower than .05 which shows that the inclusion of the random-effects structure is warranted. We can now continue with the model fitting process.</p>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">4.5</span> Model Fitting</h2>
<p>The next step is to fit the model which means that we aim to find the “best” model, i.e. the minimal adequate model. In this case, we will use a manual step-wise step-up, forward elimination procedure. Before we begin with the model fitting process we need to add ´control = glmerControl(optimizer = “bobyqa”)´ to avoid unnecessary failures to converge.</p>
<pre class="r"><code>m0.glmer &lt;- glmer(SUFlike ~ 1+ (1|ID), family = binomial, data = mblrdata, control=glmerControl(optimizer=&quot;bobyqa&quot;))</code></pre>
<p>During each step of the fitting procedure, we test whether certain assumptions on which the model relies are violated. To avoid <em>incomplete information</em> (a combination of variables does not occur in the data), we tabulate the variables we intend to include and make sure that all possible combinations are present in the data. Including variables although not all combinations are present in the data would lead to unreliable models that report (vastly) inaccurate results. A special case of incomplete information is <em>complete separation</em> which occurs if one predictor perfectly explains an outcome (in that case the incomplete information would be caused by a level of the dependent variable). In addition, we make sure that the VIFs do not exceed a maximum of 3 for main effects <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol">2010</a>)</span> - <span class="citation">(<span class="citeproc-not-found" data-reference-id="booth1994regression"><strong>???</strong></span>)</span> suggest that VIFs should ideally be lower than 1.5 - and 20 for interactions as higher values would indicate multicollinearity and thus that the model is unstable. The value of 20 should be taken with a pinch of salt because there is no clear consensus about what the maximum VIF for interactions should be or if it should be considered at all. The reason is that we would, of course, expect the VIFs to increase when we are dealing with interactions as the main effects that are part of the interaction are very likely to correlate with the interaction itself. However, if the VIFs are too high, then this will still cause the issues with the attribution of variance. The value of 20 was chosen as it is twice the most generous value for acceptable VIFs for main effects in the standard literature on multicollinearity <span class="citation">(<span class="citeproc-not-found" data-reference-id="zuur2009mixedmodels"><strong>???</strong></span>, <span class="citation">(<span class="citeproc-not-found" data-reference-id="neter1990vif"><strong>???</strong></span>)</span>)</span>. Only once we have confirmed that the incomplete information, complete separation, and <em>multicollinearity</em> are not a major concern, we generate the more saturated model and test whether the inclusion of a predictor leads to a significant reduction in residual deviance. If the predictor explains a significant amount of variance, it is retained in the model while being disregarded in case it does not explain a sufficient quantity of variance.</p>
<pre class="r"><code># add Priming
ifelse(min(ftable(mblrdata$Priming, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m1.glm &lt;- update(m0.glm, .~.+Priming)
m1.glmer &lt;- update(m0.glmer, .~.+Priming)
anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Since the tests do not show problems relating to incomplete information, because including Priming significantly improves the model fit (decrease in AIC and BIC values), and since it correlates significantly with our dependent variable, we include Priming into our model.</p>
<pre class="r"><code># add Age
ifelse(min(ftable(mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m2.glm &lt;- update(m1.glm, .~.+Age)
ifelse(max(vif(m2.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m2.glmer &lt;- update(m1.glmer, .~.+Age)
anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;)   </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m2.glmer: SUFlike ~ (1 | ID) + Priming + Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)  
## m1.glmer  3 8688 8710  -4341     8682                          
## m2.glmer  4 8687 8716  -4339     8679  3.44      1      0.064 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m2.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##          Chisq Df          Pr(&gt;Chisq)    
## Priming 537.95  1 &lt;0.0000000000000002 ***
## Age       3.48  1               0.062 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVAs show that Age is marginally significant but, more importantly, the first ANOVA report also shows that the BIC has increased which indicates that Age does not substantially decrease variance. In such cases, the variable should not be included. A case could be made, however, if the second ANOVA would report Age as being significant but before simply continuing with the model fitting, it would be better to change the ordering in which predictors are added to the model.</p>
<pre class="r"><code># add Gender
ifelse(min(ftable(mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m3.glm &lt;- update(m1.glm, .~.+Gender)
ifelse(max(vif(m3.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m3.glmer &lt;- update(m1.glmer, .~.+Gender)
anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m3.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##         Chisq Df          Pr(&gt;Chisq)    
## Priming   507  1 &lt;0.0000000000000002 ***
## Gender    144  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Gender is significant and will therefore be included as a predictor (you can also observe that including Gender has substantially decreased both AIC and BIC).</p>
<pre class="r"><code># add ConversationType
ifelse(min(ftable(mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m4.glm &lt;- update(m3.glm, .~.+ConversationType)
ifelse(max(vif(m4.glm)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m4.glmer &lt;- update(m3.glmer, .~.+ConversationType)
anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m4.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                  Chisq Df           Pr(&gt;Chisq)    
## Priming          522.2  1 &lt; 0.0000000000000002 ***
## Gender            97.9  1 &lt; 0.0000000000000002 ***
## ConversationType  44.3  1       0.000000000029 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>ConversationType improves model fit (AIC and BIC decrease and it is reported as being significant) and will, therefore, be included in the model.</p>
<pre class="r"><code># add Priming*Age
ifelse(min(ftable(mblrdata$Priming, mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m5.glm &lt;- update(m4.glm, .~.+Priming*Age)
ifelse(max(vif(m5.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) # VIFs ok</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m5.glmer &lt;- update(m4.glmer, .~.+Priming*Age)
anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m5.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m5.glmer:     Priming:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m4.glmer  5 8560 8596  -4275     8550                        
## m5.glmer  7 8563 8613  -4274     8549  1.03      2        0.6</code></pre>
<pre class="r"><code>Anova(m5.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                   Chisq Df           Pr(&gt;Chisq)    
## Priming          522.08  1 &lt; 0.0000000000000002 ***
## Gender            94.28  1 &lt; 0.0000000000000002 ***
## ConversationType  45.20  1       0.000000000018 ***
## Age                0.19  1                 0.66    
## Priming:Age        0.83  1                 0.36    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction between Priming and Age is not significant and will thus not be included.</p>
<pre class="r"><code># add Priming*Gender
ifelse(min(ftable(mblrdata$Priming, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m6.glm &lt;- update(m4.glm, .~.+Priming*Gender)
m6.glmer &lt;- update(m4.glmer, .~.+Priming*Gender)
anova(m6.glmer, m4.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df      Pr(&gt;Chisq)    
## m4.glmer  5 8560 8596  -4275     8550                                 
## m6.glmer  6 8514 8557  -4251     8502  47.6      1 0.0000000000053 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                  Chisq Df           Pr(&gt;Chisq)    
## Priming          535.5  1 &lt; 0.0000000000000002 ***
## Gender           107.5  1 &lt; 0.0000000000000002 ***
## ConversationType  38.1  1      0.0000000006765 ***
## Priming:Gender    47.8  1      0.0000000000048 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction between Priming and Gender improved model fit (AIC and BIC reduction) and significantly correlates with the use of speech-unit final LIKE. It will therefore be included in the model.</p>
<pre class="r"><code># add Priming*ConversationType
ifelse(min(ftable(mblrdata$Priming, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m7.glm &lt;- update(m6.glm, .~.+Priming*ConversationType)
ifelse(max(vif(m7.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m7.glmer &lt;- update(m6.glmer, .~.+Priming*ConversationType)
anova(m7.glmer, m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m7.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m7.glmer:     Priming:ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
## m6.glmer  6 8514 8557  -4251     8502                           
## m7.glmer  7 8509 8559  -4247     8495  7.09      1     0.0078 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m7.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                           Chisq Df           Pr(&gt;Chisq)    
## Priming                  538.66  1 &lt; 0.0000000000000002 ***
## Gender                   102.19  1 &lt; 0.0000000000000002 ***
## ConversationType          39.35  1        0.00000000035 ***
## Priming:Gender            33.47  1        0.00000000724 ***
## Priming:ConversationType   7.11  1               0.0077 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction between Priming and ConversationType significantly correlates with the use of speech-unit final LIKE but it does not explain much variance (AIC and BIC increase). It will be included in the model but it will very likely have a very small or spurious effect.</p>
<pre class="r"><code># add Age*Gender
ifelse(min(ftable(mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m8.glm &lt;- update(m7.glm, .~.+Age*Gender)
ifelse(max(vif(m8.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m8.glmer &lt;- update(m7.glmer, .~.+Age*Gender)
anova(m8.glmer, m7.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m7.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m7.glmer:     Priming:ConversationType
## m8.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m8.glmer:     Priming:Gender + Priming:ConversationType + Gender:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m7.glmer  7 8509 8559  -4247     8495                        
## m8.glmer  9 8512 8577  -4247     8494  0.45      2        0.8</code></pre>
<p>The interaction between Age and Gender is not significant and will thus continue without it.</p>
<pre class="r"><code># add Age*ConversationType
ifelse(min(ftable(mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m9.glm &lt;- update(m7.glm, .~.+Age*ConversationType)
ifelse(max(vif(m9.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m9.glmer &lt;- update(m7.glmer, .~.+Age*ConversationType)
anova(m9.glmer, m7.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m7.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m7.glmer:     Priming:ConversationType
## m9.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m9.glmer:     Priming:Gender + Priming:ConversationType + ConversationType:Age
##          Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m7.glmer  7 8509 8559  -4247     8495                        
## m9.glmer  9 8511 8576  -4246     8493  2.38      2        0.3</code></pre>
<p>The interaction between Age and ConversationType is not significant and will thus continue without it.</p>
<pre class="r"><code># add Gender*ConversationType
ifelse(min(ftable(mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m10.glm &lt;- update(m7.glm, .~.+Gender*ConversationType)
ifelse(max(vif(m10.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m10.glmer &lt;- update(m7.glmer, .~.+Gender*ConversationType)
anova(m10.glmer, m7.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m7.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m7.glmer:     Priming:ConversationType
## m10.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m10.glmer:     Priming:ConversationType + Gender:ConversationType
##           Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)    
## m7.glmer   7 8509 8559  -4247     8495                            
## m10.glmer  8 8500 8557  -4242     8484  11.3      1    0.00079 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m10.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                           Chisq Df           Pr(&gt;Chisq)    
## Priming                  557.48  1 &lt; 0.0000000000000002 ***
## Gender                   105.77  1 &lt; 0.0000000000000002 ***
## ConversationType          38.20  1        0.00000000064 ***
## Priming:Gender            21.28  1        0.00000397666 ***
## Priming:ConversationType   8.99  1               0.0027 ** 
## Gender:ConversationType   10.72  1               0.0011 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction between Gender and ConversationType improved model fit (AIC and BIC reduction) and significantly correlates with the use of speech-unit final LIKE. It will therefore be included in the model.</p>
<pre class="r"><code># add Priming*Age*Gender
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m11.glm &lt;- update(m10.glm, .~.+Priming*Age*Gender)
ifelse(max(vif(m11.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m11.glmer &lt;- update(m10.glmer, .~.+Priming*Age*Gender)
anova(m11.glmer, m10.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m10.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m10.glmer:     Priming:ConversationType + Gender:ConversationType
## m11.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m11.glmer:     Priming:Gender + Priming:ConversationType + Gender:ConversationType + 
## m11.glmer:     Priming:Age + Gender:Age + Priming:Gender:Age
##           Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m10.glmer  8 8500 8557  -4242     8484                        
## m11.glmer 12 8506 8593  -4241     8482  1.63      4        0.8</code></pre>
<p>The interaction between Priming, Age and Gender is not significant and we will thus continue without it.</p>
<pre class="r"><code># add Priming*Age*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m12.glm &lt;- update(m10.glm, .~.+Priming*Age*ConversationType)
ifelse(max(vif(m12.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>m12.glmer &lt;- update(m10.glmer, .~.+Priming*Age*ConversationType)
anova(m12.glmer, m10.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m10.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m10.glmer:     Priming:ConversationType + Gender:ConversationType
## m12.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m12.glmer:     Priming:Gender + Priming:ConversationType + Gender:ConversationType + 
## m12.glmer:     Priming:Age + ConversationType:Age + Priming:ConversationType:Age
##           Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m10.glmer  8 8500 8557  -4242     8484                        
## m12.glmer 12 8506 8593  -4241     8482  1.71      4       0.79</code></pre>
<p>The interaction between Priming, Age and ConversationType is not significant and we will thus continue without it.</p>
<pre class="r"><code># add Priming*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m13.glm &lt;- update(m10.glm, .~.+Priming*Gender*ConversationType)
ifelse(max(vif(m13.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>vif(m13.glm)</code></pre>
<pre><code>##                                        PrimingPrime 
##                                               7.872 
##                                         GenderWomen 
##                                               1.878 
##                          ConversationTypeSameGender 
##                                              18.336 
##                            PrimingPrime:GenderWomen 
##                                              10.311 
##             PrimingPrime:ConversationTypeSameGender 
##                                              19.881 
##              GenderWomen:ConversationTypeSameGender 
##                                              20.301 
## PrimingPrime:GenderWomen:ConversationTypeSameGender 
##                                              21.643</code></pre>
<pre class="r"><code>m13.glmer &lt;- update(m10.glmer, .~.+Priming*Gender*ConversationType)
anova(m13.glmer, m10.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m10.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m10.glmer:     Priming:ConversationType + Gender:ConversationType
## m13.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m13.glmer:     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##           Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)    
## m10.glmer  8 8500 8557  -4242     8484                            
## m13.glmer  9 8484 8549  -4233     8466  17.9      1   0.000024 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m13.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                                  Chisq Df           Pr(&gt;Chisq)    
## Priming                         555.33  1 &lt; 0.0000000000000002 ***
## Gender                          105.98  1 &lt; 0.0000000000000002 ***
## ConversationType                 32.67  1          0.000000011 ***
## Priming:Gender                   21.06  1          0.000004451 ***
## Priming:ConversationType          8.32  1               0.0039 ** 
## Gender:ConversationType           7.26  1               0.0071 ** 
## Priming:Gender:ConversationType  17.30  1          0.000031905 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Although the VIFs are slightly higher than 20, the maximum values is 21.643 and thus not excessive. And since the three-way interaction between Priming, Gender, and ConversationType is not only significantly correlated with the dependent variable but also decreases AIC and BIC, we will include it in the model.</p>
<pre class="r"><code># add Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m14.glm &lt;- update(m13.glm, .~.+Age*Gender*ConversationType)
ifelse(max(vif(m14.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;)</code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>vif(m14.glm)</code></pre>
<pre><code>##                                        PrimingPrime 
##                                               7.873 
##                                         GenderWomen 
##                                               2.716 
##                          ConversationTypeSameGender 
##                                              34.024 
##                                              AgeOld 
##                                               3.514 
##                            PrimingPrime:GenderWomen 
##                                              10.359 
##             PrimingPrime:ConversationTypeSameGender 
##                                              22.239 
##              GenderWomen:ConversationTypeSameGender 
##                                              36.440 
##                                  GenderWomen:AgeOld 
##                                               5.590 
##                   ConversationTypeSameGender:AgeOld 
##                                              18.324 
## PrimingPrime:GenderWomen:ConversationTypeSameGender 
##                                              23.780 
##       GenderWomen:ConversationTypeSameGender:AgeOld 
##                                              19.981</code></pre>
<p>In this case, the VIFs are excessive and have values higher than 30 which shows an unacceptable degree of multicollinearity so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m15.glm &lt;- update(m13.glm, .~.+Priming*Age*Gender*ConversationType)
ifelse(max(vif(m15.glm)) &lt;= 20,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>vif(m15.glm)</code></pre>
<pre><code>##                                               PrimingPrime 
##                                                     13.123 
##                                                GenderWomen 
##                                                      2.829 
##                                 ConversationTypeSameGender 
##                                                     39.295 
##                                                     AgeOld 
##                                                      3.833 
##                                   PrimingPrime:GenderWomen 
##                                                     16.322 
##                    PrimingPrime:ConversationTypeSameGender 
##                                                     34.213 
##                     GenderWomen:ConversationTypeSameGender 
##                                                     41.821 
##                                        PrimingPrime:AgeOld 
##                                                      9.257 
##                                         GenderWomen:AgeOld 
##                                                      6.742 
##                          ConversationTypeSameGender:AgeOld 
##                                                     29.734 
##        PrimingPrime:GenderWomen:ConversationTypeSameGender 
##                                                     35.893 
##                            PrimingPrime:GenderWomen:AgeOld 
##                                                     11.411 
##             PrimingPrime:ConversationTypeSameGender:AgeOld 
##                                                     19.269 
##              GenderWomen:ConversationTypeSameGender:AgeOld 
##                                                     31.457 
## PrimingPrime:GenderWomen:ConversationTypeSameGender:AgeOld 
##                                                     20.607</code></pre>
<p>Again, the VIFs are excessive and have values higher than 30. As this was the last possible model, we have found our final minimal adequate model in m13.glmer.</p>
<p>In a next step, we create an overview of model comparisons which serves as a summary for the model fitting process and provides AIC, BIC, and <span class="math inline">\(\chi\)</span><sup>2</sup> values.</p>
<pre class="r"><code># comparisons of glmer objects
m1.m0 &lt;- anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) 
m2.m1 &lt;- anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;)   
m3.m1 &lt;- anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;)
m4.m3 &lt;- anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) 
m5.m4 &lt;- anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) 
m6.m4 &lt;- anova(m6.glmer, m4.glmer, test = &quot;Chi&quot;) 
m7.m6 &lt;- anova(m7.glmer, m6.glmer, test = &quot;Chi&quot;)
m8.m7 &lt;- anova(m8.glmer, m7.glmer, test = &quot;Chi&quot;) 
m9.m7 &lt;- anova(m9.glmer, m7.glmer, test = &quot;Chi&quot;) 
m10.m7 &lt;- anova(m10.glmer, m7.glmer, test = &quot;Chi&quot;) 
m11.m10 &lt;- anova(m11.glmer, m10.glmer, test = &quot;Chi&quot;) 
m12.m10 &lt;- anova(m12.glmer, m10.glmer, test = &quot;Chi&quot;)
m13.m10 &lt;- anova(m13.glmer, m10.glmer, test = &quot;Chi&quot;)
# create a list of the model comparisons
mdlcmp &lt;- list(m1.m0, m2.m1, m3.m1, m4.m3, m5.m4, m6.m4, m7.m6, m8.m7, m9.m7, m10.m7, m11.m10, m12.m10, m13.m10)
# load function for summary
source(&quot;rscripts/ModelFittingSummarySWSU.R&quot;) # for GLMEM (step-wise step-up)
mdlft &lt;- mdl.fttng.swsu(mdlcmp)
mdlft &lt;- mdlft[,-2]
library(knitr)    # load library
kable(mdlft, caption = &quot;Model fitting process summary.&quot;)</code></pre>
<table>
<caption>Model fitting process summary.</caption>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="left">Term Added</th>
<th align="left">Compared to…</th>
<th align="left">DF</th>
<th align="left">AIC</th>
<th align="left">BIC</th>
<th align="left">LogLikelihood</th>
<th align="left">Residual Deviance</th>
<th align="left">X2</th>
<th align="left">X2DF</th>
<th align="left">p-value</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m1.glmer</td>
<td align="left">1+Priming</td>
<td align="left">m0.glmer</td>
<td align="left">3</td>
<td align="left">8688.39</td>
<td align="left">8710.07</td>
<td align="left">-4341.19</td>
<td align="left">8682.39</td>
<td align="left">506.84</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m2.glmer</td>
<td align="left">Age</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8686.95</td>
<td align="left">8715.86</td>
<td align="left">-4339.47</td>
<td align="left">8678.95</td>
<td align="left">3.44</td>
<td align="left">1</td>
<td align="left">0.06373</td>
<td align="left">p &lt; .10(*)</td>
</tr>
<tr class="odd">
<td align="left">m3.glmer</td>
<td align="left">Gender</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">8596.76</td>
<td align="left">8625.67</td>
<td align="left">-4294.38</td>
<td align="left">8588.76</td>
<td align="left">93.63</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m4.glmer</td>
<td align="left">ConversationType</td>
<td align="left">m3.glmer</td>
<td align="left">5</td>
<td align="left">8559.57</td>
<td align="left">8595.7</td>
<td align="left">-4274.78</td>
<td align="left">8549.57</td>
<td align="left">39.19</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">m5.glmer</td>
<td align="left">Age+Priming:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">8562.54</td>
<td align="left">8613.13</td>
<td align="left">-4274.27</td>
<td align="left">8548.54</td>
<td align="left">1.03</td>
<td align="left">2</td>
<td align="left">0.59875</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m6.glmer</td>
<td align="left">Priming:Gender</td>
<td align="left">m4.glmer</td>
<td align="left">6</td>
<td align="left">8514</td>
<td align="left">8557.36</td>
<td align="left">-4251</td>
<td align="left">8502</td>
<td align="left">47.57</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">m7.glmer</td>
<td align="left">Priming:ConversationType</td>
<td align="left">m6.glmer</td>
<td align="left">7</td>
<td align="left">8508.91</td>
<td align="left">8559.5</td>
<td align="left">-4247.45</td>
<td align="left">8494.91</td>
<td align="left">7.09</td>
<td align="left">1</td>
<td align="left">0.00776</td>
<td align="left">p &lt; .01 **</td>
</tr>
<tr class="even">
<td align="left">m8.glmer</td>
<td align="left">Age+Gender:Age</td>
<td align="left">m7.glmer</td>
<td align="left">9</td>
<td align="left">8512.45</td>
<td align="left">8577.5</td>
<td align="left">-4247.23</td>
<td align="left">8494.45</td>
<td align="left">0.45</td>
<td align="left">2</td>
<td align="left">0.79706</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m9.glmer</td>
<td align="left">Age+ConversationType:Age</td>
<td align="left">m7.glmer</td>
<td align="left">9</td>
<td align="left">8510.53</td>
<td align="left">8575.57</td>
<td align="left">-4246.26</td>
<td align="left">8492.53</td>
<td align="left">2.38</td>
<td align="left">2</td>
<td align="left">0.30422</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m10.glmer</td>
<td align="left">Gender:ConversationType</td>
<td align="left">m7.glmer</td>
<td align="left">8</td>
<td align="left">8499.65</td>
<td align="left">8557.47</td>
<td align="left">-4241.82</td>
<td align="left">8483.65</td>
<td align="left">11.26</td>
<td align="left">1</td>
<td align="left">0.00079</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">NA</td>
<td align="left"></td>
<td align="left">m10.glmer</td>
<td align="left">12</td>
<td align="left">8506.02</td>
<td align="left">8592.74</td>
<td align="left">-4241.01</td>
<td align="left">8482.02</td>
<td align="left">1.63</td>
<td align="left">4</td>
<td align="left">0.80274</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">NA</td>
<td align="left"></td>
<td align="left">m10.glmer</td>
<td align="left">12</td>
<td align="left">8505.94</td>
<td align="left">8592.66</td>
<td align="left">-4240.97</td>
<td align="left">8481.94</td>
<td align="left">1.71</td>
<td align="left">4</td>
<td align="left">0.78822</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m13.glmer</td>
<td align="left">Priming:Gender:ConversationType</td>
<td align="left">m10.glmer</td>
<td align="left">9</td>
<td align="left">8483.78</td>
<td align="left">8548.83</td>
<td align="left">-4232.89</td>
<td align="left">8465.78</td>
<td align="left">17.86</td>
<td align="left">1</td>
<td align="left">0.00002</td>
<td align="left">p &lt; .001***</td>
</tr>
</tbody>
</table>
<p>We now rename our final minimal adequate model, test whether it performs significantly better than the minimal base-line model, and print the regression summary.</p>
<pre class="r"><code>mlr.glmer &lt;- m13.glmer # rename final minimal adequate model
mlr.glm &lt;- m13.glm # rename final minimal adequate fixed-effects model
anova(mlr.glmer, m0.glmer, test = &quot;Chi&quot;) # final model better than base-line model</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## mlr.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## mlr.glmer:     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##           Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)
## m0.glmer   2 9193 9208  -4595     9189                                 
## mlr.glmer  9 8484 8549  -4233     8466   723      7 &lt;0.0000000000000002
##              
## m0.glmer     
## mlr.glmer ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>print(mlr.glmer, corr = F) # inspect final minimal adequate model</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender +  
##     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##    Data: mblrdata
##      AIC      BIC   logLik deviance df.resid 
##     8484     8549    -4233     8466    10161 
## Random effects:
##  Groups Name        Std.Dev.
##  ID     (Intercept) 0       
## Number of obs: 10170, groups:  ID, 225
## Fixed Effects:
##                                         (Intercept)  
##                                              -0.707  
##                                        PrimingPrime  
##                                               0.272  
##                                         GenderWomen  
##                                              -1.110  
##                          ConversationTypeSameGender  
##                                              -1.496  
##                            PrimingPrime:GenderWomen  
##                                               1.565  
##             PrimingPrime:ConversationTypeSameGender  
##                                               1.905  
##              GenderWomen:ConversationTypeSameGender  
##                                               1.153  
## PrimingPrime:GenderWomen:ConversationTypeSameGender  
##                                              -1.755  
## convergence code 0; 1 optimizer warnings; 0 lme4 warnings</code></pre>
<p>To extract the effect sizes of the significant fixed effects, we compare the model with that effect to a model without that effect so that we can ascertain how much variance that effect explains. In our case, this is purely to show how to do this because main effects are superseded by interactions in which they are involved and should therefore not be interpreted <span class="citation">(A. Field, Miles, and Field <a href="#ref-field2012discovering">2012</a>, 622)</span>.</p>
<pre class="r"><code>anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m0.glmer  2 9193 9208  -4595     9189                                     
## m1.glmer  3 8688 8710  -4341     8682   507      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;) # Gender effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          Df  AIC  BIC logLik deviance Chisq Chi Df          Pr(&gt;Chisq)    
## m1.glmer  3 8688 8710  -4341     8682                                     
## m3.glmer  4 8597 8626  -4294     8589  93.6      1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) #  ConversationType effect</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          Df  AIC  BIC logLik deviance Chisq Chi Df    Pr(&gt;Chisq)    
## m3.glmer  4 8597 8626  -4294     8589                               
## m4.glmer  5 8560 8596  -4275     8550  39.2      1 0.00000000038 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">4.6</span> Extracting Model Fit Parameters</h2>
<p>We now create an “lrm” and “lmer” object that are equivalent to the final minimal adequate model (but the former without the random effect).</p>
<pre class="r"><code>mlr.lrm &lt;- lrm(SUFlike ~ Priming + Gender + ConversationType, data = mblrdata, x = T, y = T)
m1.glm = glm(SUFlike ~ Priming + Gender + ConversationType, family = binomial, data = mblrdata) # baseline model glm
# we now create a lmer object equivalent to the final minimal adequate model
mlr.lmer &lt;- lmer(SUFlike ~ Age + Gender + ConversationType + (1|ID), data = mblrdata, family = binomial)</code></pre>
<p>We now check on the lmer object if the fixed effects of the “lrm” and of the “lmer” model correlate <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 281)</span>.</p>
<pre class="r"><code>cor.test(coef(mlr.lrm), fixef(mlr.lmer))</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  coef(mlr.lrm) and fixef(mlr.lmer)
## t = 2.7, df = 2, p-value = 0.1
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.5169  0.9975
## sample estimates:
##    cor 
## 0.8827</code></pre>
<p>The fixed effects correlate strongly (.8827) which is a good indicator as it suggests that the coefficient estimates are sufficiently stable. We now activate the “Hmisc” package (if not already active) to extract model fit parameters <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 281)</span>.</p>
<pre class="r"><code># load library
library(Hmisc)   
probs = 1/(1+exp(-fitted(mlr.lmer)))
probs = binomial()$linkinv(fitted(mlr.lmer))
somers2(probs, as.numeric(mblrdata$SUFlike))</code></pre>
<pre><code>##          C        Dxy          n    Missing 
##     0.6323     0.2646 10170.0000     0.0000</code></pre>
<p>The model fit parameters indicate a suboptimal fit. Both the C-value and Somers’s D<sub>xy</sub> show poor fit between predicted and observed occurrences of SUFlike. If the C-value is 0.5, the predictions are random, while the predictions are perfect if the C-value is 1. C-values above 0.8 indicates real predictive capacity <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 204)</span>. Somers’ D<sub>xy</sub> is a value that represents a rank correlation between predicted probabilities and observed responses. Somers’ D<sub>xy</sub> values range between 0, which indicates complete randomness, and 1, which indicates perfect prediction <span class="citation">(Baayen <a href="#ref-baayen2008analyzing">2008</a>, 204)</span>. This a value of .2646 suggests that the model performs better than chance but not substantially so. We will now perform the model diagnostics.</p>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">4.7</span> Model Diagnostics</h2>
<p>We begin the model diagnostics by generating a diagnostic that plots the fitted or predicted values against the residuals.</p>
<pre class="r"><code>plot(mlr.glmer, pch = 20, col = &quot;black&quot;, lty = &quot;dotted&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm38-1.png" width="672" /></p>
<p>Next, we examine the residuals using diagnostic plots <span class="citation">(<span class="citeproc-not-found" data-reference-id="pinheiro2000mixedmodels"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># diagnostic plots
plot(mlr.glmer, ID ~ resid(.), abline = 0 , cex = .5)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm40-1.png" width="672" /></p>
<pre class="r"><code># summarize final model
mblrmtb &lt;- meblrm.summary(m0.glm, m1.glm, m0.glmer, mlr.glmer, dpvar=mblrdata$SUFlike)
mblrmtb[, -c(4:5)]</code></pre>
<pre><code>##                                                     Group(s) Variance
## Random Effect(s)                                          ID        0
## Fixed Effect(s)                                     Estimate      VIF
## (Intercept)                                            -0.71         
## PrimingPrime                                            0.27     7.87
## GenderWomen                                            -1.11     1.88
## ConversationTypeSameGender                              -1.5    18.25
## PrimingPrime:GenderWomen                                1.57     10.3
## PrimingPrime:ConversationTypeSameGender                  1.9    19.82
## GenderWomen:ConversationTypeSameGender                  1.15     20.2
## PrimingPrime:GenderWomen:ConversationTypeSameGender    -1.75    21.57
## Model statistics                                                     
## Number of Groups                                                     
## Number of cases in model                                             
## Observed misses                                                      
## Observed successes                                                   
## Residual deviance                                                    
## R2 (Nagelkerke)                                                      
## R2 (Hosmer &amp; Lemeshow)                                               
## R2 (Cox &amp; Snell)                                                     
## C                                                                    
## Somers&#39; Dxy                                                          
## AIC                                                                  
## BIC                                                                  
## Prediction accuracy                                                  
## Model Likelihood Ratio Test                                          
##                                                     Std. Dev.
## Random Effect(s)                                            0
## Fixed Effect(s)                                     OddsRatio
## (Intercept)                                              0.49
## PrimingPrime                                             1.31
## GenderWomen                                              0.33
## ConversationTypeSameGender                               0.22
## PrimingPrime:GenderWomen                                 4.78
## PrimingPrime:ConversationTypeSameGender                  6.72
## GenderWomen:ConversationTypeSameGender                   3.17
## PrimingPrime:GenderWomen:ConversationTypeSameGender      0.17
## Model statistics                                             
## Number of Groups                                             
## Number of cases in model                                     
## Observed misses                                              
## Observed successes                                           
## Residual deviance                                            
## R2 (Nagelkerke)                                              
## R2 (Hosmer &amp; Lemeshow)                                       
## R2 (Cox &amp; Snell)                                             
## C                                                            
## Somers&#39; Dxy                                                  
## AIC                                                          
## BIC                                                          
## Prediction accuracy                                          
## Model Likelihood Ratio Test                                  
##                                                             L.R. X2
## Random Effect(s)                                             118.61
## Fixed Effect(s)                                          Std. Error
## (Intercept)                                                    0.06
## PrimingPrime                                                    0.2
## GenderWomen                                                    0.09
## ConversationTypeSameGender                                     0.24
## PrimingPrime:GenderWomen                                       0.25
## PrimingPrime:ConversationTypeSameGender                        0.38
## GenderWomen:ConversationTypeSameGender                         0.25
## PrimingPrime:GenderWomen:ConversationTypeSameGender            0.42
## Model statistics                                                   
## Number of Groups                                                   
## Number of cases in model                                           
## Observed misses                                                    
## Observed successes                                                 
## Residual deviance                                                  
## R2 (Nagelkerke)                                                    
## R2 (Hosmer &amp; Lemeshow)                                             
## R2 (Cox &amp; Snell)                                                   
## C                                                                  
## Somers&#39; Dxy                                                        
## AIC                                                                
## BIC                                                                
## Prediction accuracy                                                
## Model Likelihood Ratio Test                         L.R. X2: 842.06
##                                                          DF         Pr
## Random Effect(s)                                          1          0
## Fixed Effect(s)                                     z value   Pr(&gt;|z|)
## (Intercept)                                          -11.53          0
## PrimingPrime                                           1.34     0.1807
## GenderWomen                                          -12.74          0
## ConversationTypeSameGender                             -6.3          0
## PrimingPrime:GenderWomen                               6.17          0
## PrimingPrime:ConversationTypeSameGender                4.99          0
## GenderWomen:ConversationTypeSameGender                 4.63          0
## PrimingPrime:GenderWomen:ConversationTypeSameGender   -4.16          0
## Model statistics                                                      
## Number of Groups                                                      
## Number of cases in model                                              
## Observed misses                                                       
## Observed successes                                                    
## Residual deviance                                                     
## R2 (Nagelkerke)                                                       
## R2 (Hosmer &amp; Lemeshow)                                                
## R2 (Cox &amp; Snell)                                                      
## C                                                                     
## Somers&#39; Dxy                                                           
## AIC                                                                   
## BIC                                                                   
## Prediction accuracy                                                   
## Model Likelihood Ratio Test                           DF: 8 p-value: 0
##                                                         Significance
## Random Effect(s)                                         p &lt; .001***
## Fixed Effect(s)                                         Significance
## (Intercept)                                              p &lt; .001***
## PrimingPrime                                                    n.s.
## GenderWomen                                              p &lt; .001***
## ConversationTypeSameGender                               p &lt; .001***
## PrimingPrime:GenderWomen                                 p &lt; .001***
## PrimingPrime:ConversationTypeSameGender                  p &lt; .001***
## GenderWomen:ConversationTypeSameGender                   p &lt; .001***
## PrimingPrime:GenderWomen:ConversationTypeSameGender      p &lt; .001***
## Model statistics                                               Value
## Number of Groups                                                 225
## Number of cases in model                                       10170
## Observed misses                                                 8430
## Observed successes                                              1740
## Residual deviance                                            8465.78
## R2 (Nagelkerke)                                                0.133
## R2 (Hosmer &amp; Lemeshow)                                          0.09
## R2 (Cox &amp; Snell)                                               0.079
## C                                                              0.683
## Somers&#39; Dxy                                                    0.366
## AIC                                                          8483.78
## BIC                                                          8548.83
## Prediction accuracy                                           82.91%
## Model Likelihood Ratio Test                         sig: p &lt; .001***</code></pre>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. a Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” <em>Methods in Ecology and Evolution</em> 1 (1): 3–14.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
