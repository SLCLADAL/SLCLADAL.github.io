<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2020-08-31" />

<title>Mixed-Effects Regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introcomputer.html">General Tips on Computering</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Research</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Visualizing Data with R</a>
    </li>
    <li>
      <a href="maps.html">Creating maps using R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analytics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Mixed-Effects Regression</h1>
<h4 class="author">UQ SLC Digital Team</h4>
<h4 class="date">2020-08-31</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces mixed-effects regression modelling using R. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/mixedregressionsrscript.r">here</a>.</p>
<p>Mixed-effects models are rapidly increasing in use in data analysis because they allow us to incorporate hierarchical or nested data structures. Mixed-effects models are, of course, an extension of fixed-effects regression models and also multivariate and come in different types.</p>
<p>In contrast to fixed-effects regression models, mixed-effects models are not simple additive models because they are based on complex matrix multiplications where predicted values represent the product of the random effects multiplied by the intercept values plus the estimates of the fixed effects component in the model.</p>
<p>In the following, we will go over the most relevant and frequently used types of mixed-effect regression models, mixed-effects linear regression models and mixed-effects binomial logistic regression models.</p>
<p>The major difference between these types of models is that they take different types of dependent variables. While linear models take numeric dependent variables, logistic models take nominal variables.</p>
<p><strong>Preparation and session set up</strong></p>
<p>As all calculations and visualizations in this tutorial rely on <em>R</em>, it is necessary to install <em>R</em> and <em>RStudio</em>. If these programs (or, in the case of <em>R</em>, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term <em>download</em>. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain <em>packages</em> need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the packages so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;car&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;Hmisc&quot;, &quot;knitr&quot;, &quot;lme4&quot;, &quot;rms&quot;, &quot;sjPlot&quot;))</code></pre>
<p>Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="linear-mixed-effects-regression" class="section level1">
<h1><span class="header-section-number">2</span> Linear Mixed-Effects Regression </h1>
<p>The following focuses on an extension of ordinary multiple linear regressions: mixed-effects regression linear regression. Mixed-effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical or nested data structures. This applies if several observations are produced by an individual speaker, for instance.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of mixed-effects regression modelling are that they are prone to producing high <span class="math inline">\(\beta\)</span>-errors <span class="citation">(see Johnson <a href="#ref-johnson2009getting" role="doc-biblioref">2009</a>)</span> and that they require rather large data sets.</p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction</h2>
<p>So far, the regression models that we have used only had fixed-effects. Having only fixed-effects means that all data points are treated as if they are completely independent and thus on the same hierarchical level. However, it is very common, that the data is nested in the sense that data points are not independent because they are, for instance produced by the same speaker or are grouped by some other characteristic. In such cases, the data is considered hierarchical and statistical models should incorporate such structural features of the data they work upon. With respect to regression modelling, hierarchical structures are incorporated by what is called <em>random effects</em>. When models only have a fixed-effects structure, then they make use of only a single intercept and/or slope (as in the left panel in the figure below), while mixed effects models have intercepts for each level of a random effect. If the random effect structure represents speakers then this would mean that a mixed-model would have a separate intercept and/or slope for each speaker.</p>
<p><img src="mixedregressions_files/figure-html/lmm1-1.png" width="672" /></p>
</div>
<div id="random-effects" class="section level2">
<h2><span class="header-section-number">2.2</span> Random Effects</h2>
<p><em>Random Effects</em> can have two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to fixed-effects models, that have only 1 intercept and one slope (left panel of the Figure above), mixed-effects models can therefore have various <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel in the Figure).</p>
<p>What features do distinguish random and fixed effects?</p>
<ol style="list-style-type: decimal">
<li><p>Random effects represent a higher level variable under which data points are grouped.</p></li>
<li><p>Random effects represent a sample of an infinite number of possible levels. For instance, speakers represent a potentially infinite pool of elements from which a many different samples can be drawn. Thus, random effects represent a random sample sample. Fixed effects, on the other hand, typically do not represent a random sample but a fixed set of variable levels (e.g. Age groups, or parts-of-speech).</p></li>
<li><p>Random effects typically represent many different levels while fixed effects typically have only a few. <span class="citation">Zuur, Hilbe, and Ieno (<a href="#ref-zuur2013beginner" role="doc-biblioref">2013</a>)</span> propose that a variable may be used as a fixed effect if it has less than 5 levels while it should be treated as a random effect if it has more than 10 levels. Variables with 5 to 10 levels can be used as both. However, this is a rule of thumb and ignores the theoretical reasons (random sample and nestedness) for considering something as a random effect and it also is at odds with the way that repeated measures are models (namely as mixed effects) alhough they typically only have very few levels.</p></li>
</ol>
<p>In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/lmm2-1.png" width="672" /></p>
<p>The left panel merely shows the data while the centre panel includes the regression line for a regression that estimates Weight based on Height. The right panel shows the regression line and, in addition, random intercepts each of the three groups.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the depended variable solely on the base intercept (the mean), with a model, that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the random-effect model explains significantly more variance than the simple model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-preposition-use-across-time-by-genre" class="section level2">
<h2><span class="header-section-number">2.3</span> Example: Preposition Use across Time by Genre</h2>
<p>To explore how to implement a mixed-effects model in R we revisit the preposition data that contains relative frequencies of prepositions in English texts written between 1150 and 1913. As a first step, and to prepare our analysis, we load necessary R packages, specify options, and load as well as provide an overview of the data.</p>
<pre class="r"><code># activate packages
library(tidyverse)
library(knitr)
# supress scientific notation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4)      
# do not convert strings into factors
options(stringsAsFactors = F)              
# read in data
lmmdata &lt;- read.delim(&quot;https://slcladal.github.io/data/lmmdata.txt&quot;, header = TRUE) %&gt;%
# convert date into a numeric variable
    dplyr::mutate(Date = as.numeric(Date))
# inspect updated data set
head(lmmdata); nrow(lmmdata) </code></pre>
<pre><code>##   Date         Genre    Text Prepositions Region
## 1 1736       Science   albin        166.0  North
## 2 1711     Education    anon        139.9  North
## 3 1808 PrivateLetter  austen        130.8  North
## 4 1878     Education    bain        151.3  North
## 5 1743     Education barclay        145.7  North
## 6 1908     Education  benson        120.8  North</code></pre>
<pre><code>## [1] 537</code></pre>
<p>The data set contains the date when the text was written (Date), the genre of the text (Genre), the name of the text (Text), the relative frequency of prepositions in the text (Prepositions), and the region in which the text was written (Region). We now plot the data to get a first impression of its structure.</p>
<pre class="r"><code>library(gridExtra)
p1 &lt;- ggplot(lmmdata, aes(x = Date, y = Prepositions)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = F, color = &quot;red&quot;, linetype = &quot;dashed&quot;) +
  theme_bw() +
  labs(y = &quot;Frequency\n(Prepositions)&quot;)
p2 &lt;- ggplot(lmmdata, aes(x = reorder(Genre, -Prepositions), y = Prepositions)) +
  geom_boxplot() +
  theme_bw() + 
  theme(axis.text.x = element_text(angle=90)) +
  labs(x = &quot;Genre&quot;, y = &quot;Frequency\n(Prepositions)&quot;)
p3 &lt;- ggplot(lmmdata, aes(Prepositions)) +
  geom_histogram() +
  theme_bw() + 
  labs(y = &quot;Count&quot;, x = &quot;Frequency (Prepositions)&quot;)
grid.arrange(grobs = list(p1, p2, p3), widths = c(1, 1), layout_matrix = rbind(c(1, 1), c(2, 3)))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm4-1.png" width="672" /></p>
<p>The scatter plot in the upper panel indicates that the use of prepositions has moderately increased over time while the boxplots in the lower left panel show that the genres differ quite substantially with respect to their median frequencies of prepositions per text. Finally, the histogram in the lower right panel show that preposition use is distributed normally with a mean of 132.2 prepositions per text.</p>
<pre class="r"><code>p4 &lt;- ggplot(lmmdata, aes(Date, Prepositions)) +
  geom_point() +
  labs(x = &quot;Year&quot;, y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;)  + 
  theme_bw()
p5 &lt;- ggplot(lmmdata, aes(Region, Prepositions)) +
  geom_boxplot() +
  labs(x = &quot;Region&quot;, y = &quot;Prepositions per 1,000 words&quot;) +
  geom_smooth(method = &quot;lm&quot;)  + 
  theme_bw()
grid.arrange(p4, p5, nrow = 1)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm5-1.png" width="672" /></p>
<pre class="r"><code>ggplot(lmmdata, aes(Date, Prepositions)) +
  geom_point() +
  facet_wrap(~ Genre, nrow = 4) +
  geom_smooth(method = &quot;lm&quot;) +
  theme_bw() +
  labs(x = &quot;Date of composition&quot;, y = &quot;Prepositions per 1,000 words&quot;) +
  coord_cartesian(ylim = c(0, 220))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm6-1.png" width="672" /></p>
<p>Centring or scaling numeric variables is useful for later interpretation of regression models: if the date variable was not centred, the regression would show the effects of variables at year 0(!). If numeric variables are scaled, other variables are variables are considered relative not to 0 but to the mean of that variable (in this case the mean of years in our data). Centring simply means that the mean of the numeric variable is subtracted from each value.</p>
<pre class="r"><code>lmmdata$DateUnscaled &lt;- lmmdata$Date
lmmdata$Date &lt;- scale(lmmdata$Date, scale = F)
# inspect data
head(lmmdata); str(lmmdata)</code></pre>
<pre><code>##     Date         Genre    Text Prepositions Region DateUnscaled
## 1 109.87       Science   albin        166.0  North         1736
## 2  84.87     Education    anon        139.9  North         1711
## 3 181.87 PrivateLetter  austen        130.8  North         1808
## 4 251.87     Education    bain        151.3  North         1878
## 5 116.87     Education barclay        145.7  North         1743
## 6 281.87     Education  benson        120.8  North         1908</code></pre>
<pre><code>## &#39;data.frame&#39;:    537 obs. of  6 variables:
##  $ Date        : num [1:537, 1] 109.9 84.9 181.9 251.9 116.9 ...
##   ..- attr(*, &quot;scaled:center&quot;)= num 1626
##  $ Genre       : chr  &quot;Science&quot; &quot;Education&quot; &quot;PrivateLetter&quot; &quot;Education&quot; ...
##  $ Text        : chr  &quot;albin&quot; &quot;anon&quot; &quot;austen&quot; &quot;bain&quot; ...
##  $ Prepositions: num  166 140 131 151 146 ...
##  $ Region      : chr  &quot;North&quot; &quot;North&quot; &quot;North&quot; &quot;North&quot; ...
##  $ DateUnscaled: num  1736 1711 1808 1878 1743 ...</code></pre>
<p>We now set up a fixed-effects model with the “glm” function and a mixed-effects model using the “glmer” function with Genre as a random effect.</p>
<pre class="r"><code>library(lme4)
# generate models
m0.glm &lt;- glm(Prepositions ~ 1, family = gaussian, data = lmmdata)
m0.glmer = glmer(Prepositions ~ 1 + (1|Genre), data = lmmdata, family = &quot;gaussian&quot;)</code></pre>
<p>Now that we have created the base-line models, we will test whether including a random effect structure is mathematically justified. It is important to note here that we are not going to test if including a random effect structure is theoretically motivated but simply if it causes a decrease in variance.</p>
</div>
<div id="testing-random-effects" class="section level2">
<h2><span class="header-section-number">2.4</span> Testing Random Effects</h2>
<p>As a first step in the modelling process, we now need to determine whether or not including a random effect structure is justified. We do so by comparing the base-line model without random intercepts to the model with random intercepts using a Likelihood Ratio Test. A short word of warning is in order here regarding the specific of the model: we need to set “REML = T” because Relative Estimate Maximum Likelihood (REML) provides better estimates for the random effects part of the model compared with the simpler Maximum Likelihood (ML) specification <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>, 879)</span>.</p>
<pre class="r"><code>x2 = -2*logLik(m0.glm, REML = T)+2*logLik(m0.glmer, REML = T)
x2 &lt;- x2 &lt;- x2[[1]]
list(x2, pchisq(x2, df=2, lower.tail=F))</code></pre>
<pre><code>## [[1]]
## [1] 222.4
## 
## [[2]]
## [1] 0.0000000000000000000000000000000000000000000000005049</code></pre>
<p>The inclusion of a random effect structure with random intercepts is justified based on the Likelihood Ratio Test.</p>
<p>As a note on model comparisons: when we compare mixed-effects models, the REML specification must be “FALSE” or set to “method =”ML" (Maximum Likelihood) <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>, 879)</span>. This is because “ML” produces more accurate estimates of fixed regression parameters. In contrast, one should use “REML” when comparing fixed to mixed models as REML produces more accurate estimates of random variances <span class="citation">(Twisk <a href="#ref-twisk2006multilevel" role="doc-biblioref">2006</a>)</span>.</p>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">2.5</span> Model Fitting</h2>
<p>After having determined that including a random effect structure is justified, we can continue by fitting the model and including diagnostics as we go. Including diagnostics in the model fitting process can save time and prevent relying on models which only turn out to be unstable if we would perform the diagnostics after the fact.</p>
<p>We begin fitting our model by adding Date as a fixed effect and compare this model to our mixed-effects base-line model to see if Date improved the model fit by explaining variance and if Date significantly correlates with our dependent variable (this means that the difference between the models is the effect (size) of “Date”!)</p>
<pre class="r"><code>m1.glmer &lt;- glmer(Prepositions ~ (1|Genre) + Date, data = lmmdata)
anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: lmmdata
## Models:
## m0.glmer: Prepositions ~ 1 + (1 | Genre)
## m1.glmer: Prepositions ~ (1 | Genre) + Date
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)   
## m0.glmer    3 4502 4515  -2248     4496                       
## m1.glmer    4 4495 4512  -2244     4487  8.93  1     0.0028 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The model with Date is the better model (significant p-value and lower AIC). The significant p-value shows that “Date” correlates significantly with “Prepositions” (<span class="math inline">\(\chi\)</span><sup>2</sup>(1) = 8.93, p = .0028). The <span class="math inline">\(\chi\)</span><sup>2</sup> value here is labelled “L.Ratio” and the degrees of freedom are calculated by subtracting the smaller number of DFs from the larger number of DFs.</p>
<p>We now test whether Region should also be part of the final minimal adequate model. The easiest way to add predictors is by using the “predict” function (it saves time and typing).</p>
<pre class="r"><code># generate model
m2.glmer &lt;- update(m1.glmer, .~.+ Region)
# test vifs
library(car)
car::vif(m2.glmer)</code></pre>
<pre><code>##   Date Region 
##  1.203  1.203</code></pre>
<pre class="r"><code># compare models                
anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: lmmdata
## Models:
## m1.glmer: Prepositions ~ (1 | Genre) + Date
## m2.glmer: Prepositions ~ (1 | Genre) + Date + Region
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m1.glmer    4 4495 4512  -2244     4487                    
## m2.glmer    5 4495 4516  -2242     4485  2.39  1       0.12</code></pre>
<p>Three things tell us that Region should not be included: (i) the AIC does not decrease, (ii) the BIC increases(!), and the p-value is higher than .05. This means, that we will continue fitting the model without having Region included. Well… not quite - just as a note on including variables: while Region is not significant as a main effect, it must still be included in a model if it were part of a significant interaction. To test if this is indeed the case, we fit another model with the interaction between Date and Region as predictor.</p>
<pre class="r"><code># generate model
m3.glmer &lt;- update(m1.glmer, .~.+Region*Date)
# extract vifs
car::vif(m3.glmer)</code></pre>
<pre><code>##        Date      Region Date:Region 
##       1.969       1.203       1.780</code></pre>
<pre class="r"><code># compare models                
anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: lmmdata
## Models:
## m1.glmer: Prepositions ~ (1 | Genre) + Date
## m3.glmer: Prepositions ~ (1 | Genre) + Date + Region + Date:Region
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m1.glmer    4 4495 4512  -2244     4487                    
## m3.glmer    6 4496 4522  -2242     4484  2.89  2       0.24</code></pre>
<p>Again, the high p-value and the increase in AIC and BIC show that we have found our minimal adequate model with only contains Date as a main effect. In a next step, we can inspect the final minimal adequate model, i.e. the most parsimonious (the model that explains a maximum of variance with a minimum of predictors).</p>
<pre class="r"><code># inspect results
summary(m1.glmer)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Prepositions ~ (1 | Genre) + Date
##    Data: lmmdata
## 
## REML criterion at convergence: 4491
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.735 -0.657  0.006  0.661  3.597 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Genre    (Intercept) 159      12.6    
##  Residual             229      15.1    
## Number of obs: 537, groups:  Genre, 16
## 
## Fixed effects:
##              Estimate Std. Error t value
## (Intercept) 133.88516    3.24749    41.2
## Date          0.01894    0.00632     3.0
## 
## Correlation of Fixed Effects:
##      (Intr)
## Date 0.005</code></pre>
</div>
<div id="model-diagnostics" class="section level2">
<h2><span class="header-section-number">2.6</span> Model Diagnostics</h2>
<p>We can now evaluate the goodness of fit of the model and check if mathematical requirements and assumptions have been violated. In a first step, we generate diagnostic plots that focus on the random effect structure.</p>
<pre class="r"><code>plot(m1.glmer, Genre ~ resid(.), abline = 0 ) # generate diagnostic plots</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm14-1.png" width="672" /></p>
<p>The plot shows that there are some outliers (points outside the boxes) and that the variability within letters is greater than in other genres we therefore examine the genres in isolation standardized residuals versus fitted values <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 175)</span>.</p>
<pre class="r"><code>plot(m1.glmer, resid(., type = &quot;pearson&quot;) ~ fitted(.) | Genre, id = 0.05, 
     adj = -0.3, pch = 20, col = &quot;gray40&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm15-1.png" width="672" /></p>
<p>The plot shows the standardized residuals (or Pearson’s residuals) versus fitted values and suggests that there are outliers in the data (the names elements in the plots). To check if these outliers are a cause for concern, we will now use a Levene’s test to check if the variance is distributed homogeneously (homoscedasticity) or whether the assumption of variance homogeneity is violated (due to the outliers).</p>
<pre class="r"><code># check homogeneity
leveneTest(lmmdata$Prepositions, lmmdata$Genre, center = mean)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = mean)
##        Df F value Pr(&gt;F)  
## group  15    1.74   0.04 *
##       521                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The Levene’s test shows that the variance is distributed unevenly across genres which means that we do not simply continue but should either remove problematic data points (outliers) or use a weighing method.</p>
<p>In this case, we create a new model which uses weights to compensate for heterogeneity of variance and thus the influence of outliers - which is an alternative to removing the data points and rerunning the analysis <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 177)</span>. However, to do so, we need to use a different function (the “lmer” function) which means that we have to create two models: the “old” minimal adequate model and the “new” minimal adequate model with added weights. After we have created these models, we will compare them to see if including weights has improved the fit.</p>
<pre class="r"><code>library(nlme)
m4.lme = lme(Prepositions ~ Date, random = ~1|Genre, data = lmmdata, method = &quot;ML&quot;)
m5.lme &lt;- update(m4.lme, weights = varIdent(form = ~ 1 | Genre))
# compare models
anova(m5.lme, m4.lme)</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m5.lme     1 19 4486 4567  -2224                       
## m4.lme     2  4 4495 4512  -2244 1 vs 2   39.17  0.0006</code></pre>
<p>The weight model (m5.lme) that uses weights to account for unequal variance is performing significantly better than the model without weights (m4.lme) and we therefore switch to the weight model and inspect its parameters.</p>
<pre class="r"><code># inspect results
summary(m5.lme)        </code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: lmmdata 
##    AIC  BIC logLik
##   4486 4567  -2224
## 
## Random effects:
##  Formula: ~1 | Genre
##         (Intercept) Residual
## StdDev:       12.26    14.34
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | Genre 
##  Parameter estimates:
##           Bible       Biography           Diary       Education         Fiction 
##          1.0000          0.3407          0.8695          0.7888          0.9117 
##        Handbook         History             Law      Philosophy   PrivateLetter 
##          1.0965          0.9787          0.7849          0.7370          1.1906 
##    PublicLetter        Religion         Science          Sermon          Travel 
##          1.2189          0.9746          0.8486          0.9708          1.0862 
## TrialProceeding 
##          1.2602 
## Fixed effects: Prepositions ~ Date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.96    3.1444 520   42.60  0.0000
## Date          0.02    0.0055 520    3.99  0.0001
##  Correlation: 
##      (Intr)
## Date 0.004 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.31912 -0.67972  0.01469  0.69872  3.10388 
## 
## Number of Observations: 537
## Number of Groups: 16</code></pre>
<p>We can also use an ANOVA display which is more to the point.</p>
<pre class="r"><code>anova(m5.lme)          </code></pre>
<pre><code>##             numDF denDF F-value p-value
## (Intercept)     1   520  1813.9  &lt;.0001
## Date            1   520    15.9  0.0001</code></pre>
<p>As we did before, we now check, whether the final minimal model (with weights) outperforms an intercept-only base-line model.</p>
<pre class="r"><code># creat base-line model
m0.lme = lme(Prepositions ~ 1, random = ~1|Genre, data = lmmdata, method = &quot;ML&quot;, weights = varIdent(form = ~ 1 | Genre))
anova(m5.lme, m0.lme)  # test if date is significant</code></pre>
<pre><code>##        Model df  AIC  BIC logLik   Test L.Ratio p-value
## m5.lme     1 19 4486 4567  -2224                       
## m0.lme     2 18 4496 4573  -2230 1 vs 2   12.44  0.0004</code></pre>
<p>Our final minimal adequate model with weights performs significantly better than an intercept only base-line model. Before doing the final diagnostics, we well inspect the estimates for the random effect structure to check if there are values which require further inspection (e.g. because they are drastically different from all other values).</p>
<pre class="r"><code># extract estimates and sd for fixed and random effects
intervals(m5.lme)      </code></pre>
<pre><code>## Approximate 95% confidence intervals
## 
##  Fixed effects:
##                 lower      est.     upper
## (Intercept) 127.79833 133.96402 140.12970
## Date          0.01105   0.02174   0.03244
## attr(,&quot;label&quot;)
## [1] &quot;Fixed effects:&quot;
## 
##  Random Effects:
##   Level: Genre 
##                 lower  est. upper
## sd((Intercept)) 8.525 12.26 17.64
## 
##  Variance function:
##                  lower   est.  upper
## Biography       0.2139 0.3407 0.5427
## Diary           0.6317 0.8695 1.1968
## Education       0.5792 0.7888 1.0743
## Fiction         0.6529 0.9117 1.2730
## Handbook        0.7838 1.0965 1.5340
## History         0.7325 0.9787 1.3076
## Law             0.5557 0.7849 1.1088
## Philosophy      0.4650 0.7370 1.1679
## PrivateLetter   0.9512 1.1906 1.4902
## PublicLetter    0.9472 1.2189 1.5686
## Religion        0.6694 0.9746 1.4190
## Science         0.5533 0.8486 1.3013
## Sermon          0.7296 0.9708 1.2918
## Travel          0.7927 1.0862 1.4883
## TrialProceeding 0.8689 1.2602 1.8275
## attr(,&quot;label&quot;)
## [1] &quot;Variance function:&quot;
## 
##  Within-group standard error:
## lower  est. upper 
## 11.85 14.34 17.36</code></pre>
<p>The random effect estimates do not show any outliers or drastically increased or decreased values which means that the random effect structure is fine.</p>
</div>
<div id="effect-sizes" class="section level2">
<h2><span class="header-section-number">2.7</span> Effect Sizes</h2>
<p>We will now extract effect sizes (in the example: the effect size of date) and calculate normalized effect size measures (this effect size measure works for all fixed effects). To calculate the effect size, take the square root of the squared t-value divided by the t-value squared plus the degrees of freedom:</p>
<p>r = <code>sqrt(t^2^/(t^2^+df))</code>.</p>
<p>A brief word of warning is in order here: only apply this function to main effects that are not involved in interactions as they are meaningless because the amount of variance explained by main effects involved in interactions is unclear <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>, 641)</span>.</p>
<pre class="r"><code>library(ggeffects)
# calculate effect size 
ggeffect(m5.lme)</code></pre>
<pre><code>## $Date
## 
## # Predicted values of Prepositions
## # x = Date
## 
##    x | Predicted |   SE |           95% CI
## ------------------------------------------
## -500 |    123.09 | 4.15 | [114.95, 131.24]
## -400 |    125.27 | 3.81 | [117.78, 132.76]
## -300 |    127.44 | 3.53 | [120.50, 134.38]
## -200 |    129.62 | 3.32 | [123.10, 136.13]
## -100 |    131.79 | 3.18 | [125.54, 138.04]
##    0 |    133.96 | 3.14 | [127.80, 140.13]
##  100 |    136.14 | 3.19 | [129.88, 142.40]
##  300 |    140.49 | 3.54 | [133.53, 147.45]
## 
## 
## attr(,&quot;class&quot;)
## [1] &quot;ggalleffects&quot; &quot;list&quot;</code></pre>
<p>While we have already shown that the effect of Date is significant, it is small which means that the number of prepositions per text does not correlate very strongly with time. This suggests that other factors that are not included in the model also impact the frequency of prepositions (and probably more meaningfully, too).</p>
<p>Before turning to the diagnostics, we will use the fitted (or predicted) and the observed values with a regression line for the predicted values. This will not only show how good the model fit the data but also the direction and magnitude of the effect.</p>
<pre class="r"><code># extract predicted values
lmmdata$Predicted &lt;- predict(m5.lme, lmmdata)
# plot predicted values
ggplot(lmmdata, aes(DateUnscaled, Predicted)) +
  facet_wrap(~Genre) +
  geom_point(aes(x = DateUnscaled, y = Prepositions), color = &quot;gray80&quot;, size = .5) +
  geom_smooth(aes(y = Predicted), color = &quot;gray20&quot;, linetype = &quot;solid&quot;, 
              se = T, method = &quot;lm&quot;) +
  guides(color=guide_legend(override.aes=list(fill=NA))) +  
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position=&quot;top&quot;, legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  xlab(&quot;Date of composition&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm21b-1.png" width="672" /></p>
</div>
<div id="model-diagnostics-1" class="section level2">
<h2><span class="header-section-number">2.8</span> Model Diagnostics</h2>
<p>We now create diagnostic plots. What we wish to see in the diagnostic plots is a cloud of dots in the middle of the window without any structure. What we do not want to see is a funnel-shaped cloud because this indicates an increase of the errors/residuals with an increase of the predictor(s) (because this would indicate heteroscedasticity) <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 182)</span>.</p>
<pre class="r"><code># start plotting
par(mfrow = c(2, 2))           # display plots in 2 rows and 2 columns
plot(m5.lme, pch = 20, col = &quot;black&quot;, lty = &quot;dotted&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm22-1.png" width="672" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>What a wonderful unstructured cloud - the lack of structure tells us that the model is “healthy” and does not suffer from heteroscedasticity. We will now create more diagnostic plots to find potential problems <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 21)</span>.</p>
<pre class="r"><code># fitted values by Genre
plot(m5.lme, form = resid(., type = &quot;p&quot;) ~ fitted(.) | Genre, abline = 0, 
     cex = .5, pch = 20, col = &quot;black&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm23-1.png" width="672" /></p>
<p>In contrast to the unweight model, no data points are named which indicates that the outliers do no longer have unwarranted influence on the model. Now, we check the residuals of fitted values against observed values <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 179)</span>. What we would like to see is a straight, upwards going line.</p>
<pre class="r"><code># residuals of fitted values against observed
qqnorm(m5.lme, pch = 20, col = &quot;black&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm24-1.png" width="672" /></p>
<p>A beautiful, straight line! The qqplot does not indicate any problems. It is, unfortunately, rather common that the dots deviate from the straight line at the very bottom or the very tp which means that the model is good at estimating values around the middle of the dependent variable but rather bad at estimating lower or higher values. Next, we check the residuals by “Genre” <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 179)</span>.</p>
<pre class="r"><code># residuals by genre
qqnorm(m5.lme, ~resid(.) | Genre, pch = 20, col = &quot;black&quot; )</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm25-1.png" width="672" /></p>
<p>Beautiful straight lines - perfection! Now, we inspect the observed responses versus the within-group fitted values <span class="citation">(Pinheiro and Bates <a href="#ref-pinheiro2000mixedmodels" role="doc-biblioref">2000</a>, 178)</span>.</p>
<pre class="r"><code># observed responses versus the within-group fitted values
plot(m5.lme, Prepositions ~ fitted(.), id = 0.05, adj = -0.3, 
     xlim = c(80, 220), cex = .8, pch = 20, col = &quot;blue&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm26-1.png" width="672" /></p>
<p>Although some data points are named, the plot does not show any structure, like a funnel, which would have been problematic.</p>
</div>
<div id="reporting-results" class="section level2">
<h2><span class="header-section-number">2.9</span> Reporting Results</h2>
<p>Before we do the write-up, we have a look at the model summary as this will provide us with at least some of the parameters that we want to report.</p>
<pre class="r"><code>summary(m5.lme)</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: lmmdata 
##    AIC  BIC logLik
##   4486 4567  -2224
## 
## Random effects:
##  Formula: ~1 | Genre
##         (Intercept) Residual
## StdDev:       12.26    14.34
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | Genre 
##  Parameter estimates:
##           Bible       Biography           Diary       Education         Fiction 
##          1.0000          0.3407          0.8695          0.7888          0.9117 
##        Handbook         History             Law      Philosophy   PrivateLetter 
##          1.0965          0.9787          0.7849          0.7370          1.1906 
##    PublicLetter        Religion         Science          Sermon          Travel 
##          1.2189          0.9746          0.8486          0.9708          1.0862 
## TrialProceeding 
##          1.2602 
## Fixed effects: Prepositions ~ Date 
##              Value Std.Error  DF t-value p-value
## (Intercept) 133.96    3.1444 520   42.60  0.0000
## Date          0.02    0.0055 520    3.99  0.0001
##  Correlation: 
##      (Intr)
## Date 0.004 
## 
## Standardized Within-Group Residuals:
##      Min       Q1      Med       Q3      Max 
## -3.31912 -0.67972  0.01469  0.69872  3.10388 
## 
## Number of Observations: 537
## Number of Groups: 16</code></pre>
<pre class="r"><code>library(sjPlot)
tab_model(m5.lme)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
Prepositions
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
133.96
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
127.80 – 140.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Date
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01 – 0.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;">
Random Effects
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
σ<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
205.71
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
τ<sub>00</sub> <sub>Genre</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
150.39
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>Genre</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
16
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
537
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.030 / NA
</td>
</tr>
</table>
<p>A mixed-effect linear regression model which contained the genre of texts as random effect was fit to the data in a step-wise-step up procedure. Due to the presence of outliers in the data, weights were included into the model which led to a significantly improved model fit compared to an unweight model (<span class="math inline">\(\chi\)</span><sup>2</sup>(2): 39.17, p: 0.0006). The final minimal adequate model performed significantly better than an intercept-only base-line model (<span class="math inline">\(\chi\)</span><sup>2</sup>(1): 52.87, p &lt;.0001) and showed that the frequency of prepositions increases significantly but only marginally with the date of composition (<span class="math inline">\(\chi\)</span><sup>2</sup>(2): 10.12, p: 0.0063, Pearson’s <span class="math inline">\(r\)</span> = 0.172). Neither the region where the text was composed nor a higher order interaction between genre and region significantly correlated with the use of prepositions in the data.</p>
</div>
<div id="remarks-on-prediction" class="section level2">
<h2><span class="header-section-number">2.10</span> Remarks on Prediction</h2>
<p>While the number of intercepts, the model-reports, and the way how mixed- and fixed-effects arrive at predictions differ, their predictions are identical (at least when dealing with a simple random effect structure). Consider the following example where we create analogous fixed and mixed effect models and plot their predicted frequencies of prepositions per genre across the unscaled date of composition. The predictions of the mixed-effects model are plotted as a solid red line, wehile the predictions of the fixed-effects model are plotted as dashed blue lines.</p>
<pre class="r"><code># creat lm model
m5.lmeunweight &lt;- lm(Prepositions ~ DateUnscaled + Genre, data = lmmdata)
lmmdata$lmePredictions &lt;- fitted(m5.lmeunweight, lmmdata)
m5.lm &lt;- lm(Prepositions ~ DateUnscaled + Genre, data = lmmdata)
lmmdata$lmPredictions &lt;- fitted(m5.lm, lmmdata)
# plot predictions
ggplot(lmmdata, aes(x = DateUnscaled, y = lmePredictions, group = Genre)) +
  geom_line(aes(y = lmmdata$lmePredictions), linetype = &quot;solid&quot;, color = &quot;red&quot;) +
  geom_line(aes(y = lmmdata$lmPredictions), linetype = &quot;dashed&quot;, color = &quot;blue&quot;) +
  facet_wrap(~ Genre, nrow = 4) +
  theme_bw() +
  labs(x = &quot;Date of composition&quot;) +
  labs(y = &quot;Prepositions per 1,000 words&quot;) +
  coord_cartesian(ylim = c(0, 220))</code></pre>
<p><img src="mixedregressions_files/figure-html/lmm29-1.png" width="672" /></p>
<p>The predictions overlap perfectly which means that the predictions of both are identical - irrespective of whether genre is part of the mixed or the fixed effects structure.</p>
</div>
</div>
<div id="mixed-effects-binomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">3</span> Mixed-Effects Binomial Logistic Regression</h1>
<p>We now turn to an extension of binomial logistic regression: mixed-effects binomial logistic regression. As is the case with linear mixed-effects models logistic mixed effects models have the following advantages over simpler statistical tests:</p>
<ul>
<li><p>Mixed-effects models are multivariate, i.e. they test the effect of several predictors simultaneously while controlling for the effect of all other predictors.</p></li>
<li><p>Mixed models allow to statistically incorporate within-speaker variability and are thus fit to model hierarchical or nested data structures. This applies if several observations are produced by an individual speaker, for instance.</p></li>
<li><p>Mixed-models provide a wealth of diagnostic statistics which enables us to control e.g. multicollinearity, i.e. correlations between predictors, and to test whether conditions or requirements are violated (e.g. homogeneity of variance, etc.).</p></li>
</ul>
<p>Major disadvantages of regression modelling are that they are prone to producing high <span class="math inline">\(\beta\)</span>-errors <span class="citation">(see Johnson <a href="#ref-johnson2009getting" role="doc-biblioref">2009</a>)</span> and that they require rather large data sets.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>As is the case with linear mixed-effects models, binomial logistic mixed-effect models are multivariate analysis that treat data points as hierarchical or grouped in some way. In other words, they take into account that the data is nested in the sense that data points are produced by the same speaker or are grouped by some other characteristics. In mixed-models, hierarchical structures are modelled as <em>random effects</em>. If the random effect structure represents speakers then this means that a mixed-model would have a separate intercept and/or slope for each speaker.</p>
<p><em>Random Effects</em> in linear models two parameters: the intercept (the point where the regression line crosses the y-axis) and the slope (the acclivity of the regression line). In contrast to linear mixed-effects models, random effects differ in the position and the slope of the logistic function that is applied to the likelihood of the dependent variable. <em>random intercepts</em> (centre left panel ) or various <em>random slopes</em> (centre right panel ), or both, various <em>random intercepts</em> and various <em>random slopes</em> (right panel ). In the following, we will only focus on models with random intercepts because this is the by far more common method and because including both random intercepts and random slopes requires huge amounts of data. Consider the Figure below to understand what is meant by “random intercepts”.</p>
<p><img src="mixedregressions_files/figure-html/blmm1-1.png" width="672" /></p>
<p>The upper left panel merely shows the logistic curve representing the predictions of a fixed-effects logistic regression with a single intercept and slope. The upper right panel shows the logistic curves representing the predictions of a of a mixed-effects logistic regression with random intercepts for each level of a grouping variable. The lower left panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with one intercept but random slopes for each level of a grouping variable. The lower right panel shows the logistic curves representing the predictions of a mixed-effects logistic regression with random intercepts and random slopes for each level of a grouping variable.</p>
<p>After adding random intercepts, predictors (or fixed effects) are added to the model (just like with multiple regression). So mixed-effects are called mixed-effects because they contain both random and fixed effects.</p>
<p>In terms of general procedure, random effects are added first, and only after we have ascertained that including random effects is warranted, we test whether including fixed-effects is warranted <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>)</span>. We test whether including random effects is warranted by comparing a model, that bases its estimates of the dependent variable solely on the base intercept, with a model that bases its estimates of the dependent variable solely on the intercepts of the random effect. If the mixed-effects model explains significantly more variance than the fixed-effects model without random effect structure, then we continue with the mixed-effects model. In other words, including random effects is justified if they reduce residual deviance.</p>
</div>
<div id="example-discourse-like-in-irish-english" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Discourse LIKE in Irish English</h2>
<p>In this example we will investigate which factors correlate with the use of <em>final discourse like</em> (e.g. “<em>The weather is shite, like!</em>”) in Irish English. The data set represents speech units in a corpus that were coded for the speaker who uttered a given speech unit, the gender (Gender: Men versus Women) and age of that speaker (Age: Old versus Young), whether the interlocutors were of the same or a different gender (ConversationType: SameGender versus MixedGender), and whether another <em>final discourse like</em> had been used up to three speech units before (Priming: NoPrime versus Prime), whether or not the speech unit contained an <em>final discourse like</em> (SUFLike: 1 = yes, 0 = no. To begin with, we load the data and inspect the structure of the data set,</p>
<pre class="r"><code># load data
mblrdata &lt;- read.table(&quot;https://slcladal.github.io/data/mblrdata.txt&quot;, 
                       comment.char = &quot;&quot;,# data does not contain comments
                       quote = &quot;&quot;,       # data does not contain quotes
                       sep = &quot;\t&quot;,       # data is tab separated
                       header = T)       # data has column names
# inspect data structure
str(mblrdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    2000 obs. of  6 variables:
##  $ ID              : chr  &quot;S1A-061$C&quot; &quot;S1A-023$B&quot; &quot;S1A-054$A&quot; &quot;S1A-090$B&quot; ...
##  $ Gender          : chr  &quot;Women&quot; &quot;Women&quot; &quot;Women&quot; &quot;Women&quot; ...
##  $ Age             : chr  &quot;Young&quot; &quot;Young&quot; &quot;Young&quot; &quot;Young&quot; ...
##  $ ConversationType: chr  &quot;MixedGender&quot; &quot;MixedGender&quot; &quot;SameGender&quot; &quot;MixedGender&quot; ...
##  $ Priming         : chr  &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; &quot;NoPrime&quot; ...
##  $ SUFlike         : int  0 0 0 0 0 1 1 0 0 1 ...</code></pre>
<p>As all variables except for the dependent variable (SUFlike) are character strings, we factorize the independent variables.</p>
<pre class="r"><code># def. variables to be factorized
vrs &lt;- c(&quot;ID&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;ConversationType&quot;, &quot;Priming&quot;)
# def. vector with variables
fctr &lt;- which(colnames(mblrdata) %in% vrs)     
# factorize variables
mblrdata[,fctr] &lt;- lapply(mblrdata[,fctr], factor)
# relevel Age (Young = Reference)
mblrdata$Age &lt;- relevel(mblrdata$Age, &quot;Young&quot;)
# order data by ID
mblrdata &lt;- mblrdata %&gt;%
  dplyr::arrange(ID)</code></pre>
<p>Before continuing, a few words about the minimum number of random effect levels and the minimum number of observations per random effect level are in order.</p>
<p>While many data points per random variable level increases statistical power and thus to more robust estimates of the random effects <span class="citation">(Austin and Leckie <a href="#ref-austin2018multilevel" role="doc-biblioref">2018</a>)</span>, it has been shown that small numbers of observations per random effect variable level do not cause serious bias and it does not negatively affect the estimates of the fixed-effects coefficients <span class="citation">(Bell, Ferron, and Kromrey <a href="#ref-bell2008multilevel" role="doc-biblioref">2008</a>, @clarke2008can, @clarke2007addressing, @maas2005sufficient)</span>. The minimum number of observations per random effect variable level is therefore 1.</p>
<p>In simulation study, <span class="citation">(Bell, Ferron, and Kromrey <a href="#ref-bell2008multilevel" role="doc-biblioref">2008</a>)</span> tested the impact of random variable levels with only a single observation ranging from 0 to 70 percent. As long as there was a relatively high number of random effect variable levels (500 or more), small numbers of observations had almost no impact on bias and Type 1 error control.</p>
<p>After preparing the data, we have a look at the first six lines of the data set.</p>
<table>
<caption>First six rows of the data set.</caption>
<colgroup>
<col width="18%" />
<col width="12%" />
<col width="7%" />
<col width="31%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left">Gender</th>
<th align="left">Age</th>
<th align="left">ConversationType</th>
<th align="left">Priming</th>
<th align="right">SUFlike</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">S1A-001<span class="math inline">\(A |Men |Old |SameGender |NoPrime | 0| |S1A-001\)</span>A</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">S1A-001<span class="math inline">\(A |Men |Old |SameGender |NoPrime | 0| |S1A-001\)</span>A</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">S1A-001<span class="math inline">\(A |Men |Old |SameGender |NoPrime | 0| |S1A-001\)</span>A</td>
<td align="left">Men</td>
<td align="left">Old</td>
<td align="left">SameGender</td>
<td align="left">NoPrime</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We now plot the data to inspect the relationships within the data set.</p>
<pre class="r"><code>ggplot(mblrdata, aes(Gender, SUFlike, color = Priming)) +
  facet_wrap(Age~ConversationType) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
  labs(x = &quot;&quot;, y = &quot;Observed Probabilty of discourse like&quot;) +
  scale_color_manual(values = c(&quot;gray20&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm8-1.png" width="672" /></p>
<p>The upper left panel in the Figure above indicates that men sue discourse like more frequently than women. The centre right panel suggests that priming significantly increases the likelihood of discourse like being used. The centre left panel suggests that speakers use discourse like more frequently in mixed-gender conversations. However, the lower right panel indicates an interaction between gender and conversation type as women appear to use discourse like less frequently in same gender conversations while the conversation type does not seem to have an effect on men. After visualizing the data, we will now turn to the model building process.</p>
</div>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">3.3</span> Model Building</h2>
<p>In a first step, we set the options and generate a distance matrix of the data.</p>
<pre class="r"><code>library(rms)
# set options
options(contrasts  =c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;))
mblrdata.dist &lt;- datadist(mblrdata)
options(datadist = &quot;mblrdata.dist&quot;)</code></pre>
<p>In a next step, we generate fixed-effects minimal base-line models and a base-line mixed-model using the “glmer” function with a random intercept for ID (a lmer object of the final minimal adequate model will be created later).</p>
<pre class="r"><code># baseline model glm
m0.glm = glm(SUFlike ~ 1, family = binomial, data = mblrdata) 
# base-line mixed-model
m0.glmer = glmer(SUFlike ~ (1|ID), data = mblrdata, family = binomial) </code></pre>
</div>
<div id="testing-the-random-effect" class="section level2">
<h2><span class="header-section-number">3.4</span> Testing the Random Effect</h2>
<p>Now, we check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.</p>
<pre class="r"><code>aic.glmer &lt;- AIC(logLik(m0.glmer))
aic.glm &lt;- AIC(logLik(m0.glm))
aic.glmer; aic.glm</code></pre>
<pre><code>## [1] 1828</code></pre>
<pre><code>## [1] 1838</code></pre>
<p>The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, we also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.</p>
<pre class="r"><code># test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) </code></pre>
<pre><code>## [1] 0.0006314</code></pre>
<pre class="r"><code># sig m0.glmer better than m0.glm</code></pre>
<p>The p-value of the Model Likelihood Ratio Test is lower than .05 which shows that the inclusion of the random-effects structure is warranted. We can now continue with the model fitting process.</p>
</div>
<div id="model-fitting-1" class="section level2">
<h2><span class="header-section-number">3.5</span> Model Fitting</h2>
<p>The next step is to fit the model which means that we aim to find the “best” model, i.e. the minimal adequate model. In this case, we will use a manual step-wise step-up, forward elimination procedure. Before we begin with the model fitting process we need to add ´control = glmerControl(optimizer = “bobyqa”)´ to avoid unnecessary failures to converge.</p>
<pre class="r"><code>m0.glmer &lt;- glmer(SUFlike ~ 1+ (1|ID), family = binomial, data = mblrdata, control=glmerControl(optimizer=&quot;bobyqa&quot;))</code></pre>
<p>During each step of the fitting procedure, we test whether certain assumptions on which the model relies are violated. To avoid <em>incomplete information</em> (a combination of variables does not occur in the data), we tabulate the variables we intend to include and make sure that all possible combinations are present in the data. Including variables although not all combinations are present in the data would lead to unreliable models that report (vastly) inaccurate results. A special case of incomplete information is <em>complete separation</em> which occurs if one predictor perfectly explains an outcome (in that case the incomplete information would be caused by a level of the dependent variable). In addition, we make sure that the VIFs do not exceed a maximum of 3 for main effects <span class="citation">(Zuur, Ieno, and Elphick <a href="#ref-zuur2010protocol" role="doc-biblioref">2010</a>)</span> - <span class="citation">Booth GD (<a href="#ref-booth1994regression" role="doc-biblioref">1994</a>)</span> suggest that VIFs should ideally be lower than 1.5 - and 20 for interactions as higher values would indicate multicollinearity and thus that the model is unstable. The value of 20 should be taken with a pinch of salt because there is no clear consensus about what the maximum VIF for interactions should be or if it should be considered at all. The reason is that we would, of course, expect the VIFs to increase when we are dealing with interactions as the main effects that are part of the interaction are very likely to correlate with the interaction itself. However, if the VIFs are too high, then this will still cause the issues with the attribution of variance. The value of 20 was chosen as it is twice the most generous value for acceptable VIFs for main effects in the standard literature on multicollinearity <span class="citation">(Zuur et al. <a href="#ref-zuur2009mixedmodels" role="doc-biblioref">2009</a>, @neter1990vif)</span>. Only once we have confirmed that the incomplete information, complete separation, and <em>multicollinearity</em> are not a major concern, we generate the more saturated model and test whether the inclusion of a predictor leads to a significant reduction in residual deviance. If the predictor explains a significant amount of variance, it is retained in the model while being disregarded in case it does not explain a sufficient quantity of variance.</p>
<pre class="r"><code># add Priming
ifelse(min(ftable(mblrdata$Priming, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m1.glmer &lt;- update(m0.glmer, .~.+Priming)
anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          npar  AIC  BIC logLik deviance Chisq Df          Pr(&gt;Chisq)    
## m0.glmer    2 1828 1840   -912     1824                                 
## m1.glmer    3 1703 1720   -848     1697   128  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Since the tests do not show problems relating to incomplete information, because including Priming significantly improves the model fit (decrease in AIC and BIC values), and since it correlates significantly with our dependent variable, we include Priming into our model.</p>
<pre class="r"><code># add Age
ifelse(min(ftable(mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m2.glmer &lt;- update(m1.glmer, .~.+ Age)
ifelse(max(car::vif(m2.glmer)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;)   </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m2.glmer: SUFlike ~ (1 | ID) + Priming + Age
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m1.glmer    3 1703 1720   -848     1697                    
## m2.glmer    4 1704 1727   -848     1696  0.56  1       0.45</code></pre>
<pre class="r"><code>Anova(m2.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##          Chisq Df          Pr(&gt;Chisq)    
## Priming 129.51  1 &lt;0.0000000000000002 ***
## Age       0.57  1                0.45    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVAs show that Age is not significant and the first ANOVA also shows that the BIC has increased which indicates that Age does not decrease variance. In such cases, the variable should not be included.</p>
<p>However, if the second ANOVA would report Age as being marginally significant, a case could be made for including it but it would be better to change the ordering in which predictors are added to the model. This is, however, just a theoretical issue here as Age is clearly not significant.</p>
<pre class="r"><code># add Gender
ifelse(min(ftable(mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m3.glmer &lt;- update(m1.glmer, .~.+Gender)
ifelse(max(car::vif(m3.glmer)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m1.glmer: SUFlike ~ (1 | ID) + Priming
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)    
## m1.glmer    3 1703 1720   -848     1697                        
## m3.glmer    4 1679 1702   -836     1671  25.4  1 0.00000047 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m3.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##         Chisq Df           Pr(&gt;Chisq)    
## Priming 124.4  1 &lt; 0.0000000000000002 ***
## Gender   28.6  1           0.00000009 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Gender is significant and will therefore be included as a predictor (you can also observe that including Gender has substantially decreased both AIC and BIC).</p>
<pre class="r"><code># add ConversationType
ifelse(min(ftable(mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m4.glmer &lt;- update(m3.glmer, .~.+ConversationType)
ifelse(max(car::vif(m4.glmer)) &lt;= 3,  &quot;VIFs okay&quot;, &quot;VIFs unacceptable&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m3.glmer: SUFlike ~ (1 | ID) + Priming + Gender
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)    
## m3.glmer    4 1679 1702   -836     1671                        
## m4.glmer    5 1669 1697   -829     1659  12.8  1    0.00034 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m4.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                  Chisq Df           Pr(&gt;Chisq)    
## Priming          130.7  1 &lt; 0.0000000000000002 ***
## Gender            13.4  1              0.00025 ***
## ConversationType  13.0  1              0.00031 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>ConversationType improves model fit (AIC and BIC decrease and it is reported as being significant) and will, therefore, be included in the model.</p>
<pre class="r"><code># add Priming*Age
ifelse(min(ftable(mblrdata$Priming, mblrdata$Age, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m5.glmer &lt;- update(m4.glmer, .~.+Priming*Age)
ifelse(max(car::vif(m5.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m5.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m5.glmer:     Priming:Age
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m4.glmer    5 1669 1697   -829     1659                    
## m5.glmer    7 1672 1711   -829     1658  0.98  2       0.61</code></pre>
<p>The interaction between Priming and Age is not significant and will thus not be included.</p>
<pre class="r"><code># add Priming*Gender
ifelse(min(ftable(mblrdata$Priming, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m6.glmer &lt;- update(m4.glmer, .~.+Priming*Gender)
ifelse(max(car::vif(m6.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m6.glmer, m4.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m4.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)   
## m4.glmer    5 1669 1697   -829     1659                       
## m6.glmer    6 1663 1697   -826     1651  7.42  1     0.0065 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                   Chisq Df           Pr(&gt;Chisq)    
## Priming          131.96  1 &lt; 0.0000000000000002 ***
## Gender            13.58  1              0.00023 ***
## ConversationType  10.71  1              0.00107 ** 
## Priming:Gender     7.45  1              0.00633 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction between Priming and Gender improved model fit (AIC and BIC reduction) and significantly correlates with the use of speech-unit final LIKE. It will therefore be included in the model.</p>
<pre class="r"><code># add Priming*ConversationType
ifelse(min(ftable(mblrdata$Priming, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m7.glmer &lt;- update(m6.glmer, .~.+Priming*ConversationType)
ifelse(max(car::vif(m7.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m7.glmer, m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m7.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m7.glmer:     Priming:ConversationType
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer    6 1663 1697   -826     1651                    
## m7.glmer    7 1663 1702   -825     1649  2.03  1       0.15</code></pre>
<p>The interaction between Priming and ConversationType does not significantly correlate with the use of speech-unit final LIKE and it does not explain much variance (AIC and BIC increase). It will be not be included in the model.</p>
<pre class="r"><code># add Age*Gender
ifelse(min(ftable(mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m8.glmer &lt;- update(m6.glmer, .~.+Age*Gender)
ifelse(max(car::vif(m8.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m8.glmer, m6.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m8.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m8.glmer:     Priming:Gender + Gender:Age
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer    6 1663 1697   -826     1651                    
## m8.glmer    8 1666 1710   -825     1650  1.53  2       0.47</code></pre>
<p>The interaction between Age and Gender is not significant and will thus continue without it.</p>
<pre class="r"><code># add Age*ConversationType
ifelse(min(ftable(mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m9.glmer &lt;- update(m6.glmer, .~.+Age*ConversationType)
ifelse(max(car::vif(m9.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m9.glmer, m6.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m9.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m9.glmer:     Priming:Gender + ConversationType:Age
##          npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer    6 1663 1697   -826     1651                    
## m9.glmer    8 1666 1711   -825     1650   0.9  2       0.64</code></pre>
<p>The interaction between Age and ConversationType is not significant and will thus continue without it.</p>
<pre class="r"><code># add Gender*ConversationType
ifelse(min(ftable(mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m10.glmer &lt;- update(m6.glmer, .~.+Gender*ConversationType)
ifelse(max(car::vif(m10.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m10.glmer, m6.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m10.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m10.glmer:     Gender:ConversationType
##           npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer     6 1663 1697   -826     1651                    
## m10.glmer    7 1665 1704   -825     1651  0.34  1       0.56</code></pre>
<p>The interaction between Gender and ConversationType is insignificant and does not improve model fit (AIC and BIC reduction). It will therefore not be included in the model.</p>
<pre class="r"><code># add Priming*Age*Gender
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$Gender, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m11.glmer &lt;- update(m6.glmer, .~.+Priming*Age*Gender)
ifelse(max(car::vif(m11.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m11.glmer, m6.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m11.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m11.glmer:     Priming:Gender + Priming:Age + Gender:Age + Priming:Gender:Age
##           npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer     6 1663 1697   -826     1651                    
## m11.glmer   10 1668 1724   -824     1648  3.26  4       0.51</code></pre>
<p>The interaction between Priming, Age and Gender is not significant and we will thus continue without it.</p>
<pre class="r"><code># add Priming*Age*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m12.glmer &lt;- update(m6.glmer, .~.+Priming*Age*ConversationType)
ifelse(max(car::vif(m12.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;VIFs okay&quot;</code></pre>
<pre class="r"><code>anova(m12.glmer, m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m12.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Age + 
## m12.glmer:     Priming:Gender + Priming:Age + Priming:ConversationType + 
## m12.glmer:     ConversationType:Age + Priming:ConversationType:Age
##           npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)
## m6.glmer     6 1663 1697   -826     1651                    
## m12.glmer   11 1666 1728   -822     1644  6.92  5       0.23</code></pre>
<p>The interaction between Priming, Age and ConversationType is not significant and we will thus continue without it.</p>
<pre class="r"><code># add Priming*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m13.glmer &lt;- update(m6.glmer, .~.+Priming*Gender*ConversationType)
ifelse(max(car::vif(m13.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>anova(m13.glmer, m6.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m6.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender
## m13.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## m13.glmer:     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##           npar  AIC  BIC logLik deviance Chisq Df Pr(&gt;Chisq)  
## m6.glmer     6 1663 1697   -826     1651                      
## m13.glmer    9 1660 1710   -821     1642  9.66  3      0.022 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>Anova(m13.glmer, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: SUFlike
##                                  Chisq Df           Pr(&gt;Chisq)    
## Priming                         129.35  1 &lt; 0.0000000000000002 ***
## Gender                           11.83  1              0.00058 ***
## ConversationType                  8.53  1              0.00349 ** 
## Priming:Gender                    3.49  1              0.06162 .  
## Priming:ConversationType          1.81  1              0.17878    
## Gender:ConversationType           0.15  1              0.69391    
## Priming:Gender:ConversationType   6.27  1              0.01230 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Although the VIFs are higher than 20, the maximum value is 25.868 and thus not excessive. And since the three-way interaction between Priming, Gender, and ConversationType is not only significantly correlated with the dependent variable but also decreases AIC, we will include it in the model. However, it should be noted that there is a BIC increase(!) - it could be argued that this argues against including this three-way interaction. This is a judgement-call and depends on whether significance, AIC, or BIC is the main criterion for including predictors. Since we chose a p-value based approach here and have so far focused more on the AIC, we decide to disregard the BIC increase (it would be good practice to state that a BIC increase had taken place in a footnote though).</p>
<pre class="r"><code># add Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;okay&quot;</code></pre>
<pre class="r"><code>m14.glmer &lt;- update(m13.glmer, .~.+Age*Gender*ConversationType)
ifelse(max(car::vif(m14.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>car::vif(m14.glmer)</code></pre>
<pre><code>##                         Priming                          Gender 
##                           7.712                           2.649 
##                ConversationType                             Age 
##                          31.165                           3.796 
##                  Priming:Gender        Priming:ConversationType 
##                          10.286                          23.859 
##         Gender:ConversationType                      Gender:Age 
##                          33.433                           5.814 
##            ConversationType:Age Priming:Gender:ConversationType 
##                          19.786                          24.950 
##     Gender:ConversationType:Age 
##                          21.846</code></pre>
<p>In this case, the VIFs are excessive and have values higher than 30 which shows an unacceptable degree of multicollinearity so that we abort and move on the next model.</p>
<pre class="r"><code># add Priming*Age*Gender*ConversationType
ifelse(min(ftable(mblrdata$Priming,mblrdata$Age,mblrdata$Gender, mblrdata$ConversationType, mblrdata$SUFlike)) == 0, &quot;incomplete information&quot;, &quot;okay&quot;)</code></pre>
<pre><code>## [1] &quot;incomplete information&quot;</code></pre>
<pre class="r"><code>m15.glmer &lt;- update(m13.glmer, .~.+Priming*Age*Gender*ConversationType)
ifelse(max(car::vif(m15.glmer)) &lt;= 10,  &quot;VIFs okay&quot;, &quot;WARNING: high VIFs!&quot;) </code></pre>
<pre><code>## [1] &quot;WARNING: high VIFs!&quot;</code></pre>
<pre class="r"><code>car::vif(m15.glmer)</code></pre>
<pre><code>##                             Priming                              Gender 
##                              15.742                               2.786 
##                    ConversationType                                 Age 
##                              28.061                               3.900 
##                      Priming:Gender            Priming:ConversationType 
##                              18.715                              30.022 
##             Gender:ConversationType                         Priming:Age 
##                              30.344                               9.501 
##                          Gender:Age                ConversationType:Age 
##                               6.695                        31637533.686 
##     Priming:Gender:ConversationType                  Priming:Gender:Age 
##                              31.550                              11.586 
##        Priming:ConversationType:Age         Gender:ConversationType:Age 
##                         9086362.739                        30682029.288 
## Priming:Gender:ConversationType:Age 
##                         7981201.727</code></pre>
<p>Again, the VIFs are excessive! As this was the last possible model, we have found our final minimal adequate model in m13.glmer.</p>
<p>In a next step, we create an overview of model comparisons which serves as a summary for the model fitting process and provides AIC, BIC, and <span class="math inline">\(\chi\)</span><sup>2</sup> values.</p>
<pre class="r"><code>source(&quot;https://slcladal.github.io/rscripts/ModelFittingSummarySWSU.r&quot;) 
# comparisons of glmer objects
m1.m0 &lt;- anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) 
m2.m1 &lt;- anova(m2.glmer, m1.glmer, test = &quot;Chi&quot;)   
m3.m1 &lt;- anova(m3.glmer, m1.glmer, test = &quot;Chi&quot;)
m4.m3 &lt;- anova(m4.glmer, m3.glmer, test = &quot;Chi&quot;) 
m5.m4 &lt;- anova(m5.glmer, m4.glmer, test = &quot;Chi&quot;) 
m6.m4 &lt;- anova(m6.glmer, m4.glmer, test = &quot;Chi&quot;) 
m7.m6 &lt;- anova(m7.glmer, m6.glmer, test = &quot;Chi&quot;)
m8.m6 &lt;- anova(m8.glmer, m6.glmer, test = &quot;Chi&quot;) 
m9.m6 &lt;- anova(m9.glmer, m6.glmer, test = &quot;Chi&quot;) 
m10.m6 &lt;- anova(m10.glmer, m6.glmer, test = &quot;Chi&quot;) 
m11.m6 &lt;- anova(m11.glmer, m6.glmer, test = &quot;Chi&quot;) 
m12.m6 &lt;- anova(m12.glmer, m6.glmer, test = &quot;Chi&quot;)
m13.m6 &lt;- anova(m13.glmer, m6.glmer, test = &quot;Chi&quot;)
# create a list of the model comparisons
mdlcmp &lt;- list(m1.m0, m2.m1, m3.m1, m4.m3, m5.m4, m6.m4, m7.m6, m8.m6, m9.m6, m10.m6, m11.m6, m12.m6, m13.m6)
# summary table for model fitting
mdlft &lt;- mdl.fttng.swsu(mdlcmp)
mdlft &lt;- mdlft[,-2]
kable(mdlft, caption = &quot;Model fitting process summary.&quot;)</code></pre>
<table>
<caption>Model fitting process summary.</caption>
<colgroup>
<col width="4%" />
<col width="55%" />
<col width="6%" />
<col width="1%" />
<col width="3%" />
<col width="3%" />
<col width="5%" />
<col width="7%" />
<col width="2%" />
<col width="2%" />
<col width="3%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="left">Term Added</th>
<th align="left">Compared to…</th>
<th align="left">DF</th>
<th align="left">AIC</th>
<th align="left">BIC</th>
<th align="left">LogLikelihood</th>
<th align="left">Residual Deviance</th>
<th align="left">X2</th>
<th align="left">X2DF</th>
<th align="left">p-value</th>
<th align="left">Significance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m1.glmer</td>
<td align="left">1+Priming</td>
<td align="left">m0.glmer</td>
<td align="left">3</td>
<td align="left">1702.77</td>
<td align="left">1719.58</td>
<td align="left">-848.39</td>
<td align="left">1696.77</td>
<td align="left">127.72</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m2.glmer</td>
<td align="left">Age</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">1704.21</td>
<td align="left">1726.61</td>
<td align="left">-848.11</td>
<td align="left">1696.21</td>
<td align="left">0.56</td>
<td align="left">1</td>
<td align="left">0.45323</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m3.glmer</td>
<td align="left">Gender</td>
<td align="left">m1.glmer</td>
<td align="left">4</td>
<td align="left">1679.4</td>
<td align="left">1701.8</td>
<td align="left">-835.7</td>
<td align="left">1671.4</td>
<td align="left">25.38</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="even">
<td align="left">m4.glmer</td>
<td align="left">ConversationType</td>
<td align="left">m3.glmer</td>
<td align="left">5</td>
<td align="left">1668.58</td>
<td align="left">1696.59</td>
<td align="left">-829.29</td>
<td align="left">1658.58</td>
<td align="left">12.81</td>
<td align="left">1</td>
<td align="left">0.00034</td>
<td align="left">p &lt; .001***</td>
</tr>
<tr class="odd">
<td align="left">m5.glmer</td>
<td align="left">Age+Priming:Age</td>
<td align="left">m4.glmer</td>
<td align="left">7</td>
<td align="left">1671.6</td>
<td align="left">1710.81</td>
<td align="left">-828.8</td>
<td align="left">1657.6</td>
<td align="left">0.98</td>
<td align="left">2</td>
<td align="left">0.61134</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m6.glmer</td>
<td align="left">Priming:Gender</td>
<td align="left">m4.glmer</td>
<td align="left">6</td>
<td align="left">1663.16</td>
<td align="left">1696.77</td>
<td align="left">-825.58</td>
<td align="left">1651.16</td>
<td align="left">7.42</td>
<td align="left">1</td>
<td align="left">0.00645</td>
<td align="left">p &lt; .01 **</td>
</tr>
<tr class="odd">
<td align="left">m7.glmer</td>
<td align="left">Priming:ConversationType</td>
<td align="left">m6.glmer</td>
<td align="left">7</td>
<td align="left">1663.13</td>
<td align="left">1702.34</td>
<td align="left">-824.57</td>
<td align="left">1649.13</td>
<td align="left">2.03</td>
<td align="left">1</td>
<td align="left">0.15427</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m8.glmer</td>
<td align="left">Age+Gender:Age</td>
<td align="left">m6.glmer</td>
<td align="left">8</td>
<td align="left">1665.63</td>
<td align="left">1710.44</td>
<td align="left">-824.82</td>
<td align="left">1649.63</td>
<td align="left">1.53</td>
<td align="left">2</td>
<td align="left">0.46535</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m9.glmer</td>
<td align="left">Age+ConversationType:Age</td>
<td align="left">m6.glmer</td>
<td align="left">8</td>
<td align="left">1666.26</td>
<td align="left">1711.07</td>
<td align="left">-825.13</td>
<td align="left">1650.26</td>
<td align="left">0.9</td>
<td align="left">2</td>
<td align="left">0.63689</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m10.glmer</td>
<td align="left">Gender:ConversationType</td>
<td align="left">m6.glmer</td>
<td align="left">7</td>
<td align="left">1664.82</td>
<td align="left">1704.03</td>
<td align="left">-825.41</td>
<td align="left">1650.82</td>
<td align="left">0.34</td>
<td align="left">1</td>
<td align="left">0.55773</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m11.glmer</td>
<td align="left">Age+Gender:Age+Priming:Age+Priming:Gender:Age</td>
<td align="left">m6.glmer</td>
<td align="left">10</td>
<td align="left">1667.9</td>
<td align="left">1723.91</td>
<td align="left">-823.95</td>
<td align="left">1647.9</td>
<td align="left">3.26</td>
<td align="left">4</td>
<td align="left">0.5148</td>
<td align="left">n.s.</td>
</tr>
<tr class="even">
<td align="left">m12.glmer</td>
<td align="left">Age+ConversationType:Age+Priming:Age+Priming:ConversationType+Priming:ConversationType:Age+Priming:Gender+Priming:GenderSUFlike+SUFlike</td>
<td align="left">m6.glmer</td>
<td align="left">11</td>
<td align="left">1666.24</td>
<td align="left">1727.85</td>
<td align="left">-822.12</td>
<td align="left">1644.24</td>
<td align="left">6.92</td>
<td align="left">5</td>
<td align="left">0.22642</td>
<td align="left">n.s.</td>
</tr>
<tr class="odd">
<td align="left">m13.glmer</td>
<td align="left">Gender:ConversationType+Priming:ConversationType+Priming:Gender:ConversationType</td>
<td align="left">m6.glmer</td>
<td align="left">9</td>
<td align="left">1659.51</td>
<td align="left">1709.91</td>
<td align="left">-820.75</td>
<td align="left">1641.51</td>
<td align="left">9.66</td>
<td align="left">3</td>
<td align="left">0.0217</td>
<td align="left">p &lt; .05 *</td>
</tr>
</tbody>
</table>
<p>We now rename our final minimal adequate model, test whether it performs significantly better than the minimal base-line model, and print the regression summary.</p>
<pre class="r"><code>mlr.glmer &lt;- m13.glmer # rename final minimal adequate model
anova(mlr.glmer, m0.glmer, test = &quot;Chi&quot;) # final model better than base-line model</code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## mlr.glmer: SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender + 
## mlr.glmer:     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##           npar  AIC  BIC logLik deviance Chisq Df          Pr(&gt;Chisq)    
## m0.glmer     2 1828 1840   -912     1824                                 
## mlr.glmer    9 1660 1710   -821     1642   183  7 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>print(mlr.glmer, corr = F) # inspect final minimal adequate model</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## SUFlike ~ (1 | ID) + Priming + Gender + ConversationType + Priming:Gender +  
##     Priming:ConversationType + Gender:ConversationType + Priming:Gender:ConversationType
##    Data: mblrdata
##      AIC      BIC   logLik deviance df.resid 
##   1659.5   1709.9   -820.8   1641.5     1991 
## Random effects:
##  Groups Name        Std.Dev.
##  ID     (Intercept) 0.315   
## Number of obs: 2000, groups:  ID, 208
## Fixed Effects:
##                                         (Intercept)  
##                                              -0.807  
##                                        PrimingPrime  
##                                               0.371  
##                                         GenderWomen  
##                                              -1.003  
##                          ConversationTypeSameGender  
##                                              -1.809  
##                            PrimingPrime:GenderWomen  
##                                               1.680  
##             PrimingPrime:ConversationTypeSameGender  
##                                               2.486  
##              GenderWomen:ConversationTypeSameGender  
##                                               1.342  
## PrimingPrime:GenderWomen:ConversationTypeSameGender  
##                                              -2.421</code></pre>
<p>To extract the effect sizes of the significant fixed effects, we compare the model with that effect to a model without that effect so that we can ascertain how much variance that effect explains. In our case, this is purely to show how to do this because main effects are superseded by interactions in which they are involved and should therefore not be interpreted <span class="citation">(Field, Miles, and Field <a href="#ref-field2012discovering" role="doc-biblioref">2012</a>, 622)</span>.</p>
<pre class="r"><code>anova(m1.glmer, m0.glmer, test = &quot;Chi&quot;) </code></pre>
<pre><code>## Data: mblrdata
## Models:
## m0.glmer: SUFlike ~ 1 + (1 | ID)
## m1.glmer: SUFlike ~ (1 | ID) + Priming
##          npar  AIC  BIC logLik deviance Chisq Df          Pr(&gt;Chisq)    
## m0.glmer    2 1828 1840   -912     1824                                 
## m1.glmer    3 1703 1720   -848     1697   128  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="visualizing-effects" class="section level2">
<h2><span class="header-section-number">3.6</span> Visualizing Effects</h2>
<p>As we will see the effects in the final summary, we visualize the effects here by showing the probability of discourse like based on the predicted values.</p>
<pre class="r"><code># extract predicted values
mblrdata$Predicted &lt;- predict(m13.glmer, mblrdata, type = &quot;response&quot;)
# plot
ggplot(mblrdata, aes(Gender, Predicted, color = Priming)) +
  facet_wrap(~ConversationType) +
  stat_summary(fun.y = mean, geom = &quot;point&quot;) +
  stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) +
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position = &quot;top&quot;) +
    ylim(0, .75) +
  labs(x = &quot;&quot;, y = &quot;Predicted Probabilty of discourse like&quot;) +
  scale_color_manual(values = c(&quot;gray20&quot;, &quot;gray70&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm33-1.png" width="672" /></p>
<p>A proper visualization of the marginal effects can be extracted using the sjPlot package.</p>
<pre class="r"><code>plot_model(m13.glmer, type = &quot;pred&quot;, terms = c(&quot;ConversationType&quot;, &quot;Priming&quot;, &quot;Gender&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm33b-1.png" width="672" /></p>
<p>We can see that discourse like is more likely to surface in primed contexts but that in contrast to women and men in same-gender conversations as well as women in mixed-gender conversations, priming appears to affect the use of discourse like by men in mixed-gender conversations only very little.</p>
</div>
<div id="extracting-model-fit-parameters" class="section level2">
<h2><span class="header-section-number">3.7</span> Extracting Model Fit Parameters</h2>
<p>We now extract model fit parameters <span class="citation">(Baayen <a href="#ref-baayen2008analyzing" role="doc-biblioref">2008</a>, 281)</span>.</p>
<pre class="r"><code>probs = 1/(1+exp(-fitted(mlr.glmer)))
probs = binomial()$linkinv(fitted(mlr.glmer))
somers2(probs, as.numeric(mblrdata$SUFlike))</code></pre>
<pre><code>##         C       Dxy         n   Missing 
##    0.7646    0.5293 2000.0000    0.0000</code></pre>
<p>The model fit parameters indicate a suboptimal fit. Both the C-value and Somers’s D<sub>xy</sub> show poor fit between predicted and observed occurrences of SUFlike. If the C-value is 0.5, the predictions are random, while the predictions are perfect if the C-value is 1. C-values above 0.8 indicate real predictive capacity <span class="citation">(Baayen <a href="#ref-baayen2008analyzing" role="doc-biblioref">2008</a>, 204)</span>. Somers’ D<sub>xy</sub> is a value that represents a rank correlation between predicted probabilities and observed responses. Somers’ D<sub>xy</sub> values range between 0, which indicates complete randomness, and 1, which indicates perfect prediction <span class="citation">(Baayen <a href="#ref-baayen2008analyzing" role="doc-biblioref">2008</a>, 204)</span>. This a value of .2646 suggests that the model performs better than chance but not substantially so. We will now perform the model diagnostics.</p>
</div>
<div id="model-diagnostics-2" class="section level2">
<h2><span class="header-section-number">3.8</span> Model Diagnostics</h2>
<p>We begin the model diagnostics by generating a diagnostic that plots the fitted or predicted values against the residuals.</p>
<pre class="r"><code>plot(mlr.glmer, pch = 20, col = &quot;black&quot;, lty = &quot;dotted&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/blmm38-1.png" width="672" /></p>
<p>As a final step, we summarize our findings in tabulated form.</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
SUFlike
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Odds Ratios
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.45
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.32 – 0.61
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Priming [Prime]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.45
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.61 – 3.47
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.405
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Gender [Women]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.37
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.24 – 0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
ConversationType<br>[SameGender]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.05 – 0.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.006</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Priming [Prime] * Gender<br>[Women]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
5.37
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.78 – 16.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.003</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Priming [Prime] *<br>ConversationType<br>[SameGender]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
12.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.15 – 66.99
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.005</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Gender [Women] *<br>ConversationType<br>[SameGender]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.83
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.02 – 14.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.047</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Priming [Prime] * Gender<br>[Women]) *<br>ConversationType<br>[SameGender]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01 – 0.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.012</strong>
</td>
</tr>
<tr>
<td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;">
Random Effects
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
σ<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
3.29
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
τ<sub>00</sub> <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.10
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
ICC
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.03
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
208
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
2000
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.144 / 0.169
</td>
</tr>
</table>
<p>A mixed-effect binomial logistic regression model which contained speaker as random effect was fit to the data in a step-wise-step up procedure. The final minimal adequate model performed significantly better than an intercept-only base line model (<span class="math inline">\(\chi\)</span><sup>2</sup>(8): 842.06, p &lt;.0001) but has a suboptimal fit (C: 0.765, Somers’ D<sub>xy</sub>: .529). The final minimal adequate model reported a significant interaction between the gender of speakers, the type of conversation and priming (<span class="math inline">\(\chi\)</span><sup>2</sup>(3): 9.66, p = .022). The model showed that discourse <em>like</em> is more likely to surface in primed contexts but that in contrast to women and men in same-gender conversations as well as women in mixed-gender conversations, priming appears to affect the use of discourse <em>like</em> by men in mixed-gender conversations only to a marginal extent.</p>
</div>
</div>
<div id="quasi-poisson-and-negative-binomial-mixed-effects-regression" class="section level1">
<h1><span class="header-section-number">4</span> (Quasi-)Poisson and Negative-Binomial Mixed-Effects Regression</h1>
<p>Like fixed-effects Poisson models, mixed-effects Poisson models take counts as dependent variables. The data for this analysis was collected on three separate evenings (Trial). The number of the filler “uhm” (UHM) was counted in two-minute conversations that were either in English, German, Russian, or Mandarin (Language). In addition, the number of shots that speakers drank before they talked was recorded (Shots).</p>
<pre class="r"><code># load data
countdata &lt;- read.table(&quot;https://slcladal.github.io/data/countdata.txt&quot;, 
                       comment.char = &quot;&quot;,quote = &quot;&quot;, sep = &quot;\t&quot;, header = T) 
# inspect data
str(countdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    500 obs. of  6 variables:
##  $ ID      : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Trial   : int  3 3 3 1 1 3 1 3 3 2 ...
##  $ Language: chr  &quot;Russian&quot; &quot;Russian&quot; &quot;German&quot; &quot;German&quot; ...
##  $ Gender  : chr  &quot;Man&quot; &quot;Man&quot; &quot;Man&quot; &quot;Man&quot; ...
##  $ UHM     : int  0 0 0 0 2 1 1 0 0 0 ...
##  $ Shots   : int  0 0 5 3 6 5 1 4 0 2 ...</code></pre>
<p>Since the data contains character variables, we need to factorize the data before we can analyse it further and we also remove the ID column.</p>
<pre class="r"><code># factorize variables
countdata &lt;- countdata %&gt;%
  dplyr::select(-ID)
clfct &lt;- c(&quot;Trial&quot;, &quot;Language&quot;, &quot;Gender&quot;)
countdata[clfct] &lt;- lapply(countdata[clfct], factor)
 # inspect data
str(countdata); head(countdata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    500 obs. of  5 variables:
##  $ Trial   : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 3 3 3 1 1 3 1 3 3 2 ...
##  $ Language: Factor w/ 4 levels &quot;English&quot;,&quot;German&quot;,..: 4 4 2 2 2 2 3 2 4 2 ...
##  $ Gender  : Factor w/ 2 levels &quot;Man&quot;,&quot;Woman&quot;: 1 1 1 1 2 1 1 2 2 1 ...
##  $ UHM     : int  0 0 0 0 2 1 1 0 0 0 ...
##  $ Shots   : int  0 0 5 3 6 5 1 4 0 2 ...</code></pre>
<pre><code>##   Trial Language Gender UHM Shots
## 1     3  Russian    Man   0     0
## 2     3  Russian    Man   0     0
## 3     3   German    Man   0     5
## 4     1   German    Man   0     3
## 5     1   German  Woman   2     6
## 6     3   German    Man   1     5</code></pre>
<p>After the data is factorized, we can visualize the data.</p>
<pre class="r"><code>countdata %&gt;%
  # prepare data
  dplyr::select(Language, Shots) %&gt;%
  dplyr::group_by(Language) %&gt;%
  dplyr::mutate(Mean = round(mean(Shots), 1)) %&gt;%
  dplyr::mutate(SD = round(sd(Shots), 1)) %&gt;%
  # start plot
  ggplot(aes(Language, Shots, color = Language, fill = Language)) +
  geom_violin(trim=FALSE, color = &quot;gray20&quot;)+ 
  geom_boxplot(width=0.1, fill=&quot;white&quot;, color = &quot;gray20&quot;) +
  geom_text(aes(y=-4,label=paste(&quot;mean: &quot;, Mean, sep = &quot;&quot;)), size = 3, color = &quot;black&quot;) +
  geom_text(aes(y=-5,label=paste(&quot;SD: &quot;, SD, sep = &quot;&quot;)), size = 3, color = &quot;black&quot;) +
  scale_fill_manual(values=rep(&quot;grey90&quot;,4)) + 
  theme_set(theme_bw(base_size = 10)) +
  theme(legend.position=&quot;none&quot;, legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  ylim(-5, 15) +
  labs(x = &quot;Language&quot;, y = &quot;Shots&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/pmm3-1.png" width="672" /></p>
<p>The violin plots show that the English speakers drank more shots than speakers of other languages with Mandarin speakers drinking the fewest shots.</p>
<p>In the present case, we will a Boruta variable selection procedure to streamline the model fitting process. Thus, before fitting the model, we will test which variables have any kind of relationship with the dependent variable and therefore deserve to be evaluated in the regression modelling. As this is just an example, we will only consider variables which are deemed important and disregard both unimportant and tentative variables. We start the Boruta analysis by setting a seed and running an initial Boruta analysis.</p>
<pre class="r"><code>library(Boruta)
# perform variable selection
set.seed(20191220)
boruta &lt;- Boruta(UHM ~.,data=countdata)
print(boruta)</code></pre>
<pre><code>## Boruta performed 99 iterations in 5.105 secs.
##  1 attributes confirmed important: Shots;
##  1 attributes confirmed unimportant: Gender;
##  2 tentative attributes left: Language, Trial;</code></pre>
<p>As only Shots is confirmed as important, we will only check for the effect of Shots and include Language as a random effect in the regression modeling. Including Language as a random effect is probably not justified statistically (given that the Boruta analysis showed that it only has a tentative effect) but for theoretical reasons as the speakers are nested into Languages. Before we start with the modeling, however, we proceed by checking if the data does indeed approximate a Poisson distribution.</p>
<pre class="r"><code>library(vcd)
# output the results
gf = goodfit(countdata$UHM,type= &quot;poisson&quot;, method= &quot;ML&quot;)
plot(gf,main=&quot;Count data vs Poisson distribution&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/pmm5-1.png" width="672" /></p>
<p>The data does not perfectly match a distribution that would be expected if the data approximated a Poisson distribution. We will use a goodness-of-fit test to check if the data does indeed diverge significantly from being Poisson distributed. If the p-values of the goodness-of-fit test is smaller than .05, then the distribution of the data differs significantly from a Poisson distribution and, given the visualization is likely over-dispersed.</p>
<p>In case of overdispersion, we may have to use a quasi-Poisson or, even better, a negative binomial model but we will, for now continue with the Poisson model and perform diagnostics later to check if we have to switch to a more robust method. One effect of overdispersion is that the standard errors of a model are biased and quasi-Poisson models scale the standard errors to compensate bias. However, <span class="citation">Zuur, Hilbe, and Ieno (<a href="#ref-zuur2013beginner" role="doc-biblioref">2013</a>)</span> suggest to use negative-binomial model instead. This is so because the scaling of the standard errors performed by quasi-Poisson models only affects the significance of coefficients (the p-values) but it does not affect the coefficients which, however, may be affected themselves by overdispersion. Thus, the coefficients of Poisson as well as quasi-Poisson models (which are identical) may be unreliable when dealing with overdispersion. Negative binomial models, in contrast, include an additional dispersion or heterogeneity parameter which accommodates overdispersion better than merely scaling the standard errors <span class="citation">(see Zuur, Hilbe, and Ieno <a href="#ref-zuur2013beginner" role="doc-biblioref">2013</a>, 21)</span>.</p>
<pre class="r"><code>summary(gf)</code></pre>
<pre><code>## 
##   Goodness-of-fit test for poisson distribution
## 
##                    X^2 df                             P(&gt; X^2)
## Likelihood Ratio 153.4  5 0.0000000000000000000000000000002493</code></pre>
<p>The p-value is indeed smaller than .05 which means that we should indeed use a negative-binomial model rather than a Poisson model. We will ignore this, for now, and proceed to fit a Poisson mixed-effects model and check what happens if a Poisson model is fit to over-dispersed data.</p>
<div id="mixed-effects-poisson-regression" class="section level2">
<h2><span class="header-section-number">4.1</span> Mixed-Effects Poisson Regression</h2>
<p>In a first step, we create mixed-effect intercept-only baseline models and then test if including “Shots” significantly improves model fit and, thus, has a significant impact on the number of <em>uhms</em>.</p>
<pre class="r"><code># base-line mixed-model
m0.glmer = glmer(UHM ~ 1 + (1 | Language), data = countdata, family = poisson,
                 control=glmerControl(optimizer=&quot;bobyqa&quot;))
# add Shots
m1.glmer &lt;- update(m0.glmer, .~.+ Shots)</code></pre>
<pre><code>## boundary (singular) fit: see ?isSingular</code></pre>
<pre class="r"><code>Anova(m1.glmer, test = &quot;Chi&quot;)           </code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: UHM
##       Chisq Df          Pr(&gt;Chisq)    
## Shots   321  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA confirms that Shots have a significant impact on the number of instances of <em>uhm</em>. However, we get the warning that the fitted mixed model is (almost / near) singular. In such cases, the model should not be reported. As this is only an example, we will continue by having a look at the model summary.</p>
<pre class="r"><code>summary(m1.glmer)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: poisson  ( log )
## Formula: UHM ~ (1 | Language) + Shots
##    Data: countdata
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##   1041.8   1054.5   -517.9   1035.8      497 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -1.510 -0.666 -0.593  0.586  4.339 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Language (Intercept) 0        0       
## Number of obs: 500, groups:  Language, 4
## 
## Fixed effects:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -1.2789     0.0893   -14.3 &lt;0.0000000000000002 ***
## Shots         0.2336     0.0130    17.9 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##       (Intr)
## Shots -0.806
## convergence code: 0
## boundary (singular) fit: see ?isSingular</code></pre>
<p>The model summary confirms that the number of shots does have a significantly positive effect on the number of occurrences of <em>uhm</em>. Furthermore, the scaled residuals are distributed very unevenly which suggests overdispersion. Including Language as a random effect is not justified given that they have 0 variance and a standard deviation of 0 (which means that Language does not account for or explain any additional variance).</p>
<p>We now check if the model suffers from overdispersion following (<span class="citation">Zuur, Hilbe, and Ieno (<a href="#ref-zuur2013beginner" role="doc-biblioref">2013</a>)</span> 138).</p>
<pre class="r"><code># extract pearson residuals
PearsonResiduals &lt;- resid(m1.glmer, type = &quot;pearson&quot;)
# extract number of cases in model
Cases &lt;- nrow(countdata)
# extract number of predictors (plus intercept)
NumberOfPredictors &lt;- length(fixef(m1.glmer)) +1
# calculate overdispersion
Overdispersion &lt;- sum(PearsonResiduals^2) / (Cases-NumberOfPredictors)
# inspect overdispersion
Overdispersion</code></pre>
<pre><code>## [1] 1.169</code></pre>
<p>The data is slightly over-dispersed. It would also be advisable to plot the Cook’s distance (which should not show data points with values &gt; 1). If there are data points with high Cook’s D values, we could exclude them which would, very likely reduce the overdispersion <span class="citation">(see Zuur, Hilbe, and Ieno <a href="#ref-zuur2013beginner" role="doc-biblioref">2013</a>, 22)</span>. We ignore this, for now, and use diagnostic plots to check if the plots indicate problems.</p>
<pre class="r"><code>diag_data &lt;- data.frame(PearsonResiduals, fitted(m1.glmer))
colnames(diag_data) &lt;- c(&quot;Pearson&quot;, &quot;Fitted&quot;)
p9 &lt;- ggplot(diag_data, aes(x = Fitted, y = Pearson)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = &quot;dotted&quot;)
p10 &lt;- ggplot(countdata, aes(x = Shots, y = diag_data$Pearson)) +
  geom_point()  +
  geom_hline(yintercept = 0, linetype = &quot;dotted&quot;) +
  labs(y = &quot;Pearson&quot;)
p11 &lt;- ggplot(countdata, aes(x = Language, y = diag_data$Pearson)) +
  geom_boxplot() +
  labs(y = &quot;Pearson&quot;) + 
  theme(axis.text.x = element_text(angle=90))
grid.arrange(p9, p10, p11, nrow = 1)</code></pre>
<p><img src="mixedregressions_files/figure-html/pmm10-1.png" width="672" /></p>
<p>The diagnostic plots show problems as the dots in the first two plots are not random but show a pattern in the lower left corner. In addition, the variance of English (left boxplot) is notable larger than the variance of Russian (right boxplot). As a final step, we plot the predicted vales of the model to check if the predictions make sense.</p>
<pre class="r"><code>plot_model(m1.glmer, type = &quot;pred&quot;, terms = c(&quot;Shots&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/pmm11b-1.png" width="672" /></p>
<p>The model predicts that the instances of <em>uhm</em> increase with the number of shots. Note that the increase is not homogenous as the y-axis labels indicate!</p>
<p>The summary of the model can be extracted using the tab_model function from the sjPlot package.</p>
<pre class="r"><code>tab_model(m1.glmer)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
UHM
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Incidence Rate Ratios
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.28
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.23 – 0.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Shots
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.23 – 1.30
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;">
Random Effects
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
σ<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.89
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
τ<sub>00</sub> <sub>Language</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.00
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>Language</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
4
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
500
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.288 / NA
</td>
</tr>
</table>
<p>The summary table shows that our model is indeed highly problematic (the conditional R<sup>2</sup> could not be computed): this shows that our model suffers from a serious problem (near singular fit). If this were not just an example, you should not(!) report this model!</p>
</div>
<div id="quasi-possion-mixed-effects-regression" class="section level2">
<h2><span class="header-section-number">4.2</span> Quasi-Possion Mixed-Effects Regression</h2>
<p>We will now turn to a quasi-Poisson model to see if scaling the standard errors has a positive effect. This can make sense as quasi-Poisson mixed-effects models handle over-dispersed data better than normal Poisson-models.</p>
<p>We begin the model fitting process by creating a mixed- and a fixed-effects intercept-only base-line model. Unfortunately, there is not yet a procedure in place for quasi-Poisson models to test if the inclusion of random effects is justified. However, here the Boruta also provides valuable information: Language was only considered tentative but not important which suggests that it will not explain variance which means that including Language as a random effect may not be justified. This would require further inspection. Because we are only dealing with an example here, we ignore this fact (which you should not do in proper analyses) and continue right away with adding shots.</p>
<pre class="r"><code>library(MASS)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code># base-line mixed-model
m0.glmer = glmmPQL(UHM ~ 1, random = ~ 1 | Language, data = countdata, 
                   family = quasipoisson(link=&#39;log&#39;))</code></pre>
<pre><code>## iteration 1</code></pre>
<pre><code>## iteration 2</code></pre>
<pre><code>## iteration 3</code></pre>
<pre><code>## iteration 4</code></pre>
<pre class="r"><code># add Shots
m1.glmer &lt;- update(m0.glmer, .~.+ Shots)</code></pre>
<pre><code>## iteration 1</code></pre>
<pre class="r"><code>Anova(m1.glmer, test = &quot;Chi&quot;)           # SIG! (p&lt;0.0000000000000002 ***)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II tests)
## 
## Response: zz
##       Chisq Df          Pr(&gt;Chisq)    
## Shots   276  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA confirms that Shots have a significant impact on the number of instances of <em>uhm</em>. We will now have a look at the model summary.</p>
<pre class="r"><code>summary(m1.glmer)</code></pre>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: countdata 
##   AIC BIC logLik
##    NA  NA     NA
## 
## Random effects:
##  Formula: ~1 | Language
##         (Intercept) Residual
## StdDev:  0.00004081    1.078
## 
## Variance function:
##  Structure: fixed weights
##  Formula: ~invwt 
## Fixed effects: UHM ~ Shots 
##               Value Std.Error  DF t-value p-value
## (Intercept) -1.2789   0.09649 495  -13.26       0
## Shots        0.2336   0.01408 495   16.59       0
##  Correlation: 
##       (Intr)
## Shots -0.806
## 
## Standardized Within-Group Residuals:
##     Min      Q1     Med      Q3     Max 
## -1.4004 -0.6182 -0.5501  0.5437  4.0248 
## 
## Number of Observations: 500
## Number of Groups: 4</code></pre>
<p>The model summary does not provide AIC, BIC or logged likelihood values. The coefficient for “Shots” is highly significant (p &lt;.001) and the data is notably over-dispersed (the Standardized Within-Group Residuals deviate substantially from a normal distribution with higher values having a thick tail). Also, in contrast to the Poisson model, Language does explain at least a minimal share of the variance now as the mean and standard deviation are no longer 0. Note also, that the coefficients are identical to the Poisson coefficients but the standard errors and p-values differ (the model provides t- rather than z-values).</p>
<p>In a next step, we will calculate the odds ratios of the coefficient (as we only have one). We will use the coefficients from the fixed-effects model as the coefficients for mixed- and fixed-effects models are identical (the random effect structure only affects the standard error and p-values but not the coefficients; you can check by uncommenting the summary command).</p>
<pre class="r"><code>m1.glm = glm(UHM ~ Shots, data = countdata, family = quasipoisson(link=&#39;log&#39;))
exp(coef(m1.glm))</code></pre>
<pre><code>## (Intercept)       Shots 
##      0.2783      1.2632</code></pre>
<p>The standardized or <span class="math inline">\(\beta\)</span>-coefficient tells us that the likelihood of <em>uhm</em> increases by 1.26 (or 26.32 percent) with each additional shot.</p>
<p>Before inspecting the relationship between Shots and <em>uhm</em>, we will check if the overdispersion was reduced.</p>
<pre class="r"><code># extract pearson residuals
PearsonResiduals &lt;- resid(m1.glmer, type = &quot;pearson&quot;)
# extract number of cases in model
Cases &lt;- nrow(countdata)
# extract number of predictors (plus intercept)
NumberOfPredictors &lt;- length(fixef(m1.glmer)) +1
# calculate overdispersion
Overdispersion &lt;- sum(PearsonResiduals^2) / (Cases-NumberOfPredictors)
# inspect overdispersion
Overdispersion</code></pre>
<pre><code>## [1] 1.006</code></pre>
<p>The overdispersion has indeed decreased and is not so close to 1 that overdispersion is no longer an issue.</p>
<p>We continue to diagnose the model by plotting the Pearson’s residuals against fitted values. This diagnostic plot should not show a funnel-like structure or patterning as we observed in the case of the Poisson model.</p>
<pre class="r"><code># diagnostic plot
plot(m1.glmer, pch = 20, col = &quot;black&quot;, lty= &quot;dotted&quot;, ylab = &quot;Pearson&#39;s residuals&quot;)</code></pre>
<p><img src="mixedregressions_files/figure-html/qpmm5-1.png" width="672" /></p>
<p>Indeed, the plot exhibits a (slight) funnel shape (but not drastically so) and thus indicates heteroscedasticity. However, the patterning that we observed with the Poisson model has disappeared. We continue by plotting the random effect adjustments.</p>
<pre class="r"><code># generate diagnostic plots
plot(m1.glmer, Language ~ resid(.), abline = 0, fill = &quot;gray70&quot;) </code></pre>
<p><img src="mixedregressions_files/figure-html/qpmm10-1.png" width="672" /></p>
<p>The adjustments by “Language” are marginal (which was somewhat expected given that Language was only deemed tentative), which shows that there is very little variation between the languages and that we have no statistical reason to include Language as a random effect.</p>
<p>In a final step, we plot the fixed-effect of “Shots” using the “predictorEffects” function from the “effects” package.</p>
<pre class="r"><code>plot_model(m1.glmer, type = &quot;pred&quot;, terms = c(&quot;Shots&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/qpmm11b-1.png" width="672" /></p>
<p>The effects plot shows that the number of <em>uhms</em> increases near-linearly with the number of shots a speaker has had. However, the predictions do not make sense: note that the model predicts <em>negative</em> values for up to 5 shots. this does not make sense and we have to abandon the quasi-Poisson model despite it showing improvements compared to the Poisson model (some adjustments by Language and less patterning in the diagnostic plots).</p>
<p>Finally, we extract the summary table of this model.</p>
<pre class="r"><code>tab_model(m1.glmer)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
UHM
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Incidence Rate Ratios
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.28
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.23 – 0.34
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Shots
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.23 – 1.30
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>Language</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
4
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
500
</td>
</tr>
</table>
</div>
<div id="negative-binomial-mixed-effects-model" class="section level2">
<h2><span class="header-section-number">4.3</span> Negative Binomial Mixed-Effects Model</h2>
<p>In a first step, we create fixed- and mixed-effects intercept-only baseline models and then test if including “Shots” significantly improves model fit and, thus, has a significant impact on the number of <em>uhms</em>.</p>
<pre class="r"><code># base-line mixed-model
m0.glmer = glmer.nb(UHM ~ 1 + (1 | Language), data = countdata)
# add Shots
m1.glmer &lt;- update(m0.glmer, .~.+ Shots)
Anova(m1.glmer, test = &quot;Chi&quot;)           </code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: UHM
##       Chisq Df          Pr(&gt;Chisq)    
## Shots    83  1 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The negative-binomial model also reports a significant impact of shots on the number of <em>uhms</em>. We will now inspect the summary.</p>
<pre class="r"><code># inspect model
summary(m1.glmer)           </code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: Negative Binomial(0.7478)  ( log )
## Formula: UHM ~ (1 | Language) + Shots
##    Data: countdata
## 
##      AIC      BIC   logLik deviance df.resid 
##   1051.6   1068.5   -521.8   1043.6      496 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -0.770 -0.514 -0.468  0.476  2.781 
## 
## Random effects:
##  Groups   Name        Variance               Std.Dev.     
##  Language (Intercept) 0.00000000000000000425 0.00000000206
## Number of obs: 500, groups:  Language, 4
## 
## Fixed effects:
##             Estimate Std. Error z value            Pr(&gt;|z|)    
## (Intercept)  -1.4495     0.1383  -10.48 &lt;0.0000000000000002 ***
## Shots         0.2782     0.0305    9.11 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##       (Intr)
## Shots -0.816
## convergence code: 0
## boundary (singular) fit: see ?isSingular</code></pre>
<p>In a next step, we calculate the overdispersion.</p>
<pre class="r"><code># extract pearson residuals
PearsonResiduals &lt;- resid(m1.glmer, type = &quot;pearson&quot;)
# extract number of betas + predictors + sigma
NumberOfPredictors &lt;- 2+1+1
# extract number of cases in model
Cases &lt;- nrow(countdata)
# caluculate overdispersion parameter
Overdispersion &lt;- sum(PearsonResiduals^2) / (Cases / NumberOfPredictors)# show overdispersion parameter
Overdispersion</code></pre>
<pre><code>## [1] 2.469</code></pre>
<p>The overdispersion has increased in this case. We will use diagnostic plots to check for problems.</p>
<pre class="r"><code>diag_data &lt;- data.frame(PearsonResiduals, fitted(m1.glmer))
colnames(diag_data) &lt;- c(&quot;Pearson&quot;, &quot;Fitted&quot;)
p9 &lt;- ggplot(diag_data, aes(x = Fitted, y = Pearson)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = &quot;dotted&quot;)
p10 &lt;- ggplot(countdata, aes(x = Shots, y = diag_data$Pearson)) +
  geom_point()  +
  geom_hline(yintercept = 0, linetype = &quot;dotted&quot;) +
  labs(y = &quot;Pearson&quot;)
p11 &lt;- ggplot(countdata, aes(x = Language, y = diag_data$Pearson)) +
  geom_boxplot() +
  labs(y = &quot;Pearson&quot;) + 
  theme(axis.text.x = element_text(angle=90))
grid.arrange(p9, p10, p11, nrow = 1)</code></pre>
<p><img src="mixedregressions_files/figure-html/nbmm4-1.png" width="672" /></p>
<p>The diagnostics show patterning similar to the one we saw with the Poisson model which suggest that the negative binomial model is also not an optimal model for our data. We continue by plotting the predicted values and, subsequently, summarize the analysis.</p>
<pre class="r"><code>plot_model(m1.glmer, type = &quot;pred&quot;, terms = c(&quot;Shots&quot;))</code></pre>
<p><img src="mixedregressions_files/figure-html/nbmm6b-1.png" width="672" /></p>
<p>And, we extract the summary table of this model.</p>
<pre class="r"><code>tab_model(m1.glmer)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
UHM
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Incidence Rate Ratios
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.23
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.18 – 0.31
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Shots
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.32
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.24 – 1.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;">
Random Effects
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
σ<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
1.33
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
τ<sub>00</sub> <sub>Language</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.00
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>Language</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
4
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
500
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.277 / NA
</td>
</tr>
</table>
<p>The effect plot shows that the predicted number of shots increases linearly with each shot. For nine and more shots, the model substantially overestimates the number of <em>uhms</em> which shows a bad model fit. It should be noted though that the observed number of <em>uhms</em> also becomes somewhat volatile and shows fluctuations after eight shots. We will now summarize the results as if the violations had NOT occurred(!) - again: this is only because we are practicing here - this would be absolutely unacceptable in a proper write-up of an analysis!</p>
<p>A mixed-effect negative binomial regression model which contained the language in which the conversation took place as random effect was fit to the data. Prior to the regression modelling, a Boruta analysis was applied to determine whether any of the predictors had a meaningful relationship with the dependent variable (instances of <em>uhm</em>). Since the Boruta analysis indicated that only the number of shots a speaker had was important, only “Shots” was tested during model fitting. The final minimal adequate model showed that the number of <em>uhm</em> as fillers increases significantly, and near-linearly with the number of shots speakers had (<span class="math inline">\(\chi\)</span><sup>2</sup>(1):83.0, p &lt;.0001, <span class="math inline">\(\beta\)</span>: 0.2782). An inspection of the random effect structure conveyed that there was almost no variability between languages and language did not contribute meaningfully to the model fit.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-austin2018multilevel">
<p>Austin, Peter C., and George Leckie. 2018. “The Effect of Number of Clusters and Cluster Size on Statistical Power and Type I Error Rates When Testing Random Effects Variance Components in Multilevel Linear and Logistic Regression Models.” <em>Journal of Statistical Computation and Simulation</em> 88 (16): 3151–63.</p>
</div>
<div id="ref-baayen2008analyzing">
<p>Baayen, R Harald. 2008. <em>Analyzing Linguistic Data. A Practical Introduction to Statistics Using R</em>. Cambridge: Cambridge University press.</p>
</div>
<div id="ref-bell2008multilevel">
<p>Bell, Bethany A., John M. Ferron, and Jeffrey D. Kromrey. 2008. “Cluster Size in Multilevel Models: The Impact of Sparse Data Structures on Point and Interval Estimates in Two-Level Models.” In <em>JSM Proceedings. Section on Survey Research Methods</em>, 1122–9. American Statistical Association Alexandria, VA.</p>
</div>
<div id="ref-booth1994regression">
<p>Booth GD, Schuster EG, Niccolucci MJ. 1994. “Identifying Proxy Sets in Multiple Linear Regression: An Aid to Better Coefficient Interpretation. Research Paper Int-470.”</p>
</div>
<div id="ref-clarke2008can">
<p>Clarke, Philippa. 2008. “When Can Group Level Clustering Be Ignored? Multilevel Models Versus Single-Level Models with Sparse Data.” <em>Journal of Epidemiology &amp; Community Health</em> 62 (8): 752–58.</p>
</div>
<div id="ref-clarke2007addressing">
<p>Clarke, Philippa, and Blair Wheaton. 2007. “Addressing Data Sparseness in Contextual Population Research: Using Cluster Analysis to Create Synthetic Neighborhoods.” <em>Sociological Methods &amp; Research</em> 35 (3): 311–51.</p>
</div>
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoe Field. 2012. <em>Discovering Statistics Using R</em>. Sage.</p>
</div>
<div id="ref-johnson2009getting">
<p>Johnson, Daniel Ezra. 2009. “Getting Off the Goldvarb Standard: Introducing Rbrul for Mixed-Effects Variable Rule Analysis.” <em>Language and Linguistics Compass</em> 3 (1): 359–83.</p>
</div>
<div id="ref-maas2005sufficient">
<p>Maas, Cora JM, and Joop J Hox. 2005. “Sufficient Sample Sizes for Multilevel Modeling.” <em>Methodology</em> 1 (3): 86–92.</p>
</div>
<div id="ref-neter1990vif">
<p>Neter, J., W. Wasserman, and MH Kutner. 1990. <em>Applied Linear Statistical Models. Regression, Analysis of Variance, and Experimental Design</em>. Irwin, Homewood, USA.</p>
</div>
<div id="ref-pinheiro2000mixedmodels">
<p>Pinheiro, J. C., and D. M. Bates. 2000. <em>Mixed-Effects Models in S and S-Plus. Statistics and Computing</em>. New York: Springer.</p>
</div>
<div id="ref-twisk2006multilevel">
<p>Twisk, J. W. R. 2006. <em>Applied Multilevel Analysis: A Practical Guide</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-zuur2013beginner">
<p>Zuur, AF, JM Hilbe, and EN Ieno. 2013. <em>A Beginner S Guide to Glm and Glmm with R</em>. Newburgh: Highland Statistics Ltd.</p>
</div>
<div id="ref-zuur2010protocol">
<p>Zuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. “A Protocol for Data Exploration to Avoid Common Statistical Problems.” <em>Methods in Ecology and Evolution</em> 1 (1): 3–14.</p>
</div>
<div id="ref-zuur2009mixedmodels">
<p>Zuur, Alain F., Elena N. ·Ieno, Anatoly A. · Walker Neil J. and· Saveliev, and Graham M. · Smith. 2009. <em>Mixed Effects Models and Extensions in Ecology with R</em>. Springer.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
