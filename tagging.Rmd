---
title: "POS-Tagging and Syntactic Parsing with R"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction{-}

This tutorial introduces part-of-speech tagging and syntactic parsing using R. The entire R markdown document for this tutorial can be downloaded [here](https://slcladal.github.io/tagging.Rmd). Another highly recommendable tutorial on part-of-speech tagging in R produced by Andreas Niekler and Gregor Wiedemann can be found [here](https://tm4ss.github.io/docs/Tutorial_8_NER_POS.html)  [see @WN17].

# Part-Of-Speech Tagging

Many analyses of language data require that we distinguish different parts of speech. In order to determine the word class of a certain word, we use a procedure which is called part-of-speech tagging (commonly referred to as pos-, POS-, or PoS-tagging). POS-tagging is a common procedure when working with natural language data. Despite being used quite frequently, it is a rather complex issue that requires the application of statistical methods that are quite advanced. In the following, we will explore different options for pos-tagging and syntactic parsing. 

Tagging or annotation refers to a process in which information is added to existing text. The annotation can be very different depending on the task at hand. The most common type of annotation when it comes to language data is part-of-speech tagging where the word class is determined for each word in a text and the word class is then added to the word as a tag. However, there are many different ways to tag or annotate texts. Sentiment Analysis, for instance, also annotates texts or words with respect to its or their emotional value or polarity. In fact, annotation is required in many machine-learning contexts because annotated texts represent a training set on which an algorithm is trained that then predicts for unknown items what values they would most likely be assigned if the annotation were done manually. Part-of-speech tagging is offered by many online services (e.g. (here)[http://www.infogistics.com/posdemo.htm] or (here)[https://linguakit.com/en/part-of-speech-tagging]).


POS–tagging assigns part-of-speech tags to character strings (these represent mostly words, of course, but also encompass punctuation marks and other elements). This means that POS–tagging is one specific type of annotation, i.e. adding information to data (either by directly adding information to the data itself or by storing information in e.g. a list which is linked to the data). It is important to note that annotation encompasses various types of information such as pauses, overlap, etc.POS–tagging is just one of these many ways in which corpus data can be *enriched*. Parts-of-speech, or word categories, refer to the grammatical nature or category of a lexical item, e.g. in the sentence *Jane likes the girl* each lexical item can be classified according to whether it belongs to the group of determiners, verbs, nouns, etc. When POS–tagged, the example sentence could look like the example below.

1. Jane/NNP likes/VBZ the/DT girl/NN

In the example above, `NNP` stands for proper noun (singular), `VBZ` stands for 3rd person singular present tense verb, `DT` for determiner, and `NN` for noun(singular or mass). The POS tags used by the `openNLPpackage` are the [Penn English Treebank POS-tags](https://dpdearing.com/posts/2011/12/opennlp-part-of-speech-pos-tags-penn-english-treebank/) – here is a list of these tags and what they stand for:

```{r tags, echo=F, eval = T}
library(DT)
Tag <- c("CC", "CD", "DT", "EX", "FW", "IN", "JJ", "JJR", "JJS", "LS", "MD", "NN", "NNS", "NNP", "NNPS", "PDT", "POS", "PRP", "PRP$", "RB", "RBR", "RBS", "RP", "SYM", "TO", "UH", "VB", "VBD", "VBG", "VBN", "VBP", "VBZ", "WDT", "WP", "WP$", "WRB")
Description <- c("Coordinating conjunction", "Cardinal number", "Determiner", "Existential there", "Foreign word", "Preposition or subordinating con", "Adjective", "Adjective, comparative", "Adjective, superlative", "List item marker", "Modal", "Noun, singular or mass", "Noun, plural", "Proper noun, singular", "Proper noun, plural", "Predeterminer", "Possessive ending", "Personal pronoun", "Possessive pronoun", "Adverb", "Adverb, comparative", "Adverb, superlative", "Particle", "Symbol", "to", "Interjection", "Verb, base form", "Verb, past tense", "Verb, gerund or present particip", "Verb, past participle", "Verb, non-3rd person singular pr", "Verb, 3rd person singular presen", "Wh-determiner", "Wh-pronoun", "Possessive wh-pronoun", "Wh-adverb")
Examples <- c("and, or, but", "one, two, three", "a, the", "There/EX was a party in progress", "persona/FW non/FW grata/FW", "uh, well, yes", "good, bad, ugly", "better, nicer", "best, nicest", "a., b., 1., 2.", "can, would, will", "tree, chair", "trees, chairs", "John, Paul, CIA", "Johns, Pauls, CIAs", "all/PDT this marble, many/PDT a soul", "John/NNP 's/POS, the parentss/NNP '/POS distress", "I, you, he", "mine, yours", "evry, enough, not", "later", "latest", "RP", "CO2", "to", "uhm, uh", "go, walk", "walked, saw", "walking, seeing", "walked, thought", "walk, think", "walks, thinks", "which, that", "what, who, whom (wh-pronoun)", "whose, who (wh-words)", "how, where, why (wh-adverb)")
tags <- data.frame(Tag, Description, Examples)
datatable(tags, filter = "none", options = list(pageLength = 36, scrollX=T))
```

Assigning these POS tags to words appears to be rather straight forward. However, POS tagging is quite complex and there are various ways by which a computer can be trained to assign POS tags. For example, one could use orthographic or morphological information to devise rules such as. . .

* If a word ends in *ment*, assign the POS tag `NN` (for common noun)

* If a word does not occur at the beginning of a sentence but is capitalized, assign the POS tag `NNP` (for proper noun)

Using such rules has the disadvantage that POS tags can only be assigned to a relatively small number of words as most words will be ambiguous – think of the similarity of the English plural and the English past tense morpheme,for instance, which are orthographically identical.Another option would be to use a dictionary in which each word is as-signed a certain POS tag and a program could assign the POS tag if the word occurs in a given text. This procedure has the disadvantage that most words belong to more than one word class and POS tagging would thus have to rely on additional information.The problem of words that belong to more than one word class can partly be remedied by including contextual information such as. . 

* If the previous word is a determiner and the following word is a common noun, assign the POS tag `JJ` (for a common adjective)


This procedure works quite well but there are still better options.The best way to POS tag a text is to create a manually annotated training set which resembles the language variety at hand. Based on the frequency of the association between a given word and the POS tags it is assigned in the training data, it is possible to tag a word with the POS tag that is most often assigned to the given word in the training data.All of the above methods can and should be optimized by combining them and additionally including POS–n–grams, i.e. determining a POS tag of an unknown word based on which sequence of POS tags is most similar to the sequence at hand and also most common in the training data.This introduction is extremely superficial and only intends to scratch some of the basic procedures that POS tagging relies on. The interested reader is referred to introductions on machine learning and POS tagging such as e.g.https://class.coursera.org/nlp/lecture/149.


There are several different R packages that assist with POS-tagging texts [see @kumar2016mastering]. In this tutorial, we will use the `openNLP`, the `corNLP`, and the `TreeTagger` packages. Each of these has advantages and shortcomings and it is advantageous to try which result best matches one's needs.

### Preparation and session set up{-}

This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/IntroR_workshop.html). For this tutorials, we need to install certain *packages* from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).


```{r prep1, echo=T, eval = F, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options("scipen" = 100, "digits" = 4) # suppress math annotation
install libraries("dplyr", "igraph", "tm", "NLP", "openNLP",
                  "openNLPdata", "coreNLP", "stringr", "koRpus", 
                  "koRpus.lang.en"))
```

We now activate these packages and load a function provided by LADAL which allows to pos-tag English text once they are read into R.

```{r initalisierung, results='hide', message=FALSE, warning=FALSE}
# activate packages
library(dplyr)
library(igraph)
library(tm)
library(NLP)
library(openNLP)
library(openNLPdata)
#library(coreNLP)
library(stringr)
library(koRpus)
library(koRpus.lang.en)
# load function for pos-tagging objects in R
source("https://slcladal.github.io/rscripts/POStagObject.r") 
```

Once you have installed R Studio and initiated the session by executing the code shown above, you maybe good to go.

***

<span style="color: red;">Note</span>: A word of warning is in order here. The `openNLP` library is written is Java and may require a re-installation of Java as well as re-setting the path variable to Java. A short video on how to set the path variable can be found (here)[https://www.youtube.com/watch?v=yrRmLOcB9fg].

***

## Part-Of-Speech Tagging with openNLP

In R we can POS–tag large amounts of text by various means. This section explores POS-tagging using the `openNLP` package. Using the `openNLP` package for POS tagging works particularly well when the aim is to POS tag newspaper texts as the `openNLP` package implements the *Apache OpenNLPMaxent Part of Speech tagger* and it comes with pre-trained models. Ideally, POS taggers should be trained on data resembling the data to be POS tagged.However, I do not know how to trained the *Apache openNLP POS tagger* via R and it would be great if someone would provide a tutorial on how to do that. Using pre-trained models has the advantage that we do not need to train the POS tagger ourselves. However, it also means that one has to rely on models trained on data that may not really resemble the data a at hand.This implies that using it for texts that differ from newspaper texts, i.e.the language the models have been trained on, does not work as well, as the model applies the probabilities of newspaper language to the language variety at hand. POS tagging with the `openNLP` requires the `NLP` package and installing the models on which the `openNLP` package is based.

To POS-tag a text, we start by loading an example text into R.

```{r pos1, eval=T, echo=T, message=FALSE, warning=FALSE, paged.print=FALSE}
# load corpus data
text <- readLines("https://slcladal.github.io/data/testcorpus/linguistics07.txt", skipNul = T)
# clean data
text <- text %>%
 str_squish() 
# inspect data
str(text)
```

Now that the text data has been read into R, we can proceed with the part-of-speech tagging. To perform the pos-tagging, we load the function for pos-tagging, load the `NLP` and `openNLP` packages.

***

<span style="color: red;">Note</span>:  A word of warnung is in order here. The `openNLP` library is written is Java and may require a re-installation of Java as well as re-setting the path variable to Java. A short video on how to set the path variable can be found [here](https://www.youtube.com/watch?v=yrRmLOcB9fg). 

***

```{r German, eval = T}
POStag <- function(object){
  require("stringr")
  require("NLP")
  require("openNLP")
  require("openNLPdata")
  # define paths to corpus files
  corpus.tmp <- object
  # define sentence annotator
  sent_token_annotator <- Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator <- Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator <- Maxent_POS_Tag_Annotator(language = "en", probs = FALSE, 
    # WARNING: YOU NEED TO INCLUDE YOUR OWN PATH HERE!                                            
    model = "C:\\Users\\marti\\OneDrive\\Dokumente\\R\\win-library\\3.4\\openNLPdata\\models\\en-pos-maxent.bin")
  # convert all file content to strings
  Corpus <- lapply(corpus.tmp, function(x){
    x <- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 <- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2<- NLP::annotate(x, pos_tag_annotator, y1)
    y2w <- subset(y2, type == "word")
    tags <- sapply(y2w$features, '[[', "POS")
    r1 <- sprintf("%s/%s", x[y2w], tags)
    r2 <- paste(r1, collapse = " ")
    return(r2)  }  )
  }
```

We now apply this function to our text.

```{r pos2, eval=T, echo=T, message=FALSE, warning=FALSE, paged.print=FALSE}
# pos tagging data
textpos <- POStag(object = text)
textpos
```

The resulting vector contains the part-of-speech tagged text and shows that the function fulfills its purpose in automatically POS tagging the text. The pos-tagged text could now be processed further, e.g. by extracting all  adjectives in the text or by creating concordances of nouns ending in *ment*.

## Part-Of-Speech Tagging with TreeTagger

An alternative to `openNLP` for POS-tagging texts in R is the `koRpus` package. The `koRpus` package uses the [TreeTagger](cf.http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) which means that the TreeTagger has to be installed prior to POS-tagging based on `koRpus` package. The `koRpus` package simply accesses the TreeTagger via R.

The TreeTagger has the advantage that it can be relatively easily modified and trained on new data but has the disadvantage that it can  be  quite  tedious  to  implement  (in case you are running a Windows machine as I do).

### TreeTagger installation on Windows{-}

As this process was somewhat time consuming, I would like to expand on what I did to get it going as this might save you some time and frustration.

1. The first thing you should do is to install or re-install a Perl interpreter. You can simply do so by clicking [here](http://www.activestate.com/activeperl/) and following the installation instructions. 

2. Download the TreeTagger (click [here](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-windows-3.2.3.zip) for a Windows-64 version and [here](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-windows32-3.2.3.zip) for a Windows-32 version). Move the zip-file to the root directory on your C-drive (C:/) and extract the zip file.

3. Download the parameter files for the languages you need (you will find the parameters files under **Parameer files** [here](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/#Windows)). Then decompress the parameter files and move them to the subdirectory `TreeTagger/lib`. Rename the parameter files to `<language>-utf8.par`. For example, rename the file `french-par-linux-3.2-utf8.bin` as `french-utf8.par`.

4. Now you need to set a path variable. You need to add the path `C:\TreeTagger\bin` to the `PATH` environment variable. How to do this differs across Windows versions. You can find a video tutorial on how to change path variables in Windows 10 [here](https://www.youtube.com/watch?v=Frrlv_5rGhY). If you have a different Windows version, e.g. Windows 7, I recommend you search for *Set path variable in Windows 7" on YouTube and follow the instructions. 
   
5. Next, open a command prompt window and type the command:

```{r, eval = F}
set PATH=C:\TreeTagger\bin;%PATH%
```


6. Then, go to the directory C:\TreeTagger by typing the command:

```{r, eval = F}
cd c:\TreeTagger
```


7. Now, everything should be running and you can test the tagger, e.g. by pos-tagging the TreeTagger installation file. To do this, type the command:

```{r, eval = F}
tag-english INSTALL.txt
```

If you do not get the POS-tagged results after a few seconds, restart your computer and repeat steps 1 to 7. 
   
If you install the TreeTagger in a different directory, you have to modify the first path in the batch files tag-*.bat using an editor such as Wordpad.

The problem that occurred during my installation was that I had to re-install Java but once I had done so, it finally worked.  

### Using the TreeTagger{-}

In this example, we simply implement the TreeTagger without training it!  This is in fact not a good practice and should be avoided as I have no way of knowing how good the performance is or what I could do to improve its performance!

```{r}
# activate packages
library(koRpus)
library(koRpus.lang.en)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-english.bat", lang="en") 
postagged <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics07.txt")
# inspect  results
datatable(postagged@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

We can now paste the text and the pos-tags together using the `paste` function from base R.


```{r, tree8}
postaggedtext <- paste(postagged@tokens$token, postagged@tokens$tag, sep = "/", collapse = " ")
postaggedtext
```

### TreeTagger: POS-tagging multiple files{-}

To POS-tag several files at once you need to create a list of paths and then apply the `treetagger` to each of the path elements. Once we have done so, we inspect the structure of the resulting vector which now holds the POS-tagged texts.

```{r tree10}
corpuspath <- "D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus"
# generate list of corpus files
corpusfiles <- list.files(corpuspath)
cfiles <- paste0(corpuspath, "/", corpusfiles, sep = "")
# apply treetagger to each file in corpus
postagged_files <- sapply(cfiles, function(x){
  set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-english.bat", lang="en") 
  x <- treetag(x)
  x <- paste(x@tokens$token, x@tokens$tag, sep = "/", collapse = " ")
})
# inspect  text.tagged
str(postagged_files)
```

The first POS-tagged corpus file looks like this.

```{r tree12}
postagged_files[1]
```

In addition to being very flexible, the TreeTagger is appealing because it supports a comparatively large sample of languages. Here is the list of languages (or varieties) that are currently supported: Bulgarian, Catalan, Chinese, Coptic, Czech, Danish, Dutch, Another Dutch, English, English, Estonian, Finnish, French, Spoken French, Old French, Galician, German, Spoken German, Middle High German, Greek, Ancient Greek, Hausa, Italian, Korean, Latin, Mongolian, Norwegian (Bokmaal), Polish, Portuguese, Portuguese, Romanian, Russian, Slovak, Slovenian, Spanish, Swahili, Swedish.

### TreeTagger: POS-tagging languages other than English{-}

```{r de1, eval =F}
# install support
install.koRpus.lang("de")
install.koRpus.lang("fr")
install.koRpus.lang("es")
install.koRpus.lang("it")
install.koRpus.lang("nl")
install.koRpus.lang("pt")
install.koRpus.lang("ru")
```

POS-tagging a German text:

```{r de, eval = F}
# activate package
library(koRpus.lang.de)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-german.bat", lang="de") 
postagged_german <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/german.txt")
# inspect  text.tagged
postagged_german@tokens
```

POS-tagging a French text:

```{r fr}
# activate package
library(koRpus.lang.fr)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-french.bat", lang="fr") 
postagged_french <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/french.txt")
# inspect  results
datatable(postagged_french@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

POS-tagging a Spanish text:

```{r sp}
# activate package
library(koRpus.lang.es)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-spanish.bat", lang="es") 
postagged_spanish <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/spanish.txt")
# inspect results
datatable(postagged_spanish@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

POS-tagging a Italian text:

```{r it}
# activate package
library(koRpus.lang.it)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-italian.bat", lang="it") 
postagged_italian <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/italian.txt")
# inspect results
datatable(postagged_italian@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

POS-tagging a Dutch text:

```{r du, eval = F}
# activate package
library(koRpus.lang.nl)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-dutch.bat", lang="nl") 
postagged_dutch <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/dutch.txt")
# inspect results
datatable(postagged_dutch@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```
POS-tagging a Portuguese text:

```{r pt, eval = F}
# activate package
library(koRpus.lang.pt)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-dutch.bat", lang="pt") 
postagged_portuguese <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/portugese.txt")
# inspect results
datatable(postagged_portuguese@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

POS-tagging a Russian text:

```{r ru, eval = F}
# activate package
library(koRpus.lang.ru)
# perform  POS  tagging
set.kRp.env(TT.cmd="C:\\TreeTagger\\bin\\tag-russian.bat", lang="pt") 
postagged_russian <- treetag("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/russian.txt")
# inspect results
datatable(postagged_russian@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = "none")
```

## Part-Of-Speech Tagging with coreNLP

Another package that is very handy when it comes to POS-tagging but more importantly syntactic parsing is the `coreNLP` package [see @arnold2015humanities]. Unfortunately, we cannot use it at this point as it is not supported by up-to-date versions of R.

```{r, echo = T, eval = F}
library(coreNLP)
initCoreNLP()

annotation <- annotateString(text)
annotation
```


# Syntactic Parsing

Parsing refers to another type of annotation in which either structural information (as in the case of XML documents) or syntactic relations are added to text. As syntactic parsing is commonly more relevant in the language sciences, the following will focus only on syntactic parsing. syntactic parsing builds on PoS-tagging and allows drawing syntactic trees or dependencies. Unfortunately, syntactic parsing still has relatively high error rates when dealing with language that is not very formal. However, syntactic parsing is very reliable when dealing with written language.

```{r pars1, message=F, warning=F}
text <- readLines("D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/english.txt")
# convert character to string
s <- as.String(text)
# define sentence and word token annotator
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
# apply sentence and word annotator
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
# define syntactic parsing annotator
parse_annotator <- Parse_Annotator()
# apply parser
p <- parse_annotator(s, a2)
# extract parsed information
ptexts <- sapply(p$features, '[[', "parse")
ptexts
```

```{r pars2, eval=T, echo=T, message=FALSE, warning=FALSE, paged.print=FALSE}
# read into NLP Tree objects.
ptrees <- lapply(ptexts, Tree_parse)
# show frist tree
ptrees[[1]]
```

These trees can, of course, also be shown visually, for instance, in the form of a syntax trees (or tree dendrogram). 

```{r pars3, eval=T, echo=T, message=FALSE, warning=FALSE, fig.height=8, fig.width=8}
# remove punctuation
ptexts[1] <- gsub("\\(\\. \\.\\)", "", ptexts[1])
ptexts[1] <- gsub("\\(\\, \\,\\)", "", ptexts[1])
# load library

source("https://slcladal.github.io/rscripts/parsetgraph.R")
parse2graph(ptexts[1], title = "", margin=-0.2, vertex.color=NA,
 vertex.frame.color=NA, vertex.label.font=2,
 vertex.label.cex=.75, vertex.label.color="black", asp=.5,
 edge.width=1, edge.color='red', edge.arrow.size=0)
```

Syntax trees are very handy because the allow us to check how reliable the parser performed. 


# Citation & Session Info {-}

Schweinberger, Martin. 2020. *POS-Tagging and Syntactic Parsing with R*. Brisbane: The University of Queensland. url: https://slcladal.github.io/tagging.html

```
@manual{schweinberger2020pos,
  author = {Schweinberger, Martin},
  title = {POS-Tagging and Syntactic Parsing with R},
  note = {https://slcladal.github.io/tagging.html},
  year = {2020},
  organization = "The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/09/24}
}
```

```{r fin}
sessionInfo()
```


# References {-}

***

[Main page](https://slcladal.github.io/index.html)

***

