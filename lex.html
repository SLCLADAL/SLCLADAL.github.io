<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2022-05-21" />

<title>Lexicography with R</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>
<link href="site_libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<link rel="stylesheet" href="styles.css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VSGK4KYDQZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VSGK4KYDQZ');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    ABOUT LADAL
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="people.html">People | Collabs</a>
    </li>
    <li>
      <a href="news.html">News</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    EVENTS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="workshops.html">Workshops</a>
    </li>
    <li>
      <a href="webinars2022.html">LADAL Webinar Series 2022</a>
    </li>
    <li>
      <a href="opening.html">LADAL Webinar Series 2021</a>
    </li>
  </ul>
</li>
<li>
  <a href="tutorials.html">TUTORIALS</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    RESOURCES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="links.html">Links</a>
    </li>
    <li>
      <a href="base.html">Tutorial stylesheet</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    CONTACT
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="contact.html">Contact</a>
    </li>
    <li>
      <a href="services.html">Services</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Lexicography with R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2022-05-21</h4>

</div>


<p><img src="https://slcladal.github.io/images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1 class="unnumbered">Introduction</h1>
<p>This tutorial introduces lexicography with R and shows how to use R
to create dictionaries and find synonyms through determining semantic
similarity in R. While the initial example focuses on English,
subsequent sections show how easily this approach can be generalized to
languages other than English (e.g. German, French, Spanish, Italian, or
Dutch). The entire R-markdown document for the sections below can be
downloaded <a href="https://slcladal.github.io/lex.Rmd">here</a>.</p>
<p>Traditionally, dictionaries are listing of words that are commonly
arranged alphabetically, which may include information on definitions,
usage, etymologies, pronunciations, translation, etc. <span
class="citation">(see <a href="#ref-agnes2002webster"
role="doc-biblioref">Agnes, Goldman, and Soltis 2002</a>; <a
href="#ref-steiner1985dictionaries" role="doc-biblioref">Steiner
1985</a>)</span>. If such dictionaries, that are typically published as
books contain translations of words in other languages, they are
referred to as lexicons. Therefore, lexicographical references show the
inter-relationships among lexical data, i.e. words.</p>
<p>Similarly, in computational linguistics, dictionaries represent a
specific format of data where elements are linked to or paired with
other elements in a systematic way. <em>Computational lexicology</em>
refers to a branch of computational linguistics, which is concerned with
the use of computers in the study of lexicons. Hence, computational
lexicology has been defined as the use of computers in the study of
machine-readable dictionaries <span class="citation">(see e.g. <a
href="#ref-amsler1981structure" role="doc-biblioref">Amsler
1981</a>)</span>. Computational lexicology is distinguished from
<em>computational lexicography</em>, which can be defined as the use of
computers in the construction of dictionaries which is the focus of this
tutorial. It should be noted, thought, that computational lexicology and
computational lexicography are often used synonymously.</p>
<div id="preparation-and-session-set-up"
class="section level2 unnumbered">
<h2 class="unnumbered">Preparation and session set up</h2>
<p>This tutorial is based on R. If you have not installed R or are new
to it, you will find an introduction to and more information how to use
R <a href="https://slcladal.github.io/Intror.html">here</a>. For this
tutorials, we need to install certain <em>packages</em> from an R
<em>library</em> so that the scripts shown below are executed without
errors. Before turning to the code below, please install the packages by
running the code below this paragraph. If you have already installed the
packages mentioned below, then you can skip ahead and ignore this
section. To install the necessary packages, simply run the following
code - it may take some time (between 1 and 5 minutes to install all of
the packages so you do not need to worry if it takes some time).</p>
<pre class="r"><code># set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # suppress math annotation
# install packages
install.packages(&quot;dplyr&quot;)
install.packages(&quot;stringr&quot;)
install.packages(&quot;udpipe&quot;)
install.packages(&quot;tidytext&quot;)
install.packages(&quot;coop&quot;)
install.packages(&quot;cluster&quot;)
install.packages(&quot;flextable&quot;)
# install klippy for copy-to-clipboard button in code chunks
install.packages(&quot;remotes&quot;)
remotes::install_github(&quot;rlesur/klippy&quot;)</code></pre>
<p>In a next step, we load the packages.</p>
<pre class="r"><code># load packages
library(dplyr)
library(stringr)
library(udpipe)
library(tidytext)
library(coop)
library(cluster)
library(flextable)
# activate klippy for copy-to-clipboard button
klippy::klippy()</code></pre>
<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<p>Once you have installed R and RStudio and once you have initiated the
session by executing the code shown above, you are good to go.</p>
</div>
</div>
<div id="creating-dictionaries" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Creating
dictionaries</h1>
<p>In a first step, we load a text. In this case, we load George
Orwell’s <em>Nineteen Eighty-Four</em>.</p>
<pre class="r"><code>text &lt;- readLines(&quot;https://slcladal.github.io/data/orwell.txt&quot;) %&gt;%
  paste0(collapse = &quot; &quot;)
# show the first 500 characters of the text
substr(text, start=1, stop=500)</code></pre>
<pre><code>## [1] &quot;1984 George Orwell Part 1, Chapter 1 It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his breast in an effort to escape the vile wind, slipped quickly through the glass doors of Victory Mansions, though not quickly enough to prevent a swirl of gritty dust from entering along with him. The hallway smelt of boiled cabbage and old rag mats. At one end of it a coloured poster, too large for indoor display, had been tacked to the wall. It &quot;</code></pre>
<p>Next, we download a <code>udpipe</code> language model. In this case,
we download a <code>udpipe</code> language model for English, but you
can download <code>udpipe</code> language models for more than 60
languages.</p>
<pre class="r"><code># download language model
m_eng   &lt;- udpipe::udpipe_download_model(language = &quot;english-ewt&quot;)</code></pre>
<p>In my case, I have stored this model in a folder called
<code>udpipemodels</code> and you can load it (if you have also save the
model in a folder called <code>udpipemodels</code> within your Rproj
folder as shown below. )</p>
<pre class="r"><code># load language model from your computer after you have downloaded it once
m_eng &lt;- udpipe_load_model(file = here::here(&quot;udpipemodels&quot;, &quot;english-ewt-ud-2.5-191206.udpipe&quot;))</code></pre>
<p>In a next step, we implement the part-of-speech tagger.</p>
<pre class="r"><code># tokenise, tag, dependency parsing
text_ann &lt;- udpipe::udpipe_annotate(m_eng, x = text) %&gt;%
  # convert into a data frame
  as.data.frame() %&gt;%
  # remove columns we do not need
  dplyr::select(-sentence, -paragraph_id, -sentence_id, -feats, 
                -head_token_id, -dep_rel, -deps, -misc)
# inspect
head(text_ann, 10)</code></pre>
<pre><code>##    doc_id token_id   token   lemma  upos xpos
## 1    doc1        1    1984    1984 PROPN  NNP
## 2    doc1        2  George  George PROPN  NNP
## 3    doc1        3  Orwell  Orwell PROPN  NNP
## 4    doc1        4    Part    part PROPN  NNP
## 5    doc1        5       1       1   NUM   CD
## 6    doc1        6       ,       , PUNCT    ,
## 7    doc1        7 Chapter chapter PROPN  NNP
## 8    doc1        8       1       1   NUM   CD
## 9    doc1        1      It      it  PRON  PRP
## 10   doc1        2     was      be   AUX  VBD</code></pre>
<p>We can now use the resulting table to generate a first, basic
dictionary that holds information about the word form (<em>token</em>),
the part-of speech tag (<em>upos</em>), the lemmatized word type
(<em>lemma</em>), and the frequency with which the word form is used as
that part-of speech.</p>
<pre class="r"><code># generate dictionary
text_dict_raw &lt;- text_ann %&gt;%
  # remove non-words
  dplyr::filter(!stringr::str_detect(token, &quot;\\W&quot;)) %&gt;%
  # filter out numbers
  dplyr::filter(!stringr::str_detect(token, &quot;[0-9]&quot;)) %&gt;%
  # group data
  dplyr::group_by(token, lemma, upos) %&gt;%
  # summarize data
  dplyr::summarise(frequency = dplyr::n()) %&gt;%
  # arrange by frequency
  dplyr::arrange(-frequency)
# inspect
head(text_dict_raw, 10)</code></pre>
<pre><code>## # A tibble: 10 × 4
## # Groups:   token, lemma [10]
##    token lemma upos  frequency
##    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;
##  1 the   the   DET        5249
##  2 of    of    ADP        2908
##  3 a     a     DET        2277
##  4 and   and   CCONJ      2064
##  5 was   be    AUX        1795
##  6 in    in    ADP        1446
##  7 to    to    PART       1336
##  8 it    it    PRON       1295
##  9 he    he    PRON       1270
## 10 had   have  AUX        1018</code></pre>
<p>The above display is ordered by frequency but it is, of course more
common, to arrange dictionaries alphabetically. To do this, we can
simply use the <code>àrrange</code> function from the <code>dplyr</code>
package as shown below.</p>
<pre class="r"><code># generate dictionary
text_dict &lt;- text_dict_raw %&gt;%
  # arrange alphabetically
  dplyr::arrange(token)
# inspect
head(text_dict, 10)</code></pre>
<pre><code>## # A tibble: 10 × 4
## # Groups:   token, lemma [7]
##    token     lemma     upos  frequency
##    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 a         a         DET        2277
##  2 A         a         DET         107
##  3 A         a         NOUN          1
##  4 Aaronson  Aaronson  PROPN         8
##  5 aback     aback     ADV           1
##  6 aback     aback     NOUN          1
##  7 abandon   abandon   VERB          2
##  8 abandon   abandon   ADP           1
##  9 abandoned abandon   VERB          4
## 10 abasement abasement NOUN          1</code></pre>
<p>We have now generated a basic dictionary of English but, as you can
see above, there are still some errors as the part-of-speech tagging was
not perfect. As such, you will still need to check and edit the results
manually but you have already a rather clean dictionary based on George
Orwell’s <em>Nineteen Eighty-Four</em> to work with.</p>
<div id="correcting-and-extending-dictionaries"
class="section level2 unnumbered">
<h2 class="unnumbered">Correcting and Extending Dictionaries</h2>
<p>Fortunately, it is very easy in R to correct entries, i.e., changing
lemmas or part-of-speech tags, and to extend entries, i.e., adding
additional layers of information such as urls or examples.</p>
<p>We will begin to extend our dictionary by adding an additional column
(called <code>annotation</code>) in which we will add information.</p>
<pre class="r"><code># generate dictionary
text_dict_ext &lt;- text_dict %&gt;%
  # removing an entry
  dplyr::filter(!(lemma == &quot;a&quot; &amp; upos == &quot;NOUN&quot;)) %&gt;%
  # editing entries
  dplyr::mutate(upos = ifelse(lemma == &quot;aback&quot; &amp; upos == &quot;NOUN&quot;, &quot;PREP&quot;, upos)) %&gt;%
  # adding comments 
  dplyr::mutate(comment = dplyr::case_when(lemma == &quot;a&quot; ~ &quot;also an before vowels&quot;,
                                           lemma == &quot;Aaronson&quot; ~ &quot;Name of someone.&quot;, 
                                           T ~ &quot;&quot;))
# inspect
head(text_dict_ext, 10)</code></pre>
<pre><code>## # A tibble: 10 × 5
## # Groups:   token, lemma [8]
##    token     lemma     upos  frequency comment                
##    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;                  
##  1 a         a         DET        2277 &quot;also an before vowels&quot;
##  2 A         a         DET         107 &quot;also an before vowels&quot;
##  3 Aaronson  Aaronson  PROPN         8 &quot;Name of someone.&quot;     
##  4 aback     aback     ADV           1 &quot;&quot;                     
##  5 aback     aback     PREP          1 &quot;&quot;                     
##  6 abandon   abandon   VERB          2 &quot;&quot;                     
##  7 abandon   abandon   ADP           1 &quot;&quot;                     
##  8 abandoned abandon   VERB          4 &quot;&quot;                     
##  9 abasement abasement NOUN          1 &quot;&quot;                     
## 10 abashed   abashed   VERB          1 &quot;&quot;</code></pre>
<p>To make it a bit more interesting but also keep this tutorial simple
and straight-forward, we will add information about the polarity and
emotionally of the words in our dictionary. We can do this by performing
a sentiment analysis on the lemmas using the <code>tidytext</code>
package.</p>
<p>The <code>tidytext</code> package contains three sentiment
dictionaries (<code>nrc</code>, <code>bing</code>, and
<code>afinn</code>). For the present purpose, we use the
<code>ncr</code>dictionary which represents the Word-Emotion Association
Lexicon <span class="citation">(<a href="#ref-mohammad2013crowdsourcing"
role="doc-biblioref">Mohammad and Turney 2013</a>)</span>. The
Word-Emotion Association Lexicon which comprises 10,170 terms, and in
which lexical elements are assigned scores based on ratings gathered
through the crowd-sourced Amazon Mechanical Turk service. For the
Word-Emotion Association Lexicon raters were asked whether a given word
was associated with one of eight emotions. The resulting associations
between terms and emotions are based on 38,726 ratings from 2,216 raters
who answered a sequence of questions for each word which were then fed
into the emotion association rating <span class="citation">(cf. <a
href="#ref-mohammad2013crowdsourcing" role="doc-biblioref">Mohammad and
Turney 2013</a>)</span>. Each term was rated 5 times. For 85 percent of
words, at least 4 raters provided identical ratings. For instance, the
word <em>cry</em> or <em>tragedy</em> are more readily associated with
SADNESS while words such as <em>happy</em> or <em>beautiful</em> are
indicative of JOY and words like <em>fit</em> or <em>burst</em> may
indicate ANGER. This means that the sentiment analysis here allows us to
investigate the expression of certain core emotions rather than merely
classifying statements along the lines of a crude positive-negative
distinction.</p>
<p>To be able to use the Word-Emotion Association Lexicon we need to add
another column to our data frame called <code>word</code> which simply
contains the lemmatized word. The reason is that the lexicon expects
this column and only works if it finds a word column in the data. The
code below shows how to add the emotion and polarity entries to our
dictionary.</p>
<pre class="r"><code># generate dictionary
text_dict_snt &lt;- text_dict_ext %&gt;%
  dplyr::mutate(word = lemma) %&gt;%
  dplyr::left_join(get_sentiments(&quot;nrc&quot;)) %&gt;%
  dplyr::group_by(token, lemma, upos, comment) %&gt;%
  dplyr::summarise(sentiment = paste0(sentiment, collapse = &quot;, &quot;))
# inspect
head(text_dict_snt, 10) </code></pre>
<pre><code>## # A tibble: 10 × 5
## # Groups:   token, lemma, upos [10]
##    token     lemma     upos  comment                 sentiment              
##    &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                   &lt;chr&gt;                  
##  1 a         a         DET   &quot;also an before vowels&quot; NA                     
##  2 A         a         DET   &quot;also an before vowels&quot; NA                     
##  3 Aaronson  Aaronson  PROPN &quot;Name of someone.&quot;      NA                     
##  4 aback     aback     ADV   &quot;&quot;                      NA                     
##  5 aback     aback     PREP  &quot;&quot;                      NA                     
##  6 abandon   abandon   ADP   &quot;&quot;                      fear, negative, sadness
##  7 abandon   abandon   VERB  &quot;&quot;                      fear, negative, sadness
##  8 abandoned abandon   VERB  &quot;&quot;                      fear, negative, sadness
##  9 abasement abasement NOUN  &quot;&quot;                      NA                     
## 10 abashed   abashed   VERB  &quot;&quot;                      NA</code></pre>
<p>The resulting extended dictionary now contains not only the token,
the lemma, and the pos-tag but also the sentiment from the Word-Emotion
Association Lexicon.</p>
</div>
<div id="generating-dictionaries-for-other-languages"
class="section level2 unnumbered">
<h2 class="unnumbered">Generating dictionaries for other languages</h2>
<p>As mentioned above, the procedure for generating dictionaries can
easily be applied to languages other than English. If you want to follow
exactly the procedure described above, then the language set of the
TreeTagger is the limiting factors as its R implementation only supports
English, German, French, Italian, Spanish, and Dutch. fa part-of-speech
tagged text in another language is already available to you, and you do
not require the TreeTagger for the part-of-speech tagging, then you can
skip the code chunk that is related to the tagging and you can modify
the procedure described above to virtually any language.</p>
<p>We will now briefly create a German dictionary based on a subsection
of the fairy tales collected by the brothers Grimm to show how the above
procedure can be applied to a language other than English. In a first
step, we load a German text into R.</p>
<pre class="r"><code>grimm &lt;- readLines(&quot;https://slcladal.github.io/data/GrimmsFairytales.txt&quot;,
                   encoding = &quot;latin1&quot;) %&gt;%
  paste0(collapse = &quot; &quot;)
# show the first 500 characters of the text
substr(grimm, start=1, stop=200)</code></pre>
<pre><code>## [1] &quot;Der Froschkönig oder der eiserne Heinrich  Ein Märchen der Brüder Grimm Brüder Grimm  In den alten Zeiten, wo das Wünschen noch geholfen hat, lebte ein König, dessen Töchter waren alle schön; aber die&quot;</code></pre>
<p>Next, we download a <code>udpipe</code> language model. In this case,
we download a <code>udpipe</code> language model for German, but you can
download <code>udpipe</code> language models for more than 60
languages.</p>
<pre class="r"><code># download language model
udpipe::udpipe_download_model(language = &quot;german-hdt&quot;)</code></pre>
<p>In my case, I have stored this model in a folder called
<code>udpipemodels</code> and you can load it (if you have also save the
model in a folder called <code>udpipemodels</code> within your Rproj
folder as shown below).</p>
<pre class="r"><code># load language model from your computer after you have downloaded it once
m_ger &lt;- udpipe_load_model(file = here::here(&quot;udpipemodels&quot;,
                                             #&quot;german-hdt-ud-2.5-191206.udpipe&quot;))
                                             &quot;german-gsd-ud-2.5-191206.udpipe&quot;))</code></pre>
<p>In a next step, we generating the dictionary based on the brothers’
Grimm fairy tales. We go through the same steps as for the English
dictionary and collapse all the steps into a single code block.</p>
<pre class="r"><code># tokenise, tag, dependency parsing
grimm_ann &lt;- udpipe::udpipe_annotate(m_ger, x = grimm) %&gt;%
  # convert into a data frame
  as.data.frame() %&gt;%
  # remove non-words
  dplyr::filter(!stringr::str_detect(token, &quot;\\W&quot;)) %&gt;%
  # filter out numbers
  dplyr::filter(!stringr::str_detect(token, &quot;[0-9]&quot;)) %&gt;%
  dplyr::group_by(token, lemma, upos) %&gt;%
  dplyr::summarise(frequency = dplyr::n()) %&gt;%
  dplyr::arrange(lemma)
# inspect
head(grimm_ann, 10)</code></pre>
<pre><code>## # A tibble: 10 × 4
## # Groups:   token, lemma [8]
##    token    lemma    upos  frequency
##    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;     &lt;int&gt;
##  1 A        A        NOUN          1
##  2 ab       ab       ADP          12
##  3 abends   abend    ADV           2
##  4 Abend    Abend    NOUN          3
##  5 abends   abends   ADV           1
##  6 aber     aber     ADJ           1
##  7 aber     aber     ADV          56
##  8 aber     aber     CCONJ        32
##  9 Aber     aber     CCONJ        16
## 10 abfallen abfallen VERB          1</code></pre>
<p>As with the English dictionary, we have created a customized German
dictionary based of a subsample of the brothers’ Grimm fairy tales
holding the word form(<em>token</em>), the part-of-speech tag
(<em>tag</em>), the lemmatized word type (<em>lemma</em>), the general
word class (<em>wclass</em>), ad the frequency with which a word form
occurs as a part-of-speech in the data (<em>frequency</em>).</p>
</div>
</div>
<div id="finding-synonyms-creating-a-thesaurus" class="section level1"
number="2">
<h1><span class="header-section-number">2</span> Finding synonyms:
creating a thesaurus</h1>
<p>Another task that is quite common in lexicography is to determine if
words share some form of relationship such as whether they are synonyms
or antonyms. In computational linguistics, this is commonly determined
based on the collocational profiles of words. These collocational
profiles are also called <em>word vectors</em> or <em>word
embeddings</em> and approaches which determine semantic similarity based
on collocational profiles or word embeddings are called distributional
approaches (or distributional semantics). The basic assumption of
distributional approaches is that words that occur in the same context
and therefore have similar collocational profiles are also semantically
similar. In fact, various packages, such as <code>qdap</code> or ,
<code>wordnet</code> already provide synonyms for terms (all of which
are based on similar collocational profiles) but we would like to
determine if words are similar without knowing it in advance.</p>
<p>In this example, we want to determine if two degree adverbs (such as
<em>very</em>, <em>really</em>, <em>so</em>, <em>completely</em>,
<em>totally</em>, <em>amazingly</em>, etc.) are synonymous and can
therefore be exchanged without changing the meaning of the sentence (or,
at least, not changing it dramatically). This is relevant in
lexicography as such terms can then be linked to each other and inform
readers that these words are interchangeable.</p>
<p>As a first step, we load the data which contains three columns:</p>
<ul>
<li><p>one column holding the degree adverbs which is called
<em>pint</em></p></li>
<li><p>one column called <em>adjs</em> holding the adjectives that the
degree adverbs have modified</p></li>
<li><p>one column called <em>remove</em> which contains the word
<em>keep</em> and which we will remove as it is not relevant for this
tutorial</p></li>
</ul>
<p>When loading the data, we</p>
<ul>
<li><p>remove the <em>remove</em> column</p></li>
<li><p>rename the <em>pint</em> column as
<em>degree_adverb</em></p></li>
<li><p>rename the <em>adjs</em> column as <em>adjectives</em></p></li>
<li><p>filter out all instances where the degree adverb column has the
value <code>0</code> (which means that the adjective was not
modified)</p></li>
<li><p>remove instances where <em>well</em> functions as a degree adverb
(because it behaves rather differently from other degree
adverbs)</p></li>
</ul>
<pre class="r"><code># load data
degree_adverbs &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/dad.rda&quot;, &quot;rb&quot;)) %&gt;%
  dplyr::select(-remove) %&gt;%
  dplyr::rename(degree_adverb = pint,
                adjective = adjs) %&gt;%
  dplyr::filter(degree_adverb != &quot;0&quot;,
                degree_adverb != &quot;well&quot;)
# inspect
head(degree_adverbs, 10)</code></pre>
<pre><code>##    degree_adverb adjective
## 1           real       bad
## 2         really      nice
## 3           very      good
## 4         really     early
## 5         really       bad
## 6         really       bad
## 7             so      long
## 8         really wonderful
## 9         pretty      good
## 10        really      easy</code></pre>
<p>In a next step, we create a matrix from this data frame which maps
how often a given amplifier co-occurred with a given adjective. In text
mining, this format is called a text-document matrix or tdm (which is a
transposed <a
href="https://en.wikipedia.org/wiki/Document-term_matrix">document-term
matrix</a> of dtm).</p>
<pre class="r"><code># tabulate data (create term-document matrix)
tdm &lt;- ftable(degree_adverbs$adjective, degree_adverbs$degree_adverb)
# extract amplifiers and adjectives 
amplifiers &lt;- as.vector(unlist(attr(tdm, &quot;col.vars&quot;)[1]))
adjectives &lt;- as.vector(unlist(attr(tdm, &quot;row.vars&quot;)[1]))
# attach row and column names to tdm
rownames(tdm) &lt;- adjectives
colnames(tdm) &lt;- amplifiers
# inspect data
tdm[1:5, 1:5]</code></pre>
<pre><code>##           completely extremely pretty real really
## able               0         1      0    0      0
## actual             0         0      0    1      0
## amazing            0         0      0    0      4
## available          0         0      0    0      1
## bad                0         0      1    2      3</code></pre>
<p>In a next step, we extract the expected values of the co-occurrences
if the amplifiers were distributed homogeneously and calculate the
<em>Pointwise Mutual Information</em> (PMI) score and use that to then
calculate the <em>Positive Pointwise Mutual Information</em> (PPMI)
scores. According to <span class="citation">Levshina (<a
href="#ref-levshina2015linguistics"
role="doc-biblioref">2015</a>)</span> 327 - referring to <span
class="citation">Bullinaria and Levy (<a
href="#ref-bullinaria2007extracting"
role="doc-biblioref">2007</a>)</span> - PPMI perform better than PMI as
negative values are replaced with zeros. In a next step, we calculate
the cosine similarity which will for the bases for the subsequent
clustering.</p>
<pre class="r"><code># compute expected values
tdm.exp &lt;- chisq.test(tdm)$expected
# calculate PMI and PPMI
PMI &lt;- log2(tdm/tdm.exp)
PPMI &lt;- ifelse(PMI &lt; 0, 0, PMI)
# calculate cosine similarity
cosinesimilarity &lt;- cosine(PPMI)
# inspect cosine values
cosinesimilarity[1:5, 1:5]</code></pre>
<pre><code>##            completely   extremely      pretty       real      really
## completely 1.00000000 0.204188725 0.000000000 0.05304354 0.126668434
## extremely  0.20418873 1.000000000 0.007319316 0.00000000 0.004235346
## pretty     0.00000000 0.007319316 1.000000000 0.09441299 0.062323271
## real       0.05304354 0.000000000 0.094412995 1.00000000 0.131957473
## really     0.12666843 0.004235346 0.062323271 0.13195747 1.000000000</code></pre>
<p>As we have now obtained a similarity measure, we can go ahead and
perform a cluster analysis on these similarity values. However, as we
have to extract the maximum values in the similarity matrix that is not
1 as we will use this to create a distance matrix. While we could also
have simply subtracted the cosine similarity values from 1 to convert
the similarity matrix into a distance matrix, we follow the procedure
proposed by <span class="citation">Levshina (<a
href="#ref-levshina2015linguistics"
role="doc-biblioref">2015</a>)</span>.</p>
<pre class="r"><code># find max value that is not 1
cosinesimilarity.test &lt;- apply(cosinesimilarity, 1, function(x){
  x &lt;- ifelse(x == 1, 0, x) } )
maxval &lt;- max(cosinesimilarity.test)
# create distance matrix
amplifier.dist &lt;- 1 - (cosinesimilarity/maxval)
clustd &lt;- as.dist(amplifier.dist)</code></pre>
<p>In a next step, we visualize the results of the semantic vector space
model as a dendrogram.</p>
<pre class="r"><code># create cluster object
cd &lt;- hclust(clustd, method=&quot;ward.D&quot;)    
# plot cluster object
plot(cd, main = &quot;&quot;, sub = &quot;&quot;, yaxt = &quot;n&quot;, ylab = &quot;&quot;, xlab = &quot;&quot;, cex = .8)</code></pre>
<p><img src="lex_files/figure-html/vsm8-1.png" width="672" /></p>
<p>The clustering solution shows that, as expected, <em>completely</em>,
<em>extremely</em>, and <em>totally</em> - while similar to each other
and thus interchangeable with each other - form a separate cluster from
all other amplifiers. In addition, <em>real</em> and <em>really</em>
form a cluster together. The clustering of <em>very</em>,
<em>pretty</em>, <em>so</em>, <em>really</em>, and <em>real</em> suggest
that these amplifiers are more or less interchangeable with each other
but not with <em>totally</em>, <em>completely</em>, and
<em>extremely</em>.</p>
<p>To extract synonyms automatically, we can use the cosine similarity
matrix that a´we generated before. This is what we need to do:</p>
<ul>
<li>generate a column called word</li>
<li>replace the perfect similarity values of the diagonal with 0</li>
<li>look up the lowest value, i.e. the word that has the lowest distance
to a given word</li>
<li>create a vector which holds those words (the synonym
candidates).</li>
</ul>
<pre class="r"><code>syntb &lt;- cosinesimilarity %&gt;%
  as.data.frame() %&gt;%
  dplyr::mutate(word = colnames(cosinesimilarity)) %&gt;%
  dplyr::mutate_each(funs(replace(., . == 1, 0))) %&gt;%
  dplyr::mutate(synonym = colnames(.)[apply(.,1,which.max)]) %&gt;%
  dplyr::select(word, synonym)
syntb</code></pre>
<pre><code>##                  word    synonym
## completely completely  extremely
## extremely   extremely completely
## pretty         pretty       real
## real             real     really
## really         really       real
## so                 so       real
## totally       totally completely
## very             very         so</code></pre>
<hr />
<div class="warning"
style="padding:0.1em; background-color:#51247a; color:#f2f2f2">
<span>
<p style="margin-top:1em; text-align:center">
<b>NOTE</b><br><br>Remember that this is only a tutorial! A proper study
would have to take the syntactic context into account because, while we
can say <em>This really great tutorial helped me a lot</em>. we probably
would not say <em>This so great tutorial helped me a lot</em>. This is
because so syntactically more restricted and is strongly disfavored in
attributive contexts. Therefore, the syntactic context would have to be
considered in a more thorough study.
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<div class="question">
<p>`</p>
</div>
<p>`</p>
<hr />
<p>There are many more useful methods for identifying semantic
similarity. A very useful method (which we have implemented here but
only superficially is Semantic Vector Space Modeling. If you want to
know more about this, this <a
href="https://gederajeg.github.io/vector_space_model_indonesian/">tutorial
by Gede Primahadi Wijaya Rajeg, Karlina Denistia, and Simon Musgrave</a>
<span class="citation">(<a href="#ref-rajeg2020semvec"
role="doc-biblioref">Rajeg, Denistia, and Musgrave 2019</a>)</span> is
highly recommended and will give a better understanding of SVM but this
should suffice to get you started.</p>
</div>
<div id="creating-bilingual-dictionaries" class="section level1"
number="3">
<h1><span class="header-section-number">3</span> Creating bilingual
dictionaries</h1>
<p>Dictionaries commonly contain information about elements. Bilingual
or translation dictionaries represent a sub-category of dictionaries
that provide a specific type of information about a given word: the
translation of that word in another language. In principle, generating
translation dictionaries is relatively easy and straight forward.
However, not only is the devil hidden in the details but the generation
of data-driven translation dictionaries also require a substantial data
set consisting of sentences and their translation. This is often quite
tricky as well aligned translations are unfortunately, and unexpectedly,
rather hard to come by.</p>
<p>Despite these issues, if you have access to clean and well aligned,
parallel multilingual data, then you simply need to check which
correlation between the word in language A and language B is the highest
and you have a likely candidate for its translation. The same procedure
can be extended to generate multilingual dictionaries. Problems arise
due to grammatical differences between languages, idiomatic expressions,
homonymy and polysemy as well as due to word class issues. The latter,
word class issues, can be solved by part-of-speech tagging and then only
considering words that belong to the same (or realistically similar)
parts-of speech. The other issues can also be solved but require
substantial amounts of (annotated) data.</p>
<p>To explore how to generate a multilingual lexicon, we load a sample
of English sentences and their German translations.</p>
<pre class="r"><code># load translations
translations &lt;- readLines(&quot;https://slcladal.github.io/data/translation.txt&quot;,
                          encoding = &quot;UTF-8&quot;, skipNul = T)</code></pre>
<template id="b0e2531c-f42a-40a3-90d7-c8fcafc531bf"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-f4a47e56{table-layout:auto;width:50%;}.cl-f49b0614{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f49b061e{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f49b2ab8{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f49b5baa{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f49b5bb4{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f49b5bbe{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f49b5bbf{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-f4a47e56'>
<caption class="Table Caption">
<p>First 15 rows of the translations data.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bbf"><p class="cl-f49b2ab8"><span class="cl-f49b0614">.</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Guten Tag! — Good day! </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Guten Morgen! — Good morning!</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Guten Abend! — Good evening!</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Hallo! — Hello!</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Wo kommst du her? — Where are you from?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Woher kommen Sie? — Where are you from?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Ich bin aus Hamburg.  — I am from Hamburg.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Ich komme aus Hamburg. — I come from Hamburg.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Ich bin Deutscher. — I am German.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Schön Sie zu treffen. — Pleasure to meet you!</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Wie lange lebst du schon in Brisbane? — How long have you been living in Brisbane?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Leben Sie schon lange hier? — Have you been living here for long?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5baa"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Welcher Bus geht nach Brisbane? — Which bus goes to Brisbane?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bb4"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Von welchem Gleis aus fährt der Zug? — Which platform is the train leaving from?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f49b5bbe"><p class="cl-f49b2ab8"><span class="cl-f49b061e">Ist dies der Bus nach Toowong? — Is this the bus going to Toowong?</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="c320cee7-142e-4145-bc6b-c91a8b93711e"></div>
<script>
var dest = document.getElementById("c320cee7-142e-4145-bc6b-c91a8b93711e");
var template = document.getElementById("b0e2531c-f42a-40a3-90d7-c8fcafc531bf");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>In a next step, we generate separate tables which hold the German and
English sentences. However, the sentences and their translations are
identified by an identification number (<em>id</em>) so that we keep the
information about which sentence is linked to which translation.</p>
<pre class="r"><code># german sentences
german &lt;- str_remove_all(translations, &quot; — .*&quot;) %&gt;%
  str_remove_all(., &quot;[:punct:]&quot;)
# english sentences
english &lt;- str_remove_all(translations, &quot;.* — &quot;) %&gt;%
  str_remove_all(., &quot;[:punct:]&quot;)
# sentence id
sentence &lt;- 1:length(german)
# combine into table
germantb &lt;- data.frame(sentence, german)
# sentence id
sentence &lt;- 1:length(english)
# combine into table
englishtb &lt;- data.frame(sentence, english)</code></pre>
<template id="f92cffea-7649-4070-a10c-616fbdc62334"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-f4d7478c{table-layout:auto;width:50%;}.cl-f4ce99e8{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f4ce99f2{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f4ceaece{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f4ceaecf{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f4cee47a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee47b{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee484{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee485{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee48e{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee48f{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee490{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4cee498{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-f4d7478c'>
<caption class="Table Caption">
<p>First 15 rows of the germantb data.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-f4cee498"><p class="cl-f4ceaece"><span class="cl-f4ce99e8">sentence</span></p></td><td class="cl-f4cee490"><p class="cl-f4ceaecf"><span class="cl-f4ce99e8">german</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">1</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Guten Tag</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">2</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Guten Morgen</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">3</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Guten Abend</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">4</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Hallo</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">5</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Wo kommst du her</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">6</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Woher kommen Sie</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">7</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Ich bin aus Hamburg </span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">8</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Ich komme aus Hamburg</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">9</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Ich bin Deutscher</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">10</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Schön Sie zu treffen</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">11</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Wie lange lebst du schon in Brisbane</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">12</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Leben Sie schon lange hier</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee47b"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">13</span></p></td><td class="cl-f4cee47a"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Welcher Bus geht nach Brisbane</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee485"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">14</span></p></td><td class="cl-f4cee484"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Von welchem Gleis aus fährt der Zug</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4cee48f"><p class="cl-f4ceaece"><span class="cl-f4ce99f2">15</span></p></td><td class="cl-f4cee48e"><p class="cl-f4ceaecf"><span class="cl-f4ce99f2">Ist dies der Bus nach Toowong</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="6b689560-d31b-4c3e-bf0b-d3f535a6c3e5"></div>
<script>
var dest = document.getElementById("6b689560-d31b-4c3e-bf0b-d3f535a6c3e5");
var template = document.getElementById("f92cffea-7649-4070-a10c-616fbdc62334");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>We now unnest the tokens (split the sentences into words) and
subsequently add the translations which we again unnest. The resulting
table consists of two columns holding German and English words. The
relevant point here is that each German word is linked with each English
word that occurs in the translated sentence.</p>
<pre class="r"><code>library(plyr)
# tokenize by sentence: german
transtb &lt;- germantb %&gt;%
  unnest_tokens(word, german) %&gt;%
  # add english data
  plyr::join(., englishtb, by = &quot;sentence&quot;) %&gt;%
  unnest_tokens(trans, english) %&gt;%
  dplyr::rename(german = word,
                english = trans) %&gt;%
  dplyr::select(german, english) %&gt;%
  dplyr::mutate(german = factor(german),
                english = factor(english))</code></pre>
<template id="ec5863ed-0571-4a7d-9ad6-8e70dd789be4"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-f4f93734{table-layout:auto;width:25%;}.cl-f4eff3d6{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f4eff3e0{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f4f00876{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f4f04728{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f04732{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f0473c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f0473d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f0473e{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f04746{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f04747{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4f04748{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-f4f93734'>
<caption class="Table Caption">
<p>First 15 rows of the transtb data.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-f4f04748"><p class="cl-f4f00876"><span class="cl-f4eff3d6">german</span></p></td><td class="cl-f4f04747"><p class="cl-f4f00876"><span class="cl-f4eff3d6">english</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">day</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">tag</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">tag</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">day</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">morning</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">morgen</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">morgen</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">morning</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">guten</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">evening</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">abend</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">good</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">abend</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">evening</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04732"><p class="cl-f4f00876"><span class="cl-f4eff3e0">hallo</span></p></td><td class="cl-f4f04728"><p class="cl-f4f00876"><span class="cl-f4eff3e0">hello</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f0473d"><p class="cl-f4f00876"><span class="cl-f4eff3e0">wo</span></p></td><td class="cl-f4f0473c"><p class="cl-f4f00876"><span class="cl-f4eff3e0">where</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4f04746"><p class="cl-f4f00876"><span class="cl-f4eff3e0">wo</span></p></td><td class="cl-f4f0473e"><p class="cl-f4f00876"><span class="cl-f4eff3e0">are</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="f452e26a-7cf1-4746-92cb-59df5728df2f"></div>
<script>
var dest = document.getElementById("f452e26a-7cf1-4746-92cb-59df5728df2f");
var template = document.getElementById("ec5863ed-0571-4a7d-9ad6-8e70dd789be4");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>Based on this table, we can now generate a term-document matrix which
shows how frequently each word co-occurred in the translation of any of
the sentences. For instance, the German word <em>alles</em> occurred one
time in a translation of a sentence which contained the English word
<em>all</em>.</p>
<pre class="r"><code># tabulate data (create term-document matrix)
tdm &lt;- ftable(transtb$german, transtb$english)
# extract amplifiers and adjectives 
german &lt;- as.vector(unlist(attr(tdm, &quot;col.vars&quot;)[1]))
english &lt;- as.vector(unlist(attr(tdm, &quot;row.vars&quot;)[1]))
# attach row and column names to tdm
rownames(tdm) &lt;- english
colnames(tdm) &lt;- german
# inspect data
tdm[1:10, 1:10]</code></pre>
<pre><code>##          a accident all am ambulance an and any anything are
## ab       0        0   0  0         0  0   0   0        0   0
## abend    0        0   0  0         0  0   0   0        0   0
## allem    0        0   0  0         0  0   0   0        0   0
## alles    0        0   1  0         0  0   0   0        0   0
## am       0        0   0  0         0  0   0   0        0   0
## an       0        0   0  0         0  0   0   0        0   0
## anderen  1        0   0  0         0  0   0   0        0   0
## apotheke 1        0   0  1         0  0   0   0        0   0
## arzt     1        0   0  0         0  0   0   0        0   0
## auch     3        0   0  0         0  0   0   0        1   0</code></pre>
<p>Now, we reformat this co-occurrence matrix so that we have the
frequency information that is necessary for setting up 2x2 contingency
tables which we will use to calculate the co-occurrence strength between
each word and its potential translation.</p>
<pre class="r"><code>coocdf &lt;- as.data.frame(as.matrix(tdm))
cooctb &lt;- coocdf %&gt;%
  dplyr::mutate(German = rownames(coocdf)) %&gt;%
  tidyr::gather(English, TermCoocFreq,
                colnames(coocdf)[1]:colnames(coocdf)[ncol(coocdf)]) %&gt;%
  dplyr::mutate(German = factor(German),
                English = factor(English)) %&gt;%
  dplyr::mutate(AllFreq = sum(TermCoocFreq)) %&gt;%
  dplyr::group_by(German) %&gt;%
  dplyr::mutate(TermFreq = sum(TermCoocFreq)) %&gt;%
  dplyr::ungroup(German) %&gt;%
  dplyr::group_by(English) %&gt;%
  dplyr::mutate(CoocFreq = sum(TermCoocFreq)) %&gt;%
  dplyr::arrange(German) %&gt;%
  dplyr::mutate(a = TermCoocFreq,
                b = TermFreq - a,
                c = CoocFreq - a, 
                d = AllFreq - (a + b + c)) %&gt;%
  dplyr::mutate(NRows = nrow(coocdf))%&gt;%
  dplyr::filter(TermCoocFreq &gt; 0)</code></pre>
<template id="28fcd39b-f64e-4301-b38d-fe46f7c51db7"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-f5354cb0{table-layout:auto;width:75%;}.cl-f52acdd0{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f52acde4{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f52ae284{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f52ae28e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f52b3fb8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fc2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fc3{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fc4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fcc{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fcd{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fce{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fd6{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fd7{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fe0{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fe1{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fe2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fe3{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3fea{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3feb{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f52b3ff4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-f5354cb0'>
<caption class="Table Caption">
<p>First 15 rows of the cooctb data.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-f52b3feb"><p class="cl-f52ae284"><span class="cl-f52acdd0">German</span></p></td><td class="cl-f52b3ff4"><p class="cl-f52ae284"><span class="cl-f52acdd0">English</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">TermCoocFreq</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">AllFreq</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">TermFreq</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">CoocFreq</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">a</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">b</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">c</span></p></td><td class="cl-f52b3fe3"><p class="cl-f52ae28e"><span class="cl-f52acdd0">d</span></p></td><td class="cl-f52b3fea"><p class="cl-f52ae28e"><span class="cl-f52acdd0">NRows</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">ab</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">departing</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,495</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">ab</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">is</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">116</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">115</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,384</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">ab</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">the</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">125</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">124</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,375</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">ab</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">train</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">16</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">15</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,484</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">ab</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">when</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">27</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">26</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,473</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">abend</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">evening</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">2</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">2</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,501</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">abend</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">good</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">2</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">16</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">15</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,487</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">allem</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">döner</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">10</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">9</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,490</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">allem</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">everything</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,495</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">allem</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">one</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">30</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">29</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,470</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">allem</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">please</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">111</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">110</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,389</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">allem</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">with</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">22</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">21</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,478</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fb8"><p class="cl-f52ae284"><span class="cl-f52acde4">alles</span></p></td><td class="cl-f52b3fc3"><p class="cl-f52ae284"><span class="cl-f52acde4">all</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">6</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">4</span></p></td><td class="cl-f52b3fc2"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,494</span></p></td><td class="cl-f52b3fc4"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fd6"><p class="cl-f52ae284"><span class="cl-f52acde4">alles</span></p></td><td class="cl-f52b3fce"><p class="cl-f52ae284"><span class="cl-f52acde4">for</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">6</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">93</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">92</span></p></td><td class="cl-f52b3fcc"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,406</span></p></td><td class="cl-f52b3fcd"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f52b3fe2"><p class="cl-f52ae284"><span class="cl-f52acde4">alles</span></p></td><td class="cl-f52b3fd7"><p class="cl-f52ae284"><span class="cl-f52acde4">no</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,504</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">6</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">7</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">1</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">5</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">6</span></p></td><td class="cl-f52b3fe0"><p class="cl-f52ae28e"><span class="cl-f52acde4">3,492</span></p></td><td class="cl-f52b3fe1"><p class="cl-f52ae28e"><span class="cl-f52acde4">215</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="d6d197c8-fd8d-4802-9104-6e5303210b22"></div>
<script>
var dest = document.getElementById("d6d197c8-fd8d-4802-9104-6e5303210b22");
var template = document.getElementById("28fcd39b-f64e-4301-b38d-fe46f7c51db7");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>In a final step, we extract those potential translations that
correlate most strongly with each given term. The results then form a
list of words and their most likely translation.</p>
<pre class="r"><code>translationtb &lt;- cooctb  %&gt;%
  dplyr::rowwise() %&gt;%
  dplyr::mutate(p = round(as.vector(unlist(fisher.test(matrix(c(a, b, c, d), ncol = 2, byrow = T))[1])), 5), 
                x2 = round(as.vector(unlist(chisq.test(matrix(c(a, b, c, d), ncol = 2, byrow = T))[1])), 3)) %&gt;%
  dplyr::mutate(phi = round(sqrt((x2/(a + b + c + d))), 3),
                expected = as.vector(unlist(chisq.test(matrix(c(a, b, c, d), ncol = 2, byrow = T))$expected[1]))) %&gt;%
  dplyr::filter(TermCoocFreq &gt; expected) %&gt;%
  dplyr::arrange(-phi) %&gt;%
  dplyr::select(-AllFreq, -a, -b, -c, -d, -NRows, -expected)</code></pre>
<template id="3e6dbffb-782b-488f-9b62-9c64dc945edf"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-1ac0714e{table-layout:auto;width:75%;}.cl-1ab6a600{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1ab6a60a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1ab6badc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1ab6bae6{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1ab70e4c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e56{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e57{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e60{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e61{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e62{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e6a{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e6b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e74{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e75{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e7e{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e7f{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e80{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e88{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e89{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1ab70e8a{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-1ac0714e'>
<caption class="Table Caption">
<p>First 15 rows of the translationtb data.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e8a"><p class="cl-1ab6badc"><span class="cl-1ab6a600">German</span></p></td><td class="cl-1ab70e88"><p class="cl-1ab6badc"><span class="cl-1ab6a600">English</span></p></td><td class="cl-1ab70e80"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">TermCoocFreq</span></p></td><td class="cl-1ab70e80"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">TermFreq</span></p></td><td class="cl-1ab70e80"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">CoocFreq</span></p></td><td class="cl-1ab70e80"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">p</span></p></td><td class="cl-1ab70e80"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">x2</span></p></td><td class="cl-1ab70e89"><p class="cl-1ab6bae6"><span class="cl-1ab6a600">phi</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">hallo</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">hello</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00029</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">875.500</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.500</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">abend</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">evening</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00114</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">218.250</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.250</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">ja</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">yes</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00114</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">218.250</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.250</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">morgen</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">morning</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00114</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">218.250</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.250</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">tag</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">day</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00114</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">218.250</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.250</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">guten</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">good</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">4</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">13</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">16</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00000</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">201.086</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.240</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">brauche</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">need</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">5</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">20</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">27</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00000</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">124.215</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.188</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">nein</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">no</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">9</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">7</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00012</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">122.721</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.187</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">bier</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">beer</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">8</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">8</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00013</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">120.757</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.186</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">hamburg</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">hamburg</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">2</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">8</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">8</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00013</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">120.757</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.186</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">braucht</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">he</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00257</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">96.501</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.166</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">braucht</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">medication</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00257</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">96.501</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.166</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e4c"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">braucht</span></p></td><td class="cl-1ab70e60"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">needs</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00257</span></p></td><td class="cl-1ab70e56"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">96.501</span></p></td><td class="cl-1ab70e57"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.166</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e6b"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">deutscher</span></p></td><td class="cl-1ab70e62"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">german</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00257</span></p></td><td class="cl-1ab70e61"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">96.501</span></p></td><td class="cl-1ab70e6a"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.166</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1ab70e7f"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">er</span></p></td><td class="cl-1ab70e75"><p class="cl-1ab6badc"><span class="cl-1ab6a60a">he</span></p></td><td class="cl-1ab70e74"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">1</span></p></td><td class="cl-1ab70e74"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e74"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">3</span></p></td><td class="cl-1ab70e74"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.00257</span></p></td><td class="cl-1ab70e74"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">96.501</span></p></td><td class="cl-1ab70e7e"><p class="cl-1ab6bae6"><span class="cl-1ab6a60a">0.166</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="12faddca-37f7-4d22-a543-c32e25c157df"></div>
<script>
var dest = document.getElementById("12faddca-37f7-4d22-a543-c32e25c157df");
var template = document.getElementById("3e6dbffb-782b-488f-9b62-9c64dc945edf");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>The results show that even using the very limited data base can
produce some very reasonable results. In fact, based on the data that we
used here, the first translations appear to be very sensible, but the
mismatches also show that more data is required to disambiguate
potential translations.</p>
<p>While this method still requires manual correction, it is a very
handy and useful tool for generating custom bilingual dictionaries that
can be extended to any set of languages as long as these languages can
be represented as distinct words and as long as parallel data is
available.</p>
</div>
<div id="going-further-crowd-sourced-dictionaries-with-r-and-git"
class="section level1" number="4">
<h1><span class="header-section-number">4</span> Going further:
crowd-sourced dictionaries with R and Git</h1>
<p>While it would go beyond the scope of this tutorial, it should be
noted that the approach for creating dictionaries can be applied to
crowed-sourced dictionaries. To do this, you could, e.g. upload your
dictionary to a Git repository such as <a
href="https://github.com/">GitHub</a> or <a
href="https://about.gitlab.com/">GitLab</a> which would then allow
everybody with an account on either of these platforms to add content to
the dictionary.</p>
<p><img src="https://slcladal.github.io/images/git.png" width="50%" style="float:right; padding:15px" /></p>
<p>To add to the dictionary, contributors would simply have to fork the
repository of the dictionary and then merge with the existing, original
dictionary repository. The quality of the data would meanwhile remain
under control of the owner of the original repository he they can decide
on a case-by-case basis which change they would like to accept. In
addition, and because Git is a version control environment, the owner
could also go back to previous versions, if they think they erroneously
accepted a change (merge).</p>
<p>This option is particularly interesting for the approach to creating
dictionaries presented here because R Studio has an integrated and very
easy to use pipeline to Git (see, e.g., <a
href="https://support.rstudio.com/hc/en-us/articles/200532077-Version-Control-with-Git-and-SVN">here</a>
and <a
href="https://happygitwithr.com/rstudio-git-github.html">here</a>)</p>
<p>We have reached the end of this tutorial and you now know how to
create and modify networks in R and how you can highlight aspects of
your data.</p>
<p><br><br></p>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1 class="unnumbered">Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2022. <em>Lexicography with R</em>. Brisbane:
The University of Queensland. url: <a
href="https://slcladal.github.io/lex.html"
class="uri">https://slcladal.github.io/lex.html</a> (Version
2022.05.21).</p>
<pre><code>@manual{schweinberger2022lex,
  author = {Schweinberger, Martin},
  title = {Lexicography with R},
  note = {https://slcladal.github.io/lex.html},
  year = {2022},
  organization = &quot;The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2022.05.21}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.2.0 (2022-04-22 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19043)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   
## [3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices datasets  utils     methods   base     
## 
## other attached packages:
## [1] plyr_1.8.7      flextable_0.7.0 cluster_2.1.3   coop_0.6-3     
## [5] tidytext_0.3.3  udpipe_0.8.9    stringr_1.4.0   dplyr_1.0.9    
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.8.3      here_1.0.1        lattice_0.20-45   tidyr_1.2.0      
##  [5] assertthat_0.2.1  rprojroot_2.0.3   digest_0.6.29     utf8_1.2.2       
##  [9] R6_2.5.1          evaluate_0.15     highr_0.9         pillar_1.7.0     
## [13] gdtools_0.2.4     rlang_1.0.2       uuid_1.1-0        rstudioapi_0.13  
## [17] data.table_1.14.2 textdata_0.4.2    jquerylib_0.1.4   Matrix_1.4-1     
## [21] klippy_0.0.0.9500 rmarkdown_2.14    readr_2.1.2       compiler_4.2.0   
## [25] janeaustenr_0.1.5 xfun_0.30         pkgconfig_2.0.3   systemfonts_1.0.4
## [29] base64enc_0.1-3   htmltools_0.5.2   tidyselect_1.1.2  tibble_3.1.7     
## [33] fansi_1.0.3       crayon_1.5.1      tzdb_0.3.0        rappdirs_0.3.3   
## [37] SnowballC_0.7.0   grid_4.2.0        jsonlite_1.8.0    lifecycle_1.0.1  
## [41] DBI_1.1.2         magrittr_2.0.3    tokenizers_0.2.1  zip_2.2.0        
## [45] cli_3.3.0         stringi_1.7.6     renv_0.15.4       fs_1.5.2         
## [49] xml2_1.3.3        bslib_0.3.1       ellipsis_0.3.2    generics_0.1.2   
## [53] vctrs_0.4.1       tools_4.2.0       glue_1.6.2        officer_0.4.2    
## [57] purrr_0.3.4       hms_1.1.1         fastmap_1.1.0     yaml_2.3.5       
## [61] knitr_1.39        sass_0.4.1</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<hr />
<p><a href="#introduction">Back to top</a></p>
<p><a href="https://slcladal.github.io/index.html">Back to HOME</a></p>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-agnes2002webster" class="csl-entry">
Agnes, Michael, Jonathan L Goldman, and Katherine Soltis. 2002.
<em>Webster’s New World Compact Desk Dictionary and Style Guide</em>.
Hungry Minds.
</div>
<div id="ref-amsler1981structure" class="csl-entry">
Amsler, Robert Alfred. 1981. <em>The Structure of the Merriam-Webster
Pocket Dictionary</em>. Austin, TX: he University of Texas at Austin.
</div>
<div id="ref-bullinaria2007extracting" class="csl-entry">
Bullinaria, J. A., and J. P. Levy. 2007. <span>“Extracting Semantic
Representations from Word Co-Occurrence Statistics: A Computational
Study.”</span> <em>Behavior Research Methods</em> 39: 510–26.
</div>
<div id="ref-levshina2015linguistics" class="csl-entry">
Levshina, Natalia. 2015. <em>How to Do Linguistics with r: Data
Exploration and Statistical Analysis</em>. Amsterdam: John Benjamins
Publishing Company.
</div>
<div id="ref-mohammad2013crowdsourcing" class="csl-entry">
Mohammad, Saif M, and Peter D Turney. 2013. <span>“Crowdsourcing a
Word-Emotion Association Lexicon.”</span> <em>Computational
Intelligence</em> 29 (3): 436–65.
</div>
<div id="ref-rajeg2020semvec" class="csl-entry">
Rajeg, Gede Primahadi Wijaya, Karlina Denistia, and Simon Musgrave.
2019. <span>“R Markdown Notebook for Vector Space Model and the Usage
Patterns of Indonesian Denominal Verbs.”</span> <a
href="https://doi.org10.6084/m9.figshare.9970205. https://figshare.com/articles/R\%5FMarkdown\%5FNotebook\%5Ffor\%5Fi\%5FVector\%5Fspace\%5Fmodel\%5Fand\%5Fthe\%5Fusage\%5Fpatterns\%5Fof\%5FIndonesian\%5Fdenominal\%5Fverbs\%5Fi\%5F/9970205">https://doi.org10.6084/m9.figshare.9970205.
https://figshare.com/articles/R\%5FMarkdown\%5FNotebook\%5Ffor\%5Fi\%5FVector\%5Fspace\%5Fmodel\%5Fand\%5Fthe\%5Fusage\%5Fpatterns\%5Fof\%5FIndonesian\%5Fdenominal\%5Fverbs\%5Fi\%5F/9970205</a>.
</div>
<div id="ref-steiner1985dictionaries" class="csl-entry">
Steiner, Roger J. 1985. <span>“Dictionaries. The Art and Craft of
Lexicography.”</span> <em>Dictionaries: Journal of the Dictionary
Society of North America</em> 7 (1): 294–300.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
