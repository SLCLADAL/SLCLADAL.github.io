<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-09-29" />

<title>Questionnaires and Surveys: Analyses with R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    NEWS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="news.html">News &amp; Announcements</a>
    </li>
    <li>
      <a href="conferences.html">Events &amp; Presentations</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="introcomputer.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="reproducibility.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="IntroR_workshop.html">Getting started</a>
    </li>
    <li>
      <a href="stringprocessing.html">String Processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular Expressions</a>
    </li>
    <li>
      <a href="introtables.html">Working with Tables</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="basicgraphs.html">Common Visualization Types</a>
    </li>
    <li>
      <a href="basicgraphs.html">Advanced Visualization Methods</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
    <li>
      <a href="vc.html">Creating Vowel Charts with Praat and R</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES &amp; CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Questionnaires and Surveys: Analyses with R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-09-29</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial offers some advice on what to consider when creating surveys and questionnaires, provides tips on visualizing survey data, and exemplifies how survey and questionnaire data can be analyzed. As this tutorial is introductory, issues relating to what software to use when creating a survey (e.g. SurveyMonkey, Qualtrics, GoogleForms, etc.) or how to program questionnaires or online experiments in Java or R are not discussed. The R Notebook for this tutorial can be downloaded <a href="https://slcladal.github.io/surveys.Rmd">here</a>.</p>
<p><strong>How to use the R Notebook for this tutorial</strong></p>
<p>As all calculations and visualizations in this tutorial rely on R, it is necessary to install R and RStudio. If these programs (or, in the case of R, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>To follow this tutorial interactively (by using the R Notebook), follow the instructions listed below.</p>
<ol style="list-style-type: decimal">
<li>Create a folder somewhere on your computer</li>
<li>Download the <a href="https://slcladal.github.io/surveys.Rmd">R Notebook</a> and save it in the folder you have just created</li>
<li>Open R Studio</li>
<li>Click on “File” in the upper left corner of the R Studio interface</li>
<li>Click on “New Project…”</li>
<li>Select „Existing Directory“</li>
<li>Browse to the folder you have just created and click on “Create New Project”</li>
<li>Now click on “Files” above the lower right panel</li>
<li>Click on the file “surveys.Rmd”</li>
</ol>
<ul>
<li>The Markdown file of this tutorial should now be open in the upper left panel of R Studio. To execute the code blocks used in this session, simply click on the green arrows in the top right corner of the code boxes.</li>
<li>To render a PDF of this tutorial, simply click on “Knit” above the upper left panel in R Studio.</li>
</ul>
</div>
<div id="an-introduction-to-surveys-and-questionnaires" class="section level1">
<h1><span class="header-section-number">2</span> An introduction to surveys and questionnaires</h1>
<p>A survey is a research method for gathering information based on a sample of people. Questionnaires are a research instrument and typically represent a part of a survey, i.e. that part where participants are asked to answer a set of questions. <span class="citation">(Brown <a href="#ref-brown2001surveys" role="doc-biblioref">2001</a>, 6)</span> defines questionnaires as “any written instruments that present respondents with a series of questions or statements to which they are to react either by writing out their answers or selecting among existing answers.”</p>
<p>Questionnaires elicit three types of data:</p>
<ul>
<li>Factual</li>
<li>Behavioral</li>
<li>Attitudinal</li>
</ul>
<p>While factual and behavioral questions are about what the respondent is and does, attitudinal questions tap into what the respondent thinks or feels.</p>
<p>The advantages of surveys are that they * offer a relative cheap, quick, and effective way to collect (targeted) data from a comparatively large set of people; and * that they can be distributed or carried out in various formats (face-to-face, by telephone, by computer or via social media, or by postal service).</p>
<p>Disadvantages of questionnaires are that they are prone to providing unreliable or unnatural data. Data gathered via surveys can be unreliable due to the social desirability bias which is the tendency of respondents to answer questions in a manner that will be viewed favorably by others. Thus, the data that surveys provide may not necessarily be representative of actual natural behavior.</p>
<p>Questionnaires and surveys are widely used in language research and thus one of the most common research designs. In this section, we will discuss what needs to kept in mind when designing questionnaires and surveys, what pieces of software or platforms one can use, options for visualizing questionnaire and survey data, statistical methods that are used to evaluate questionnaire and survey data (reliability), and which statistical methods are used in analyzing the data.</p>
</div>
<div id="what-to-consider-when-creating-surveys-and-questionnaires" class="section level1">
<h1><span class="header-section-number">3</span> What to consider when creating surveys and questionnaires?</h1>
<p>Here are some rules to consider during the creation of questionnaires and before any survey is distributed.</p>
<ul>
<li><p>Surveys should not be longer than they have to be while they have to be long enough to collect all the data that are needed. It is crucial that a questionnaire collects all necessary data (including socio-demographic details).</p></li>
<li><p>The language should be simple and easy to understand - this means that jargon should be avoided. Also, leading questions and value judgement on the side of the creators of questionnaires should be avoided to prevent social desirability bias.</p></li>
<li><p>Before distributing a questionnaire, it should be piloted. Piloting is essential to check if respondents understand the questions as intended, and to check how long it takes to answer the questions. Also, the people who are involved in the piloting should be allowed to provide feedback to avoid errors.</p></li>
<li><p>When questions go beyond simply collecting socio-demographic details and if the data contains test and filler items, the order of questions (within blocks) should be quasi-randomized. Quasi-randomization means that test items are not asked in direct succession and that they do not appear as first or last items. Quasi-randomization helps to avoid fatigue effects or results that are caused by the ordering of questions. However, the questions should still follow an internally consistent logic so that related questions appear in the same block. Also, more specific questions should be asked after more general questions.</p></li>
<li><p>Questions must be unambiguous and they cannot ask multiple aspects at once. Take, for instance, the following question “Do you consider UQ to be a good university with respect to teaching and research?” If the respondent answers positively, then no issues arise but if the answer is negative, i.e. “No”, then we do not know if the respondent thinks that UQ is not a good university with respect to teaching OR with respect to research OR both! In such cases, questions should be split:</p>
<ul>
<li><p>Do you consider UQ to be a good university with respect to teaching?</p></li>
<li><p>Do you consider UQ to be a good university with respect to research?"</p></li>
</ul></li>
<li><p>To check if respondents are concentrated, read the questions carefully, and answering truthfully, it is useful to include reverse questions, i.e. questions that have the opposite polarity. Reverse questions allow to check if respondents only answers “very satisfied” or “completely agree” without respect to the content of the question. Giving the same answer to questions which have opposite propositions would indicate that respondents do not read questions carefully or do not answer truthfully.</p></li>
<li><p>If questions are not open or unstructured, i.e. if different options to answer to a question are provided, it is crucial that the options are fine-grained enough so that the data that is collected allows us to answer the research question that we want to investigate. In this context, the scaling of answer options is important. Scales reflect different types of answering options and they come in three basic forms: nominal and categorical, ordinal, or numeric.</p>
<ul>
<li><p><em>Nominal and categorical scales</em>: Nominal and categorical scales only list the membership of a particular class. Nominal scales offer exactly two options (yes/no or on/off), while categorical scales offer several options (e.g. the state in which someone was born).</p></li>
<li><p><em>Ordinal scales</em>: With <em>ordinal scales</em> it is possible to rank the values, but the distances between the ranks can not be exactly quantified. An example of an ordinal scales is the ranking in a 100-meter run. The 2nd in a 100-meter run did not go twice as fast as the 4th. It is often the case that ordinal variables consist of integer, positive numbers (1, 2, 3, 4, etc.). In the context of surveys, ordinal scales are the most important as all Likert scales (after the psychologist Rensis Likert) are ordinal scales. The levels of the typical five-level Likert item could be: <em>Strongly disagree (1)</em>, <em>Disagree (2) </em>, <em>Neither agree nor disagree (3)</em>, <em>Agree (4)</em>, and <em>Strongly agree (5)</em>. As such, the Likert scale is a bipolar scale that can be balanced, if there is an uneven number of options with the center option being neutral, or unbalanced, if there are an even number of options which forces respondents to express a preferences for wither of the two poles (this is called a “forced choice” method.</p></li>
<li><p><em>(True) Numeric scales</em>: There are two basic types of numeric scales: <em>interval-scales</em> and <em>ratio-scales</em>. For <em>interval scales</em>, the differences between levels are significant, but not the relationship between levels. For instance, 20 degree Celsius is not twice as hot as 10 degree Celsius. For <em>ratio-scales</em> both the differences and the relationships between the levels are significant (e.g. the times in a 100-meter dash: 10 is exactly twice as high as 5 and half as much as 20).</p></li>
</ul></li>
</ul>
<p>Of these scales, numeric is the most informative and questionnaires should always aim to extract the most detailed information without becoming to long.</p>
</div>
<div id="visualizing-survey-data" class="section level1">
<h1><span class="header-section-number">4</span> Visualizing survey data</h1>
<p>Just as the data that is provided by surveys and questionnaires can take various forms, there are numerous ways to display survey data. In the following, we will have a look at some of the most common or useful ways in which survey and questionnaire data can be visualized. However, before we can begin, we need to set up our R session as shown below.</p>
<p><strong>Preparation and session set up</strong></p>
<p>To run the scripts shown below without errors, certain <em>packages</em> need to be installed from an R <em>library</em>. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;knitr&quot;, &quot;lattice&quot;, &quot;tidyverse&quot;, &quot;likert&quot;, 
                   &quot;MASS&quot;, &quot;psych&quot;, &quot;viridis&quot;, &quot;ggplot2&quot;, 
                   &quot;userfriendlyscience&quot;))</code></pre>
<p>Once you have installed R, R-Studio, and have also initiated the session by executing the code shown above, you are good to go.</p>
<div id="line-graphs-for-likert-scaled-data" class="section level2">
<h2><span class="header-section-number">4.1</span> Line graphs for Likert-scaled data</h2>
<p>A special case of line graphs is used when dealing with Likert-scaled variables (we will talk about Likert scales in more detail below). In such cases, the line graph displays the density of cumulative frequencies of responses. The difference between the cumulative frequencies of responses displays differences in preferences. We will only focus on how to create such graphs using the “ggplot” environment here as it has an in-build function (“ecdf”) which is designed to handle such data.</p>
<p>In a first step, we create a data set which consists of a Likert-scaled variable. The fictitious data created here consists of rating of students from three courses about how satisfied they were with their language-learning course. The response to the Likert item is numeric so that “strongly disagree/very dissatisfied” would get the lowest (1) and “strongly agree/very satisfied” the highest numeric value (5).</p>
<pre class="r"><code># activate packages
library(knitr)
library(lattice)             
library(tidyverse)
library(likert) 
library(MASS)
library(psych)
library(viridis)
# load data
plotdata &lt;- read.delim(&quot;https://slcladal.github.io/data/lmmdata.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
likertdata1 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata1.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
likertdata2 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata2.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
# inspect data
kable(head(likertdata1), caption = &quot;First 6 rows of likertdata1&quot;)</code></pre>
<table>
<caption>First 6 rows of likertdata1</caption>
<thead>
<tr class="header">
<th align="left">Course</th>
<th align="right">Satisfaction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Now that we have data resembling a Likert-scaled item from a questionnaire, we will display the data in a cumulative line graph.</p>
<pre class="r"><code># create cumulative density plot
ggplot(likertdata1,
       aes(x = Satisfaction, color = Course)) + 
  geom_step(aes(y = ..y..), stat = &quot;ecdf&quot;) +
  labs(y = &quot;Cumulative Density&quot;) + 
  scale_x_discrete(limits = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;), 
                   breaks = c(1,2,3,4,5),
                   labels=c(&quot;very dissatisfied&quot;, &quot;dissatisfied&quot;, 
                            &quot;neutral&quot;, &quot;satisfied&quot;, &quot;very satisfied&quot;)) + 
  scale_colour_manual(values = c(&quot;goldenrod2&quot;, &quot;indianred4&quot;, &quot;blue&quot;)) + 
  theme_bw() </code></pre>
<p><img src="surveys_files/figure-html/line_03-1.png" width="672" /></p>
<p>The satisfaction of the German course was the lowest as the red line shows the highest density (frequency of responses) of “very dissatisfied” and “dissatisfied” ratings. The students in our fictitious data set were most satisfied with the Chinese course as the blue line is the lowest for “very dissatisfied” and “dissatisfied” ratings while the difference between the courses shrinks for “satisfied” and “very satisfied”. The Japanese language course is in-between the German and the Chinese course.</p>
</div>
<div id="pie-charts" class="section level2">
<h2><span class="header-section-number">4.2</span> Pie charts</h2>
<p>Most commonly, the data for visualization comes from tables of absolute frequencies associated with a categorical or nominal variable. The default way to visualize such frequency tables are pie charts and bar plots. In a first step, we modify the data to get counts and percentages.</p>
<pre class="r"><code># create bar plot data
bardata &lt;- likertdata1 %&gt;%
  group_by(Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  # replace numeric values with their values in words
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  # order the levels of Satisfaction manually so that the order is not alphabetical
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;)))
# inspect data
kable(head(bardata), caption = &quot;First 6 rows of bardata&quot;)</code></pre>
<table>
<caption>First 6 rows of bardata</caption>
<thead>
<tr class="header">
<th align="left">Satisfaction</th>
<th align="right">Frequency</th>
<th align="right">Percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">very dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
</tr>
<tr class="even">
<td align="left">dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
</tr>
<tr class="odd">
<td align="left">neutral</td>
<td align="right">60</td>
<td align="right">20.0</td>
</tr>
<tr class="even">
<td align="left">satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
</tr>
<tr class="odd">
<td align="left">very satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
</tr>
</tbody>
</table>
<p>Before creating bar plots, we will briefly turn to pie charts because pie charts are very common despite suffering from certain shortcomings. Consider the following example which highlights some of the issues that arise when using pie charts.</p>
<pre class="r"><code># create pie chart
ggplot(bardata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void()</code></pre>
<p><img src="surveys_files/figure-html/pie_03-1.png" width="672" /></p>
<p>If the slices of the pie chart are not labelled, it is difficult to see which slices are smaller or bigger compared to other slices. This problem can easily be avoided when using a bar plot instead. This issue can be avoided by adding labels to pie charts. The labeling of pie charts is, however, somewhat tedious as the positioning is tricky. Below is an example for adding labels without specification.</p>
<pre class="r"><code># create pie chart
ggplot(bardata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Percent, label = Percent), color = &quot;white&quot;, size=6)</code></pre>
<p><img src="surveys_files/figure-html/pie_05-1.png" width="672" /></p>
<p>To place the labels where they make sense, we will add another variable to the data called “Position”.</p>
<pre class="r"><code>piedata &lt;- bardata %&gt;%
  dplyr::arrange(desc(Satisfaction)) %&gt;%
  dplyr::mutate(Position = cumsum(Percent)- 0.5*Percent)
# inspect data
kable(head(piedata), caption = &quot;First 6 rows of piedata&quot;)</code></pre>
<table>
<caption>First 6 rows of piedata</caption>
<thead>
<tr class="header">
<th align="left">Satisfaction</th>
<th align="right">Frequency</th>
<th align="right">Percent</th>
<th align="right">Position</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">very satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
<td align="right">8.35</td>
</tr>
<tr class="even">
<td align="left">satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
<td align="right">25.05</td>
</tr>
<tr class="odd">
<td align="left">neutral</td>
<td align="right">60</td>
<td align="right">20.0</td>
<td align="right">43.40</td>
</tr>
<tr class="even">
<td align="left">dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
<td align="right">65.05</td>
</tr>
<tr class="odd">
<td align="left">very dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
<td align="right">88.35</td>
</tr>
</tbody>
</table>
<p>Now that we have specified the position, we can include it into the pie chart.</p>
<pre class="r"><code># create pie chart
ggplot(piedata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Position, label = Percent), color = &quot;white&quot;, size=6)</code></pre>
<p><img src="surveys_files/figure-html/pie_09-1.png" width="672" /></p>
<p>We will now create separate pie charts for each course. In a first step, we create a data set that does not only contain the Satisfaction levels and their frequency but also the course.</p>
<pre class="r"><code># create grouped pie data
groupedpiedata &lt;- likertdata1 %&gt;%
  group_by(Course, Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;))) %&gt;%
  dplyr::arrange(desc(Satisfaction)) %&gt;%
  dplyr::mutate(Position = cumsum(Percent)- 0.5*Percent)
# inspect data
kable(head(groupedpiedata), caption = &quot;First 6 rows of groupedpiedata&quot;)</code></pre>
<table>
<caption>First 6 rows of groupedpiedata</caption>
<thead>
<tr class="header">
<th align="left">Course</th>
<th align="left">Satisfaction</th>
<th align="right">Frequency</th>
<th align="right">Percent</th>
<th align="right">Position</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Chinese</td>
<td align="left">very satisfied</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">7.5</td>
</tr>
<tr class="even">
<td align="left">German</td>
<td align="left">very satisfied</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2.5</td>
</tr>
<tr class="odd">
<td align="left">Japanese</td>
<td align="left">very satisfied</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">15.0</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="left">satisfied</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">20.0</td>
</tr>
<tr class="odd">
<td align="left">German</td>
<td align="left">satisfied</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">12.5</td>
</tr>
<tr class="even">
<td align="left">Japanese</td>
<td align="left">satisfied</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">42.5</td>
</tr>
</tbody>
</table>
<p>Now that we have created the data, we can plot separate pie charts for each course.</p>
<pre class="r"><code># create pie chart
ggplot(groupedpiedata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  facet_wrap(~Course) +
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Position, label = Percent), color = &quot;white&quot;, size=4)</code></pre>
<p><img src="surveys_files/figure-html/pie_15-1.png" width="672" /></p>
</div>
<div id="bar-plots" class="section level2">
<h2><span class="header-section-number">4.3</span> Bar plots</h2>
<p>Like pie charts, bar plot display frequency information across categorical variable levels.</p>
<pre class="r"><code># bar plot
ggplot(bardata, aes(Satisfaction, Percent, fill = Satisfaction)) +
  # determine type of plot
  geom_bar(stat=&quot;identity&quot;) +          
  # use black &amp; white theme
  theme_bw() +                         
  # add and define text
  geom_text(aes(y = Percent-5, label = Percent), color = &quot;white&quot;, size=3) + 
  # add colors
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  # supress legend
  theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="surveys_files/figure-html/bar_01-1.png" width="672" /></p>
<p>Compared with the pie chart, it is much easier to grasp the relative size and order of the percentage values which shows that pie charts are unfit to show relationships between elements in a graph and, as a general rule of thumb, should be avoided.</p>
<p>Bar plots can be grouped which adds another layer of information that is particularly useful when dealing with frequency counts across multiple categorical variables. But before we can create grouped bar plots, we need to create an appropriate data set.</p>
<pre class="r"><code># create bar plot data
groupedbardata &lt;- likertdata1 %&gt;%
  group_by(Course, Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;)))
# inpsect data
kable(head(groupedbardata), caption = &quot;First 6 rows of groupedbardata&quot;)</code></pre>
<p>We have now added <em>Course</em> as an additional categorical variable and will include Course as the “fill” argument in our bar plot. To group the bars, we use the command “position=position_dodge()”.</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Satisfaction, Frequency, fill = Course)) + 
  geom_bar(stat=&quot;identity&quot;, position = position_dodge()) +
  # define colors
  scale_fill_manual(values = c(&quot;goldenrod2&quot;, &quot;indianred4&quot;, &quot;blue&quot;)) + 
  # add text
  geom_text(aes(label=Frequency), vjust=1.6, color=&quot;white&quot;, 
            # define text position and size
            position = position_dodge(0.9),  size=3.5) + 
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_05-1.png" width="672" /></p>
<p>If we leave out the “position=position_dodge()” argument, we get a stacked bar plot as shown below.</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Satisfaction, Frequency, fill = Course)) + 
  geom_bar(stat=&quot;identity&quot;) + 
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_07-1.png" width="672" /></p>
<p>One issue to consider when using stacked bar plots is the number of variable levels: when dealing with many variable levels, stacked bar plots tend to become rather confusing. This can be solved by either collapsing infrequent variable levels or choose a color palette that reflects some other inherent piece of information such as <em>formality</em> (e.g. blue) versus <em>informality</em> (e.g. red).</p>
<p>Stacked bar plots can also be normalized so that changes in percentages become visible. This is done by exchanging “position=position_dodge()” with “position=”“fill”".</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Course, Frequency, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, position=&quot;fill&quot;) +  
  # define colors
  scale_fill_viridis(discrete = T, option = &quot;C&quot;) +
  labs(y = &quot;Percent&quot;) +
  scale_y_continuous(breaks=seq(0,1,.2),
                     labels=seq(0,100,20)) +
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_09-1.png" width="672" /></p>
<p>Bar plots are particularly useful when visualizing data obtained through Likert items. As this is a very common issue that empirical researchers face. There are two basic ways to display Likert items using bar plots: grouped bar plots and more elaborate scaled bar plots.</p>
<p>Although we have seen above how to create grouped bar plots, we will repeat it here with the language course example used above when we used cumulative density line graphs to visualize how to display Likert data.</p>
<p>In a first step, we recreate the data set which we have used above. The data set consists of a Likert-scaled variable (Satisfaction) which represents rating of students from three courses about how satisfied they were with their language-learning course. The response to the Likert item is numeric so that “strongly disagree/very dissatisfied” would get the lowest and “strongly agree/very satisfied” the highest numeric value.</p>
<p>Again, we can also plot separate bar graphs for each class by specifying “facets”.</p>
<pre class="r"><code># create grouped bar plot
ggplot(groupedbardata, aes(Satisfaction, Frequency,  
                          fill = Satisfaction, color = Satisfaction)) +
  facet_grid(~Course) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge()) +
  geom_line() +
  # define colors
  scale_fill_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  scale_color_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  # add text and define colour
  geom_text(aes(label=Frequency), vjust=1.6, color=&quot;white&quot;, 
            # define text position and size
            position = position_dodge(0.9),  size=3.5) +     
  theme_bw()</code></pre>
<p><img src="surveys_files/figure-html/bar_13-1.png" width="672" /></p>
<p>Another and very interesting way to display such data is by using the Likert package. In a first step, we need to activate the package, clean the data, and extract a subset for the data visualization example.</p>
<p>One aspect that is different to previous visualizations is that, when using the Likert package, we need to transform the data into a “likert” object (which is, however, very easy and is done by using the “likert()” function as shown below).</p>
<pre class="r"><code># load data
likertdata2 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata2.txt&quot;, header = TRUE)
# inspect data
kable(head(likertdata2), caption = &quot;First 6 rows of the data&quot;)</code></pre>
<table>
<caption>First 6 rows of the data</caption>
<colgroup>
<col width="6%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Question1</th>
<th align="left">Question2</th>
<th align="left">Question3</th>
<th align="left">Question4</th>
<th align="left">Question5</th>
<th align="left">Question6</th>
<th align="left">Question7</th>
<th align="left">Question8</th>
<th align="left">Question9</th>
<th align="left">Question10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Respondent1</td>
<td align="left">Disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Respondent2</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
<tr class="odd">
<td align="left">Respondent3</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
</tr>
<tr class="even">
<td align="left">Respondent4</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="odd">
<td align="left">Respondent5</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Respondent6</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
</tbody>
</table>
<pre class="r"><code># order likert variable
likertdata2 &lt;- likertdata2 %&gt;%
  dplyr::mutate(Question1 = factor(Question1,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question2 = factor(Question2,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question3 = factor(Question3,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question4 = factor(Question4,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question5 = factor(Question5,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question6 = factor(Question6,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question7 = factor(Question7,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question8 = factor(Question8,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question9 = factor(Question9,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)),
                Question10 = factor(Question10,
                                   levels = c(&quot;Strongly disagree&quot;,
                                              &quot;Disagree&quot;,
                                              &quot;Agree&quot;,
                                              &quot;Strongly agree&quot;)))
# inspect data
kable(head(likertdata2), caption = &quot;First 6 rows of the edited data&quot;)</code></pre>
<table style="width:100%;">
<caption>First 6 rows of the edited data</caption>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Question1</th>
<th align="left">Question2</th>
<th align="left">Question3</th>
<th align="left">Question4</th>
<th align="left">Question5</th>
<th align="left">Question6</th>
<th align="left">Question7</th>
<th align="left">Question8</th>
<th align="left">Question9</th>
<th align="left">Question10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
<tr class="odd">
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
</tr>
<tr class="even">
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="odd">
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
</tbody>
</table>
<pre class="r"><code># transform into a likert object
likertdata2 &lt;- likert(likertdata2)
# inspect data
kable(likertdata2$results, caption = &quot;Summary of the data&quot;) </code></pre>
<table>
<caption>Summary of the data</caption>
<thead>
<tr class="header">
<th align="left">Item</th>
<th align="right">Strongly disagree</th>
<th align="right">Disagree</th>
<th align="right">Agree</th>
<th align="right">Strongly agree</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Question1</td>
<td align="right">38</td>
<td align="right">40</td>
<td align="right">14</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">Question2</td>
<td align="right">12</td>
<td align="right">48</td>
<td align="right">26</td>
<td align="right">14</td>
</tr>
<tr class="odd">
<td align="left">Question3</td>
<td align="right">28</td>
<td align="right">20</td>
<td align="right">40</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">Question4</td>
<td align="right">34</td>
<td align="right">40</td>
<td align="right">18</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="left">Question5</td>
<td align="right">22</td>
<td align="right">24</td>
<td align="right">44</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">Question6</td>
<td align="right">54</td>
<td align="right">30</td>
<td align="right">12</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">Question7</td>
<td align="right">16</td>
<td align="right">28</td>
<td align="right">44</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">Question8</td>
<td align="right">36</td>
<td align="right">40</td>
<td align="right">12</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">Question9</td>
<td align="right">48</td>
<td align="right">32</td>
<td align="right">10</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">Question10</td>
<td align="right">12</td>
<td align="right">22</td>
<td align="right">42</td>
<td align="right">24</td>
</tr>
</tbody>
</table>
<pre class="r"><code># inspect data
kable(head(likertdata2$items), caption = &quot;First 6 rows of the data&quot;) </code></pre>
<table style="width:100%;">
<caption>First 6 rows of the data</caption>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Question1</th>
<th align="left">Question2</th>
<th align="left">Question3</th>
<th align="left">Question4</th>
<th align="left">Question5</th>
<th align="left">Question6</th>
<th align="left">Question7</th>
<th align="left">Question8</th>
<th align="left">Question9</th>
<th align="left">Question10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
<tr class="odd">
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
</tr>
<tr class="even">
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="odd">
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
</tbody>
</table>
<p>After extracting a sample of the data, we plot it to show how the Likert data can be displayed.</p>
<pre class="r"><code># plot likert data
plot(likertdata2)</code></pre>
<p><img src="surveys_files/figure-html/bar_25-1.png" width="672" /></p>
</div>
<div id="boxplots-and-violin-plots" class="section level2">
<h2><span class="header-section-number">4.4</span> Boxplots and violin plots</h2>
<p>So far, we have plotted values but we have not plotted the underlying distributions. For instance, we have plotted mean values but not the variance within the distribution. One handy way to combine plotting general trends and their underlying distributions are boxplots.</p>
<p>Boxplots, or Box-and-Whisker Plots, are exploratory graphics first created by John W. Tukey and they show the relationships between categorical and numeric variables. They are very useful because they not only provide measures of central tendency (the median which is the line in the middle of the box) but they also offer information about the distribution of the data. To elaborate, fifty percent of data points fall within the box while seventy-five percent of data points fall within the whiskers (the lines which look like extended error bars): the box thus encompasses the interquartile range between the first and third quartile. The whiskers show the minimum and maximum values in the data and only outliers (data points that lie 1.5 times the interquartile range or more above the third quartile or 1.5 times the interquartile range or more below the first quartile. If the whiskers differ in length, then this means that the data is asymmetrically distributed.</p>
<p>We will now create simple boxplots that show the distribution of prepositions per time period.</p>
<pre class="r"><code># load data
likertdata1 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata1.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
# create boxplot
ggplot(likertdata1, aes(Course, Satisfaction, fill = Course)) +
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, option = &quot;D&quot;) +
  scale_y_discrete(limits = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;), 
                   breaks = c(1,2,3,4,5),
                   labels=c(&quot;very dissatisfied&quot;, &quot;dissatisfied&quot;, 
                            &quot;neutral&quot;, &quot;satisfied&quot;, &quot;very satisfied&quot;)) + 
  theme_bw()</code></pre>
<p><img src="surveys_files/figure-html/box2-1.png" width="672" /></p>
<p>Another interesting feature of boxplots is that they allow us to visually get an idea whether categories differ significantly. Because if add “notch = T” and the notches of the boxplots do not overlap, then this is a very strong indication that the categories actually differ significantly (see below).</p>
<pre class="r"><code># create boxplot
ggplot(likertdata1, aes(Course, Satisfaction, fill = Course)) +
  geom_boxplot(notch=T,) +
  scale_fill_viridis(discrete = TRUE, option = &quot;D&quot;) +
  scale_y_discrete(limits = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;), 
                   breaks = c(1,2,3,4,5),
                   labels=c(&quot;very dissatisfied&quot;, &quot;dissatisfied&quot;, 
                            &quot;neutral&quot;, &quot;satisfied&quot;, &quot;very satisfied&quot;)) + 
  theme_bw()</code></pre>
<p><img src="surveys_files/figure-html/box3-1.png" width="672" /></p>
</div>
</div>
<div id="useful-statistics-for-survey-data" class="section level1">
<h1><span class="header-section-number">5</span> Useful statistics for survey data</h1>
<p>This section introduces some statistical measures or tests that useful when dealing with survey data. We will begin with measures of reliability (Cronbach’s <span class="math inline">\(\alpha\)</span>), then move on to methods for merging variables (Factor analysis and principle component analysis), and finally to ordinal regression which tests which variables correlate with a certain outcome.</p>
<div id="evaluating-the-reliability-of-questions" class="section level2">
<h2><span class="header-section-number">5.1</span> Evaluating the reliability of questions</h2>
<p><strong>Cronbach’s Alpha</strong></p>
<p>Oftentimes several questions in one questionnaire aim to tap into the same cognitive concept or attitude or whatever we are interested in. The answers to these related questions should be internally consistent, i.e. the responses should correlate strongly and positively.</p>
<p>Cronbach’s <span class="math inline">\(\alpha\)</span> <span class="citation">(Cronbach <a href="#ref-cronbach1951alpha" role="doc-biblioref">1951</a>)</span> is measure of internal consistency or reliability that provides information on how strongly the responses to a set of questions correlate. The formula for Cronbach’s <span class="math inline">\(\alpha\)</span> is shown below (N: number of items, <span class="math inline">\(\bar c\)</span>: average inter-item co-variance among items, <span class="math inline">\(\bar v\)</span>: average variance).</p>
<p><span class="math inline">\(\alpha = \frac{N*\bar c}{\bar v + (N-1)\bar c}\)</span></p>
<p>If the values for Cronbach’s <span class="math inline">\(\alpha\)</span> are low (below .7), then this indicates that the questions are not internally consistent (and do not tap into the same concept) or that the questions are not uni-dimensional (as they should be).</p>
<p>While Cronbach’s <span class="math inline">\(\alpha\)</span> is the most frequently used measures of reliability (probably because it is conceptually simple and can be computed very easily), it underestimates the reliability of a test and overestimates the first factor saturation. This can be a problem is the data is <em>lumpy</em>. Thus, various other measures of reliability have been proposed. Also,Cronbach’s <span class="math inline">\(\alpha\)</span> assumes that scale items are repeated measurements, an assumption that is often violated.</p>
<p>An alternative reliability measure that takes the amount of variance per item into account and thus performs better when dealing with <em>lumpy</em> data (although it is still affected by <em>lumpiness</em>) is Guttman’s Lambda 6 (G6) <span class="citation">(Guttman <a href="#ref-guttman1945lambda" role="doc-biblioref">1945</a>)</span>. In contrast to Cronbach’s <span class="math inline">\(\alpha\)</span>, G6 is mostly used to evaluate the reliability of individual test items though. This means that it provides information about how well individual questions reflect the concept that they aim to tap into.</p>
<p>Probably the best measures of reliability are <span class="math inline">\(\omega\)</span> (<em>omega</em>) measures. Hierarchical <span class="math inline">\(\omega\)</span> provides more appropriate estimates of the general factor saturation while total <span class="math inline">\(\omega\)</span> is a better estimate of the reliability of the total test compared to both Cronbach’s <span class="math inline">\(\alpha\)</span> and G6 <span class="citation">(Revelle and Zinbarg <a href="#ref-revelle2009coefficients" role="doc-biblioref">2009</a>)</span>.</p>
<p><strong>Calculating Cronbach’s alpha in R</strong></p>
<p>We will now calculate Cronbach’s <span class="math inline">\(\alpha\)</span> in R. In a first step, we activate the “psych” package and load as well as inspect the data.</p>
<pre class="r"><code># load data
surveydata &lt;- read.delim(&quot;https://slcladal.github.io/data/surveydata1.txt&quot;, sep = &quot;\t&quot;, header = T)
# inpsect data
kable(head(surveydata), caption = &quot;First 6 rows of surveydata&quot;)</code></pre>
<table style="width:100%;">
<caption>First 6 rows of surveydata</caption>
<colgroup>
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Respondent</th>
<th align="right">Q01_Outgoing</th>
<th align="right">Q02_Outgoing</th>
<th align="right">Q03_Outgoing</th>
<th align="right">Q04_Outgoing</th>
<th align="right">Q05_Outgoing</th>
<th align="right">Q06_Intelligence</th>
<th align="right">Q07_Intelligence</th>
<th align="right">Q08_Intelligence</th>
<th align="right">Q09_Intelligence</th>
<th align="right">Q10_Intelligence</th>
<th align="right">Q11_Attitude</th>
<th align="right">Q12_Attitude</th>
<th align="right">Q13_Attitude</th>
<th align="right">Q14_Attitude</th>
<th align="right">Q15_Attitude</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Respondent_01</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Respondent_02</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">Respondent_03</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">Respondent_04</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="left">Respondent_05</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="left">Respondent_06</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>The inspection of the data shows that the responses of participants represent the rows and that the questions represent columns. The column names show that we have 15 questions and that the first five questions aim to test how outgoing respondents are. To check if the first five questions reliably test “outgoingness” (or “extraversion”), we calculate Cronbach’s alpha for these five questions.</p>
<p>Thus, we use the “alpha()” function and provide the questions that tap into the concept we want to assess. In addition to Cronbach’s <span class="math inline">\(\alpha\)</span>, the “alpha()” function also reports Guttman’s lambda_6 which is an alternative measure for reliability. This is an advantage because Cronbach’s <span class="math inline">\(\alpha\)</span> underestimates the reliability of a test and overestimates the first factor saturation.</p>
<pre class="r"><code># calculate cronbach&#39;s alpha
Cronbach &lt;- alpha(surveydata[c(&quot;Q01_Outgoing&quot;,  
                   &quot;Q02_Outgoing&quot;,  
                   &quot;Q03_Outgoing&quot;,  
                   &quot;Q04_Outgoing&quot;,  
                   &quot;Q05_Outgoing&quot;)], check.keys=F)
# inspect results
Cronbach</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: alpha(x = surveydata[c(&quot;Q01_Outgoing&quot;, &quot;Q02_Outgoing&quot;, &quot;Q03_Outgoing&quot;, 
##     &quot;Q04_Outgoing&quot;, &quot;Q05_Outgoing&quot;)], check.keys = F)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r
##       0.98      0.98    0.97      0.89  42 0.0083  3.1 1.5      0.9
## 
##  lower alpha upper     95% confidence boundaries
## 0.96 0.98 0.99 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r S/N alpha se   var.r med.r
## Q01_Outgoing      0.97      0.97    0.97      0.89  33   0.0108 0.00099  0.89
## Q02_Outgoing      0.97      0.97    0.96      0.89  31   0.0116 0.00054  0.89
## Q03_Outgoing      0.97      0.97    0.97      0.90  35   0.0104 0.00095  0.90
## Q04_Outgoing      0.97      0.97    0.96      0.89  31   0.0115 0.00086  0.89
## Q05_Outgoing      0.98      0.98    0.97      0.91  41   0.0088 0.00034  0.91
## 
##  Item statistics 
##               n raw.r std.r r.cor r.drop mean  sd
## Q01_Outgoing 20  0.96  0.96  0.95   0.94  3.1 1.5
## Q02_Outgoing 20  0.97  0.97  0.96   0.95  3.2 1.6
## Q03_Outgoing 20  0.95  0.95  0.94   0.93  3.1 1.5
## Q04_Outgoing 20  0.97  0.97  0.96   0.95  3.0 1.6
## Q05_Outgoing 20  0.94  0.94  0.91   0.90  3.2 1.6
## 
## Non missing response frequency for each item
##                 1   2    3    4    5 miss
## Q01_Outgoing 0.20 0.2 0.10 0.25 0.25    0
## Q02_Outgoing 0.15 0.3 0.05 0.15 0.35    0
## Q03_Outgoing 0.15 0.3 0.05 0.25 0.25    0
## Q04_Outgoing 0.25 0.2 0.05 0.30 0.20    0
## Q05_Outgoing 0.20 0.2 0.10 0.20 0.30    0</code></pre>
<p>The output of the “alpha()” function is rather extensive and we will only interpret selected output here.</p>
<p>The value under alpha is Cronbach’s <span class="math inline">\(\alpha\)</span> and it should be above 0.7. The values to its left and right are the lower and upper bound of its confidence interval. The values in the column with the header “G6” show how well each question represents the concept it aims to reflect. Low values indicate that the question does not reflect the underlying concept while high values (.7 and higher) indicate that the question captures that concept well (or to an acceptable degree).</p>
<p><strong>Omega</strong></p>
<p>The omega (<span class="math inline">\(\omega\)</span>) coefficient is also a reliability measure of internal consistency. <span class="math inline">\(\omega\)</span> represents an estimate of the general factor saturation of a test that was proposed by McDonald. <span class="citation">(<span class="citeproc-not-found" data-reference-id="zinbarg2005cronbach"><strong>???</strong></span>)</span> compare McDonald’s Omega to Cronbach’s <span class="math inline">\(\alpha\)</span> and Revelle’s <span class="math inline">\(\beta\)</span>. They conclude that omega is the best estimate <span class="citation">(<span class="citeproc-not-found" data-reference-id="zinbarg2006omega"><strong>???</strong></span>)</span>.</p>
<p>A very handy way to calculate McDonald’s <span class="math inline">\(\omega\)</span> is to use the “scaleReliability()” function from the “userfriendlyscience” package (which also provides Cronbach’s <span class="math inline">\(\alpha\)</span> and the Greatest Lower Bound (GLB) estimate which is also a very good and innovative measure of reliability) <span class="citation">(see also <span class="citeproc-not-found" data-reference-id="peters2014alpha"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code># activate package
library(userfriendlyscience)
# extract reliability measures
reliability &lt;- userfriendlyscience::scaleReliability(surveydata[c(&quot;Q01_Outgoing&quot;,   
                   &quot;Q02_Outgoing&quot;,  
                   &quot;Q03_Outgoing&quot;,  
                   &quot;Q04_Outgoing&quot;,  
                   &quot;Q05_Outgoing&quot;)])
# inspect results
reliability</code></pre>
<pre><code>## 
## Information about this analysis:
## 
##                  Dataframe: surveydata[c(&quot;Q01_Outgoing&quot;, &quot;Q02_Outgoing&quot;, &quot;Q03_Outgoing&quot;, 
##                      Items: all
##               Observations: 20
##      Positive correlations: 10 out of 10 (100%)
## 
## Estimates assuming interval level:
##  
## Information about this analysis:
## 
##                  Dataframe:     &quot;Q04_Outgoing&quot;, &quot;Q05_Outgoing&quot;)]
##                      Items: all
##               Observations: 20
##      Positive correlations: 10 out of 10 (100%)
## 
## Estimates assuming interval level:
## 
##              Omega (total): 0.98
##       Omega (hierarchical): 0.95
##    Revelle&#39;s omega (total): 0.98
## Greatest Lower Bound (GLB): 0.99
##              Coefficient H: 0.98
##           Cronbach&#39;s alpha: 0.98
## Confidence intervals:
##              Omega (total): [0.96, 0.99]
##           Cronbach&#39;s alpha: [0.96, 0.99]
## 
## Estimates assuming ordinal level:
## 
##      Ordinal Omega (total): 0.98
##  Ordinal Omega (hierarch.): 0.93
##   Ordinal Cronbach&#39;s alpha: 0.98
## Confidence intervals:
##      Ordinal Omega (total): [0.96, 0.99]
##   Ordinal Cronbach&#39;s alpha: [0.96, 0.99]
## 
## Note: the normal point estimate and confidence interval for omega are based on the procedure suggested by Dunn, Baguley &amp; Brunsden (2013) using the MBESS function ci.reliability, whereas the psych package point estimate was suggested in Revelle &amp; Zinbarg (2008). See the help (&#39;?scaleStructure&#39;) for more information.</code></pre>
</div>
<div id="factor-analysis" class="section level2">
<h2><span class="header-section-number">5.2</span> Factor analysis</h2>
<p>When dealing with many variables it is often the case that several variables are related and represent a common, underlying factor. To find such underlying factors, we can use a factor analysis.</p>
<p>Factor analysis is a method that allows to find commonalities or structure in data. This is particularly useful when dealing with many variables. Factors can be considered hidden latent variables or driving forces that affect or underlie several variables at once.</p>
<p>This becomes particularly apparent when considering socio-demographic variables as behaviors are not only dependent on single variables, e.g., economic status, but on the interaction of several additional variables such as education level, marital status, number of children, etc. All of these variables can be combined into a single factor (or hidden latent variable).</p>
<pre class="r"><code># remove respondent
surveydata &lt;- surveydata %&gt;% 
  dplyr::select(-Respondent)
factoranalysis &lt;- factanal(surveydata, 3, rotation=&quot;varimax&quot;)
print(factoranalysis, digits=2, cutoff=.2, sort=TRUE)</code></pre>
<pre><code>## 
## Call:
## factanal(x = surveydata, factors = 3, rotation = &quot;varimax&quot;)
## 
## Uniquenesses:
##     Q01_Outgoing     Q02_Outgoing     Q03_Outgoing     Q04_Outgoing 
##             0.09             0.06             0.12             0.07 
##     Q05_Outgoing Q06_Intelligence Q07_Intelligence Q08_Intelligence 
##             0.14             0.10             0.13             0.10 
## Q09_Intelligence Q10_Intelligence     Q11_Attitude     Q12_Attitude 
##             0.28             0.41             0.08             0.14 
##     Q13_Attitude     Q14_Attitude     Q15_Attitude 
##             0.04             0.09             0.06 
## 
## Loadings:
##                  Factor1 Factor2 Factor3
## Q06_Intelligence -0.82    0.25    0.41  
## Q07_Intelligence -0.80            0.47  
## Q08_Intelligence -0.85            0.42  
## Q09_Intelligence -0.79            0.29  
## Q11_Attitude      0.96                  
## Q12_Attitude      0.92                  
## Q13_Attitude      0.97                  
## Q14_Attitude      0.95                  
## Q15_Attitude      0.96                  
## Q01_Outgoing              0.94          
## Q02_Outgoing              0.96          
## Q03_Outgoing              0.93          
## Q04_Outgoing              0.96          
## Q05_Outgoing              0.92          
## Q10_Intelligence -0.22   -0.46    0.57  
## 
##                Factor1 Factor2 Factor3
## SS loadings       7.29    4.78    1.02
## Proportion Var    0.49    0.32    0.07
## Cumulative Var    0.49    0.80    0.87
## 
## Test of the hypothesis that 3 factors are sufficient.
## The chi square statistic is 62.79 on 63 degrees of freedom.
## The p-value is 0.484</code></pre>
<p>The results of a factor analysis can be visualized so that questions which reflect the same underlying factor are grouped together.</p>
<pre class="r"><code># plot factor 1 by factor 2
load &lt;- factoranalysis$loadings[,1:2]
# set up plot
plot(load, type=&quot;n&quot;, xlim = c(-1.5, 1.5)) 
# add variable names
text(load,
     # define labels
     labels=names(surveydata),
     # define font size 
     # (smaller than default = values smaller than 1)
     cex=.7)  </code></pre>
<p><img src="surveys_files/figure-html/fa_04-1.png" width="672" /></p>
<p>The plot shows that the questions form groups which indicates that the questions do a rather good job at reflecting the concepts that they aim to tap into. The only problematic question is question 10 (Q10) which aimed to tap into the intelligence of respondents but appears not to correlate strongly with the other questions that aim to extract information about the respondents intelligence. In such cases, it makes sense, to remove a question (in this case Q10) from the survey as it does not appear to reflect what we wanted it to.</p>
</div>
<div id="principle-component-analysis" class="section level2">
<h2><span class="header-section-number">5.3</span> Principle component analysis</h2>
<p>Principal component analysis is used when several questions or variables reflect a common factor and they should be combined into a single variable, e.g. during the statistical analysis of the data. Thus, principal component analysis can be used to collapse different variables (or questions) into one.</p>
<p>Imagine you have measured lengths of sentences in different ways (in words, syllables, characters, time it takes to pronounce, etc.). You could combine all these different measures of length by applying a PCA to those measures and using the first principal component as a single proxy for all these different measures.</p>
<pre class="r"><code># entering raw data and extracting PCs  from the correlation matrix
PrincipalComponents &lt;- princomp(surveydata[c(&quot;Q01_Outgoing&quot;,    
                   &quot;Q02_Outgoing&quot;,  
                   &quot;Q03_Outgoing&quot;,  
                   &quot;Q04_Outgoing&quot;,  
                   &quot;Q05_Outgoing&quot;)], cor=TRUE)
summary(PrincipalComponents) # print variance accounted for</code></pre>
<pre><code>## Importance of components:
##                           Comp.1     Comp.2     Comp.3     Comp.4      Comp.5
## Standard deviation     2.1399452 0.41221349 0.33747971 0.29869830 0.218177126
## Proportion of Variance 0.9158731 0.03398399 0.02277851 0.01784413 0.009520252
## Cumulative Proportion  0.9158731 0.94985710 0.97263561 0.99047975 1.000000000</code></pre>
<p>The output shows that the first component (Comp.1) explains 91.58 percent of the variance. This shows that we only lose 8.42 percent of the variance if we use this component as a proxy for “outgoingness” if we use the collapsed component rather than the five individual items.</p>
<pre class="r"><code>loadings(PrincipalComponents) # pc loadings</code></pre>
<pre><code>## 
## Loadings:
##              Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## Q01_Outgoing  0.448  0.324         0.831       
## Q02_Outgoing  0.453  0.242 -0.408 -0.360  0.663
## Q03_Outgoing  0.446  0.405  0.626 -0.405 -0.286
## Q04_Outgoing  0.452 -0.191 -0.568 -0.114 -0.650
## Q05_Outgoing  0.437 -0.798  0.342         0.230
## 
##                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## SS loadings       1.0    1.0    1.0    1.0    1.0
## Proportion Var    0.2    0.2    0.2    0.2    0.2
## Cumulative Var    0.2    0.4    0.6    0.8    1.0</code></pre>
<p>We now check if the five questions that are intended to tap into “outgoingness” represent one (and not more) underlying factors. Do check this, we create a scree plot.</p>
<pre class="r"><code>plot(PrincipalComponents,type=&quot;lines&quot;) # scree plot</code></pre>
<p><img src="surveys_files/figure-html/pca_07-1.png" width="672" /></p>
<p>The scree plot shown above indicates that we only need a single component to explain the variance as there is a steep decline from the first to the second component. This confirms that the questions that tap into “outgoingness” represent one (and not more) underlying factors.</p>
<pre class="r"><code>PrincipalComponents$scores # the principal components</code></pre>
<pre><code>##           Comp.1      Comp.2      Comp.3       Comp.4      Comp.5
##  [1,]  1.8381566 -0.36615228 -0.05472481 -0.185982784  0.45151980
##  [2,]  1.8663059  0.49141424  0.43588461  0.293520579 -0.29327024
##  [3,]  2.1435874 -0.43109571 -0.14566197  0.529200331 -0.37631017
##  [4,]  2.4439739  0.12865309  0.39433418  0.093406447  0.28596101
##  [5,]  2.1362155 -0.49209851 -0.42957061 -0.260901209  0.02261552
##  [6,]  2.4573568  0.52187899 -0.20319399 -0.014602480 -0.29283073
##  [7,]  2.1362155 -0.49209851 -0.42957061 -0.260901209  0.02261552
##  [8,]  1.8506180 -0.24517164  0.63889114 -0.230285827 -0.17380089
##  [9,]  1.8538444  0.37043360 -0.25773134  0.337823622  0.33205045
## [10,]  1.8589340  0.43041145  0.15197597 -0.496580962  0.10565545
## [11,] -2.2853351  0.62953122  0.07366357  0.047245923  0.18176903
## [12,] -0.8111853  0.23229139 -0.69790263  0.254191848 -0.06639018
## [13,] -1.1175602 -0.31734547  0.16385834  0.595405408  0.08305777
## [14,] -2.2853351  0.62953122  0.07366357  0.047245923  0.18176903
## [15,] -2.2876401  0.28617124 -0.32085807 -0.584569410 -0.27755336
## [16,] -2.8994684 -0.54085723  0.11151975  0.034151826  0.06787149
## [17,] -1.7026001 -0.01558712 -0.07849987  0.005417999 -0.09724779
## [18,] -3.1841445 -0.02168511 -0.11116261  0.001061325 -0.08201597
## [19,] -1.1124706 -0.25736763  0.57356565 -0.238999176 -0.14333724
## [20,] -2.8994684 -0.54085723  0.11151975  0.034151826  0.06787149</code></pre>
<p>You could now replace the five items which tap into “outgoingness” with the single first component shown in the table above.</p>
</div>
<div id="ordinal-regression" class="section level2">
<h2><span class="header-section-number">5.4</span> Ordinal Regression</h2>
<p>Ordinal regression is very similar to multiple linear regression but takes an ordinal dependent variable <span class="citation">(Agresti <a href="#ref-agresti2010analysis" role="doc-biblioref">2010</a>)</span>. For this reason, ordinal regression is one of the key methods in analyzing Likert data.</p>
<p>To see how an ordinal regression is implemented in R, we load and inspect the “ordinaldata” data set. The data set consists of 400 observations of students that were either educated at this school (Internal = 1) or not (Internal = 0). Some of the students have been abroad (Exchange = 1) while other have not (Exchange = 0). In addition, the data set contains the students’ final score of a language test (FinalScore) and the dependent variable which the recommendation of a committee for an additional, very prestigious program. The recommendation has three levels (“very likely”, “somewhat likely”, and “unlikely”) and reflects the committees’ assessment of whether the student is likely to succeed in the program.</p>
<pre class="r"><code># load data
ordata &lt;- read.delim(&quot;https://slcladal.github.io/data/ordinaldata.txt&quot;, sep = &quot;\t&quot;, header = T)
colnames(ordata) &lt;- c(&quot;Recommend&quot;, &quot;Internal&quot;, &quot;Exchange&quot;, &quot;FinalScore&quot;)
# inspect data
str(ordata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    400 obs. of  4 variables:
##  $ Recommend : chr  &quot;very likely&quot; &quot;somewhat likely&quot; &quot;unlikely&quot; &quot;somewhat likely&quot; ...
##  $ Internal  : int  0 1 1 0 0 0 0 0 0 1 ...
##  $ Exchange  : int  0 0 1 0 0 1 0 0 0 0 ...
##  $ FinalScore: num  3.26 3.21 3.94 2.81 2.53 ...</code></pre>
<p>In a first step, we need to re-level the ordinal variable to represent an ordinal factor (or a progression from “unlikely” over “somewhat likely” to “very likely”. And we will also factorize Internal and Exchange to make it easier to interpret the output later on.</p>
<pre class="r"><code># relevel data
ordata &lt;- ordata %&gt;%
dplyr::mutate(Recommend = factor(Recommend, 
                           levels=c(&quot;unlikely&quot;, &quot;somewhat likely&quot;, &quot;very likely&quot;),
                           labels=c(&quot;unlikely&quot;,  &quot;somewhat likely&quot;,  &quot;very likely&quot;))) %&gt;%
  dplyr::mutate(Exchange = ifelse(Exchange == 1, &quot;Exchange&quot;, &quot;NoExchange&quot;)) %&gt;%
  dplyr::mutate(Internal = ifelse(Internal == 1, &quot;Internal&quot;, &quot;External&quot;))</code></pre>
<p>Now that the dependent variable is re-leveled, we check the distribution of the variable levels by tabulating the data. To get a better understanding of the data we create frequency tables across variables rather than viewing the variables in isolation.</p>
<pre class="r"><code>## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Exchange + Recommend + Internal, data = ordata))</code></pre>
<pre><code>##                            Internal External Internal
## Exchange   Recommend                                 
## Exchange   unlikely                       25        6
##            somewhat likely                12        4
##            very likely                     7        3
## NoExchange unlikely                      175       14
##            somewhat likely                98       26
##            very likely                    20       10</code></pre>
<p>We also check the mean and standard deviation of the final score as final score is a numeric variable and cannot be tabulated (unless we convert it to a factor).</p>
<pre class="r"><code>summary(ordata$FinalScore); sd(ordata$FinalScore)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.900   2.720   2.990   2.999   3.270   4.000</code></pre>
<pre><code>## [1] 0.3979409</code></pre>
<p>The lowest score is 1.9 and the highest score is a 4.0 with a mean of approximately 3. Finally, we inspect the distributions graphically.</p>
<pre class="r"><code># visualize data
ggplot(ordata, aes(x = Recommend, y = FinalScore)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) +
  facet_grid(Exchange ~ Internal, margins = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))</code></pre>
<p><img src="surveys_files/figure-html/orr5-1.png" width="672" /></p>
<p>We see that we have only few students that have taken part in an exchange program and there are also only few internal students overall. With respect to recommendations, only few students are considered to very likely succeed in the program. We can now start with the modelling by using the “polr” function. To make things easier for us, we will only consider the main effects here as this tutorial only aims to how to implement an ordinal regression but not how it should be done in a proper study - then, the model fitting and diagnostic procedures would have to be performed accurately, of course.</p>
<pre class="r"><code>## fit ordered logit model and store results &#39;m&#39;
m &lt;- polr(Recommend ~ Internal + Exchange + FinalScore, data = ordata, Hess=TRUE)
## view a summary of the model
summary(m)</code></pre>
<pre><code>## Call:
## polr(formula = Recommend ~ Internal + Exchange + FinalScore, 
##     data = ordata, Hess = TRUE)
## 
## Coefficients:
##                      Value Std. Error t value
## InternalInternal   1.04766     0.2658   3.942
## ExchangeNoExchange 0.05868     0.2979   0.197
## FinalScore         0.61574     0.2606   2.363
## 
## Intercepts:
##                             Value  Std. Error t value
## unlikely|somewhat likely    2.2620 0.8822     2.5641 
## somewhat likely|very likely 4.3574 0.9045     4.8177 
## 
## Residual Deviance: 717.0249 
## AIC: 727.0249</code></pre>
<p>The results show that having studied here at this school increases the chances of receiving a positive recommendation but that having been on an exchange has a negative but insignificant effect on the recommendation. The final score also correlates positively with a positive recommendation but not as much as having studied here.</p>
<pre class="r"><code>## store table
(ctable &lt;- coef(summary(m)))</code></pre>
<pre><code>##                                  Value Std. Error   t value
## InternalInternal            1.04766394  0.2657891 3.9417109
## ExchangeNoExchange          0.05868108  0.2978588 0.1970097
## FinalScore                  0.61574360  0.2606313 2.3625085
## unlikely|somewhat likely    2.26199764  0.8821736 2.5641185
## somewhat likely|very likely 4.35744190  0.9044678 4.8176858</code></pre>
<p>As the regression report does not provide p-values, we have to calculate them separately (after having calculated them, we add them to the coefficient table).</p>
<pre class="r"><code>## calculate and store p values
p &lt;- pnorm(abs(ctable[, &quot;t value&quot;]), lower.tail = FALSE) * 2
## combined table
(ctable &lt;- cbind(ctable, &quot;p value&quot; = p))</code></pre>
<pre><code>##                                  Value Std. Error   t value      p value
## InternalInternal            1.04766394  0.2657891 3.9417109 8.090244e-05
## ExchangeNoExchange          0.05868108  0.2978588 0.1970097 8.438199e-01
## FinalScore                  0.61574360  0.2606313 2.3625085 1.815173e-02
## unlikely|somewhat likely    2.26199764  0.8821736 2.5641185 1.034382e-02
## somewhat likely|very likely 4.35744190  0.9044678 4.8176858 1.452328e-06</code></pre>
<p>As predicted, Exchange does not have a significant effect but FinalScore and Internal both correlate significantly with the likelihood of receiving a positive recommendation.</p>
<pre class="r"><code># extract profiled confidence intervals
ci &lt;- confint(m)
# calculate odds ratios and combine them with profiled CIs
exp(cbind(OR = coef(m), ci))</code></pre>
<pre><code>##                          OR     2.5 %   97.5 %
## InternalInternal   2.850983 1.6958378 4.817114
## ExchangeNoExchange 1.060437 0.5950332 1.919771
## FinalScore         1.851033 1.1136253 3.098491</code></pre>
<p>The odds ratios show that internal students are 2.85 or 285 percent more likely compared to non-internal students to receive positive evaluations and that a 1-point increase in the test score lead to a 1.85 or 185 percent increase in the chances of receiving a positive recommendation. The effect of an exchange is slightly negative but, as we have seen above, not significant.</p>
<p>In a final step, we will visualize the results of the ordinal regression model. To do that, we need to reformat the data and add the predictions.</p>
<pre class="r"><code># extract redictions
predictions &lt;- predict(m, data = ordata, type = &quot;prob&quot;)
# add predictions to the data
newordata &lt;- cbind(ordata, predictions)
# rename columns
colnames(newordata)[6:7] &lt;- c(&quot;somewhat_likely&quot;, &quot;very_likely&quot;)
# reformat data
newordata &lt;- newordata %&gt;%
  dplyr::select(-Recommend) %&gt;%
  tidyr::gather(Recommendation, Probability, unlikely:very_likely)  %&gt;%
  dplyr::mutate(Recommendation = factor(Recommendation, 
                                        levels = c(&quot;unlikely&quot;,
                                                   &quot;somewhat_likely&quot;,
                                                   &quot;very_likely&quot;)))
# inspect data
head(newordata)</code></pre>
<pre><code>##   Internal   Exchange FinalScore Recommendation Probability
## 1 External NoExchange       3.26       unlikely   0.5488419
## 2 Internal NoExchange       3.21       unlikely   0.3055760
## 3 Internal   Exchange       3.94       unlikely   0.2294011
## 4 External NoExchange       2.81       unlikely   0.6161118
## 5 External NoExchange       2.53       unlikely   0.6559924
## 6 External   Exchange       2.59       unlikely   0.6608808</code></pre>
<p>We can now visualize the predictions of the model.</p>
<pre class="r"><code># bar plot
ggplot(newordata, 
       aes(x = FinalScore, Probability, 
           color = Recommendation, group = Recommendation)) + 
  facet_grid(Exchange~Internal) +
  geom_smooth() +  
  # define colors
  scale_fill_manual(values=c(&quot;firebrick4&quot;, &quot;gray70&quot;, &quot;darkblue&quot;)) +
  scale_color_manual(values=c(&quot;firebrick4&quot;, &quot;gray70&quot;, &quot;darkblue&quot;)) +
  theme_bw()  </code></pre>
<p><img src="surveys_files/figure-html/orr13-1.png" width="672" /></p>
<p>For more information about regression modeling, model fitting, and model diagnostics, please have a look at the tutorial on <a href="https://slcladal.github.io/fixedregressions.html">fixed-effects regressions</a>.</p>
</div>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2020. <em>Questionnaires and Surveys: Analyses with R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/surveys.html" class="uri">https://slcladal.github.io/surveys.html</a> (Version 2020.09.29).</p>
<pre><code>@manual{schweinberger2020survey,
  author = {Schweinberger, Martin},
  title = {Questionnaires and Surveys: Analyses with R},
  note = {https://slcladal.github.io/survey.html},
  year = {2020},
  organization = &quot;The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/09/29}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] userfriendlyscience_0.7.2 viridis_0.5.1            
##  [3] viridisLite_0.3.0         psych_2.0.8              
##  [5] MASS_7.3-51.6             likert_1.3.5             
##  [7] xtable_1.8-4              forcats_0.5.0            
##  [9] stringr_1.4.0             dplyr_1.0.2              
## [11] purrr_0.3.4               readr_1.3.1              
## [13] tidyr_1.1.2               tibble_3.0.3             
## [15] ggplot2_3.3.2             tidyverse_1.3.0          
## [17] lattice_0.20-41           knitr_1.30               
## 
## loaded via a namespace (and not attached):
##  [1] minqa_1.2.4           colorspace_1.4-1      ellipsis_0.3.1       
##  [4] rio_0.5.16            ggridges_0.5.2        fs_1.5.0             
##  [7] rstudioapi_0.11       lavaan_0.6-7          farver_2.0.3         
## [10] ggrepel_0.8.2         fansi_0.4.1           lubridate_1.7.9      
## [13] xml2_1.3.2            splines_4.0.2         mnormt_2.0.2         
## [16] SuppDists_1.1-9.5     jsonlite_1.7.1        nloptr_1.2.2.2       
## [19] broom_0.7.0           dbplyr_1.4.4          data.tree_1.0.0      
## [22] DiagrammeR_1.0.6.1    compiler_4.0.2        httr_1.4.2           
## [25] backports_1.1.10      MBESS_4.8.0           assertthat_0.2.1     
## [28] Matrix_1.2-18         cli_2.0.2             visNetwork_2.0.9     
## [31] htmltools_0.5.0       tools_4.0.2           gtable_0.3.0         
## [34] glue_1.4.2            reshape2_1.4.4        Rcpp_1.0.5           
## [37] carData_3.0-4         cellranger_1.1.0      vctrs_0.3.4          
## [40] nlme_3.1-148          xfun_0.16             openxlsx_4.2.2       
## [43] lme4_1.1-23           rvest_0.3.6           lifecycle_0.2.0      
## [46] statmod_1.4.34        XML_3.99-0.5          scales_1.1.1         
## [49] hms_0.5.3             parallel_4.0.2        pwr_1.3-0            
## [52] RColorBrewer_1.1-2    yaml_2.2.1            curl_4.3             
## [55] gridExtra_2.3         pander_0.6.3          reshape_0.8.8        
## [58] stringi_1.5.3         highr_0.8             SCRT_1.3.1           
## [61] boot_1.3-25           zip_2.1.1             rlang_0.4.7          
## [64] pkgconfig_2.0.3       evaluate_0.14         htmlwidgets_1.5.1    
## [67] labeling_0.3          tidyselect_1.1.0      GGally_2.0.0         
## [70] plyr_1.8.6            magrittr_1.5          R6_2.4.1             
## [73] generics_0.0.2        DBI_1.1.0             mgcv_1.8-31          
## [76] pillar_1.4.6          haven_2.3.1           foreign_0.8-80       
## [79] withr_2.3.0           abind_1.4-5           modelr_0.1.8         
## [82] crayon_1.3.4          car_3.0-9             tmvnsim_1.0-2        
## [85] rmarkdown_2.3         grid_4.0.2            readxl_1.3.1         
## [88] minpack.lm_1.2-1      data.table_1.13.0     pbivnorm_0.6.0       
## [91] blob_1.2.1            reprex_0.3.0          digest_0.6.25        
## [94] diptest_0.75-7        GPArotation_2014.11-1 stats4_4.0.2         
## [97] munsell_0.5.0         BiasedUrn_1.07</code></pre>
<hr />
<p><a href="https://slcladal.github.io/index.html">Main page</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-agresti2010analysis">
<p>Agresti, Alan. 2010. <em>Analysis of Ordinal Categorical Data</em>. Vol. 656. John Wiley &amp; Sons.</p>
</div>
<div id="ref-brown2001surveys">
<p>Brown, James Dean. 2001. <em>Using Surveys in Language Programs</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-cronbach1951alpha">
<p>Cronbach, Lee J. 1951. “Coefficient Alpha and the Internal Strucuture of Tests.” <em>Psychometrika</em> 16: 297–334.</p>
</div>
<div id="ref-guttman1945lambda">
<p>Guttman, Louis. 1945. “A Basis for Analyzing Test-Retest Reliability.” <em>Psychometrika</em> 10 (4): 255–82.</p>
</div>
<div id="ref-revelle2009coefficients">
<p>Revelle, W., and Richard E. Zinbarg. 2009. “Coefficients Alpha, Beta, Omega and the Glb: Comments on Sijtsma.” <em>Psychometrika</em> 74 (1): 1145–54.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
