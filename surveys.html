<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-06-12" />

<title>An introduction to creating and analyzing surveys and questionnaires</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introcomputer.html">General Tips on Computering</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Research</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Visualizing Data with R</a>
    </li>
    <li>
      <a href="maps.html">Creating maps using R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analytics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">An introduction to creating and analyzing surveys and questionnaires</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-06-12</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial focuses on creating and analyzing surveys and questionnaires, offers some advice on what to consider when creating surveys and questionnaires, and provides some options for visualizing survey and questionnare data. However, issues relating to what software to use when creating a survey (e.g. SurveyMonkey, Qualtrics, GoogleForms, etc.) or how to program questionnaires or online experiments in Java or R are not discussed.</p>
<p>A survey is a research method for gathering information based on a sample of people. Questionnaires are a research instrument and typically represent a part of a survey, i.e. that part where participants are asked to answer a set of questions.</p>
<p>“Questionnaires are any written instruments that present respondents with a series of questions or statements to which they are to react either by writing out their answers or selecting among existing answers.” <span class="citation">(Brown <a href="#ref-brown2001surveys" role="doc-biblioref">2001</a>, 6)</span></p>
<p>Questionnaires elicit three types of data:</p>
<ul>
<li>Factual</li>
<li>Behavioral</li>
<li>Attitudinal</li>
</ul>
<p>While factual and behavioral questions are about what the respondent is and does, attitudinal questions tap into what the respondent thinks or feels.</p>
<p>The advantages of surveys are that they (a) offer a relative cheap, quick, and effective way to collect (targeted) data from a comparatively large set of people and (b) that they can be distributed or carried out in various formats (face-to-face, by telephone, by computer or via social media, or by postal service).</p>
<p>Disadvantages of questionnaires are that they prone to providing unreliable or unnatural data. Data gathered via surveys can be unreliable due to the social desirability bias which is the tendency of respondents to answer questions in a manner that will be viewed favorably by others. Thus, the data that surveys provide may not necessarily be representative of actual natural behavior.</p>
<p>Questionnaires and surveys are widely used in language research and thus one of the most common research designs. In this section, we will discuss what needs to kept in mind when designing questionnaires and surveys, what pieces of software or platforms one can use, options for visualizing questionnaire and survey data, statistical methods that are used to evaluate questionnaire and survey data (reliability), and which statistical methods are used in analyzing the data.</p>
</div>
<div id="things-to-consider-when-creating-surveys" class="section level1">
<h1><span class="header-section-number">2</span> Things to consider when creating surveys</h1>
<p>Here are some rules to consider during the creation of questionnaires and before the survey is distributed.</p>
<ul>
<li><p>Surveys should not be longer than they have to be while collecting all the data that are needed. It is crucial that questionnaire collects all necessary data (including socio-demographic details).</p></li>
<li><p>The language should be simple and easy to understand - this means that jargon should be avoided. Also, leading questions are to be avoided and value judgements on the side of the creators of questionnaires should be avoided to prevent social desirability bias.</p></li>
<li><p>Before distributing a questionnaire, it should be piloted. Piloting is essential to check if respondents understand the questions as intended, and to check how long it takes to answer the questions. Also, the people who are involved in the piloting should be allowed to provide feedback to avoid errors.</p></li>
<li><p>When questions go beyond simply collecting socio-demographic details and if the data contains test and filler items, the order of questions (within blocks) should be quasi-randomized. Quasi-randomization means that test items are not asked in direct succession and that they do not appear as first or last items. Quasi-randomization helps to avoid fatigue effects or results that are caused by the ordering of questions. However, the questions should still follow an internally consistent logic so that related questions appear in the same block. Also, more specific questions should be asked after more general questions.</p></li>
<li><p>Questions must be unambigious and not refer to different aspects at once. Take, for instance, the following question:</p>
<ul>
<li>Do you consider UQ to be a good university with respect to teaching and research?".</li>
</ul>
<p>If the resondent answers positively, then no issue arise but if the answer id “No”, then we do not know if the respondent thinks that UQ is not a good university with respect to teaching OR with resepct to research OR both! In such cases, questions should be split:</p>
<ul>
<li><p>Do you consider UQ to be a good university with respect to teaching?</p></li>
<li><p>Do you consider UQ to be a good university with respect to research?"</p></li>
</ul></li>
<li><p>To check if respondents are concentrated, read the questions carefilly, and answering truthfully, it is useful to include reverse questions, i.e. questions that have the opposite polarity. Reverse questions allow to check if respondents only answers “very satisfied” or “completely agree” without respect to the content of the question. Giving the same answer toquestions which have opposite propositions would indicate that respondents do not erad questions carefully or do not answer truthfully.</p></li>
<li><p>If questions are not open or unstructured, i.e. if differnt options to answer to a question are provided, it is crucial that the options are fine-grained enough so that the data that is collected allows us to answer the research question that we want to investigate. In this context, the scaling of answer options is important. Scales reflect different types of answering options and they come in three basic forms: nominal and categorical, ordinal, or numeric.</p>
<ul>
<li><p><em>Nominal and categorical scales</em>: Nominal and categorical scales only list the membership of a particular class. Nominal scales offer exactly two options (yes/no or on/off), while categorical scales offer several options (e.g. the state in which someone was born).</p></li>
<li><p><em>Ordinal scales</em>: With <em>ordinal scales</em> it is possible to rank the values, but the distances between the ranks can not be exactly quantified. An example of an ordinal scales is the ranking in a 100-meter run. The 2nd in a 100-meter run did not go twice as fast as the 4th. It is often the case that ordinal variables consist of integer, positive numbers (1, 2, 3, 4, etc.). In the context of surveys, ordinal scales are the most important as all Likert scales (after the psychologist Rensis Likert) are ordinal scales. The levels of the typical five-level Likert item could be: <em>Strongly disagree (1)</em>, <em>Disagree (2) </em>, <em>Neither agree nor disagree (3)</em>, <em>Agree (4)</em>, and <em>Strongly agree (5)</em>. As such, the Likert scale is a bipolar scale that can be balanced, if there is an uneven number of options with the center option being neutral, or unbalaced, if there are an even number of options which forces respondents to express a preferences for wither of the two poles (this is called a “forced choice” method.</p></li>
<li><p><em>(True) Numeric scales</em>: There are two basic types of numeric scales: <em>interval-scales</em> and <em>ratio-scales</em>. For <em>interval scales</em>, the differences between levels are significant, but not the relationship between levels. For instance, 20 degree Celsius is not twice as hot as 10 degree Celsius. For <em>ratio-scales</em> both the differences and the relationships between the levels are significant (e.g. the times in a 100-meter dash: 10 is exactly twice as high as 5 and half as much as 20).</p></li>
</ul></li>
</ul>
</div>
<div id="visualizing-survey-data" class="section level1">
<h1><span class="header-section-number">3</span> Visualizing survey data</h1>
<p>Just as the data that is provided by surveys and questionnaires can take various forms, there are numerous ways to display survey data. In the following, we will have a look at some of the most common or useful ways in which survey and questionnaire data can be visualized.</p>
<p><strong>Line graphs for Likert-scaled data</strong></p>
<p>A special case of line graphs is used when dealing with Likert-scaled variables. In such cases, the line graph displays the density of cumulative frequencies of responses. The difference between the cumulative frequencies of responses displays differences in preferences. We will only focus on how to create such graphs using the “ggplot” environment here as it has an inbuild function (“ecdf”) which is designed to handle such data.</p>
<p>In a first step, we create a data set which consists of a Likert-scaled variable. The fictitious data created here consists of rating of students from three courses about how satisfied they were with their language-learning course. The response to the Likert item is numeric so that “strongly disagree/very dissatisfied” would get the lowest and “strongly agree/very satisfied” the highest numeric value.</p>
<pre class="r"><code># activate packages
library(knitr)
library(lattice)             
library(ggplot2)               
library(dplyr)
library(likert) 
library(MASS)
# load data
plotdata &lt;- read.delim(&quot;https://slcladal.github.io/data/lmmdata.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
likertdata1 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata1.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
likertdata2 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata2.txt&quot;, 
                       sep = &quot;\t&quot;, header = TRUE)
# inspect data
kable(head(likertdata1), caption = &quot;First 6 rows of likertdata1&quot;)</code></pre>
<table>
<caption>First 6 rows of likertdata1</caption>
<thead>
<tr class="header">
<th align="left">Course</th>
<th align="right">Satisfaction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Now that we have data resembling a Likert-scaled item from a questionnaire, we will display the data in a cumulative line graph.</p>
<pre class="r"><code># activate package
library(ggplot2)
# create cumulative density plot
ggplot(likertdata1,
       aes(x = Satisfaction, color = Course)) + 
  geom_step(aes(y = ..y..), stat = &quot;ecdf&quot;) +
  labs(y = &quot;Cumulative Density&quot;) + 
  scale_x_discrete(limits = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;), 
                   breaks = c(1,2,3,4,5),
                   labels=c(&quot;very dissatisfied&quot;, &quot;dissatisfied&quot;, 
                            &quot;neutral&quot;, &quot;satisfied&quot;, &quot;very satisfied&quot;)) + 
  scale_colour_manual(values = c(&quot;goldenrod2&quot;, &quot;indianred4&quot;, &quot;blue&quot;)) + 
  theme_bw() </code></pre>
<p><img src="surveys_files/figure-html/line_03-1.png" width="672" /></p>
<p>The satisfaction of the German course was the lowest as the red line shows the highest density (frequency of responses) of “very dissatisfied” and “dissatisfied” ratings. The students in our fictitious data set were most satisfied with the Chinese course as the blue line is the lowest for “very dissatisfied” and “dissatisfied” ratings while the difference between the courses shrinks for “satisfied” and “very satisfied”. The Japanese language course is in-between the German and the Chinese course.</p>
<p><strong>Pie charts</strong></p>
<p>Most commonly, the data for visualization comes from tables of absolute frequencies associated with a categorical or nominal variable. The default way to visualize such frequency tables are pie charts and bar plots.</p>
<p>In a first step, we modify the original data to get counts and percentages. The data represents the number of documents per time period and the percentage of those documents across all time periods.</p>
<pre class="r"><code># create bar plot data
bardata &lt;- likertdata1 %&gt;%
  group_by(Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;)))
# inpsect data
# inspect data
kable(head(bardata), caption = &quot;First 6 rows of bardata&quot;)</code></pre>
<p>Before creating bar plots, we will briefly turn to pie charts because pie charts are very common despite suffering from certain shortcomings. Consider the following example which highlights some of the issues that arise when using pie charts.</p>
<pre class="r"><code># create pie chart
ggplot(bardata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void()</code></pre>
<p><img src="surveys_files/figure-html/pie_03-1.png" width="672" /></p>
<p>If the slices of the pie chart are not labelled, it is difficult to see which slices are smaller or bigger compared to other slices. This problem can easily be avoided when using a bar plot instead.</p>
<p>The labelling of pie charts is, however, somewhat tedious as the positioning is tricky. Below is an example for adding labels without specification.</p>
<pre class="r"><code># create pie chart
ggplot(bardata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Percent, label = Percent), color = &quot;white&quot;, size=6)</code></pre>
<p><img src="surveys_files/figure-html/pie_05-1.png" width="672" /></p>
<p>To place the labels where they make sense, we will add another variable to the data called “Position”.</p>
<pre class="r"><code>piedata &lt;- bardata %&gt;%
  dplyr::arrange(desc(Satisfaction)) %&gt;%
  dplyr::mutate(Position = cumsum(Percent)- 0.5*Percent)
# inspect data
kable(head(piedata), caption = &quot;First 6 rows of piedata&quot;)</code></pre>
<table>
<caption>First 6 rows of piedata</caption>
<thead>
<tr class="header">
<th align="left">Satisfaction</th>
<th align="right">Frequency</th>
<th align="right">Percent</th>
<th align="right">Position</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">very satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
<td align="right">8.35</td>
</tr>
<tr class="even">
<td align="left">satisfied</td>
<td align="right">50</td>
<td align="right">16.7</td>
<td align="right">25.05</td>
</tr>
<tr class="odd">
<td align="left">neutral</td>
<td align="right">60</td>
<td align="right">20.0</td>
<td align="right">43.40</td>
</tr>
<tr class="even">
<td align="left">dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
<td align="right">65.05</td>
</tr>
<tr class="odd">
<td align="left">very dissatisfied</td>
<td align="right">70</td>
<td align="right">23.3</td>
<td align="right">88.35</td>
</tr>
</tbody>
</table>
<p>Now that we have specified the position, we can include it into the pie chart.</p>
<pre class="r"><code># create pie chart
ggplot(piedata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Position, label = Percent), color = &quot;white&quot;, size=6)</code></pre>
<p><img src="surveys_files/figure-html/pie_09-1.png" width="672" /></p>
<p>We will now create separate pie charts for each course. In a first step, we cerate a data set that does not only contain the Satisfaction levels and their frequency but also the course.</p>
<pre class="r"><code># create grouped pie data
groupedpiedata &lt;- likertdata1 %&gt;%
  group_by(Course, Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;))) %&gt;%
  dplyr::arrange(desc(Satisfaction)) %&gt;%
  dplyr::mutate(Position = cumsum(Percent)- 0.5*Percent)
# inspect data
kable(head(groupedpiedata), caption = &quot;First 6 rows of groupedpiedata&quot;)</code></pre>
<table>
<caption>First 6 rows of groupedpiedata</caption>
<thead>
<tr class="header">
<th align="left">Course</th>
<th align="left">Satisfaction</th>
<th align="right">Frequency</th>
<th align="right">Percent</th>
<th align="right">Position</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Chinese</td>
<td align="left">very satisfied</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">7.5</td>
</tr>
<tr class="even">
<td align="left">German</td>
<td align="left">very satisfied</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2.5</td>
</tr>
<tr class="odd">
<td align="left">Japanese</td>
<td align="left">very satisfied</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">15.0</td>
</tr>
<tr class="even">
<td align="left">Chinese</td>
<td align="left">satisfied</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">20.0</td>
</tr>
<tr class="odd">
<td align="left">German</td>
<td align="left">satisfied</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">12.5</td>
</tr>
<tr class="even">
<td align="left">Japanese</td>
<td align="left">satisfied</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">42.5</td>
</tr>
</tbody>
</table>
<p>Now that we have created the data, we can plot separate pie charts for each course.</p>
<pre class="r"><code># create pie chart
ggplot(groupedpiedata,  aes(&quot;&quot;, Percent, fill = Satisfaction)) + 
  facet_wrap(~Course) +
  geom_bar(stat=&quot;identity&quot;, width=1, color = &quot;white&quot;) +
  coord_polar(&quot;y&quot;, start=0) +
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  theme_void() +
  geom_text(aes(y = Position, label = Percent), color = &quot;white&quot;, size=4)</code></pre>
<p><img src="surveys_files/figure-html/pie_15-1.png" width="672" /></p>
<p><strong>Bar plots</strong></p>
<p>Like pie charts, bar plot display frequency information across categorical variable levels.</p>
<pre class="r"><code># bar plot
ggplot(bardata, aes(Satisfaction, Percent, fill = Satisfaction)) +
  # determine type of plot
  geom_bar(stat=&quot;identity&quot;) +          
  # use black &amp; white theme
  theme_bw() +                         
  # add and define text
  geom_text(aes(y = Percent-5, label = Percent), color = &quot;white&quot;, size=3) + 
  # add colors
  scale_fill_manual(values = c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, 
                               &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  # supress legend
  theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="surveys_files/figure-html/bar_01-1.png" width="672" /></p>
<p>Compared with the pie chart, it is much easier to grasp the relative size and order of the percentage values which shows that pie charts are unfit to show relationships between elements in a graph and, as a general rule of thumb, should be avoided.</p>
<p>Bar plot can be grouped to add another layer of information which is particularly useful when dealing with frequency counts across multiple categorical variables. But before we can create grouped bar plots, we need to create an appropriate data set.</p>
<pre class="r"><code># create bar plot data
groupedbardata &lt;- likertdata1 %&gt;%
  group_by(Course, Satisfaction) %&gt;%
  dplyr::summarise(Frequency = n()) %&gt;%
  dplyr::mutate(Percent = round(Frequency/sum(Frequency)*100, 1)) %&gt;%
  dplyr::mutate(Satisfaction = ifelse(Satisfaction == 1, &quot;very dissatisfied&quot;,
                               ifelse(Satisfaction == 2, &quot;dissatisfied&quot;,
                               ifelse(Satisfaction == 3, &quot;neutral&quot;, 
                               ifelse(Satisfaction == 4, &quot;satisfied&quot;, 
                               ifelse(Satisfaction == 5, &quot;very satisfied&quot;, Satisfaction)))))) %&gt;%
  dplyr::mutate(Satisfaction = factor(Satisfaction, 
                                      levels = c(&quot;very dissatisfied&quot;,
                                                 &quot;dissatisfied&quot;, 
                                                 &quot;neutral&quot;, 
                                                 &quot;satisfied&quot;, 
                                                 &quot;very satisfied&quot;)))
# inpsect data
kable(head(groupedbardata), caption = &quot;First 6 rows of groupedbardata&quot;)</code></pre>
<p>We have now added Genre as an additional categorical variable and will include Genre as the “fill” argument in our bar plot. To group the bars, we use the command “position=position_dodge()”.</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Satisfaction, Frequency, fill = Course)) + 
  geom_bar(stat=&quot;identity&quot;, position = position_dodge()) +  
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_05-1.png" width="672" /></p>
<p>If we leave out the “position=position_dodge()” argument, we get a stacked bar plot as shown below.</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Satisfaction, Frequency, fill = Course)) + 
  geom_bar(stat=&quot;identity&quot;) + 
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_07-1.png" width="672" /></p>
<p>One issue to consider when using stacked bar plots is the number of variable levels: when dealing with many variable levels, stacked bar plots tend to become rather confusing. This can be solved by either collapsing infrequent variable levels or choose a colour palette that reflects some other inherent piece of information such as <em>formality</em> (e.g. blue) versus <em>informality</em> (e.g. red).</p>
<p>Stacked bar plots can also be normalized so that changes in percentages become visible. This is done by exchanging “position=position_dodge()” with “position=”“fill”".</p>
<pre class="r"><code># bar plot
ggplot(groupedbardata, 
       aes(Course, Frequency, fill = Satisfaction)) + 
  geom_bar(stat=&quot;identity&quot;, position=&quot;fill&quot;) +  
  # define colors
  scale_fill_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  scale_color_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  labs(y = &quot;Percent&quot;) +
  scale_y_continuous(breaks=seq(0,1,.2),
                     labels=seq(0,100,20)) +
  theme_bw()                         </code></pre>
<p><img src="surveys_files/figure-html/bar_09-1.png" width="672" /></p>
<p><strong>Bar plots for Likert data</strong></p>
<p>Bar plots are particularly useful when visualizing data obtained through Likert items. As this is a very common issue that empirical researchers face. There are two basic ways to display Likert items using bar plots: grouped bar plots and more elaborate scaled bar plots.</p>
<p>Although we have seen above how to create grouped bar plots, we will repeat it here with the language course example used above when we used cumulative density line graphs to visualise how to display Likert data.</p>
<p>In a first step, we recreate the data set which we have used above. The data set consists of a Likert-scaled variable (Satisfaction) which represents rating of students from three courses about how satisfied they were with their language-learning course. The response to the Likert item is numeric so that “strongly disagree/very dissatisfied” would get the lowest and “strongly agree/very satisfied” the highest numeric value.</p>
<p>Now that we have data resembling a Likert-scaled item from a questionnaire, we will display the data in a cumulative line graph.</p>
<pre class="r"><code># create grouped bar plot
ggplot(groupedbardata, aes(Satisfaction, Frequency,  
                          fill = Course, color = Course)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge()) +
  geom_line() +
  # define colors
  scale_fill_manual(values=c(&quot;goldenrod2&quot;, &quot;gray70&quot;,  &quot;indianred4&quot;)) +
  scale_color_manual(values=c(&quot;goldenrod&quot;, &quot;gray60&quot;,  &quot;indianred&quot;)) +
  # add text and define colour
  geom_text(aes(label=Frequency), vjust=1.6, color=&quot;white&quot;, 
            # define text position and size
            position = position_dodge(0.9),  size=3.5) +     
  theme_bw()</code></pre>
<p><img src="surveys_files/figure-html/bar_11-1.png" width="672" /></p>
<p>Again, we can also plot separate bar graphs for each class by specifying “facets”.</p>
<pre class="r"><code># create grouped bar plot
ggplot(groupedbardata, aes(Satisfaction, Frequency,  
                          fill = Satisfaction, color = Satisfaction)) +
  facet_grid(rows = groupedbardata$Course) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge()) +
  geom_line() +
  # define colors
  scale_fill_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  scale_color_manual(values=c(&quot;firebrick4&quot;, &quot;firebrick1&quot;, &quot;gray70&quot;, 
                               &quot;blue&quot;, &quot;darkblue&quot;)) +
  # add text and define colour
  geom_text(aes(label=Frequency), vjust=1.6, color=&quot;white&quot;, 
            # define text position and size
            position = position_dodge(0.9),  size=3.5) +     
  theme_bw()</code></pre>
<p><img src="surveys_files/figure-html/bar_13-1.png" width="672" /></p>
<p>Another and very interesting way to display such data is by using the Likert package. In a first step, we need to activate the package, clean the data, and extract a subset for the data visualization example.</p>
<p>One aspect that is different to previous visualizations is that, when using the Likert package, we need to transform the data into a “likert” object (which is, however, very eays and is done by using the “likert()” function as shown below).</p>
<pre class="r"><code># load data
likertdata2 &lt;- read.delim(&quot;https://slcladal.github.io/data/likertdata2.txt&quot;, header = TRUE)
# transform into a likert object
likertdata2 &lt;- likert(likertdata2)
# inspect data
kable(likertdata2$results, caption = &quot;Summary of the data&quot;) </code></pre>
<table>
<caption>Summary of the data</caption>
<thead>
<tr class="header">
<th align="left">Item</th>
<th align="right">Agree</th>
<th align="right">Disagree</th>
<th align="right">Strongly agree</th>
<th align="right">Strongly disagree</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Question1</td>
<td align="right">14</td>
<td align="right">40</td>
<td align="right">8</td>
<td align="right">38</td>
</tr>
<tr class="even">
<td align="left">Question2</td>
<td align="right">26</td>
<td align="right">48</td>
<td align="right">14</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">Question3</td>
<td align="right">40</td>
<td align="right">20</td>
<td align="right">12</td>
<td align="right">28</td>
</tr>
<tr class="even">
<td align="left">Question4</td>
<td align="right">18</td>
<td align="right">40</td>
<td align="right">8</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="left">Question5</td>
<td align="right">44</td>
<td align="right">24</td>
<td align="right">10</td>
<td align="right">22</td>
</tr>
<tr class="even">
<td align="left">Question6</td>
<td align="right">12</td>
<td align="right">30</td>
<td align="right">4</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="left">Question7</td>
<td align="right">44</td>
<td align="right">28</td>
<td align="right">12</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">Question8</td>
<td align="right">12</td>
<td align="right">40</td>
<td align="right">12</td>
<td align="right">36</td>
</tr>
<tr class="odd">
<td align="left">Question9</td>
<td align="right">10</td>
<td align="right">32</td>
<td align="right">10</td>
<td align="right">48</td>
</tr>
<tr class="even">
<td align="left">Question10</td>
<td align="right">42</td>
<td align="right">22</td>
<td align="right">24</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<pre class="r"><code># inspect data
kable(head(likertdata2$items), caption = &quot;First 6 rows of the data&quot;) </code></pre>
<table>
<caption>First 6 rows of the data</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Question1</th>
<th align="left">Question2</th>
<th align="left">Question3</th>
<th align="left">Question4</th>
<th align="left">Question5</th>
<th align="left">Question6</th>
<th align="left">Question7</th>
<th align="left">Question8</th>
<th align="left">Question9</th>
<th align="left">Question10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Respondent1</td>
<td align="left">Disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td>Respondent2</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
<tr class="odd">
<td>Respondent3</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
</tr>
<tr class="even">
<td>Respondent4</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
</tr>
<tr class="odd">
<td>Respondent5</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Disagree</td>
<td align="left">Disagree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
<td align="left">Agree</td>
</tr>
<tr class="even">
<td>Respondent6</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly disagree</td>
<td align="left">Agree</td>
<td align="left">Strongly agree</td>
<td align="left">Strongly disagree</td>
</tr>
</tbody>
</table>
<p>After extracting a sample of the data, we plot it to show how the Likert data can be displayed.</p>
<pre class="r"><code># plot likert data
plot(likertdata2)</code></pre>
<p><img src="surveys_files/figure-html/bar_25-1.png" width="672" /></p>
</div>
<div id="useful-statistics-for-survey-data" class="section level1">
<h1><span class="header-section-number">4</span> Useful statistics for survey data</h1>
<p>This section introduces some statistical measures or tests that sueful when dealing with survey data. We will begin with measures of realiability (Cronbach’s <span class="math inline">\(\alpha\)</span>), then move on to methods for merging variables (Factor analysis and principle component naalysis), and finally to ordinal regression which tests which variables correlate with a certain outcome.</p>
<div id="cronbachs-alpha" class="section level2">
<h2><span class="header-section-number">4.1</span> Cronbach’s Alpha</h2>
<p><strong>Evaluating the reliability of questions: Cronbach’s Alpha</strong></p>
<p>Oftentimes several questions in one questionnaire aim to tap into the same cognitive concept or attitude or whatever we are interested in. The answers to these related questions should be internally consistent, i.e. the responses should correlate strongly and positively.</p>
<p>Cronbach’s <span class="math inline">\(\alpha\)</span> <span class="citation">(Cronbach <a href="#ref-cronbach1951alpha" role="doc-biblioref">1951</a>)</span> is measure of internal consistency or reliability that provides information on how strongly the responses to a set of questions correlate. The formula for Cronbach’s <span class="math inline">\(\alpha\)</span> is shown below (N: number of items, <span class="math inline">\(\bar c\)</span>: average inter-item co-variance among items, <span class="math inline">\(\bar v\)</span>: average variance).</p>
<p><span class="math inline">\(\alpha = \frac{N*\bar c}{\bar v + (N-1)\bar c}\)</span></p>
<p>If the values for Cronbach’s <span class="math inline">\(\alpha\)</span> are low (below .7), then this indicates that the questions are not internally consistent (and do not tap into the same concept) or that the questions are not uni-dimensional (as they should be).</p>
<p>While Cronbach’s <span class="math inline">\(\alpha\)</span> is the most frequently used measures of reliability (probably because it is conceptually simple and can be computed very easily), it underestimates the reliability of a test and overestimates the first factor saturation. This can be a problem is the data is <em>lumpy</em>. Thus, various other measuers of realiability have been proposed.</p>
<p>An alternative reliability measuer that takes the amount of variance per itsm into account and thus performs better when dealing with <em>lumpy</em> data (although it is still affected by <em>lumpyness</em>) is Guttman’s Lambda 6 (G6) <span class="citation">(Guttman <a href="#ref-guttman1945lambda" role="doc-biblioref">1945</a>)</span>. In contrast to Cronbach’s <span class="math inline">\(\alpha\)</span>, G6 is mostly used to evaluate the reliability of individual test items though. This means that it provides information about how well individual questions reflect the concept that they aim to tap into.</p>
<p>Probably the best measures of reliability are <span class="math inline">\(\omega\)</span> (<em>omega</em>) measures. Hierarchical <span class="math inline">\(\omega\)</span> provides more appropriate estimates of the general factor saturation while total <span class="math inline">\(\omega\)</span> is a better estimate of the reliability of the total test compared to both Cronbach’s <span class="math inline">\(\alpha\)</span> and G6 <span class="citation">(Revelle and Zinbarg <a href="#ref-revelle2009coefficients" role="doc-biblioref">2009</a>)</span>.</p>
<p><strong>Calculating Cronbach’s alpha in R</strong></p>
<p>We will now calculate Cronbach’s <span class="math inline">\(\alpha\)</span> in R. In a first step, we activate the “psych” package and load as well as inspect the data.</p>
<pre class="r"><code># activate package
library(psych)
# load data
surveydata &lt;- read.delim(&quot;https://slcladal.github.io/data/surveydata1.txt&quot;, sep = &quot;\t&quot;, header = T)
# inpsect data
kable(head(surveydata), caption = &quot;First 6 rows of surveydata&quot;)</code></pre>
<table>
<caption>First 6 rows of surveydata</caption>
<thead>
<tr class="header">
<th align="left">Respondent</th>
<th align="right">Q01_Outgoing</th>
<th align="right">Q02_Outgoing</th>
<th align="right">Q03_Outgoing</th>
<th align="right">Q04_Outgoing</th>
<th align="right">Q05_Outgoing</th>
<th align="right">Q06_Intelligence</th>
<th align="right">Q07_Intelligence</th>
<th align="right">Q08_Intelligence</th>
<th align="right">Q09_Intelligence</th>
<th align="right">Q10_Intelligence</th>
<th align="right">Q11_Attitude</th>
<th align="right">Q12_Attitude</th>
<th align="right">Q13_Attitude</th>
<th align="right">Q14_Attitude</th>
<th align="right">Q15_Attitude</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Respondent_01</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Respondent_02</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">Respondent_03</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">Respondent_04</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="left">Respondent_05</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="left">Respondent_06</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>The inspection of the data shows that the responses of participants represent the rows and that the questions represent columns. The column names show that we have 15 questions and that the first five questions aim to test how outgoing respondents are. To check if the first five questions reliably test “outgoingness” (or “extraversion”), we calculate Cronbach’s aplha for these five questions.</p>
<p>Thus, we use the “alpha()” function and provide the questions that tap into the concept we want to assess. In addition to Cronbach’s <span class="math inline">\(\alpha\)</span>, the “alpha()” function also reports Guttman’s lambda_6 which is an alternative measure for realiability. This is an advantage becuse Cronbach’s <span class="math inline">\(\alpha\)</span> underestimates the reliability of a test and overestimates the first factor saturation.</p>
<pre class="r"><code># calculate cronbach&#39;s alpha
Cronbach &lt;- alpha(surveydata[c(&quot;Q01_Outgoing&quot;,  
                   &quot;Q02_Outgoing&quot;,  
                   &quot;Q03_Outgoing&quot;,  
                   &quot;Q04_Outgoing&quot;,  
                   &quot;Q05_Outgoing&quot;)], check.keys=F)
# inspect results
Cronbach</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: alpha(x = surveydata[c(&quot;Q01_Outgoing&quot;, &quot;Q02_Outgoing&quot;, &quot;Q03_Outgoing&quot;, 
##     &quot;Q04_Outgoing&quot;, &quot;Q05_Outgoing&quot;)], check.keys = F)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r
##       0.98      0.98    0.97      0.89  42 0.0083  3.1 1.5      0.9
## 
##  lower alpha upper     95% confidence boundaries
## 0.96 0.98 0.99 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r S/N alpha se   var.r med.r
## Q01_Outgoing      0.97      0.97    0.97      0.89  33   0.0108 0.00099  0.89
## Q02_Outgoing      0.97      0.97    0.96      0.89  31   0.0116 0.00054  0.89
## Q03_Outgoing      0.97      0.97    0.97      0.90  35   0.0104 0.00095  0.90
## Q04_Outgoing      0.97      0.97    0.96      0.89  31   0.0115 0.00086  0.89
## Q05_Outgoing      0.98      0.98    0.97      0.91  41   0.0088 0.00034  0.91
## 
##  Item statistics 
##               n raw.r std.r r.cor r.drop mean  sd
## Q01_Outgoing 20  0.96  0.96  0.95   0.94  3.1 1.5
## Q02_Outgoing 20  0.97  0.97  0.96   0.95  3.2 1.6
## Q03_Outgoing 20  0.95  0.95  0.94   0.93  3.1 1.5
## Q04_Outgoing 20  0.97  0.97  0.96   0.95  3.0 1.6
## Q05_Outgoing 20  0.94  0.94  0.91   0.90  3.2 1.6
## 
## Non missing response frequency for each item
##                 1   2    3    4    5 miss
## Q01_Outgoing 0.20 0.2 0.10 0.25 0.25    0
## Q02_Outgoing 0.15 0.3 0.05 0.15 0.35    0
## Q03_Outgoing 0.15 0.3 0.05 0.25 0.25    0
## Q04_Outgoing 0.25 0.2 0.05 0.30 0.20    0
## Q05_Outgoing 0.20 0.2 0.10 0.20 0.30    0</code></pre>
<p>The output of the “alpha()” function is rather extensive and we will only interpret selected output here.</p>
<p>The value under alpha is Cronbach’s <span class="math inline">\(\alpha\)</span> and it should be above 0.7. The values to its left and right are the lower and upper bound of its confidence interval. The values in the column with the header “G6” show how well each question represents the concept it aims to reflect. Low values indicate that the question does not reflect the underyling concept while high values (.7 and higher) indicate that the question acptures that concept well (or to an acceptable degree).</p>
</div>
<div id="factor-analysis" class="section level2">
<h2><span class="header-section-number">4.2</span> Factor analysis</h2>
<p>When dealing with many variables it is often the case that several variables are related and represent a common, underlying factor. To find such underlying factors, we can use a factor analysis.</p>
<p>Factor analysis is a method that allows to find commonalities or structure in data. This is particularly useful when dealing with many variables. Factors can be considered hidden latent variables or driving forces that affect or underly serveral variables at once.</p>
<p>This becomes particularly apparent when considering sociodemographic variables as behaviors are not only dependent on single variables, e.g., economic status, but on the interaction of several additonal variables such as education level, marital status, number of children, etc. All of these variables can be combined into a single factor (or hidden latent variable).</p>
<pre class="r"><code># remove respondent
surveydata &lt;- surveydata %&gt;% 
  dplyr::select(-Respondent)
factoranalysis &lt;- factanal(surveydata, 3, rotation=&quot;varimax&quot;)
print(factoranalysis, digits=2, cutoff=.2, sort=TRUE)</code></pre>
<pre><code>## 
## Call:
## factanal(x = surveydata, factors = 3, rotation = &quot;varimax&quot;)
## 
## Uniquenesses:
##     Q01_Outgoing     Q02_Outgoing     Q03_Outgoing     Q04_Outgoing 
##             0.09             0.06             0.12             0.07 
##     Q05_Outgoing Q06_Intelligence Q07_Intelligence Q08_Intelligence 
##             0.14             0.10             0.13             0.10 
## Q09_Intelligence Q10_Intelligence     Q11_Attitude     Q12_Attitude 
##             0.28             0.41             0.08             0.14 
##     Q13_Attitude     Q14_Attitude     Q15_Attitude 
##             0.04             0.09             0.06 
## 
## Loadings:
##                  Factor1 Factor2 Factor3
## Q06_Intelligence -0.82    0.25    0.41  
## Q07_Intelligence -0.80            0.47  
## Q08_Intelligence -0.85            0.42  
## Q09_Intelligence -0.79            0.29  
## Q11_Attitude      0.96                  
## Q12_Attitude      0.92                  
## Q13_Attitude      0.97                  
## Q14_Attitude      0.95                  
## Q15_Attitude      0.96                  
## Q01_Outgoing              0.94          
## Q02_Outgoing              0.96          
## Q03_Outgoing              0.93          
## Q04_Outgoing              0.96          
## Q05_Outgoing              0.92          
## Q10_Intelligence -0.22   -0.46    0.57  
## 
##                Factor1 Factor2 Factor3
## SS loadings       7.29    4.78    1.02
## Proportion Var    0.49    0.32    0.07
## Cumulative Var    0.49    0.80    0.87
## 
## Test of the hypothesis that 3 factors are sufficient.
## The chi square statistic is 62.79 on 63 degrees of freedom.
## The p-value is 0.484</code></pre>
<p>The results of a factor analysis can be visualized so that questions which reflect the same underlying factor are grouped together.</p>
<pre class="r"><code># plot factor 1 by factor 2
load &lt;- factoranalysis$loadings[,1:2]
plot(load,type=&quot;n&quot;) # set up plot
text(load,
     labels=names(surveydata),
     cex=.7) # add variable names </code></pre>
<p><img src="surveys_files/figure-html/fa_04-1.png" width="672" /></p>
<p>The plot shows that the questions form groups which indicates that the questions do a rather good job at reflecting the concepts that they aim to tap into. The only problematic question is question 10 (Q10) which aimed to tap into the intelligence of respondents but appears not to correlate strongly with the other questions that aim to extract information about the respondents intelligance. In such cases, it makes sense, to remove a question (in this case Q10) from the survey as it does not appear to reflect waht we wanted it to.</p>
</div>
<div id="principle-component-analysis" class="section level2">
<h2><span class="header-section-number">4.3</span> Principle component analysis</h2>
<p>Principal component analysis is used when several questions or variables reflect a common factor and they should be combined into a single variable, e.g. during the statistical analysis of the data. Thus, principal component analysis can be used to collapse different variables (or questions) into one.</p>
<p>Imagine you have measured leghts of sentences in different ways (in words, syllables, characters, time it takes to pronounce, etc.). You could combine all these different measures of length by applying a PCA to those measures and using the first principal component as a single proxy for all these different measures.</p>
<pre class="r"><code># entering raw data and extracting PCs  from the correlation matrix
PrincipalComponents &lt;- princomp(surveydata[c(&quot;Q01_Outgoing&quot;,    
                   &quot;Q02_Outgoing&quot;,  
                   &quot;Q03_Outgoing&quot;,  
                   &quot;Q04_Outgoing&quot;,  
                   &quot;Q05_Outgoing&quot;)], cor=TRUE)
summary(PrincipalComponents) # print variance accounted for</code></pre>
<pre><code>## Importance of components:
##                           Comp.1     Comp.2     Comp.3     Comp.4      Comp.5
## Standard deviation     2.1399452 0.41221349 0.33747971 0.29869830 0.218177126
## Proportion of Variance 0.9158731 0.03398399 0.02277851 0.01784413 0.009520252
## Cumulative Proportion  0.9158731 0.94985710 0.97263561 0.99047975 1.000000000</code></pre>
<p>The output shows that the first component (Comp.1) explains 91.58 percent of the variance. This shows that we only lose 8.42 percent of the variance if we use this component as a proxy for “outgoingness” if we use th collapsed componnet rather than the five individual items.</p>
<pre class="r"><code>loadings(PrincipalComponents) # pc loadings</code></pre>
<pre><code>## 
## Loadings:
##              Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## Q01_Outgoing  0.448  0.324         0.831       
## Q02_Outgoing  0.453  0.242 -0.408 -0.360  0.663
## Q03_Outgoing  0.446  0.405  0.626 -0.405 -0.286
## Q04_Outgoing  0.452 -0.191 -0.568 -0.114 -0.650
## Q05_Outgoing  0.437 -0.798  0.342         0.230
## 
##                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## SS loadings       1.0    1.0    1.0    1.0    1.0
## Proportion Var    0.2    0.2    0.2    0.2    0.2
## Cumulative Var    0.2    0.4    0.6    0.8    1.0</code></pre>
<p>We now check if the five questions that are intended to tap into “outgoingness” represent one (and not more) underlying factors. Do check this, we create a scree plot.</p>
<pre class="r"><code>plot(PrincipalComponents,type=&quot;lines&quot;) # scree plot</code></pre>
<p><img src="surveys_files/figure-html/pca_07-1.png" width="672" /></p>
<p>The scree plot shown above indicates that we only need a single component to explain the variance as there is a steep decline from the first to the second component. This confims that the questions that tap into “outgoingness” represent one (and not more) underlying factors.</p>
<pre class="r"><code>PrincipalComponents$scores # the principal components</code></pre>
<pre><code>##           Comp.1      Comp.2      Comp.3       Comp.4      Comp.5
##  [1,]  1.8381566 -0.36615228 -0.05472481 -0.185982784  0.45151980
##  [2,]  1.8663059  0.49141424  0.43588461  0.293520579 -0.29327024
##  [3,]  2.1435874 -0.43109571 -0.14566197  0.529200331 -0.37631017
##  [4,]  2.4439739  0.12865309  0.39433418  0.093406447  0.28596101
##  [5,]  2.1362155 -0.49209851 -0.42957061 -0.260901209  0.02261552
##  [6,]  2.4573568  0.52187899 -0.20319399 -0.014602480 -0.29283073
##  [7,]  2.1362155 -0.49209851 -0.42957061 -0.260901209  0.02261552
##  [8,]  1.8506180 -0.24517164  0.63889114 -0.230285827 -0.17380089
##  [9,]  1.8538444  0.37043360 -0.25773134  0.337823622  0.33205045
## [10,]  1.8589340  0.43041145  0.15197597 -0.496580962  0.10565545
## [11,] -2.2853351  0.62953122  0.07366357  0.047245923  0.18176903
## [12,] -0.8111853  0.23229139 -0.69790263  0.254191848 -0.06639018
## [13,] -1.1175602 -0.31734547  0.16385834  0.595405408  0.08305777
## [14,] -2.2853351  0.62953122  0.07366357  0.047245923  0.18176903
## [15,] -2.2876401  0.28617124 -0.32085807 -0.584569410 -0.27755336
## [16,] -2.8994684 -0.54085723  0.11151975  0.034151826  0.06787149
## [17,] -1.7026001 -0.01558712 -0.07849987  0.005417999 -0.09724779
## [18,] -3.1841445 -0.02168511 -0.11116261  0.001061325 -0.08201597
## [19,] -1.1124706 -0.25736763  0.57356565 -0.238999176 -0.14333724
## [20,] -2.8994684 -0.54085723  0.11151975  0.034151826  0.06787149</code></pre>
<pre class="r"><code>biplot(PrincipalComponents) </code></pre>
<p><img src="surveys_files/figure-html/pca_11-1.png" width="672" /></p>
</div>
<div id="ordinal-regression" class="section level2">
<h2><span class="header-section-number">4.4</span> Ordinal Regression</h2>
<p>Ordinal regression is very similar to multiple linear regression but takes an ordinal dependent variable <span class="citation">(Agresti <a href="#ref-agresti2010analysis" role="doc-biblioref">2010</a>)</span>. For this reason, ordinal regression is one of the key methods in analysing Likert data.</p>
<p>To see how an ordinal regression is implemented in R, we load and inspect the “ordinaldata” data set. The data set consists of 400 observations of students that were either educated at this school (Internal = 1) or not (Internal = 0). Some of the students have been abroad (Exchange = 1) while other have not (Exchange = 0). In addition, the data set contains the students’ final score of a language test (FinalScore) and the dependent variable which the recommendation of a committee for an additional, very prestigious program. The recommendation has three levels (“very likely”, “somewhat likely”, and “unlikely”) and reflects the committees’ assessment of whether the student is likely to succeed in the program.</p>
<pre class="r"><code># load data
ordata &lt;- read.delim(&quot;https://slcladal.github.io/data/ordinaldata.txt&quot;, sep = &quot;\t&quot;, header = T)
colnames(ordata) &lt;- c(&quot;Recommend&quot;, &quot;Internal&quot;, &quot;Exchange&quot;, &quot;FinalScore&quot;)
# inspect data
str(ordata)</code></pre>
<pre><code>## &#39;data.frame&#39;:    400 obs. of  4 variables:
##  $ Recommend : Factor w/ 3 levels &quot;somewhat likely&quot;,..: 3 1 2 1 1 2 1 1 2 1 ...
##  $ Internal  : int  0 1 1 0 0 0 0 0 0 1 ...
##  $ Exchange  : int  0 0 1 0 0 1 0 0 0 0 ...
##  $ FinalScore: num  3.26 3.21 3.94 2.81 2.53 ...</code></pre>
<p>In a first step, we need to relevel the ordinal variable to represent an ordinal factor (or a progression from “unlikely” over “somewhat likely” to “very likely”. And we will also factorize Internal and Exchange to make it easier to interpret the output later on.</p>
<pre class="r"><code># relevel data
ordata &lt;- ordata %&gt;%
dplyr::mutate(Recommend = factor(Recommend, 
                           levels=c(&quot;unlikely&quot;, &quot;somewhat likely&quot;, &quot;very likely&quot;),
                           labels=c(&quot;unlikely&quot;,  &quot;somewhat likely&quot;,  &quot;very likely&quot;))) %&gt;%
  dplyr::mutate(Exchange = ifelse(Exchange == 1, &quot;Exchange&quot;, &quot;NoExchange&quot;)) %&gt;%
  dplyr::mutate(Internal = ifelse(Internal == 1, &quot;Internal&quot;, &quot;External&quot;))</code></pre>
<p>Now that the dependent variable is releveled, we check the distribution of the variable levels by tabulating the data. To get a better understanding of the data we create frequency tables across variables rather than viewing the variables in isolation.</p>
<pre class="r"><code>## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Exchange + Recommend + Internal, data = ordata))</code></pre>
<pre><code>##                            Internal External Internal
## Exchange   Recommend                                 
## Exchange   unlikely                       25        6
##            somewhat likely                12        4
##            very likely                     7        3
## NoExchange unlikely                      175       14
##            somewhat likely                98       26
##            very likely                    20       10</code></pre>
<p>We also check the mean and standard deviation of the final score as final score is a numeric variable and cannot be tabulated (unless we convert it to a factor).</p>
<pre class="r"><code>summary(ordata$FinalScore); sd(ordata$FinalScore)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.900   2.720   2.990   2.999   3.270   4.000</code></pre>
<pre><code>## [1] 0.3979409</code></pre>
<p>The lowest score is 1.9 and the highest score is a 4.0 with a mean of approximately 3. Finally, we inspect the distributions graphically.</p>
<pre class="r"><code># visualize data
ggplot(ordata, aes(x = Recommend, y = FinalScore)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) +
  facet_grid(Exchange ~ Internal, margins = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))</code></pre>
<p><img src="surveys_files/figure-html/orr5-1.png" width="672" /></p>
<p>We see that we have only few students that have taken part in an exchange program and there are also only few internal students overall. With respect to recommendations, only few students are considered to very likely succeed in the program. We can now start with the modelling by using the “polr” function. To make things easier for us, we will only consider the main effects here as this tutorial only aims to how to implement an ordinal regression but not how it should be done in a proper study - then, the model fitting and diagnostic procedures would have to be performed accurately, of course.</p>
<pre class="r"><code>## fit ordered logit model and store results &#39;m&#39;
m &lt;- polr(Recommend ~ Internal + Exchange + FinalScore, data = ordata, Hess=TRUE)
## view a summary of the model
summary(m)</code></pre>
<pre><code>## Call:
## polr(formula = Recommend ~ Internal + Exchange + FinalScore, 
##     data = ordata, Hess = TRUE)
## 
## Coefficients:
##                      Value Std. Error t value
## InternalInternal   1.04766     0.2658   3.942
## ExchangeNoExchange 0.05868     0.2979   0.197
## FinalScore         0.61574     0.2606   2.363
## 
## Intercepts:
##                             Value  Std. Error t value
## unlikely|somewhat likely    2.2620 0.8822     2.5641 
## somewhat likely|very likely 4.3574 0.9045     4.8177 
## 
## Residual Deviance: 717.0249 
## AIC: 727.0249</code></pre>
<p>The results show that having studied here at this school increases the chances of receiving a positive recommendation but that having been on an exchange has a negative but insignificant effect on the recommendation. The final score also correlates positively with a positive recommendation but not as much as having studied here.</p>
<pre class="r"><code>## store table
(ctable &lt;- coef(summary(m)))</code></pre>
<pre><code>##                                  Value Std. Error   t value
## InternalInternal            1.04766394  0.2657891 3.9417109
## ExchangeNoExchange          0.05868108  0.2978588 0.1970097
## FinalScore                  0.61574360  0.2606313 2.3625085
## unlikely|somewhat likely    2.26199764  0.8821736 2.5641185
## somewhat likely|very likely 4.35744190  0.9044678 4.8176858</code></pre>
<p>As the regression report does not provide p-values, we have to calculate them separately (after having calculated them, we add them to the coefficient table).</p>
<pre class="r"><code>## calculate and store p values
p &lt;- pnorm(abs(ctable[, &quot;t value&quot;]), lower.tail = FALSE) * 2
## combined table
(ctable &lt;- cbind(ctable, &quot;p value&quot; = p))</code></pre>
<pre><code>##                                  Value Std. Error   t value      p value
## InternalInternal            1.04766394  0.2657891 3.9417109 8.090244e-05
## ExchangeNoExchange          0.05868108  0.2978588 0.1970097 8.438199e-01
## FinalScore                  0.61574360  0.2606313 2.3625085 1.815173e-02
## unlikely|somewhat likely    2.26199764  0.8821736 2.5641185 1.034382e-02
## somewhat likely|very likely 4.35744190  0.9044678 4.8176858 1.452328e-06</code></pre>
<p>As predicted, Exchange does not have a significant effect but FinalScore and Internal both correlate significantly with the likelihood of receiving a positive recommendation.</p>
<pre class="r"><code># extract profiled confidence intervals
ci &lt;- confint(m)
# calculate odds ratios and combine them with profiled CIs
exp(cbind(OR = coef(m), ci))</code></pre>
<pre><code>##                          OR     2.5 %   97.5 %
## InternalInternal   2.850983 1.6958378 4.817114
## ExchangeNoExchange 1.060437 0.5950332 1.919771
## FinalScore         1.851033 1.1136253 3.098491</code></pre>
<p>The odds ratios show that internal students are 2.85 or 285 percent more likely compraed to non-internal students to receive positive evaluations and that a 1-point increase in the test score lead to a 1.85 or 185 percent increase in the chances of receiving a positive recommendation. The effect of an exchange is slightly negative but, as we have seen above, not significant.</p>
<p><strong>References</strong></p>
<div id="refs" class="references">
<div id="ref-agresti2010analysis">
<p>Agresti, Alan. 2010. <em>Analysis of Ordinal Categorical Data</em>. Vol. 656. John Wiley &amp; Sons.</p>
</div>
<div id="ref-brown2001surveys">
<p>Brown, James Dean. 2001. <em>Using Surveys in Language Programs</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-cronbach1951alpha">
<p>Cronbach, Lee J. 1951. “Coefficient Alpha and the Internal Strucuture of Tests.” <em>Psychometrika</em> 16: 297–334.</p>
</div>
<div id="ref-guttman1945lambda">
<p>Guttman, Louis. 1945. “A Basis for Analyzing Test-Retest Reliability.” <em>Psychometrika</em> 10 (4): 255–82.</p>
</div>
<div id="ref-revelle2009coefficients">
<p>Revelle, W., and Richard E. Zinbarg. 2009. “Coefficients Alpha, Beta, Omega and the Glb: Comments on Sijtsma.” <em>Psychometrika</em> 74 (1): 1145–54.</p>
</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
