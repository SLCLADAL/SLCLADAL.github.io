<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="UQ SLC Digital Team" />

<meta name="date" content="2019-08-13" />

<title>Classification</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-play-circle"></span>
     
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basics</li>
    <li>
      <a href="introquant.html">Introduction To Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts In Quantitative Reasoning</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Research Designs</li>
    <li>
      <a href="researchdesigns.html">Overview</a>
    </li>
    <li>
      <a href="corpling.html">Corpus Linguistics</a>
    </li>
    <li>
      <a href="experiments.html">Experimental Designs</a>
    </li>
    <li>
      <a href="acoustic.html">Acoustic Analysis</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Collection</li>
    <li>
      <a href="introdatacollection.html">Introduction</a>
    </li>
    <li>
      <a href="questionnaires.html">Questionnaires and Surveys</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Processing
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Processing</li>
    <li>
      <a href="intror.html">Basics: Getting started with R</a>
    </li>
    <li>
      <a href="introloading.html">Loading and saving data</a>
    </li>
    <li>
      <a href="stringprocessing.html">String processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular expressions</a>
    </li>
    <li>
      <a href="introtables.html">Tabulating data</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="dataprocessingexcel.html">Data Processing with Excel</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Visualization</li>
    <li>
      <a href="basicgraphs.html">Basic Visualization with R</a>
    </li>
    <li>
      <a href="maps.html">Geo-Spatial Data Visualizaion in R</a>
    </li>
    <li>
      <a href="motion.html">Motion Charts in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-eye"></span>
     
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Basic Interential Statistics</li>
    <li>
      <a href="basicstatz.html">Basic Inferential Tests</a>
    </li>
    <li>
      <a href="basicstatzchi.html">The Chi-Square Family</a>
    </li>
    <li>
      <a href="basicstatzregression.html">Simple Linear Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Advanced Interential Statistics</li>
    <li>
      <a href="fixedregressions.html">Fixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="mixedregressions.html">Mixed-Effects Regression Models</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Classification</a>
    </li>
    <li>
      <a href="collostructionalanalysis.html">Collostructional Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-bars"></span>
     
    Text Analysis/Corpus Linguistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Text Analysis</li>
    <li>
      <a href="textanalysis.html">Introduction</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling</a>
    </li>
    <li>
      <a href="network.html">Network Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="classification.html">Classification</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Corpus Linguistics</li>
    <li>
      <a href="corplingr.html">Corpus Linguistics in R</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    Contact
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Classification</h1>
<h4 class="author"><em>UQ SLC Digital Team</em></h4>
<h4 class="date"><em>2019-08-13</em></h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This tutorial introduces classification using “R”. The entire code for the sections below can be downloaded <a href="https://slcladal.github.io/rscripts/classificationscript.r">here</a>. Classification methods are used to find groups or patterns in data or to predict group membership. As such, they are widely used and applied in machine learning. For linguists classification is not only common when it comes to phylogenetics but also in annotation-based procedures such as part-of-speech tagging and syntactic parsing.</p>
</div>
<div id="preparation-and-session-set-up" class="section level1">
<h1><span class="header-section-number">2</span> Preparation and session set up</h1>
<p>As all caluculations and visualizations in this tutorial rely on “R”, it is necessary to install “R”, “RStudio”, and “Tinn-R”. If these programms (or, in the case of “R”, environments) are not already installed on your machine, please search for them in your favorite search engine and add the term “download”. Open any of the first few links and follow the installation instructions (they are easy to follow, do not require any specifications, and are pretty much self-explanatory).</p>
<p>In addition, certain “libraries” or “packages” need to be installed so that the scripts shown below are executed without errors. Before turning to the code below, please install the libraries by running the code below this paragraph. If you have already installed the libraries mentioned below, then you can skip ahead ignore this section. To install the necessary libraries, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # supress math annotation
# install libraries
install.packages(c(&quot;cluster&quot;, &quot;factoextra&quot;, &quot;cluster&quot;, 
                   &quot;seriation&quot;, &quot;pvclust&quot;, &quot;ape&quot;, &quot;vcd&quot;, 
                   &quot;exact2x2&quot;, &quot;factoextra&quot;, &quot;seriation&quot;, 
                   &quot;NbClust&quot;, &quot;pvclust&quot;))</code></pre>
<p>Once you have installed “R”, “R-Studio”, “Tinn-R”, and have also initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="cluster-analysis" class="section level1">
<h1><span class="header-section-number">3</span> Cluster Analysis</h1>
<p>The most common method in linguistics that is sued to detect groups in data are cluster analyses. Cluster analyses are common in linguistics because they not only detect commonalities based on the frequency or occurrence of featutres but they also allow to visualize when splits between groups have occurred and are thus the method of choice in historical linguistics to determine and show genealogical relationships.</p>
<div id="underlying-concepts" class="section level2">
<h2><span class="header-section-number">3.1</span> Underlying Concepts</h2>
<p>The next section focuses on the basic idea that underlies all cluster analyses. WE will have a look at some very basic examples to highlight and discuss the principles that cluster analyses rely on.</p>
<p>The underlying idea of cluster analysis is very simple and rather intuitive as we ourselves perform cluster analyses everyday in our our lives. This is so because we group things together under certain lables and into concepts. The first example to exemplyfy this deals with types of trees and how we group these types of trees based on their outward appearance.</p>
<p>Imagine you see six trees representing different types of trees: a pine tree, a fir tree, an oak tree, a beech tree, a phoenix palm tree, and a nikau palm tree. Now, you were asked to group these trees accroing to similarity. Have a look at the plot below and see whether you would have come up with a similar type of grouping.</p>
<p><img src="groupingstatz_files/figure-html/cl1-1.png" width="672" /></p>
<p>An alternative way to group the trees would be the follwoing.</p>
<p><img src="groupingstatz_files/figure-html/cl2-1.png" width="672" /></p>
<p>In this display, conifers and broad-leaf trees are grouped together because their are more similar to each other compared to palm trees. This poses the question of what is meant by similarity. Consider the display below.</p>
<p><img src="groupingstatz_files/figure-html/cl3-1.png" width="672" /></p>
<p>Are the red and the blue line more similar because they have the same shape or are the red and the black line more similar becaus etheir are closer together? Ther is no single correct answer here. Rather the plot indends to raise awarness about the fact that how cluster analyses group data depends on how similarity is defined in the respective algorithm.</p>
<p>Let’s consider another example to better understand how cluster analyses determine which data points should be merged when. Imagine you have five students adn want to group them togehter based on their overall performance in school. The data that you rely on are their grades in math, music, and biology (with 1 being the best grade and 6 being the worst).</p>
<table>
<caption>Sample of five students and their grades in math, music, and biology</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Math</th>
<th align="right">Music</th>
<th align="right">Biology</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>StudentA</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td>StudentB</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td>StudentC</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>StudentD</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td>StudentE</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">3</td>
</tr>
</tbody>
</table>
<p>The first step in determining the similarity among students is to create a distance matrix.</p>
<pre class="r"><code>diststudents &lt;- dist(students, method = &quot;manhattan&quot;) # create a distance matrix</code></pre>
<p>The distance matrix below shows that Student A and Student B only differ by one grade. Student B and Student C differ by 2 grades. Student A and Student C differ by 3 grades and so on.</p>
<table>
<caption>Distance matrix based of students based on grades in math, music, and biology.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">StudentA</th>
<th align="left">StudentB</th>
<th align="left">StudentC</th>
<th align="left">StudentD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>StudentB</td>
<td align="left">1</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td>StudentC</td>
<td align="left">3</td>
<td align="left">2</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td>StudentD</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">6</td>
<td align="left"></td>
</tr>
<tr class="even">
<td>StudentE</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">6</td>
<td align="left">2</td>
</tr>
</tbody>
</table>
<p>Based on this distance matrix, we can now implement a cluster analysis in <code>R</code>.</p>
</div>
<div id="cluster-analysis-numeric-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Cluster Analysis: Numeric Data</h2>
<p>To create a simple cluster object in <code>R</code>, we use the <code>hclust</code> function from the <code>cluster</code> package. The resulting object is then plotted to create a dentrogram which shows how students have been amalgamated (combined) by the clustering algorithm (which, in the present case, is called “ward.D”).</p>
<pre class="r"><code>library(&quot;cluster&quot;)    # activate library
clusterstudents &lt;- hclust( # hierarchical cluster object
  diststudents,       # use data diststudents
  method=&quot;ward.D&quot;)    # ward.D as linkage method
plot(clusterstudents, # plot result as dendrogram
     hang = 0)        # labels at split</code></pre>
<p><img src="groupingstatz_files/figure-html/cl8-1.png" width="672" /></p>
<p>Let us have a look at how the clustering algorythm has amalgamated the students. The amalgamation process takes the distance matrix from above as a starting point and, in a first step, has merged Student A and Student B (because they were the most similar students in the data based on the distance matrix). After colapsing Student A and Stdent B, the resulting distance matrix looks like the distance matrix below (notice that Student A and Student B now form a cluster that is represented by the means of the grades of the two students).</p>
<pre class="r"><code>students2 &lt;- matrix(c(1.5, 3, 2, 1,  2,  1, 2,  4,  4, 3,  4,  3),
  nrow = 4, byrow = T)
students2 &lt;- as.data.frame(students2)
rownames(students2) &lt;- c(&quot;Cluster1&quot;, &quot;StudentC&quot;, &quot;StudentD&quot;, &quot;StudentE&quot;)
diststudents2 &lt;- dist(students2, method = &quot;manhattan&quot;)</code></pre>
<table>
<caption>Distance matrix of students based on grades in math, music, and biology.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Cluster 1</th>
<th align="left">Student C</th>
<th align="left">Student D</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Student C</td>
<td align="left">2.5</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td>Student D</td>
<td align="left">3.5</td>
<td align="left">6.0</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td>Student E</td>
<td align="left">3.5</td>
<td align="left">6.0</td>
<td align="left">2.0</td>
</tr>
</tbody>
</table>
<p>The next lowest distnce now is 2.0 between Student D and Student E which means that these two students are merged next. The resulting distance matrix is shown below.</p>
<pre class="r"><code>students3 &lt;- matrix(c(1.5,3,2,1,2,1,2.5,4,3.5),
  nrow = 3, byrow = T)
students3 &lt;- as.data.frame(students3)
rownames(students3) &lt;- c(&quot;Cluster1&quot;, &quot;StudentC&quot;, &quot;Cluster2&quot;)
diststudents3 &lt;- dist(students3, 
                      method = &quot;manhattan&quot;)</code></pre>
<table>
<caption>Distance matrix based of students based on grades in math, music, and biology.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">Cluster 1</th>
<th align="left">Student C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Student C</td>
<td align="left">2.5</td>
<td align="left"></td>
</tr>
<tr class="even">
<td>Cluster 2</td>
<td align="left">3.5</td>
<td align="left">6.0</td>
</tr>
</tbody>
</table>
<p>Now, the lowest distance value occurs between Cluster 1 and Stundent C. Thus, Student Cand Cluster 1 are merged. In the final step, the Cluster 2 is merged with the new cluster encompassing Student C and Cluster 1. This amalgamtion process can then be displayed visually as a dendrogram (see above).</p>
<p>How and which elements are merged depends on the what is understood as distance. Since “distance” is such an important concept in cluster analyses, we will briefly discuss this notion to undertsand why there are so many different types of clustering algorithms and ths cluster analyses.</p>
<div id="distances" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Distances</h3>
<p>To understand how a cluster analysis determines to which cluster a given data point belongs, we need to understand what different distance measures represent. Have a look at the Figure below which visually represents three different ways to conceptualize distance.</p>
<pre class="r"><code>par(mar=c(1,1,1,1))  # define margine width of the plot
x &lt;- c(1,5)          # define an x value
y &lt;- c(1,5)          # define a y value
plot(x, y, 
     pch = 20, 
     cex = 1, 
     axes = F, 
     las = 1, 
     xlab = &quot;&quot;, 
     ylab = &quot;&quot;, 
     xlim = c(0,7), 
     ylim = c(0,10))
text(0.5, .5, &quot;Point A&quot;, cex = 1)
text(5, 5.5, &quot;Point B&quot;, cex = 1)
lines(x = c(1, 5), y = c(1, 5), type = &quot;l&quot;, lty = 3, lwd = 2, col = &quot;red&quot;)
lines(x = c(1, 5), y = c(1, 1), type = &quot;l&quot;, lty = 2, lwd = 2, col = &quot;blue&quot;)
lines(x = c(5, 5), y = c(1, 5), type = &quot;l&quot;, lty = 4, lwd = 2, col = &quot;green&quot;)
lines(x = c(.9, 5), y = c(.9, .9), type = &quot;l&quot;, lty = 4, lwd = 2, col = &quot;green&quot;)
legend(&quot;topleft&quot;, inset=.05, title=&quot;&quot;, bty = &quot;n&quot;, lty = c(3, 2, 4), lwd = 2,
   c(&quot;euclidean distance&quot;, &quot;maximum distance&quot;, &quot;manhatten distance&quot;), col=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;), horiz=F, cex = 1)</code></pre>
<p><img src="groupingstatz_files/figure-html/cl13-1.png" width="672" /></p>
<pre class="r"><code>par(mar=c(5.1,4.1,4.1,2.1))</code></pre>
<p>The Figure above depicts three ways to measure distance: the “eucledian distance” represents the distance between points as the hypothenuse of the x- and y-axis distances while the “maximum distance” represents distance as the longer distance of either the distance on the x- or the y-axis. The manhatten distance (or block distance) is the sum of the distances on the x- and the y-axis.</p>
<p>We will now turn to another example in order to delve a little deeper into how clustering algorithms work. In this example, we will find cluster of varieties of English based on the relative frequency of selected non-standard features (such as the relative freqeuncies of cleaft constructions and tag questions). As a frist setp, we generate some fictional data set for this analysis.</p>
<pre class="r"><code># generate data
IrishEnglish &lt;- round(sqrt((rnorm(10, 9.5, .5))^2), 3)
ScottishEnglish &lt;- round(sqrt((rnorm(10, 9.3, .4))^2), 3)
BritishEnglish &lt;- round(sqrt((rnorm(10, 6.4, .7))^2), 3)
AustralianEnglish &lt;- round(sqrt((rnorm(10, 6.6, .5))^2), 3)
NewZealandEnglish &lt;- round(sqrt((rnorm(10, 6.5, .4))^2), 3)
AmericanEnglish &lt;- round(sqrt((rnorm(10, 4.6, .8))^2), 3)
CanadianEnglish &lt;- round(sqrt((rnorm(10, 4.5, .7))^2), 3)
JamaicanEnglish &lt;- round(sqrt((rnorm(10, 1.4, .2))^2), 3)
PhillipineEnglish &lt;- round(sqrt((rnorm(10, 1.5, .4))^2), 3)
IndianEnglish &lt;- round(sqrt((rnorm(10, 1.3, .5))^2), 3)
clus &lt;- data.frame(IrishEnglish, ScottishEnglish, BritishEnglish, 
                   AustralianEnglish, NewZealandEnglish, AmericanEnglish, 
                   CanadianEnglish, JamaicanEnglish, PhillipineEnglish, IndianEnglish)
# add row names
rownames(clus) &lt;- c(&quot;nae_neg&quot;, &quot;like&quot;, &quot;clefts&quot;, &quot;tags&quot;, &quot;youse&quot;, &quot;soitwas&quot;, &quot;dt&quot;, &quot;nsr&quot;, &quot;invartag&quot;, &quot;wh_cleft&quot;)
summary(clus) # inspect results</code></pre>
<pre><code>##   IrishEnglish    ScottishEnglish  BritishEnglish  AustralianEnglish
##  Min.   : 8.657   Min.   : 8.732   Min.   :5.207   Min.   :5.417    
##  1st Qu.: 9.066   1st Qu.: 9.297   1st Qu.:5.889   1st Qu.:6.212    
##  Median : 9.527   Median : 9.422   Median :6.214   Median :6.308    
##  Mean   : 9.489   Mean   : 9.474   Mean   :6.379   Mean   :6.337    
##  3rd Qu.: 9.748   3rd Qu.: 9.589   3rd Qu.:6.902   3rd Qu.:6.598    
##  Max.   :10.623   Max.   :10.205   Max.   :7.761   Max.   :6.947    
##  NewZealandEnglish AmericanEnglish CanadianEnglish JamaicanEnglish
##  Min.   :5.548     Min.   :3.414   Min.   :2.406   Min.   :0.980  
##  1st Qu.:6.210     1st Qu.:3.851   1st Qu.:3.651   1st Qu.:1.266  
##  Median :6.551     Median :4.274   Median :4.231   Median :1.404  
##  Mean   :6.375     Mean   :4.458   Mean   :4.151   Mean   :1.399  
##  3rd Qu.:6.615     3rd Qu.:4.665   3rd Qu.:4.624   3rd Qu.:1.546  
##  Max.   :6.939     Max.   :6.227   Max.   :5.323   Max.   :1.772  
##  PhillipineEnglish IndianEnglish   
##  Min.   :1.323     Min.   :0.5530  
##  1st Qu.:1.549     1st Qu.:0.9815  
##  Median :1.778     Median :1.2725  
##  Mean   :1.736     Mean   :1.2968  
##  3rd Qu.:1.911     3rd Qu.:1.6818  
##  Max.   :2.112     Max.   :1.9010</code></pre>
<p>As a next step, we cerate a cluster object based on the data we have just generated.</p>
<pre class="r"><code># clean data
clust &lt;- t(clus)            # transpose data
clust &lt;- na.omit(clust)     # remove missing values
clusts &lt;- scale(clust)      # standardize variables
clusts &lt;- as.matrix(clusts) # convert into matrix
clust</code></pre>
<pre><code>##                   nae_neg  like clefts  tags youse soitwas    dt   nsr
## IrishEnglish        9.566 9.487  8.983 8.912 9.923   8.657 9.632 9.786
## ScottishEnglish     9.611 9.525 10.205 9.433 9.293   8.732 9.932 9.292
## BritishEnglish      6.126 5.968  5.687 5.207 6.302   5.863 6.504 7.034
## AustralianEnglish   6.304 6.947  6.190 5.417 6.677   6.311 6.189 6.279
## NewZealandEnglish   5.548 5.714  6.557 6.545 6.599   6.191 6.939 6.775
## AmericanEnglish     3.751 4.559  4.336 4.213 4.701   5.548 3.414 4.150
## CanadianEnglish     5.323 3.627  3.612 2.406 4.464   4.514 4.661 3.997
## JamaicanEnglish     1.262 1.573  0.980 1.364 1.444   1.772 1.533 1.226
## PhillipineEnglish   1.933 2.112  1.825 1.690 1.502   2.074 1.323 1.844
## IndianEnglish       0.787 1.001  0.975 1.887 1.704   1.164 1.901 1.615
##                   invartag wh_cleft
## IrishEnglish        10.623    9.316
## ScottishEnglish      9.310    9.411
## BritishEnglish       7.336    7.761
## AustralianEnglish    6.362    6.698
## NewZealandEnglish    6.267    6.620
## AmericanEnglish      3.680    6.227
## CanadianEnglish      5.184    3.721
## JamaicanEnglish      1.551    1.280
## PhillipineEnglish    1.324    1.730
## IndianEnglish        1.381    0.553</code></pre>
<p>We now assess if data is clusterable by testing whether or not the data includes nonrandom structures. To means to determine whether the data contains nonrandomness, we calculate the Hopkins statistic which informs how similar the data is to a random distribution. If the values of the Hopkins statistic are higher than 0.5 then this indicates that the data is random and that there are no inherent clusters. However, if the Hopkins statistic is close to 0, then the data is clusterable. The <code>n</code> in the <code>get_clust_tendency</code> functions represents the maximum number of clusters to be tested whcih should be number of predictors in the data.</p>
<pre class="r"><code>library(&quot;factoextra&quot;)         # load library to extract cluster tendency
clusttendency &lt;- get_clust_tendency(clusts,    # apply get_clust_tendency to cluster object
                   n = 9,     # define number of points from sampe speace 
                   gradient = list(low = &quot;steelblue&quot;,  # define color for low values 
                                   high = &quot;white&quot;))    # define color for high values
clusttendency[1]</code></pre>
<pre><code>## $hopkins_stat
## [1] 0.2491981</code></pre>
<p>As the Hopkins statistic above shows, there is sufficient structure in the data and we can assume that there are actual clusters in the data. Next, we create a distance matrix based on eucleadian distances.</p>
<pre class="r"><code>clustd &lt;- dist(clusts,                 # create distance matrix
               method = &quot;euclidean&quot;)   # use eucledian (!) distance
round(clustd, 2)                       # display distance matrix</code></pre>
<pre><code>##                   IrishEnglish ScottishEnglish BritishEnglish
## ScottishEnglish           0.64                               
## BritishEnglish            3.26            3.32               
## AustralianEnglish         3.25            3.26           0.66
## NewZealandEnglish         3.23            3.20           0.77
## AmericanEnglish           5.23            5.20           2.15
## CanadianEnglish           5.50            5.54           2.41
## JamaicanEnglish           8.26            8.26           5.10
## PhillipineEnglish         7.93            7.91           4.77
## IndianEnglish             8.38            8.37           5.24
##                   AustralianEnglish NewZealandEnglish AmericanEnglish
## ScottishEnglish                                                      
## BritishEnglish                                                       
## AustralianEnglish                                                    
## NewZealandEnglish              0.68                                  
## AmericanEnglish                2.05              2.14                
## CanadianEnglish                2.38              2.52            1.37
## JamaicanEnglish                5.06              5.11            3.26
## PhillipineEnglish              4.71              4.77            2.90
## IndianEnglish                  5.20              5.21            3.45
##                   CanadianEnglish JamaicanEnglish PhillipineEnglish
## ScottishEnglish                                                    
## BritishEnglish                                                     
## AustralianEnglish                                                  
## NewZealandEnglish                                                  
## AmericanEnglish                                                    
## CanadianEnglish                                                    
## JamaicanEnglish              2.91                                  
## PhillipineEnglish            2.62            0.49                  
## IndianEnglish                3.08            0.48              0.79</code></pre>
<p>Below are other methods to cerate distance matrices.</p>
<pre class="r"><code># create distance matrix (eucledian method: not good when dealing with many dimensions)
clustd &lt;- dist(clusts, method = &quot;euclidean&quot;)
# create distance matrix (maximum method: here the difference between points dominates)
clustd_maximum &lt;- round(dist(clusts, method = &quot;maximum&quot;), 2)
# create distance matrix (manhattan method: most popular choice)
clustd_manhatten &lt;- round(dist(clusts, method = &quot;manhattan&quot;), 2) 
# create distance matrix (canberra method: for count data only - focuses on small differences and neglects larger differences)
clustd_canberra &lt;- round(dist(clusts, method = &quot;canberra&quot;), 2)
# create distance matrix (binary method: for binary data only!)
clustd_binary &lt;- round(dist(clusts, method = &quot;binary&quot;), 2) 
# create distance matrix (minkowski method: is not a true distance measure)
clustd_minkowski &lt;- round(dist(clusts, method = &quot;minkowski&quot;), 2) 
# distance method for words: daisy (other possible distances are &quot;manhattan&quot; and &quot;gower&quot;)
library(cluster)
clustd_daisy &lt;- round(daisy(clusts, metric = &quot;euclidean&quot;), 2) </code></pre>
<p>If you call the individual distance matrices, you will see that depending on which distance measure is used, the distance matrices differ dramatically! Have alook at the distance matrix created using the manhatten metric and compare it to the distance matrix created using the eucledian metric (see above).</p>
<pre class="r"><code>clustd_maximum </code></pre>
<pre><code>##                   IrishEnglish ScottishEnglish BritishEnglish
## ScottishEnglish           0.40                               
## BritishEnglish            1.26            1.44               
## AustralianEnglish         1.29            1.36           0.32
## NewZealandEnglish         1.32            1.30           0.45
## AmericanEnglish           2.10            2.05           1.11
## CanadianEnglish           2.21            2.39           1.23
## JamaicanEnglish           2.76            2.88           1.97
## PhillipineEnglish         2.81            2.71           1.83
## IndianEnglish             2.80            2.89           2.19
##                   AustralianEnglish NewZealandEnglish AmericanEnglish
## ScottishEnglish                                                      
## BritishEnglish                                                       
## AustralianEnglish                                                    
## NewZealandEnglish              0.40                                  
## AmericanEnglish                0.87              1.11                
## CanadianEnglish                1.09              1.41            0.76
## JamaicanEnglish                1.76              1.78            1.50
## PhillipineEnglish              1.68              1.77            1.37
## IndianEnglish                  1.95              1.87            1.72
##                   CanadianEnglish JamaicanEnglish PhillipineEnglish
## ScottishEnglish                                                    
## BritishEnglish                                                     
## AustralianEnglish                                                  
## NewZealandEnglish                                                  
## AmericanEnglish                                                    
## CanadianEnglish                                                    
## JamaicanEnglish              1.30                                  
## PhillipineEnglish            1.17            0.26                  
## IndianEnglish                1.45            0.23              0.37</code></pre>
<p>Next, we create a distance plot using the <code>distplot</code> function. If the distance plot shows different regions (non random, non uniform grey areas) then clustering the data is permitable as the data contains actual structures.</p>
<pre class="r"><code>library(seriation)
dissplot(clustd)  # create distance plot</code></pre>
<p><img src="groupingstatz_files/figure-html/cl20-1.png" width="672" /></p>
<pre class="r"><code>cd &lt;- hclust(clustd,             # create cluster object
             method=&quot;ward.D2&quot;)   # ward.D2 linkage (minimum variance)
plot(cd, hang = -1)              # display dendogram</code></pre>
<p><img src="groupingstatz_files/figure-html/cl21-1.png" width="672" /></p>
<p>Other linkage methods.</p>
<pre class="r"><code># single linkage: cluster with nearest data point
cd_single &lt;- hclust(clustd, method=&quot;single&quot;) 
# create cluster object (ward.D linkage)
cd_wardd &lt;- hclust(clustd, method=&quot;ward.D&quot;)
# create cluster object (ward.D2 linkage): 
# cluster in a way to achieve minimum variance
cd_wardd2 &lt;- hclust(clustd, method=&quot;ward.D2&quot;)
# average linkage: cluster with closest mean
cd_average &lt;- hclust(clustd, method=&quot;average&quot;) 
# mcquitty linkage
cd_mcquitty &lt;- hclust(clustd, method=&quot;mcquitty&quot;) 
# median linkage: cluster with closest median
cd_median &lt;- hclust(clustd, method=&quot;median&quot;)
# centroid linkage: cluster with closest prototypical point of target cluster
cd_centroid &lt;- hclust(clustd, method=&quot;centroid&quot;) 
# complete linkage: cluster with nearest/furthest data point of target cluster
cd_complete &lt;- hclust(clustd, method=&quot;complete&quot;)  </code></pre>
<p>Now, we determine the optimal number of clusters based on silhouette widths which shows the ratio of internal similarity of clusters against the similarity between clusters. If the silhuette widths have values lower than .2 then this indicates that clustering is not appropriate (<span class="citation">(Levshina <a href="#ref-levshina2015linguistics">2015</a>)</span> 311). The function below displays the silhouette width values of 2 to 8 clusters.</p>
<pre class="r"><code>optclus &lt;- sapply(2:8, function(x) summary(silhouette(cutree(cd, k = x), clustd))$avg.width)
optclus # inspect results</code></pre>
<pre><code>## [1] 0.5498244 0.6537919 0.6882543 0.5985924 0.4158267 0.2195046 0.2020694</code></pre>
<pre class="r"><code>optnclust &lt;- which(optclus == max(optclus)) # determine optimal number of clusters
groups &lt;- cutree(cd, k=optnclust) # cut tree into optimal number of clusters</code></pre>
<p>The optimal number of clusters is the cluster solution with the highest silhouette width. We cut the tree into the optimal number of clusters and plot the result.</p>
<pre class="r"><code>groups &lt;- cutree(cd, k=optnclust)          # cut tree into optimal clusters
plot(cd, hang = -1, cex = .75)             # plot result as dendrogram
rect.hclust(cd, k=optnclust, border=&quot;red&quot;) # draw red borders around clusters</code></pre>
<p><img src="groupingstatz_files/figure-html/cl24-1.png" width="672" /></p>
<p>In a next step, we aim to determine which factors are particularly important for the clustering - this step is soemwhat comparable to measuring the effect size in inferential designs.</p>
<pre class="r"><code># which factors are particularly important
celtic &lt;- clusts[c(1,2),]
others &lt;- clusts[-c(1,2),]
# calculate column means
celtic.cm &lt;- colMeans(celtic)
others.cm &lt;- colMeans(others)
# calcualte difference between celtic and other englishes
diff &lt;- celtic.cm - others.cm
sort(diff, decreasing = F)</code></pre>
<pre><code>## wh_cleft  soitwas      nsr invartag    youse       dt   clefts     like 
## 1.530686 1.675524 1.742124 1.762687 1.766385 1.804296 1.821153 1.822933 
##  nae_neg     tags 
## 1.824098 1.896891</code></pre>
<pre class="r"><code>plot(                   # start plot
  sort(diff),           # y-values
  1:length(diff),       # x-values 
  type= &quot;n&quot;,            # plot type (empty)
  cex.axis = .75,       # axis font size
  cex.lab = .75,        # label font size
  xlab =&quot;Prototypical for Non-Celtic Varieties (Cluster 2) &lt;-----&gt; Prototypical for Celtic Varieties (Cluster 1)&quot;, # x-axis label
  yaxt = &quot;n&quot;,           # no y-axis tick marks
  ylab = &quot;&quot;)            # no y-axis label
text(sort(diff), 1:length(diff), names(sort(diff)), cex = .75) # plot text into plot</code></pre>
<p><img src="groupingstatz_files/figure-html/cl26-1.png" width="672" /></p>
<pre class="r"><code>Outer &lt;- clusts[c(6:8),]     # data of outer circle varieties
Inner &lt;- clusts[-c(6:8),]    # data of inner circle varieties
Outer.cm &lt;- colMeans(Outer)  # column means for outer circle
Inner.cm &lt;- colMeans(Inner)  # column means for inner circle
diff &lt;- Outer.cm - Inner.cm  # difference between inner and outer circle
sort(diff, decreasing = F)   # order difference between inner and outer circle</code></pre>
<pre><code>##       tags        nsr         dt     clefts       like      youse 
## -0.9935590 -0.9523073 -0.9006768 -0.8751450 -0.8410198 -0.8008619 
##   invartag    nae_neg   wh_cleft    soitwas 
## -0.7903622 -0.7192220 -0.6894647 -0.6032866</code></pre>
<pre class="r"><code>plot(                   # start plot
  sort(diff),           # y-values
  1:length(diff),       # x-values 
  type= &quot;n&quot;,            # plot type (empty)
  cex.axis = .75,       # axis font size
  cex.lab = .75,        # label font size
  xlab =&quot;Prototypical for Inner Circle Varieties (Cluster 2) &lt;-----&gt; Prototypical for Outer Circle Varieties (Cluster 1)&quot;, # x-axis label
  yaxt = &quot;n&quot;,           # no y-axis tick marks
  ylab = &quot;&quot;)            # no y-axis label
text(sort(diff), 1:length(diff), names(sort(diff)), cex = .75) # plot text into plot</code></pre>
<p><img src="groupingstatz_files/figure-html/cl28-1.png" width="672" /></p>
<p>We see that discourse like and and the frequency of like is typical for other varieties and that the use of youse as 2nd pl pronoun and inveáriant tags are typical for celtic englishes.</p>
<p>We will now test whether the cluster is justified by validating the cluster solution using bootstrapping.</p>
<pre class="r"><code>library(pvclust) # activate library
res.pv &lt;- pvclust(clus,                     # apply pvclust method to clus data
                  method.dist=&quot;euclidean&quot;,  # use eucledian distance
                  method.hclust=&quot;ward.D2&quot;,  # use ward.d2 linkage
                  nboot = 100)              # use 100 bootstrap runs</code></pre>
<pre><code>## Bootstrap (r = 0.5)... Done.
## Bootstrap (r = 0.6)... Done.
## Bootstrap (r = 0.7)... Done.
## Bootstrap (r = 0.8)... Done.
## Bootstrap (r = 0.9)... Done.
## Bootstrap (r = 1.0)... Done.
## Bootstrap (r = 1.1)... Done.
## Bootstrap (r = 1.2)... Done.
## Bootstrap (r = 1.3)... Done.
## Bootstrap (r = 1.4)... Done.</code></pre>
<p>The clustering provides approximately unbiased p-values and bootstrap probability value <span class="citation">(cf. <span class="citeproc-not-found" data-reference-id="levlevshina2015linguistics"><strong>???</strong></span>)</span>.</p>
<pre class="r"><code>plot(res.pv, 
     cex = .75)
pvrect(res.pv)</code></pre>
<p><img src="groupingstatz_files/figure-html/cl30-1.png" width="672" /></p>
<p>We can alsouse other libraries to customize the dendrograms.</p>
<pre class="r"><code>library(ape)            # load package ape
plot(as.phylo(cd),      # plot cluster object
     cex = 0.75,        # .75 font size
     label.offset = .5) # .5 label offset</code></pre>
<p><img src="groupingstatz_files/figure-html/cl31-1.png" width="672" /></p>
<p>One useful customization is to display an unrooted rather than a rooted tree diagram.</p>
<pre class="r"><code># plot as unrooted tree
plot(as.phylo(cd),      # plot cluster object
     type = &quot;unrooted&quot;, # plot as unrooted tree
     cex = .75,         # .75 font size
     label.offset = 1)  # .5 label offset</code></pre>
<p><img src="groupingstatz_files/figure-html/cl32-1.png" width="672" /></p>
</div>
</div>
<div id="cluster-analysis-nominal-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Cluster Analysis: Nominal Data</h2>
<pre class="r"><code># generate data
IrishEnglish &lt;- c(1,1,1,1,1,1,1,1,1,1)
ScottishEnglish &lt;- c(1,1,1,1,1,1,1,1,1,1)
BritishEnglish &lt;- c(0,1,1,1,0,0,1,0,1,1)
AustralianEnglish &lt;- c(0,1,1,1,0,0,1,0,1,1)
NewZealandEnglish &lt;- c(0,1,1,1,0,0,1,0,1,1)
AmericanEnglish &lt;- c(0,1,1,1,0,0,0,0,1,0)
CanadianEnglish &lt;- c(0,1,1,1,0,0,0,0,1,0)
JamaicanEnglish &lt;- c(0,0,1,0,0,0,0,0,1,0)
PhillipineEnglish &lt;- c(0,0,1,0,0,0,0,0,1,0)
IndianEnglish &lt;- c(0,0,1,0,0,0,0,0,1,0)
clus &lt;- data.frame(IrishEnglish, ScottishEnglish, BritishEnglish, 
                   AustralianEnglish, NewZealandEnglish, AmericanEnglish, 
                   CanadianEnglish, JamaicanEnglish, PhillipineEnglish, IndianEnglish)
# add row names
rownames(clus) &lt;- c(&quot;nae_neg&quot;, &quot;like&quot;, &quot;clefts&quot;, &quot;tags&quot;, &quot;youse&quot;, &quot;soitwas&quot;, &quot;dt&quot;, &quot;nsr&quot;, &quot;invartag&quot;, &quot;wh_cleft&quot;)
# convert into factors
clus &lt;- apply(clus, 1, function(x){
  x &lt;- as.factor(x) })
# inspect data
clus</code></pre>
<pre><code>##                   nae_neg like clefts tags youse soitwas dt  nsr invartag
## IrishEnglish      &quot;1&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;1&quot;   &quot;1&quot;     &quot;1&quot; &quot;1&quot; &quot;1&quot;     
## ScottishEnglish   &quot;1&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;1&quot;   &quot;1&quot;     &quot;1&quot; &quot;1&quot; &quot;1&quot;     
## BritishEnglish    &quot;0&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;0&quot;   &quot;0&quot;     &quot;1&quot; &quot;0&quot; &quot;1&quot;     
## AustralianEnglish &quot;0&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;0&quot;   &quot;0&quot;     &quot;1&quot; &quot;0&quot; &quot;1&quot;     
## NewZealandEnglish &quot;0&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;0&quot;   &quot;0&quot;     &quot;1&quot; &quot;0&quot; &quot;1&quot;     
## AmericanEnglish   &quot;0&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;0&quot;   &quot;0&quot;     &quot;0&quot; &quot;0&quot; &quot;1&quot;     
## CanadianEnglish   &quot;0&quot;     &quot;1&quot;  &quot;1&quot;    &quot;1&quot;  &quot;0&quot;   &quot;0&quot;     &quot;0&quot; &quot;0&quot; &quot;1&quot;     
## JamaicanEnglish   &quot;0&quot;     &quot;0&quot;  &quot;1&quot;    &quot;0&quot;  &quot;0&quot;   &quot;0&quot;     &quot;0&quot; &quot;0&quot; &quot;1&quot;     
## PhillipineEnglish &quot;0&quot;     &quot;0&quot;  &quot;1&quot;    &quot;0&quot;  &quot;0&quot;   &quot;0&quot;     &quot;0&quot; &quot;0&quot; &quot;1&quot;     
## IndianEnglish     &quot;0&quot;     &quot;0&quot;  &quot;1&quot;    &quot;0&quot;  &quot;0&quot;   &quot;0&quot;     &quot;0&quot; &quot;0&quot; &quot;1&quot;     
##                   wh_cleft
## IrishEnglish      &quot;1&quot;     
## ScottishEnglish   &quot;1&quot;     
## BritishEnglish    &quot;1&quot;     
## AustralianEnglish &quot;1&quot;     
## NewZealandEnglish &quot;1&quot;     
## AmericanEnglish   &quot;0&quot;     
## CanadianEnglish   &quot;0&quot;     
## JamaicanEnglish   &quot;0&quot;     
## PhillipineEnglish &quot;0&quot;     
## IndianEnglish     &quot;0&quot;</code></pre>
<pre class="r"><code># clean data
clusts &lt;- as.matrix(clus)
# create distance matrix
clustd &lt;- dist(clusts, method = &quot;binary&quot;)   # create a distance object with binary (!) distance
# display distance matrix
round(clustd, 2)</code></pre>
<pre><code>##                   IrishEnglish ScottishEnglish BritishEnglish
## ScottishEnglish           0.00                               
## BritishEnglish            0.40            0.40               
## AustralianEnglish         0.40            0.40           0.00
## NewZealandEnglish         0.40            0.40           0.00
## AmericanEnglish           0.60            0.60           0.33
## CanadianEnglish           0.60            0.60           0.33
## JamaicanEnglish           0.80            0.80           0.67
## PhillipineEnglish         0.80            0.80           0.67
## IndianEnglish             0.80            0.80           0.67
##                   AustralianEnglish NewZealandEnglish AmericanEnglish
## ScottishEnglish                                                      
## BritishEnglish                                                       
## AustralianEnglish                                                    
## NewZealandEnglish              0.00                                  
## AmericanEnglish                0.33              0.33                
## CanadianEnglish                0.33              0.33            0.00
## JamaicanEnglish                0.67              0.67            0.50
## PhillipineEnglish              0.67              0.67            0.50
## IndianEnglish                  0.67              0.67            0.50
##                   CanadianEnglish JamaicanEnglish PhillipineEnglish
## ScottishEnglish                                                    
## BritishEnglish                                                     
## AustralianEnglish                                                  
## NewZealandEnglish                                                  
## AmericanEnglish                                                    
## CanadianEnglish                                                    
## JamaicanEnglish              0.50                                  
## PhillipineEnglish            0.50            0.00                  
## IndianEnglish                0.50            0.00              0.00</code></pre>
<pre class="r"><code># create cluster object (ward.D2 linkage)   : cluster in a way to achieve minimum variance
cd &lt;- hclust(clustd, method=&quot;ward.D2&quot;)
# plot result as dendrogram
plot(cd, hang = -1)              # display dendogram</code></pre>
<p><img src="groupingstatz_files/figure-html/cl35-1.png" width="672" /></p>
<pre class="r"><code># create factor with celtic varieties on one hand and other varieties on other
cluster &lt;- as.factor(ifelse(as.character(rownames(clusts)) == &quot;IrishEnglish&quot;, &quot;1&quot;,
  ifelse(as.character(rownames(clusts)) == &quot;ScottishEnglish&quot;, &quot;1&quot;, &quot;0&quot;)))
# load library
library(vcd)
clsts.df &lt;- as.data.frame(clusts)
# determine significance
library(exact2x2)
pfish &lt;- fisher.exact(table(cluster, clsts.df$youse))
pfish[[1]]</code></pre>
<pre><code>## [1] 0.02222222</code></pre>
<pre class="r"><code># determine effect size
assocstats(table(cluster, clsts.df$youse))</code></pre>
<pre><code>##                     X^2 df  P(&gt; X^2)
## Likelihood Ratio 10.008  1 0.0015586
## Pearson          10.000  1 0.0015654
## 
## Phi-Coefficient   : 1 
## Contingency Coeff.: 0.707 
## Cramer&#39;s V        : 1</code></pre>
<pre class="r"><code>assocstats(table(cluster, clsts.df$like))</code></pre>
<pre><code>##                     X^2 df P(&gt; X^2)
## Likelihood Ratio 1.6323  1  0.20139
## Pearson          1.0714  1  0.30062
## 
## Phi-Coefficient   : 0.327 
## Contingency Coeff.: 0.311 
## Cramer&#39;s V        : 0.327</code></pre>
<pre class="r"><code>library(&quot;factoextra&quot;)
library(&quot;seriation&quot;)
library(&quot;NbClust&quot;)
library(&quot;pvclust&quot;)</code></pre>
</div>
</div>
<div id="correspondence-analysis" class="section level1">
<h1><span class="header-section-number">4</span> Correspondence Analysis</h1>
<pre class="r"><code># load libraries
library(&quot;FactoMineR&quot;)
library(&quot;factoextra&quot;)
# load preinstalled data
data(housetasks)
# inspect data
head(housetasks)</code></pre>
<pre><code>##            Wife Alternating Husband Jointly
## Laundry     156          14       2       4
## Main_meal   124          20       5       4
## Dinner       77          11       7      13
## Breakfeast   82          36      15       7
## Tidying      53          11       1      57
## Dishes       32          24       4      53</code></pre>
<pre class="r"><code># load library
library(&quot;gplots&quot;)
# 1. convert the data as a table
dt &lt;- as.table(as.matrix(housetasks))
# 2. Graph
balloonplot(t(dt), main =&quot;housetasks&quot;, xlab =&quot;&quot;, ylab=&quot;&quot;,
            label = FALSE, show.margins = FALSE)</code></pre>
<p><img src="groupingstatz_files/figure-html/ca1-1.png" width="672" /></p>
<pre class="r"><code>chisq &lt;- chisq.test(housetasks)
chisq</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  housetasks
## X-squared = 1944.5, df = 36, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>library(&quot;FactoMineR&quot;)
res.ca &lt;- CA(housetasks, graph = FALSE)
print(res.ca)</code></pre>
<pre><code>## **Results of the Correspondence Analysis (CA)**
## The row variable has  13  categories; the column variable has 4 categories
## The chi square of independence between the two variables is equal to 1944.456 (p-value =  0 ).
## *The results are available in the following objects:
## 
##    name              description                   
## 1  &quot;$eig&quot;            &quot;eigenvalues&quot;                 
## 2  &quot;$col&quot;            &quot;results for the columns&quot;     
## 3  &quot;$col$coord&quot;      &quot;coord. for the columns&quot;      
## 4  &quot;$col$cos2&quot;       &quot;cos2 for the columns&quot;        
## 5  &quot;$col$contrib&quot;    &quot;contributions of the columns&quot;
## 6  &quot;$row&quot;            &quot;results for the rows&quot;        
## 7  &quot;$row$coord&quot;      &quot;coord. for the rows&quot;         
## 8  &quot;$row$cos2&quot;       &quot;cos2 for the rows&quot;           
## 9  &quot;$row$contrib&quot;    &quot;contributions of the rows&quot;   
## 10 &quot;$call&quot;           &quot;summary called parameters&quot;   
## 11 &quot;$call$marge.col&quot; &quot;weights of the columns&quot;      
## 12 &quot;$call$marge.row&quot; &quot;weights of the rows&quot;</code></pre>
<pre class="r"><code># Chi-square statistics
chi2 &lt;- 1944.456
# Degree of freedom
df &lt;- (nrow(housetasks) - 1) * (ncol(housetasks) - 1)
# P-value
pval &lt;- pchisq(chi2, df = df, lower.tail = FALSE)
pval</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>library(&quot;factoextra&quot;)
eig.val &lt;- get_eigenvalue(res.ca)
eig.val</code></pre>
<pre><code>##       eigenvalue variance.percent cumulative.variance.percent
## Dim.1  0.5428893         48.69222                    48.69222
## Dim.2  0.4450028         39.91269                    88.60491
## Dim.3  0.1270484         11.39509                   100.00000</code></pre>
<pre class="r"><code>fviz_screeplot(res.ca) +
 geom_hline(yintercept=33.33, linetype=2, color=&quot;red&quot;, addlabels = TRUE, ylim = c(0, 50))</code></pre>
<p><img src="groupingstatz_files/figure-html/ca1-2.png" width="672" /></p>
<pre class="r"><code># repel= TRUE to avoid text overlapping (slow if many point)
fviz_ca_biplot(res.ca, repel = TRUE)</code></pre>
<p><img src="groupingstatz_files/figure-html/ca1-3.png" width="672" /></p>
</div>
<div id="principal-component-analysis" class="section level1">
<h1><span class="header-section-number">5</span> Principal Component Analysis</h1>
<pre class="r"><code># inspect data
data(iris)
head(iris, 3)</code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa</code></pre>
<pre class="r"><code># log transform 
log.ir &lt;- log(iris[, 1:4])
ir.species &lt;- iris[, 5]
 
# apply PCA - scale. = TRUE is highly 
# advisable, but default is FALSE. 
ir.pca &lt;- prcomp(log.ir, center = TRUE, scale. = TRUE) </code></pre>
<pre class="r"><code># print method
print(ir.pca)</code></pre>
<pre><code>## Standard deviations (1, .., p=4):
## [1] 1.7124583 0.9523797 0.3647029 0.1656840
## 
## Rotation (n x k) = (4 x 4):
##                     PC1         PC2        PC3         PC4
## Sepal.Length  0.5038236 -0.45499872  0.7088547  0.19147575
## Sepal.Width  -0.3023682 -0.88914419 -0.3311628 -0.09125405
## Petal.Length  0.5767881 -0.03378802 -0.2192793 -0.78618732
## Petal.Width   0.5674952 -0.03545628 -0.5829003  0.58044745</code></pre>
<pre class="r"><code># plot method
plot(ir.pca, type = &quot;l&quot;)</code></pre>
<p><img src="groupingstatz_files/figure-html/pca4-1.png" width="672" /></p>
<pre class="r"><code># summary method
summary(ir.pca)</code></pre>
<pre><code>## Importance of components:
##                           PC1    PC2     PC3     PC4
## Standard deviation     1.7125 0.9524 0.36470 0.16568
## Proportion of Variance 0.7331 0.2268 0.03325 0.00686
## Cumulative Proportion  0.7331 0.9599 0.99314 1.00000</code></pre>
<pre class="r"><code># predict PCs
predict(ir.pca, newdata=tail(log.ir, 2))</code></pre>
<pre><code>##           PC1         PC2        PC3         PC4
## 149 1.0809930 -1.01155751 -0.7082289 -0.06811063
## 150 0.9712116 -0.06158655 -0.5008674 -0.12411524</code></pre>
<pre class="r"><code># load library
#library(devtools)
# install library from github
#install_github(&quot;vqv/ggbiplot&quot;)
# load installed library
library(ggbiplot)
# create plot
g &lt;- ggbiplot(ir.pca, obs.scale = 1, var.scale = 1, 
              groups = ir.species, ellipse = TRUE, 
              circle = TRUE)
g &lt;- g + scale_color_discrete(name = &#39;&#39;)
g &lt;- g + theme(legend.direction = &#39;horizontal&#39;, 
               legend.position = &#39;top&#39;)
print(g)</code></pre>
<p><img src="groupingstatz_files/figure-html/pca7-1.png" width="672" /></p>
<pre class="r"><code>require(caret)
trans = preProcess(iris[,1:4], 
                   method=c(&quot;BoxCox&quot;, &quot;center&quot;, 
                            &quot;scale&quot;, &quot;pca&quot;))
PC = predict(trans, iris[,1:4])</code></pre>
<pre class="r"><code># inspect retained PCs
head(PC, 3)</code></pre>
<pre><code>##         PC1        PC2
## 1 -2.303540 -0.4748260
## 2 -2.151310  0.6482903
## 3 -2.461341  0.3463921</code></pre>
<pre class="r"><code># inspect loadings
trans$rotation</code></pre>
<pre><code>##                     PC1         PC2
## Sepal.Length  0.5202351 -0.38632246
## Sepal.Width  -0.2720448 -0.92031253
## Petal.Length  0.5775402 -0.04885509
## Petal.Width   0.5672693 -0.03732262</code></pre>
</div>
<div id="multidimensional-scaling" class="section level1">
<h1><span class="header-section-number">6</span> Multidimensional Scaling</h1>
<pre class="r"><code># Classical MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name

d &lt;- dist(clus) # euclidean distances between the rows
fit &lt;- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit # view results</code></pre>
<pre><code>## $points
##                         [,1]       [,2]
## IrishEnglish      -1.6526159  0.7103453
## ScottishEnglish   -1.6526159  0.7103453
## BritishEnglish    -0.3730922 -0.7849119
## AustralianEnglish -0.3730922 -0.7849119
## NewZealandEnglish -0.3730922 -0.7849119
## AmericanEnglish    0.4833173 -0.2933771
## CanadianEnglish    0.4833173 -0.2933771
## JamaicanEnglish    1.1526246  0.5069331
## PhillipineEnglish  1.1526246  0.5069331
## IndianEnglish      1.1526246  0.5069331
## 
## $eig
##  [1]  1.033269e+01  3.800525e+00  1.466781e+00  1.084123e-15  2.265363e-16
##  [6]  1.357406e-16  2.756578e-17 -2.439914e-17 -2.683037e-17 -6.103001e-16
## 
## $x
## NULL
## 
## $ac
## [1] 0
## 
## $GOF
## [1] 0.9059756 0.9059756</code></pre>
<pre class="r"><code># plot solution
x &lt;- fit$points[,1]
y &lt;- fit$points[,2]
plot(x, y, xlab=&quot;Coordinate 1&quot;, ylab=&quot;Coordinate 2&quot;,
  main=&quot;Metric MDS&quot;, type=&quot;n&quot;)
text(x, y, labels = row.names(clus), cex=.7) </code></pre>
<p><img src="groupingstatz_files/figure-html/mds1-1.png" width="672" /></p>
</div>
<div id="vector-space-models" class="section level1">
<h1><span class="header-section-number">7</span> Vector Space Models</h1>
<p>Work in progress</p>
<p><img src="images/uq2.jpg" width="100%" /></p>
<div id="refs" class="references">
<div id="ref-levshina2015linguistics">
<p>Levshina, Natalia. 2015. <em>How to Do Linguistics with R: Data Exploration and Statistical Analysis</em>. Amsterdam: John Benjamins Publishing Company.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
