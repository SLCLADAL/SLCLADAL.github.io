{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<!--html_preserve-->\n",
                "<!-- Global site tag (gtag.js) - Google Analytics -->\n",
                "<script async src=\"https://www.googletagmanager.com/gtag/js?id=UA-130562131-1\"><\/script>\n",
                "<script>\n",
                "  window.dataLayer = window.dataLayer || [];\n",
                "  function gtag(){dataLayer.push(arguments);}\n",
                "  gtag('js', new Date());\n",
                "\n",
                "  gtag('config', 'UA-130562131-1');\n",
                "<\/script>\n",
                "<!--/html_preserve-->\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::include_graphics(\"https://slcladal.github.io/images/uq1.jpg\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction{-}\n",
                "\n",
                "This tutorial introduces classification and clustering using R. The entire R markdown document for this tutorial can be downloaded [here](https://slcladal.github.io/clust.Rmd). A more elaborate and highly recommendable introduction to cluster analysis is @kassambara2017practical. Other very useful resources are, e.g.,  @king2015cluster; @kettenring2006practice; @romesburg2004cluster; and @blashfield1988methods.\n",
                "\n",
                "Cluster analyses fall within the domain of classification methods which are used to find groups or patterns in data or to predict group membership. As such, they are widely used and applied in machine learning. For linguists, classification is not only common when it comes to phylogenetics but also in annotation-based procedures such as part-of-speech tagging and syntactic parsing. \n",
                "\n",
                "## Preparation and session set up{-}\n",
                "\n",
                "This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/intror.html). For this tutorials, we need to install certain *packages* from an R *library* so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(stringsAsFactors = F)         # no automatic data transformation\n",
                "options(\"scipen\" = 100, \"digits\" = 4) # suppress math annotation\n",
                "# install libraries\n",
                "install.packages(c(\"cluster\", \"factoextra\", \"cluster\", \n",
                "                   \"seriation\", \"pvclust\", \"ape\", \"vcd\", \n",
                "                   \"exact2x2\", \"factoextra\", \"seriation\", \n",
                "                   \"NbClust\", \"pvclust\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.\n",
                "\n",
                "# Cluster Analysis\n",
                "\n",
                "The most common method in linguistics that is sued to detect groups in data are cluster analyses. Cluster analyses are common in linguistics because they not only detect commonalities based on the frequency or occurrence of features but they also allow to visualize when splits between groups have occurred and are thus the method of choice in historical linguistics to determine and show genealogical relationships. \n",
                "\n",
                "## Underlying Concepts{-}\n",
                "\n",
                "The next section focuses on the basic idea that underlies all cluster analyses. WE will have a look at some very basic examples to highlight and discuss the principles that cluster analyses rely on. \n",
                "\n",
                "The underlying idea of cluster analysis is very simple and rather intuitive as we ourselves perform cluster analyses every day in our lives. This is so because we group things together under certain labels and into concepts. The first example used to show this, deals with types of trees and how we group these types of trees based on their outward appearance. \n",
                "\n",
                "Imagine you see six trees representing different types of trees: a pine tree, a fir tree, an oak tree, a beech tree, a phoenix palm tree, and a nikau palm tree. Now, you were asked to group these trees according to similarity. Have a look at the plot below and see whether you would have come up with a similar type of grouping.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x <- 1:10\n",
                "y <- 1:10\n",
                "plot(x, y, type = \"n\", ylim = c(-.5,10), xlim = c(0,5), axes = F, xlab = \"\", ylab = \"\")\n",
                "text(\"Trees\", x = 2.25, y = 10, cex = 1.5)\n",
                "text(\"Conifers\", x = .5, y = 6.5, cex = 1.5)\n",
                "text(\"Broad leaf\", x = 2.25, y = 6.5, cex = 1.5)\n",
                "text(\"Palms\", x = 4, y = 6.5, cex = 1.5)\n",
                "text(\"Pine tree\", x = .25, y = 1.5, srt=90, cex = 1.5)\n",
                "text(\"Fir tree\", x = .75, y = 1.5, srt=90, cex = 1.5)\n",
                "text(\"Oak tree\", x = 2, y = 1.5, srt=90, cex = 1.5)\n",
                "text(\"Beech tree\", x = 2.5, y = 1.5, srt=90, cex = 1.5)\n",
                "text(\"Phoenix palm\", x = 3.75, y = 1.75, srt=90, cex = 1.5)\n",
                "text(\"Nikau palm\", x = 4.25, y = 1.5, srt=90, cex = 1.5)\n",
                "#\n",
                "lines(x = c(.5, 1.75), y = c(7, 9), lwd = 2)\n",
                "lines(x = c(2.25, 2.25), y = c(7, 9), lwd = 2)\n",
                "lines(x = c(4, 2.75), y = c(7, 9), lwd = 2)\n",
                "#\n",
                "lines(x = c(.5, .5), y = c(6, 4.5), lwd = 2)\n",
                "lines(x = c(2.25, 2.25), y = c(6, 4.5), lwd = 2)\n",
                "lines(x = c(4, 4), y = c(6, 4.75), lwd = 2)\n",
                "#\n",
                "lines(x = c(.25, .75), y = c(4.5, 4.5), lwd = 2)\n",
                "lines(x = c(2, 2.5), y = c(4.5, 4.5), lwd = 2)\n",
                "lines(x = c(3.75, 4.25), y = c(4.75, 4.75), lwd = 2)\n",
                "#\n",
                "lines(x = c(.25, .25), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(.75, .75), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(2, 2), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(2.5, 2.5), y = c(4.5, 4), lwd = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "An alternative way to group the trees would be the following.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x <- 1:10\n",
                "y <- 1:10\n",
                "plot(x, y, type = \"n\", ylim = c(-.5,15), xlim = c(0,5), axes = F, xlab = \"\", ylab = \"\")\n",
                "text(\"Trees\", x = 2.25, y = 15, cex = 1)\n",
                "text(\"Conifers\", x = .5, y = 6.5, cex = 1)\n",
                "text(\"Broad leaf\", x = 2.25, y = 6.5, cex = 1)\n",
                "text(\"Palm Trees\", x = 3.5, y = 10, cex = 1)\n",
                "text(\"Pine tree\", x = .25, y = 1.5, srt=90, cex = 1)\n",
                "text(\"Fir tree\", x = .75, y = 1.5, srt=90, cex = 1)\n",
                "text(\"Oak tree\", x = 2, y = 1.5, srt=90, cex = 1)\n",
                "text(\"Beech tree\", x = 2.5, y = 1.5, srt=90, cex = 1)\n",
                "text(\"Phoenix palm\", x = 3.25, y = 1.75, srt=90, cex = 1)\n",
                "text(\"Nikau palm\", x = 3.75, y = 1.5, srt=90, cex = 1)\n",
                "#\n",
                "lines(x = c(1.5, 2.15), y = c(11, 13.5), lwd = 2)\n",
                "lines(x = c(3.5, 2.5), y = c(11, 13.5), lwd = 2)\n",
                "lines(x = c(.5, 1.5), y = c(7.25, 11), lwd = 2)\n",
                "lines(x = c(1.5, 2.25), y = c(11, 7.25), lwd = 2)\n",
                "#\n",
                "lines(x = c(.5, .5), y = c(6, 4.5), lwd = 2)\n",
                "lines(x = c(2.25, 2.25), y = c(6, 4.5), lwd = 2)\n",
                "lines(x = c(3.5, 3.5), y = c(8.75, 6.25), lwd = 2)\n",
                "#\n",
                "lines(x = c(.25, .75), y = c(4.5, 4.5), lwd = 2)\n",
                "lines(x = c(2, 2.5), y = c(4.5, 4.5), lwd = 2)\n",
                "lines(x = c(3.25, 3.75), y = c(6.25, 6.25), lwd = 2)\n",
                "#\n",
                "lines(x = c(.25, .25), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(.75, .75), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(2, 2), y = c(4.5, 4), lwd = 2)\n",
                "lines(x = c(2.5, 2.5), y = c(4.5, 4), lwd = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this display, conifers and broad-leaf trees are grouped together because there are more similar to each other compared to palm trees. This poses the question of what is meant by similarity. Consider the display below. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate data\n",
                "y <- c(1, 3.1, 1.2, 2.3, 3.4, 2.5, 1.6, 2.7, 3.8, 2.9)\n",
                "x <- c(1:10)\n",
                "plot(x, y, \n",
                "     type = \"l\", \n",
                "     ylim = c(0,11), \n",
                "     xaxt='n', \n",
                "     yaxt='n', \n",
                "     ann=FALSE, \n",
                "     lwd = 2, \n",
                "     ylab = \"\", \n",
                "     xlab = \"\")\n",
                "lines(x = 1:10, y = c(5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9), col = \"blue\", lwd = 2)\n",
                "lines(x = 1:10, y = c(8, 10.1, 8.2, 9.3, 10.4, 9.5, 8.6, 9.7, 10.8, 9.9), col = \"red\", lwd = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Are the red and the blue line more similar because they have the same shape or are the red and the black line more similar because they are closer together? There is no single correct answer here. Rather the plot intends to raise awareness about the fact that how cluster analyses group data depends on how similarity is defined in the respective algorithm.\n",
                "\n",
                "Let's consider another example to better understand how cluster analyses determine which data points should be merged when. Imagine you have five students and want to group them together based on their overall performance in school. The data that you rely on are their grades in math, music, and biology (with 1 being the best grade and 6 being the worst).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# similarity\n",
                "students <- matrix(c(2,  3,  2, 1,  3,  2, 1,  2,  1, 2,  4,  4, 3,  4,  3),\n",
                "  nrow = 5, byrow = T)\n",
                "students <- as.data.frame(students)\n",
                "colnames(students) <- c(\"Math\", \"Music\", \"Biology\")\n",
                "rownames(students) <- c(\"StudentA\", \"StudentB\", \"StudentC\", \"StudentD\", \"StudentE\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(knitr)\n",
                "kable(students, caption = \"Sample of five students and their grades in math, music, and biology\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " \n",
                " The first step in determining the similarity among students is to create a distance matrix. \n",
                " \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diststudents <- dist(students, method = \"manhattan\") # create a distance matrix\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The distance matrix below shows that Student A and Student B only differ by one grade. Student B and Student C differ by 2 grades. Student A and Student C differ by 3 grades and so on.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(knitr)\n",
                "diststudentstb <- matrix(c(\"1\", \"3\", \"3\",\"3\", \"\", \"2\", \"4\", \"4\",\"\", \"\", \"6\", \"6\", \"\", \"\", \"\", \"2\"), nrow = 4, byrow = F)\n",
                "# add column and row names\n",
                "colnames(diststudentstb) <- c(\"StudentA\", \"StudentB\", \"StudentC\", \"StudentD\")\n",
                "rownames(diststudentstb) <- c(\"StudentB\", \"StudentC\", \"StudentD\", \"StudentE\")\n",
                "kable(diststudentstb, caption = \"Distance matrix based of students based on grades in math, music, and biology.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Based on this distance matrix, we can now implement a cluster analysis in `R`. \n",
                "\n",
                "## Cluster Analysis on Numeric Data{-}\n",
                "\n",
                "To create a simple cluster object in R, we use the \"hclust\" function from the \"cluster\" package. The resulting object is then plotted to create a dendrogram which shows how students have been amalgamated (combined) by the clustering algorithm (which, in the present case, is called \"ward.D\").\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# activate library\n",
                "library(\"cluster\")    \n",
                "library(\"factoextra\")\n",
                "library(\"seriation\")\n",
                "library(\"NbClust\")\n",
                "library(\"pvclust\")\n",
                "# create hierarchical cluster object with ward.D as linkage method\n",
                "clusterstudents <- hclust(diststudents, method=\"ward.D\")\n",
                "# plot result as dendrogram\n",
                "plot(clusterstudents, hang = 0)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us have a look at how the clustering algorithm has amalgamated the students. The amalgamation process takes the distance matrix from above as a starting point and, in a first step, has merged Student A and Student B (because they were the most similar students in the data based on the distance matrix). After collapsing Student A and Student B, the resulting distance matrix looks like the distance matrix below (notice that Student A and Student B now form a cluster that is represented by the means of the grades of the two students).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "students2 <- matrix(c(1.5, 3, 2, 1,  2,  1, 2,  4,  4, 3,  4,  3),\n",
                "  nrow = 4, byrow = T)\n",
                "students2 <- as.data.frame(students2)\n",
                "rownames(students2) <- c(\"Cluster1\", \"StudentC\", \"StudentD\", \"StudentE\")\n",
                "diststudents2 <- dist(students2, method = \"manhattan\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(knitr)\n",
                "diststudentstb <- matrix(c(\"2.5\",\"3.5\",\"3.5\",\"\",\"6.0\",\"6.0\",\"\",\"\",\"2.0\"), \n",
                "                         nrow = 3, byrow = F)\n",
                "# add column and row names\n",
                "colnames(diststudentstb) <- c(\"Cluster 1\", \"Student C\", \"Student D\")\n",
                "rownames(diststudentstb) <- c(\"Student C\", \"Student D\", \"Student E\")\n",
                "kable(diststudentstb, \n",
                "      caption = \"Distance matrix of students based on grades in math, music, and biology.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The next lowest distance now is 2.0 between Student D and Student E which means that these two students are merged next. The resulting distance matrix is shown below.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "students3 <- matrix(c(1.5,3,2,1,2,1,2.5,4,3.5),\n",
                "  nrow = 3, byrow = T)\n",
                "students3 <- as.data.frame(students3)\n",
                "rownames(students3) <- c(\"Cluster1\", \"StudentC\", \"Cluster2\")\n",
                "diststudents3 <- dist(students3, \n",
                "                      method = \"manhattan\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(knitr)\n",
                "diststudentstb <- matrix(c(\"2.5\", \"3.5\", \"\", \"6.0\"), nrow = 2, byrow = F)\n",
                "# add column and row names\n",
                "colnames(diststudentstb) <- c(\"Cluster 1\", \"Student C\")\n",
                "rownames(diststudentstb) <- c(\"Student C\", \"Cluster 2\")\n",
                "kable(diststudentstb, caption = \"Distance matrix based of students based on grades in math, music, and biology.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, the lowest distance value occurs between Cluster 1 and Student C. Thus, Student C and Cluster 1 are merged. In the final step, the Cluster 2 is merged with the new cluster encompassing Student C and Cluster 1. This amalgamation process can then be displayed visually as a dendrogram (see above). \n",
                "\n",
                "How and which elements are merged depends on the what is understood as distance. Since \"distance\" is such an important concept in cluster analyses, we will briefly discuss this notion to understand why there are so many different types of clustering algorithms and this cluster analyses.\n",
                "\n",
                "## Distance and Similarity Measures{-}\n",
                "\n",
                "To understand how a cluster analysis determines to which cluster a given data point belongs, we need to understand what different distance measures represent. Have a look at the Figure below which visually represents three different ways to conceptualize distance.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "par(mar=c(1,1,1,1))  # define margine width of the plot\n",
                "x <- c(1,5)          # define an x value\n",
                "y <- c(1,5)          # define a y value\n",
                "plot(x, y, \n",
                "     pch = 20, \n",
                "     cex = 1, \n",
                "     axes = F, \n",
                "     las = 1, \n",
                "     xlab = \"\", \n",
                "     ylab = \"\", \n",
                "     xlim = c(0,7), \n",
                "     ylim = c(0,10))\n",
                "text(0.5, .5, \"Point A\", cex = 1)\n",
                "text(5, 5.5, \"Point B\", cex = 1)\n",
                "lines(x = c(1, 5), y = c(1, 5), type = \"l\", lty = 3, lwd = 2, col = \"red\")\n",
                "lines(x = c(1, 5), y = c(1, 1), type = \"l\", lty = 2, lwd = 2, col = \"blue\")\n",
                "lines(x = c(5, 5), y = c(1, 5), type = \"l\", lty = 4, lwd = 2, col = \"green\")\n",
                "lines(x = c(.9, 5), y = c(.9, .9), type = \"l\", lty = 4, lwd = 2, col = \"green\")\n",
                "legend(\"topleft\", inset=.05, title=\"\", bty = \"n\", lty = c(3, 2, 4), lwd = 2,\n",
                "   c(\"euclidean distance\", \"maximum distance\", \"manhatten distance\"), col=c(\"red\", \"blue\", \"green\"), horiz=F, cex = 1)\n",
                "par(mar=c(5.1,4.1,4.1,2.1))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Figure above depicts three ways to measure distance: the \"eucledian distance\" represents the distance between points as the hypothenuse of the x- and y-axis distances while the \"maximum distance\" represents distance as the longer distance of either the distance on the x- or the y-axis. The manhatten distance (or block distance) is the sum of the distances on the x- and the y-axis. \n",
                "\n",
                "We will now turn to another example in order to delve a little deeper into how clustering algorithms work. In this example, we will find cluster of varieties of English based on the relative frequency of selected non-standard features (such as the relative frequencies of cleft constructions and tag questions). As a first step, we generate some fictional data set for this analysis. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate data\n",
                "IrishEnglish <- round(sqrt((rnorm(10, 9.5, .5))^2), 3)\n",
                "ScottishEnglish <- round(sqrt((rnorm(10, 9.3, .4))^2), 3)\n",
                "BritishEnglish <- round(sqrt((rnorm(10, 6.4, .7))^2), 3)\n",
                "AustralianEnglish <- round(sqrt((rnorm(10, 6.6, .5))^2), 3)\n",
                "NewZealandEnglish <- round(sqrt((rnorm(10, 6.5, .4))^2), 3)\n",
                "AmericanEnglish <- round(sqrt((rnorm(10, 4.6, .8))^2), 3)\n",
                "CanadianEnglish <- round(sqrt((rnorm(10, 4.5, .7))^2), 3)\n",
                "JamaicanEnglish <- round(sqrt((rnorm(10, 1.4, .2))^2), 3)\n",
                "PhillipineEnglish <- round(sqrt((rnorm(10, 1.5, .4))^2), 3)\n",
                "IndianEnglish <- round(sqrt((rnorm(10, 1.3, .5))^2), 3)\n",
                "clus <- data.frame(IrishEnglish, ScottishEnglish, BritishEnglish, \n",
                "                   AustralianEnglish, NewZealandEnglish, AmericanEnglish, \n",
                "                   CanadianEnglish, JamaicanEnglish, PhillipineEnglish, IndianEnglish)\n",
                "# add row names\n",
                "rownames(clus) <- c(\"nae_neg\", \"like\", \"clefts\", \"tags\", \"youse\", \"soitwas\", \"dt\", \"nsr\", \"invartag\", \"wh_cleft\")\n",
                "# inspect results\n",
                "summary(clus) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a next step, we create a cluster object based on the data we have just generated.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# clean data\n",
                "clust <- t(clus)            # transpose data\n",
                "clust <- na.omit(clust)     # remove missing values\n",
                "clusts <- scale(clust)      # standardize variables\n",
                "clusts <- as.matrix(clusts) # convert into matrix\n",
                "clust\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now assess if data is clusterable by testing whether or not the data includes nonrandom structures. To means to determine whether the data contains nonrandomness, we calculate the Hopkins statistic which informs how similar the data is to a random distribution. If the values of the Hopkins statistic are higher than 0.5 then this indicates that the data is random and that there are no inherent clusters. However, if the Hopkins statistic is close to 0, then the data is clusterable. The \"n\" in the \"get_clust_tendency\" functions represents the maximum number of clusters to be tested which should be  number of predictors in the data. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(\"factoextra\")         # load library to extract cluster tendency\n",
                "clusttendency <- get_clust_tendency(clusts,    # apply get_clust_tendency to cluster object\n",
                "                   n = 9,     # define number of points from sampe speace \n",
                "                   gradient = list(low = \"steelblue\",  # define color for low values \n",
                "                                   high = \"white\"))    # define color for high values\n",
                "clusttendency[1]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As the Hopkins statistic above shows, there is sufficient structure in the data and we can assume that there are actual clusters in the data. Next, we create a distance matrix based on Euclidian distances.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clustd <- dist(clusts,                 # create distance matrix\n",
                "               method = \"euclidean\")   # use eucledian (!) distance\n",
                "round(clustd, 2)                       # display distance matrix\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Below are other methods to cerate distance matrices. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create distance matrix (eucledian method: not good when dealing with many dimensions)\n",
                "clustd <- dist(clusts, method = \"euclidean\")\n",
                "# create distance matrix (maximum method: here the difference between points dominates)\n",
                "clustd_maximum <- round(dist(clusts, method = \"maximum\"), 2)\n",
                "# create distance matrix (manhattan method: most popular choice)\n",
                "clustd_manhatten <- round(dist(clusts, method = \"manhattan\"), 2) \n",
                "# create distance matrix (canberra method: for count data only - focuses on small differences and neglects larger differences)\n",
                "clustd_canberra <- round(dist(clusts, method = \"canberra\"), 2)\n",
                "# create distance matrix (binary method: for binary data only!)\n",
                "clustd_binary <- round(dist(clusts, method = \"binary\"), 2) \n",
                "# create distance matrix (minkowski method: is not a true distance measure)\n",
                "clustd_minkowski <- round(dist(clusts, method = \"minkowski\"), 2) \n",
                "# distance method for words: daisy (other possible distances are \"manhattan\" and \"gower\")\n",
                "library(cluster)\n",
                "clustd_daisy <- round(daisy(clusts, metric = \"euclidean\"), 2) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you call the individual distance matrices, you will see that depending on which distance measure is used, the distance matrices differ dramatically! Have a look at the distance matrix created using the manhatten metric and compare it to the distance matrix created using the Euclidian metric (see above).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clustd_maximum \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we create a distance plot using the \"distplot\" function. If the distance plot shows different regions (non-random, non-uniform grey areas) then clustering the data is permittable as the data contains actual structures.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load library\n",
                "library(seriation)\n",
                "# create distance plot\n",
                "dissplot(clustd) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The most common method for clustering is called \"ward.D\" or \"ward.D2\". Both of these linkage functions seek to minimize variance. This means that they cluster in a way that the amount of variance is at a minimum (comparable to the regression line in an *ordinary least squares* (OLS) design).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create cluster object\n",
                "cd <- hclust(clustd, method=\"ward.D2\") \n",
                "# display dendogram              \n",
                "plot(cd, hang = -1)              \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will briefly go over some other, alternative linkage methods. Which linkage method is and should be used depends on various factors, for example, the type of variables (nominal versus numeric) or whether the focus should be placed on commonalities or differences.\n",
                " \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# single linkage: cluster with nearest data point\n",
                "cd_single <- hclust(clustd, method=\"single\") \n",
                "# create cluster object (ward.D linkage)\n",
                "cd_wardd <- hclust(clustd, method=\"ward.D\")\n",
                "# create cluster object (ward.D2 linkage): \n",
                "# cluster in a way to achieve minimum variance\n",
                "cd_wardd2 <- hclust(clustd, method=\"ward.D2\")\n",
                "# average linkage: cluster with closest mean\n",
                "cd_average <- hclust(clustd, method=\"average\") \n",
                "# mcquitty linkage\n",
                "cd_mcquitty <- hclust(clustd, method=\"mcquitty\") \n",
                "# median linkage: cluster with closest median\n",
                "cd_median <- hclust(clustd, method=\"median\")\n",
                "# centroid linkage: cluster with closest prototypical point of target cluster\n",
                "cd_centroid <- hclust(clustd, method=\"centroid\") \n",
                "# complete linkage: cluster with nearest/furthest data point of target cluster\n",
                "cd_complete <- hclust(clustd, method=\"complete\")  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we determine the optimal number of clusters based on silhouette widths which shows the ratio of internal similarity of clusters against the similarity between clusters. If the silhouette widths have values lower than .2 then this indicates that clustering is not appropriate [@levshina2015linguistics 311]. The function below displays the silhouette width values of 2 to 8 clusters.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optclus <- sapply(2:8, function(x) summary(silhouette(cutree(cd, k = x), clustd))$avg.width)\n",
                "optclus # inspect results\n",
                "\n",
                "optnclust <- which(optclus == max(optclus)) # determine optimal number of clusters\n",
                "groups <- cutree(cd, k=optnclust) # cut tree into optimal number of clusters\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The optimal number of clusters is the cluster solution with the highest silhouette width. We cut the tree into the optimal number of clusters and plot the result.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "groups <- cutree(cd, k=optnclust)          # cut tree into optimal clusters\n",
                "plot(cd, hang = -1, cex = .75)             # plot result as dendrogram\n",
                "rect.hclust(cd, k=optnclust, border=\"red\") # draw red borders around clusters\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In a next step, we aim to determine which factors are particularly important for the clustering - this step is comparable to measuring the effect size in inferential designs.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# which factors are particularly important\n",
                "celtic <- clusts[c(1,2),]\n",
                "others <- clusts[-c(1,2),]\n",
                "# calculate column means\n",
                "celtic.cm <- colMeans(celtic)\n",
                "others.cm <- colMeans(others)\n",
                "# calcualte difference between celtic and other englishes\n",
                "diff <- celtic.cm - others.cm\n",
                "sort(diff, decreasing = F)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(sort(diff),           # y-values\n",
                "  1:length(diff),       # x-values \n",
                "  type= \"n\",            # plot type (empty)\n",
                "  cex.axis = .75,       # axis font size\n",
                "  cex.lab = .75,        # label font size\n",
                "  xlab =\"Prototypical for Non-Celtic Varieties (Cluster 2) <-----> Prototypical for Celtic Varieties (Cluster 1)\", # x-axis label\n",
                "  yaxt = \"n\",           # no y-axis tick marks\n",
                "  ylab = \"\")            # no y-axis label\n",
                "text(sort(diff), 1:length(diff), names(sort(diff)), cex = .75) # plot text into plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Outer <- clusts[c(6:8),]     # data of outer circle varieties\n",
                "Inner <- clusts[-c(6:8),]    # data of inner circle varieties\n",
                "Outer.cm <- colMeans(Outer)  # column means for outer circle\n",
                "Inner.cm <- colMeans(Inner)  # column means for inner circle\n",
                "diff <- Outer.cm - Inner.cm  # difference between inner and outer circle\n",
                "sort(diff, decreasing = F)   # order difference between inner and outer circle\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(                   # start plot\n",
                "  sort(diff),           # y-values\n",
                "  1:length(diff),       # x-values \n",
                "  type= \"n\",            # plot type (empty)\n",
                "  cex.axis = .75,       # axis font size\n",
                "  cex.lab = .75,        # label font size\n",
                "  xlab =\"Prototypical for Inner Circle Varieties (Cluster 2) <-----> Prototypical for Outer Circle Varieties (Cluster 1)\", # x-axis label\n",
                "  yaxt = \"n\",           # no y-axis tick marks\n",
                "  ylab = \"\")            # no y-axis label\n",
                "text(sort(diff), 1:length(diff), names(sort(diff)), cex = .75) # plot text into plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see that discourse *like* is typical for other varieties and that the use of *youse* as 2^nd^ person plural pronoun and invariant tags are typical for Celtic Englishes.\n",
                "\n",
                "We will now test whether the cluster is justified by validating the cluster solution using bootstrapping.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(pvclust) # activate library\n",
                "res.pv <- pvclust(clus,                     # apply pvclust method to clus data\n",
                "                  method.dist=\"euclidean\",  # use eucledian distance\n",
                "                  method.hclust=\"ward.D2\",  # use ward.d2 linkage\n",
                "                  nboot = 100)              # use 100 bootstrap runs\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The clustering provides approximately unbiased p-values and bootstrap probability value [see @levlevshina2015linguistics 316].\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(res.pv, \n",
                "     cex = .75)\n",
                "pvrect(res.pv)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can alsouse other libraries to customize the dendrograms. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(ape)            # load package ape\n",
                "plot(as.phylo(cd),      # plot cluster object\n",
                "     cex = 0.75,        # .75 font size\n",
                "     label.offset = .5) # .5 label offset\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One useful customization is to display an unrooted rather than a rooted tree diagram.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot as unrooted tree\n",
                "plot(as.phylo(cd),      # plot cluster object\n",
                "     type = \"unrooted\", # plot as unrooted tree\n",
                "     cex = .75,         # .75 font size\n",
                "     label.offset = 1)  # .5 label offset\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cluster Analysis on Nominal Data{-}\n",
                "\n",
                "So far, all analyses were based on numeric data. However, especially when working with language data, the data is nominal or categorical rather than numeric. The following will thus show to implement a clustering method for nominal data.\n",
                "\n",
                "In a first step, we will create a simple data set representing the presence and absence of features across varities of English.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate data\n",
                "IrishEnglish <- c(1,1,1,1,1,1,1,1,1,1)\n",
                "ScottishEnglish <- c(1,1,1,1,1,1,1,1,1,1)\n",
                "BritishEnglish <- c(0,1,1,1,0,0,1,0,1,1)\n",
                "AustralianEnglish <- c(0,1,1,1,0,0,1,0,1,1)\n",
                "NewZealandEnglish <- c(0,1,1,1,0,0,1,0,1,1)\n",
                "AmericanEnglish <- c(0,1,1,1,0,0,0,0,1,0)\n",
                "CanadianEnglish <- c(0,1,1,1,0,0,0,0,1,0)\n",
                "JamaicanEnglish <- c(0,0,1,0,0,0,0,0,1,0)\n",
                "PhillipineEnglish <- c(0,0,1,0,0,0,0,0,1,0)\n",
                "IndianEnglish <- c(0,0,1,0,0,0,0,0,1,0)\n",
                "clus <- data.frame(IrishEnglish, ScottishEnglish, BritishEnglish, \n",
                "                   AustralianEnglish, NewZealandEnglish, AmericanEnglish, \n",
                "                   CanadianEnglish, JamaicanEnglish, PhillipineEnglish, IndianEnglish)\n",
                "# add row names\n",
                "rownames(clus) <- c(\"nae_neg\", \"like\", \"clefts\", \"tags\", \"youse\", \"soitwas\", \"dt\", \"nsr\", \"invartag\", \"wh_cleft\")\n",
                "# convert into factors\n",
                "clus <- apply(clus, 1, function(x){\n",
                "  x <- as.factor(x) })\n",
                "# inspect data\n",
                "clus\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have our data, we will create a distance matrix but in contrast to previous methods, we will use a different distance measure that takes into account that we are dealing with nominal (or binary) data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# clean data\n",
                "clusts <- as.matrix(clus)\n",
                "# create distance matrix\n",
                "clustd <- dist(clusts, method = \"binary\")   # create a distance object with binary (!) distance\n",
                "# display distance matrix\n",
                "round(clustd, 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As before, we can now use hierarchical clustering to display the results as a dendrogram\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create cluster object (ward.D2 linkage)   : cluster in a way to achieve minimum variance\n",
                "cd <- hclust(clustd, method=\"ward.D2\")\n",
                "# plot result as dendrogram\n",
                "plot(cd, hang = -1)              # display dendogram\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In a next step, we want to determine which features are particularly distinctive for one cluster (the \"Celtic\" cluster containing Irish and Scottish English). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create factor with celtic varieties on one hand and other varieties on other\n",
                "cluster <- as.factor(ifelse(as.character(rownames(clusts)) == \"IrishEnglish\", \"1\",\n",
                "  ifelse(as.character(rownames(clusts)) == \"ScottishEnglish\", \"1\", \"0\")))\n",
                "# load library\n",
                "library(vcd)\n",
                "clsts.df <- as.data.frame(clusts)\n",
                "# determine significance\n",
                "library(exact2x2)\n",
                "pfish <- fisher.exact(table(cluster, clsts.df$youse))\n",
                "pfish[[1]]\n",
                "\n",
                "# determine effect size\n",
                "assocstats(table(cluster, clsts.df$youse))\n",
                "\n",
                "assocstats(table(cluster, clsts.df$like))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Clustering is a highly complex topic and there many more complexities to it. However, this should have helped to get you started.\n",
                "\n",
                "\n",
                "# Correspondence Analysis\n",
                "\n",
                "Correspondence analysis (CA) represents a multivariate statistical technique that provides a graphic method of exploring the relationship between variables in a contingency table. CA is conceptually similar to principal component analysis (PCA), but applies to categorical rather than continuous data.\n",
                "\n",
                "CA consists out of the following four steps:\n",
                "\n",
                "1. Computing row and column averages\n",
                "2. Computing expected values\n",
                "3. Computing the residuals\n",
                "4. Plotting residuals\n",
                "\n",
                "In this tutorial, we investigate similarities among amplifiers based on their co-occurrences (word embeddings) with adjectives. Adjective amplifiers are elements such as those in 1. to 5.\n",
                "\n",
                "1. The *very*~amplifier~ *nice*~adjective~ man.\n",
                "2. A *truely*~amplifier~ *remarkable*~adjective~ woman. \n",
                "2. He was *really*~amplifier~ *hesitant*~adjective~.\n",
                "4. The child was *awefully*~amplifier~ *loud*~adjective~.\n",
                "5. The festival was *so*~amplifier~ *amazing*~adjective~!\n",
                "\n",
                "The similarity among adjective amplifiers can then be used to find clusters or groups of amplifiers that *behave* similarly and are interchangeable. To elaborate, adjective amplifiers are interchangeable with some variants but not with others (consider 6. to 8.; the question mark signifies that the example is unlikely to be used or grammatically not acceptable by L1 speakers of English).\n",
                "\n",
                "6. The *very*~amplifier~ *nice*~adjective~ man.\n",
                "7. The *really*~amplifier~ *nice*~adjective~ man.\n",
                "8. ^?^The *completely*~amplifier~ *nice*~adjective~ man.\n",
                "\n",
                "We start by loading the required packages, the data, and then displaying the data which is called \"vsmdata\" and consist of 5,000 observations of adjectives and contains two columns: one column with the adjectives (Adjectives) and another column which has the amplifiers (\"0\" means that the adjective occurred without an amplifier). \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load packages\n",
                "library(dplyr)\n",
                "library(FactoMineR)\n",
                "library(factoextra)\n",
                "library(gplots)\n",
                "library(DT)\n",
                "# load data\n",
                "vsmdata <- read.delim(\"https://slcladal.github.io/data/vsmdata.txt\", sep = \"\\t\", header = T)\n",
                "# inspect data\n",
                "datatable(vsmdata, rownames = FALSE, filter=\"top\", options = list(pageLength = 5, scrollX=T))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For this tutorial, we will reduce the number of amplifiers and adjectives and thus simplify the data to render it easier to understand what is going on. To simplify the data, we remove \n",
                "\n",
                "+ all non-amplified adjectives\n",
                "+ the adjectives many and much\n",
                "+ adjectives that are amplified less than 10 times\n",
                "\n",
                "In addition, we collapse all amplifiers that occur less than 20 times into a bin category (*other*).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# simplify data\n",
                "vsmdata_simp <- vsmdata %>%\n",
                "  # remove non-amplifier adjectives\n",
                "  dplyr::filter(Amplifier != 0,\n",
                "         Adjective != \"many\",\n",
                "         Adjective != \"much\") %>%\n",
                "  # collapse infrequent amplifiers\n",
                "  dplyr::group_by(Amplifier) %>%\n",
                "  dplyr::mutate(AmpFreq = dplyr::n()) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Amplifier = ifelse(AmpFreq > 20, Amplifier, \"other\")) %>%\n",
                "  # collapse infrequent adjectives\n",
                "  dplyr::group_by(Adjective) %>%\n",
                "  dplyr::mutate(AdjFreq = dplyr::n()) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Adjective = ifelse(AdjFreq > 10, Adjective, \"other\")) %>%\n",
                "  dplyr::filter(Adjective != \"other\") %>%\n",
                "  dplyr::select(-AmpFreq, -AdjFreq)\n",
                "# inspect data\n",
                "datatable(vsmdata_simp, rownames = FALSE, filter=\"top\", options = list(pageLength = 5, scrollX=T))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now use a balloon plot to see if tehre are any potential correlations between amplifiers and adjectives.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. convert the data as a table\n",
                "dt <- as.matrix(table(vsmdata_simp))\n",
                "# 2. Graph\n",
                "balloonplot(t(dt), main =\"vsmdata_simp\", xlab =\"\", ylab=\"\",\n",
                "            label = FALSE, show.margins = FALSE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The balloon plot suggests that there are potential correlations as the dots (balloons) are not distributed evenly according to frequency. To validate if there is significant correlation between the amplifier types and the adjectives using a $\\chi$^2^- test. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chisq <- chisq.test(dt)\n",
                "chisq\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The $\\chi$^2^- test confirms that there is a significant correlations between amplifier types and the adjectives.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res.ca <- CA(dt, graph = FALSE)\n",
                "# inpsect results of the CA\n",
                "#print(res.ca)\n",
                "eig.val <- get_eigenvalue(res.ca)\n",
                "eig.val\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The display of the *eigenvalues* provides information on the amount of variance that is explained by each dimension. The first dimension explains 49.87 percent of the variance, the second dimension explains another 30.34 percent of the variance, leaving all other variables with relative moderate explanatory power as they only account for 20 percent variance. We now plot and interpret the results of the CA.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# repel= TRUE to avoid text overlapping (slow if many point)\n",
                "fviz_ca_biplot(res.ca, \n",
                "               repel = TRUE,\n",
                "               col.row = \"orange\",\n",
                "               col.col = \"darkgray\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The results of the CA show that the adjective *different* is collocating with *other* amplifiers while *very* is collocating with *difficult* and *important*, *pretty* is collocating with *big*, *really* is collocating with *nice*, and *so* is collocating with *bad*.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Principal Component Analysis\n",
                "\n",
                "# inspect data\n",
                "data(iris)\n",
                "head(iris, 3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# log transform \n",
                "log.ir <- log(iris[, 1:4])\n",
                "ir.species <- iris[, 5]\n",
                " \n",
                "# apply PCA - scale. = TRUE is highly \n",
                "# advisable, but default is FALSE. \n",
                "ir.pca <- prcomp(log.ir, center = TRUE, scale. = TRUE) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print method\n",
                "print(ir.pca)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot method\n",
                "plot(ir.pca, type = \"l\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# summary method\n",
                "summary(ir.pca)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# predict PCs\n",
                "predict(ir.pca, newdata=tail(log.ir, 2))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load library\n",
                "library(devtools)\n",
                "# install library from github\n",
                "install_github(\"vqv/ggbiplot\")\n",
                "# load installed library\n",
                "library(ggbiplot)\n",
                "# create plot\n",
                "g <- ggbiplot(ir.pca, obs.scale = 1, var.scale = 1, \n",
                "              groups = ir.species, ellipse = TRUE, \n",
                "              circle = TRUE)\n",
                "g <- g + scale_color_discrete(name = '')\n",
                "g <- g + theme(legend.direction = 'horizontal', \n",
                "               legend.position = 'top')\n",
                "print(g)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "require(caret)\n",
                "trans = preProcess(iris[,1:4], \n",
                "                   method=c(\"BoxCox\", \"center\", \n",
                "                            \"scale\", \"pca\"))\n",
                "PC = predict(trans, iris[,1:4])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect retained PCs\n",
                "head(PC, 3)\n",
                "\n",
                "# inspect loadings\n",
                "trans$rotation\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multidimensional Scaling \n",
                "\n",
                "\n",
                "# Classical MDS\n",
                "# N rows (objects) x p columns (variables)\n",
                "# each row identified by a unique row name\n",
                "\n",
                "d <- dist(clus) # Euclidean distances between the rows\n",
                "fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim\n",
                "fit # view results\n",
                "\n",
                "# plot solution\n",
                "x <- fit$points[,1]\n",
                "y <- fit$points[,2]\n",
                "plot(x, y, xlab=\"Coordinate 1\", ylab=\"Coordinate 2\",\n",
                "  main=\"Metric MDS\", type=\"n\")\n",
                "text(x, y, labels = row.names(clus), cex=.7) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Nonmetric MDS\n",
                "# N rows (objects) x p columns (variables)\n",
                "# each row identified by a unique row name\n",
                "\n",
                "library(MASS)\n",
                "d <- dist(clus) # Euclidean distances between the rows\n",
                "fit <- isoMDS(d, k=2) # k is the number of dim\n",
                "fit # view results\n",
                "\n",
                "# plot solution\n",
                "x <- fit$points[,1]\n",
                "y <- fit$points[,2]\n",
                "plot(x, y, xlab=\"Coordinate 1\", ylab=\"Coordinate 2\",\n",
                "  main=\"Nonmetric MDS\", type=\"n\")\n",
                "text(x, y, labels = row.names(clus), cex=.7) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Citation & Session Info {-}\n",
                "\n",
                "Schweinberger, Martin. `r format(Sys.time(), '%Y')`. *Cluster and Correspondence Analysis in R*. Brisbane: The University of Queensland. url: https://slcladal.github.io/clust.html (Version `r format(Sys.time(), '%Y.%m.%d')`).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@manual{schweinberger`r format(Sys.time(), '%Y')`clust,\n",
                "  author = {Schweinberger, Martin},\n",
                "  title = {Cluster and Correspondence Analysis in R},\n",
                "  note = {https://slcladal.github.io/clust.html},\n",
                "  year = {`r format(Sys.time(), '%Y')`},\n",
                "  organization = \"The University of Queensland, Australia. School of Languages and Cultures},\n",
                "  address = {Brisbane},\n",
                "  edition = {`r format(Sys.time(), '%Y.%m.%d')`}\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sessionInfo()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "[Back to top](#introduction)\n",
                "\n",
                "[Back to HOME](https://slcladal.github.io/index.html)\n",
                "\n",
                "***\n",
                "\n",
                "# References {-}\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
