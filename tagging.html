<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2020-10-04" />

<title>POS-Tagging and Syntactic Parsing with R</title>

<script src="site_libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.15/datatables.js"></script>
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LADAL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="people.html">OUR PEOPLE</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    NEWS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="news.html">Announcements</a>
    </li>
    <li>
      <a href="conferences.html">Events</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="introcomputer.html">Working with Computers: Tips and Tricks</a>
    </li>
    <li>
      <a href="reproducibility.html">Data Management, Version Control, and Reproducibility</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Quantitative Research</li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="IntroR_workshop.html">Getting started</a>
    </li>
    <li>
      <a href="stringprocessing.html">String Processing</a>
    </li>
    <li>
      <a href="regularexpressions.html">Regular Expressions</a>
    </li>
    <li>
      <a href="introtables.html">Working with Tables</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="basicgraphs.html">Common Visualization Types</a>
    </li>
    <li>
      <a href="basicgraphs.html">Advanced Visualization Methods</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="descriptivestatz.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="advancedstatztrees.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="groupingstatz.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="basicnetwork.html">Network Analysis</a>
    </li>
    <li>
      <a href="collocations.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS &amp; CASE STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lex.html">Lexicography with R: Generating Dictionaries</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys: Analyses with R</a>
    </li>
    <li>
      <a href="corplingr.html">Corpus Linguistics with R: Swearing in Irish English</a>
    </li>
    <li>
      <a href="vc.html">Phonetics: Creating Vowel Charts with Praat and R</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Useful How-To Tutorials</li>
    <li>
      <a href="convertpdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
  </ul>
</li>
<li>
  <a href="services.html">SERVICES &amp; CONTACT</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">POS-Tagging and Syntactic Parsing with R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2020-10-04</h4>

</div>


<p><img src="images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>This tutorial introduces part-of-speech tagging and syntactic parsing using R. The entire R markdown document for this tutorial can be downloaded <a href="https://slcladal.github.io/tagging.Rmd">here</a>. Another highly recommendable tutorial on part-of-speech tagging in R produced by Andreas Niekler and Gregor Wiedemann can be found <a href="https://tm4ss.github.io/docs/Tutorial_8_NER_POS.html">here</a> <span class="citation">(see Wiedemann and Niekler <a href="#ref-WN17" role="doc-biblioref">2017</a>)</span>.</p>
</div>
<div id="part-of-speech-tagging" class="section level1">
<h1><span class="header-section-number">1</span> Part-Of-Speech Tagging</h1>
<p>Many analyses of language data require that we distinguish different parts of speech. In order to determine the word class of a certain word, we use a procedure which is called part-of-speech tagging (commonly referred to as pos-, pos-, or PoS-tagging). pos-tagging is a common procedure when working with natural language data. Despite being used quite frequently, it is a rather complex issue that requires the application of statistical methods that are quite advanced. In the following, we will explore different options for pos-tagging and syntactic parsing.</p>
<p>Parts-of-speech, or word categories, refer to the grammatical nature or category of a lexical item, e.g. in the sentence <em>Jane likes the girl</em> each lexical item can be classified according to whether it belongs to the group of determiners, verbs, nouns, etc. pos-tagging refers to a (computation) process in which information is added to existing text. This process is also called <em>annotation</em>. Annotation can be very different depending on the task at hand. The most common type of annotation when it comes to language data is part-of-speech tagging where the word class is determined for each word in a text and the word class is then added to the word as a tag. However, there are many different ways to tag or annotate texts.</p>
<p>Pos–tagging assigns part-of-speech tags to character strings (these represent mostly words, of course, but also encompass punctuation marks and other elements). This means that pos–tagging is one specific type of annotation, i.e. adding information to data (either by directly adding information to the data itself or by storing information in e.g. a list which is linked to the data). It is important to note that annotation encompasses various types of information such as pauses, overlap, etc. pos–tagging is just one of these many ways in which corpus data can be <em>enriched</em>. Sentiment Analysis, for instance, also annotates texts or words with respect to its or their emotional value or polarity.</p>
<p>Annotation is required in many machine-learning contexts because annotated texts are commonly used as training sets on which machine learning or deep learning models are trained that then predict, for unknown words or texts, what values they would most likely be assigned if the annotation were done manually. Also, it should be mentioned that by many online services offer pos-tagging (e.g. <a href="http://www.infogistics.com/posdemo.htm">here</a> or <a href="https://linguakit.com/en/part-of-speech-tagging">here</a>.</p>
<p>When pos–tagged, the example sentence could look like the example below.</p>
<ol style="list-style-type: decimal">
<li>Jane/NNP likes/VBZ the/DT girl/NN</li>
</ol>
<p>In the example above, <code>NNP</code> stands for proper noun (singular), <code>VBZ</code> stands for 3rd person singular present tense verb, <code>DT</code> for determiner, and <code>NN</code> for noun(singular or mass). The pos-tags used by the <code>openNLPpackage</code> are the <a href="https://dpdearing.com/posts/2011/12/opennlp-part-of-speech-pos-tags-penn-english-treebank/">Penn English Treebank pos-tags</a>. A more elaborate description of the tags can be found here which is summarised below:</p>
<div id="htmlwidget-447f7681decb9781676b" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-447f7681decb9781676b">{"x":{"filter":"none","data":[["CC","CD","DT","EX","FW","IN","JJ","JJR","JJS","LS","MD","NN","NNS","NNP","NNPS","PDT","POS","PRP","PRP$","RB","RBR","RBS","RP","SYM","TO","UH","VB","VBD","VBG","VBN","VBP","VBZ","WDT","WP","WP$","WRB"],["Coordinating conjunction","Cardinal number","Determiner","Existential there","Foreign word","Preposition or subordinating con","Adjective","Adjective, comparative","Adjective, superlative","List item marker","Modal","Noun, singular or mass","Noun, plural","Proper noun, singular","Proper noun, plural","Predeterminer","Possessive ending","Personal pronoun","Possessive pronoun","Adverb","Adverb, comparative","Adverb, superlative","Particle","Symbol","to","Interjection","Verb, base form","Verb, past tense","Verb, gerund or present particip","Verb, past participle","Verb, non-3rd person singular pr","Verb, 3rd person singular presen","Wh-determiner","Wh-pronoun","Possessive wh-pronoun","Wh-adverb"],["and, or, but","one, two, three","a, the","There/EX was a party in progress","persona/FW non/FW grata/FW","uh, well, yes","good, bad, ugly","better, nicer","best, nicest","a., b., 1., 2.","can, would, will","tree, chair","trees, chairs","John, Paul, CIA","Johns, Pauls, CIAs","all/PDT this marble, many/PDT a soul","John/NNP 's/POS, the parentss/NNP '/POS distress","I, you, he","mine, yours","evry, enough, not","later","latest","RP","CO2","to","uhm, uh","go, walk","walked, saw","walking, seeing","walked, thought","walk, think","walks, thinks","which, that","what, who, whom (wh-pronoun)","whose, who (wh-words)","how, where, why (wh-adverb)"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Tag<\/th>\n      <th>Description<\/th>\n      <th>Examples<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Assigning these pos-tags to words appears to be rather straight forward. However, pos-tagging is quite complex and there are various ways by which a computer can be trained to assign pos-tags. For example, one could use orthographic or morphological information to devise rules such as. . .</p>
<ul>
<li><p>If a word ends in <em>ment</em>, assign the pos-tag <code>NN</code> (for common noun)</p></li>
<li><p>If a word does not occur at the beginning of a sentence but is capitalized, assign the pos-tag <code>NNP</code> (for proper noun)</p></li>
</ul>
<p>Using such rules has the disadvantage that pos-tags can only be assigned to a relatively small number of words as most words will be ambiguous – think of the similarity of the English plural and the English past tense morpheme,for instance, which are orthographically identical.Another option would be to use a dictionary in which each word is as-signed a certain pos-tag and a program could assign the pos-tag if the word occurs in a given text. This procedure has the disadvantage that most words belong to more than one word class and pos-tagging would thus have to rely on additional information.The problem of words that belong to more than one word class can partly be remedied by including contextual information such as. .</p>
<ul>
<li>If the previous word is a determiner and the following word is a common noun, assign the pos-tag <code>JJ</code> (for a common adjective)</li>
</ul>
<p>This procedure works quite well but there are still better options.The best way to pos-tag a text is to create a manually annotated training set which resembles the language variety at hand. Based on the frequency of the association between a given word and the pos-tags it is assigned in the training data, it is possible to tag a word with the pos-tag that is most often assigned to the given word in the training data.All of the above methods can and should be optimized by combining them and additionally including pos–n–grams, i.e. determining a pos-tag of an unknown word based on which sequence of pos-tags is most similar to the sequence at hand and also most common in the training data.This introduction is extremely superficial and only intends to scratch some of the basic procedures that pos-tagging relies on. The interested reader is referred to introductions on machine learning and pos-tagging such as e.g.https://class.coursera.org/nlp/lecture/149.</p>
<p>There are several different R packages that assist with pos-tagging texts <span class="citation">(see Kumar and Paul <a href="#ref-kumar2016mastering" role="doc-biblioref">2016</a>)</span>. In this tutorial, we will use the <code>openNLP</code>, the <code>corNLP</code>, and the <code>TreeTagger</code> packages. Each of these has advantages and shortcomings and it is advantageous to try which result best matches one’s needs.</p>
<div id="preparation-and-session-set-up" class="section level3 unnumbered">
<h3>Preparation and session set up</h3>
<p>This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R <a href="https://slcladal.github.io/IntroR_workshop.html">here</a>. For this tutorials, we need to install certain <em>packages</em> from an R <em>library</em> so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># clean current workspace
rm(list=ls(all=T))
# set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # suppress math annotation
install libraries(&quot;dplyr&quot;, &quot;igraph&quot;, &quot;tm&quot;, &quot;NLP&quot;, &quot;openNLP&quot;,
                  &quot;openNLPdata&quot;, &quot;coreNLP&quot;, &quot;stringr&quot;, &quot;koRpus&quot;, 
                  &quot;koRpus.lang.en&quot;))</code></pre>
<p>We now activate these packages and load a function provided by LADAL which allows to pos-tag English text once they are read into R.</p>
<pre class="r"><code># activate packages
library(dplyr)
library(igraph)
library(tm)
library(NLP)
library(openNLP)
library(openNLPdata)
#library(coreNLP)
library(stringr)
library(koRpus)
library(koRpus.lang.en)
# load function for pos-tagging objects in R
source(&quot;https://slcladal.github.io/rscripts/POStagObject.r&quot;) </code></pre>
<p>Once you have installed R Studio and initiated the session by executing the code shown above, you maybe good to go.</p>
<p><span style="color: red;">NOTE</span></p>
<pre><code>A word of warning is in order here. The `openNLP` library is written is Java and may require a re-installation of Java as well as re-setting the path variable to Java. 
</code></pre>
<p>A short video on how to set the path variable can be found <a href="https://www.youtube.com/watch?v=yrRmLOcB9fg">here</a>.</p>
</div>
</div>
<div id="part-of-speech-tagging-with-opennlp" class="section level1">
<h1><span class="header-section-number">2</span> Part-Of-Speech Tagging with openNLP</h1>
<p>In R we can pos–tag large amounts of text by various means. This section explores pos-tagging using the <code>openNLP</code> package. Using the <code>openNLP</code> package for pos-tagging works particularly well when the aim is to pos-tag newspaper texts as the <code>openNLP</code> package implements the <em>Apache OpenNLPMaxent Part of Speech tagger</em> and it comes with pre-trained models. Ideally, pos-taggers should be trained on data resembling the data to be pos-tagged.However, I do not know how to trained the <em>Apache openNLP pos-tagger</em> via R and it would be great if someone would provide a tutorial on how to do that. Using pre-trained models has the advantage that we do not need to train the pos-tagger ourselves. However, it also means that one has to rely on models trained on data that may not really resemble the data a at hand.This implies that using it for texts that differ from newspaper texts, i.e.the language the models have been trained on, does not work as well, as the model applies the probabilities of newspaper language to the language variety at hand. pos-tagging with the <code>openNLP</code> requires the <code>NLP</code> package and installing the models on which the <code>openNLP</code> package is based.</p>
<p>To pos-tag a text, we start by loading an example text into R.</p>
<pre class="r"><code># load corpus data
text &lt;- readLines(&quot;https://slcladal.github.io/data/testcorpus/linguistics07.txt&quot;, skipNul = T)
# clean data
text &lt;- text %&gt;%
 str_squish() 
# inspect data
str(text)</code></pre>
<pre><code>##  chr &quot;Related areas of study also includes the disciplines of semiotics (the study of direct and indirect language th&quot;| __truncated__</code></pre>
<p>Now that the text data has been read into R, we can proceed with the part-of-speech tagging. To perform the pos-tagging, we load the function for pos-tagging, load the <code>NLP</code> and <code>openNLP</code> packages.</p>
<p><span style="color: red;">NOTE</span></p>
<pre><code>You need to change the path that is used in the code below and include the path to `en-pos-maxent.bin` on your computer! 
</code></pre>
<pre class="r"><code>POStag &lt;- function(object){
  require(&quot;stringr&quot;)
  require(&quot;NLP&quot;)
  require(&quot;openNLP&quot;)
  require(&quot;openNLPdata&quot;)
  # define paths to corpus files
  corpus.tmp &lt;- object
  # define sentence annotator
  sent_token_annotator &lt;- Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator &lt;- Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator &lt;- Maxent_POS_Tag_Annotator(language = &quot;en&quot;, probs = FALSE, 
    # WARNING: YOU NEED TO INCLUDE YOUR OWN PATH HERE!                                            
    model = &quot;C:\\Users\\marti\\OneDrive\\Dokumente\\R\\win-library\\3.4\\openNLPdata\\models\\en-pos-maxent.bin&quot;)
  # convert all file content to strings
  Corpus &lt;- lapply(corpus.tmp, function(x){
    x &lt;- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 &lt;- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2&lt;- NLP::annotate(x, pos_tag_annotator, y1)
    y2w &lt;- subset(y2, type == &quot;word&quot;)
    tags &lt;- sapply(y2w$features, &#39;[[&#39;, &quot;POS&quot;)
    r1 &lt;- sprintf(&quot;%s/%s&quot;, x[y2w], tags)
    r2 &lt;- paste(r1, collapse = &quot; &quot;)
    return(r2)  }  )
  }</code></pre>
<p>We now apply this function to our text.</p>
<pre class="r"><code># pos tagging data
textpos &lt;- POStag(object = text)
textpos</code></pre>
<pre><code>## [[1]]
## [1] &quot;Related/JJ areas/NNS of/IN study/NN also/RB includes/VBZ the/DT disciplines/NNS of/IN semiotics/NNS (/-LRB- the/DT study/NN of/IN direct/JJ and/CC indirect/JJ language/NN through/IN signs/NNS and/CC symbols/NNS )/-RRB- ,/, literary/JJ criticism/NN (/-LRB- the/DT historical/JJ and/CC ideological/JJ analysis/NN of/IN literature/NN ,/, cinema/NN ,/, art/NN ,/, or/CC published/JJ material/NN )/-RRB- ,/, translation/NN (/-LRB- the/DT conversion/NN and/CC documentation/NN of/IN meaning/NN in/IN written/spoken/VBN text/NN from/IN one/CD language/NN or/CC dialect/NN onto/IN another/DT )/-RRB- ,/, and/CC speech-language/NN pathology/NN (/-LRB- a/DT corrective/JJ method/NN to/TO cure/VB phonetic/JJ disabilities/NNS and/CC dis-functions/NNS at/IN the/DT cognitive/JJ level/NN )/-RRB- ./.&quot;</code></pre>
<p>The resulting vector contains the part-of-speech tagged text and shows that the function fulfills its purpose in automatically pos-tagging the text. The pos-tagged text could now be processed further, e.g. by extracting all adjectives in the text or by creating concordances of nouns ending in <em>ment</em>.</p>
<div id="opennlp-pos-tagging-languages-other-than-english" class="section level2 unnumbered">
<h2>openNLP: pos-tagging languages other than English</h2>
<p>By default, <code>openNLP</code> is only able to handle English text. However, the functionality of <code>openNLP</code> can be extended to languages other than English. In order to extend <code>openNLP</code>’s functionality, you need to download the available language models from <a href="http://opennlp.sourceforge.net/models-1.5/" class="uri">http://opennlp.sourceforge.net/models-1.5/</a> and save them in the <code>models</code> folder of the <code>openNLPdata</code> package in your R library.</p>
<p>To ease the implementation of openNLP-based pos-tagging, we will write functions for pos-tagging that we can then apply to the texts that we want to tag rather than executing a pipeling of commands.</p>
<div id="part-of-speech-tagging-a-dutch-text" class="section level3 unnumbered">
<h3>Part-of-speech tagging a Dutch text</h3>
<p>One of the languages that openNLP can handle is Dutch. To pos-tag Dutch texts, we write a function that we can then apply to the Dutch text in order to pos-tag it.</p>
<pre class="r"><code>postag_nl &lt;- function(object){
  require(&quot;stringr&quot;)
  require(&quot;NLP&quot;)
  require(&quot;openNLP&quot;)
  require(&quot;openNLPdata&quot;)
  # define sentence annotator
  sent_token_annotator &lt;- Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator &lt;- Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator &lt;- Maxent_POS_Tag_Annotator(language = &quot;nl&quot;, probs = FALSE,                                    model = &quot;C:\\Users\\marti\\OneDrive\\Dokumente\\R\\win-library\\4.0\\openNLPdata\\models\\nl-pos-maxent.bin&quot;)
  # convert all file content to strings
  Corpus &lt;- lapply(object, function(x){
    x &lt;- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 &lt;- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2&lt;- NLP::annotate(x, pos_tag_annotator, y1)
    y2w &lt;- subset(y2, type == &quot;word&quot;)
    tags &lt;- sapply(y2w$features, &#39;[[&#39;, &quot;POS&quot;)
    r1 &lt;- sprintf(&quot;%s/%s&quot;, x[y2w], tags)
    r2 &lt;- paste(r1, collapse = &quot; &quot;)
    return(r2)  }  )
  }</code></pre>
<p>We now apply this function to our text.</p>
<pre class="r"><code>dutchtext &lt;- readLines(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/dutch.txt&quot;)
# pos tagging data
textpos_nl &lt;- postag_nl(object = dutchtext)
textpos_nl</code></pre>
<pre><code>## [[1]]
## [1] &quot;Taalkunde/N ,/Punc ook/Adv wel/Adv taalwetenschap/N of/Conj linguÃ¯stiek/N ,/Punc is/V de/Art wetenschappelijke/Adj studie/N van/Prep de/Art natuurlijke/Adj talen/N ./Punc&quot;</code></pre>
</div>
<div id="part-of-speech-tagging-a-german-text" class="section level3 unnumbered">
<h3>Part-of-speech tagging a German text</h3>
<pre class="r"><code>postag_de &lt;- function(object){
  require(&quot;stringr&quot;)
  require(&quot;NLP&quot;)
  require(&quot;openNLP&quot;)
  require(&quot;openNLPdata&quot;)
  # define sentence annotator
  sent_token_annotator &lt;- Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator &lt;- Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator &lt;- Maxent_POS_Tag_Annotator(language = &quot;de&quot;, probs = FALSE,                                    model = &quot;C:\\Users\\marti\\OneDrive\\Dokumente\\R\\win-library\\4.0\\openNLPdata\\models\\de-pos-maxent.bin&quot;)
  # convert all file content to strings
  Corpus &lt;- lapply(object, function(x){
    x &lt;- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 &lt;- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2&lt;- NLP::annotate(x, pos_tag_annotator, y1)
    y2w &lt;- subset(y2, type == &quot;word&quot;)
    tags &lt;- sapply(y2w$features, &#39;[[&#39;, &quot;POS&quot;)
    r1 &lt;- sprintf(&quot;%s/%s&quot;, x[y2w], tags)
    r2 &lt;- paste(r1, collapse = &quot; &quot;)
    return(r2)  }  )
  }</code></pre>
<p>We now apply this function to our text.</p>
<pre class="r"><code>gertext &lt;- readLines(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/german.txt&quot;)
# pos tagging data
textpos_de &lt;- postag_nl(object = gertext)
textpos_de</code></pre>
<pre><code>## [[1]]
## [1] &quot;Sprachwissenschaft/Adj untersucht/N in/Prep verschiedenen/N Herangehensweisen/N die/Pron menschliche/N Sprache/Adj ./Punc&quot;</code></pre>
</div>
</div>
</div>
<div id="part-of-speech-tagging-with-treetagger" class="section level1">
<h1><span class="header-section-number">3</span> Part-Of-Speech Tagging with TreeTagger</h1>
<p>An alternative to <code>openNLP</code> for pos-tagging texts in R is the <code>koRpus</code> package. The <code>koRpus</code> package uses the <a href="cf.http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/">TreeTagger</a> which means that the TreeTagger has to be installed prior to pos-tagging based on <code>koRpus</code> package. The <code>koRpus</code> package simply accesses the TreeTagger via R. The fact that the the implementation of the TreeTagger requires software outside of R that has to be installed separately and prior to being able to use the <code>koRpus</code> package and its functions in R represents a major disadvantage compared to the <code>openNLP</code> approach (which also relies on external software but this is contained within the <code>openNLP</code> package). In addition, the installation of the TreeTagger can be quite tedious to implement (in case you are running a Windows machine as I do). On the other hand, the <code>koRpus</code> package has the advantage that the TreeTagger encompasses more languages than the <code>openNLP</code> package and the TreeTagger can be relatively easily modified and trained on new data.</p>
<div id="treetagger-installation-on-windows" class="section level2 unnumbered">
<h2>TreeTagger installation on Windows</h2>
<p>As the installation of the TreeTagger can be somewhat tedious and time consuming, I would like to expand on what I did to get it going as this might save you some time and frustration.</p>
<ol style="list-style-type: decimal">
<li><p>The first thing you should do is to install or re-install a Perl interpreter. You can simply do so by clicking <a href="http://www.activestate.com/activeperl/">here</a> and following the installation instructions.</p></li>
<li><p>Download the TreeTagger (click <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-windows-3.2.3.zip">here</a> for a Windows-64 version and <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-windows32-3.2.3.zip">here</a> for a Windows-32 version). Move the zip-file to the root directory on your C-drive (C:/) and extract the zip file.</p></li>
<li><p>Download the parameter files for the languages you need (you will find the parameters files under <em>Parameter files</em> <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/#Windows">here</a>). Then decompress the parameter files and move them to the sub-directory <code>TreeTagger/lib</code>. Rename the parameter files to <code>&lt;language&gt;-utf8.par</code>. For example, rename the file <code>french-par-linux-3.2-utf8.bin</code> as <code>french-utf8.par</code>.</p></li>
<li><p>Now you need to set a path variable. You need to add the path <code>C:\TreeTagger\bin</code> to the <code>PATH</code> environment variable. How to do this differs across Windows versions. You can find a video tutorial on how to change path variables in Windows 10 <a href="https://www.youtube.com/watch?v=Frrlv_5rGhY">here</a>. If you have a different Windows version, e.g. Windows 7, I recommend you search for <em>Set path variable in Windows 7</em> on YouTube and follow the instructions.</p></li>
<li><p>Next, open a command prompt window and type the command:</p></li>
</ol>
<pre class="r"><code>set PATH=C:\TreeTagger\bin;%PATH%</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Then, go to the directory C:by typing the command:</li>
</ol>
<pre class="r"><code>cd c:\TreeTagger</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Now, everything should be running and you can test the tagger, e.g. by pos-tagging the TreeTagger installation file. To do this, type the command:</li>
</ol>
<pre class="r"><code>tag-english INSTALL.txt</code></pre>
<p>If you do not get the pos-tagged results after a few seconds, restart your computer and repeat steps 1 to 7.</p>
<p>If you install the TreeTagger in a different directory, you have to modify the first path in the batch files tag-*.bat using an editor such as <code>Wordpad</code>.</p>
<p>The main issues that occurred during my installation was that I had to re-install Java but once I had done so, it finally worked.</p>
</div>
<div id="using-the-treetagger" class="section level2 unnumbered">
<h2>Using the TreeTagger</h2>
<p>In this example, we simply implement the TreeTagger without training it! This is in fact not a good practice and should be avoided as I have no way of knowing how good the performance is or what I could do to improve its performance!</p>
<pre class="r"><code># activate packages
library(koRpus)
library(koRpus.lang.en)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-english.bat&quot;, lang=&quot;en&quot;) 
postagged &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics07.txt&quot;)
# inspect  results
datatable(postagged@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-21fcb08bc2b55a00a3d8" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-21fcb08bc2b55a00a3d8">{"x":{"filter":"none","data":[["linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt","linguistics07.txt"],["Related","areas","of","study","also","includes","the","disciplines","of","semiotics","(","the","study","of","direct","and","indirect","language","through","signs","and","symbols",")",",","literary","criticism","(","the","historical","and","ideological","analysis","of","literature",",","cinema",",","art",",","or","published","material",")",",","translation","(","the","conversion","and","documentation","of","meaning","in","written/spoken","text","from","one","language","or","dialect","onto","another",")",",","and","speech-language","pathology","(","a","corrective","method","to","cure","phonetic","disabilities","and","dis-functions","at","the","cognitive","level",")","."],["JJ","NNS","IN","NN","RB","VVZ","DT","NNS","IN","NNS","(","DT","NN","IN","JJ","CC","JJ","NN","IN","NNS","CC","NNS",")",",","JJ","NN","(","DT","JJ","CC","JJ","NN","IN","NN",",","NN",",","NN",",","CC","VVN","NN",")",",","NN","(","DT","NN","CC","NN","IN","VVG","IN","JJ","NN","IN","CD","NN","CC","NN","IN","DT",")",",","CC","NN","NN","(","DT","JJ","NN","TO","VV","JJ","NNS","CC","NNS","IN","DT","JJ","NN",")","SENT"],["related","area","of","study","also","include","the","discipline","of","semiotics","(","the","study","of","direct","and","indirect","language","through","sign","and","symbol",")",",","literary","criticism","(","the","historical","and","ideological","analysis","of","literature",",","cinema",",","art",",","or","publish","material",")",",","translation","(","the","conversion","and","documentation","of","mean","in","written/spoken","text","from","one","language","or","dialect","onto","another",")",",","and","speech-language","pathology","(","a","corrective","method","to","cure","phonetic","disability","and","dis-functions","at","the","cognitive","level",")","."],[7,5,2,5,4,8,3,11,2,9,1,3,5,2,6,3,8,8,7,5,3,7,1,1,8,9,1,3,10,3,11,8,2,10,1,6,1,3,1,2,9,8,1,1,11,1,3,10,3,13,2,7,2,14,4,4,3,8,2,7,4,7,1,1,3,15,9,1,1,10,6,2,4,8,12,3,13,2,3,9,5,1,1],["adjective","noun","preposition","noun","adverb","verb","determiner","noun","preposition","noun","punctuation","determiner","noun","preposition","adjective","conjunction","adjective","noun","preposition","noun","conjunction","noun","punctuation","comma","adjective","noun","punctuation","determiner","adjective","conjunction","adjective","noun","preposition","noun","comma","noun","comma","noun","comma","conjunction","verb","noun","punctuation","comma","noun","punctuation","determiner","noun","conjunction","noun","preposition","verb","preposition","adjective","noun","preposition","number","noun","conjunction","noun","preposition","determiner","punctuation","comma","conjunction","noun","noun","punctuation","determiner","adjective","noun","to","verb","adjective","noun","conjunction","noun","preposition","determiner","adjective","noun","punctuation","fullstop"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>We can now paste the text and the pos-tags together using the <code>paste</code> function from base R.</p>
<pre class="r"><code>postaggedtext &lt;- paste(postagged@tokens$token, postagged@tokens$tag, sep = &quot;/&quot;, collapse = &quot; &quot;)
postaggedtext</code></pre>
<pre><code>## [1] &quot;Related/JJ areas/NNS of/IN study/NN also/RB includes/VVZ the/DT disciplines/NNS of/IN semiotics/NNS (/( the/DT study/NN of/IN direct/JJ and/CC indirect/JJ language/NN through/IN signs/NNS and/CC symbols/NNS )/) ,/, literary/JJ criticism/NN (/( the/DT historical/JJ and/CC ideological/JJ analysis/NN of/IN literature/NN ,/, cinema/NN ,/, art/NN ,/, or/CC published/VVN material/NN )/) ,/, translation/NN (/( the/DT conversion/NN and/CC documentation/NN of/IN meaning/VVG in/IN written/spoken/JJ text/NN from/IN one/CD language/NN or/CC dialect/NN onto/IN another/DT )/) ,/, and/CC speech-language/NN pathology/NN (/( a/DT corrective/JJ method/NN to/TO cure/VV phonetic/JJ disabilities/NNS and/CC dis-functions/NNS at/IN the/DT cognitive/JJ level/NN )/) ./SENT&quot;</code></pre>
</div>
<div id="treetagger-pos-tagging-multiple-files" class="section level2 unnumbered">
<h2>TreeTagger: pos-tagging multiple files</h2>
<p>To pos-tag several files at once you need to create a list of paths and then apply the <code>treetagger</code> to each of the path elements. Once we have done so, we inspect the structure of the resulting vector which now holds the pos-tagged texts.</p>
<pre class="r"><code>corpuspath &lt;- &quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus&quot;
# generate list of corpus files
corpusfiles &lt;- list.files(corpuspath)
cfiles &lt;- paste0(corpuspath, &quot;/&quot;, corpusfiles, sep = &quot;&quot;)
# apply treetagger to each file in corpus
postagged_files &lt;- sapply(cfiles, function(x){
  set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-english.bat&quot;, lang=&quot;en&quot;) 
  x &lt;- treetag(x)
  x &lt;- paste(x@tokens$token, x@tokens$tag, sep = &quot;/&quot;, collapse = &quot; &quot;)
})
# inspect  text.tagged
str(postagged_files)</code></pre>
<pre><code>##  Named chr [1:7] &quot;Linguistics/NN is/VBZ the/DT scientific/JJ study/NN of/IN language/NN ./SENT It/PP involves/VVZ analysing/VVG l&quot;| __truncated__ ...
##  - attr(*, &quot;names&quot;)= chr [1:7] &quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics01.txt&quot; &quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics02.txt&quot; &quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics03.txt&quot; &quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics04.txt&quot; ...</code></pre>
<p>The first pos-tagged corpus file looks like this.</p>
<pre class="r"><code>postagged_files[1]</code></pre>
<pre><code>##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data\\testcorpus/linguistics01.txt 
## &quot;Linguistics/NN is/VBZ the/DT scientific/JJ study/NN of/IN language/NN ./SENT It/PP involves/VVZ analysing/VVG language/NN form/NN language/NN meaning/NN and/CC language/NN in/IN context/NN ./SENT The/DT earliest/JJS activities/NNS in/IN the/DT documentation/NN and/CC description/NN of/IN language/NN have/VHP been/VBN attributed/VVN to/TO the/DT th-century-BC/NN Indian/JJ grammarian/NN Pa/NP ?/SENT ini/NNS who/WP wrote/VVD a/DT formal/JJ description/NN of/IN the/DT Sanskrit/NN language/NN in/IN his/PP$ A/NP ?/SENT ?adhyayi/NNS ./SENT Linguists/NNS traditionally/RB analyse/VVP human/JJ language/NN by/IN observing/VVG an/DT interplay/NN between/IN sound/NN and/CC meaning/NN ./SENT Phonetics/NN is/VBZ the/DT study/NN of/IN speech/NN and/CC non-speech/NN sounds/NNS and/CC delves/VVZ into/IN their/PP$ acoustic/JJ and/CC articulatory/JJ properties/NNS ./SENT The/DT study/NN of/IN language/NN meaning/NN on/IN the/DT other/JJ hand/NN deals/NNS with/IN how/WRB languages/NNS encode/VVP relations/NNS between/IN entities/NNS properties/NNS and/CC other/JJ aspects/NNS of/IN the/DT world/NN to/TO convey/VV process/NN and/CC assign/VV meaning/VVG as/RB well/RB as/RB manage/VV and/CC resolve/VV ambiguity/NN ./SENT While/IN the/DT study/NN of/IN semantics/NN typically/RB concerns/VVZ itself/PP with/IN truth/NN conditions/NNS pragmatics/NN deals/NNS with/IN how/WRB situational/JJ context/NN influences/VVZ the/DT production/NN of/IN meaning/NN ./SENT&quot;</code></pre>
<p>Note that the tag set used for the pos-tagging above differs slightly from the Penn Treebank Tag set. For example, the end of sentences are tagged as <code>SENT</code> rather as <code>PUNC</code>.</p>
</div>
<div id="treetagger-pos-tagging-languages-other-than-english" class="section level2 unnumbered">
<h2>TreeTagger: pos-tagging languages other than English</h2>
<p>In addition to being very flexible, the TreeTagger is appealing because it supports a comparatively large sample of languages. Here is the list of languages (or varieties) that are currently supported: Bulgarian, Catalan, Chinese, Coptic, Czech, Danish, Dutch, English, Estonian, Finnish, French, Spoken French, Old French, Galician, German, Spoken German, Middle High German, Greek, Ancient Greek, Hausa, Italian, Korean, Latin, Mongolian, Norwegian (Bokmaal), Polish, Portuguese, Romanian, Russian, Slovak, Slovenian, Spanish, Swahili, Swedish.</p>
<p>Unfortunately, not all of these language models are available for R. Currently only language support for English, German, French, Spanish, Italian, and Dutch is currently available via the <code>koRpus</code> package. To be able to use the existing pos-tagging models, you need to download the parameter files as described above and then stored in the <code>lib</code> folder of the TreeTagger folder at the root of your <code>C:/</code>- drive as well as install the respective <code>koRpus.lang</code> models (see below). These models then have to be activated using the <code>library</code> function.</p>
<pre class="r"><code># install support
install.koRpus.lang(&quot;de&quot;)
install.koRpus.lang(&quot;fr&quot;)
install.koRpus.lang(&quot;es&quot;)
install.koRpus.lang(&quot;it&quot;)
install.koRpus.lang(&quot;nl&quot;)</code></pre>
<div id="part-of-speech-tagging-a-german-text-1" class="section level3 unnumbered">
<h3>Part-of-speech tagging a German text</h3>
<pre class="r"><code># activate package
library(koRpus.lang.de)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-german.bat&quot;, lang=&quot;de&quot;) 
postagged_german &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/german.txt&quot;)
# inspect  results
datatable(postagged_german@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-d4a6e0f290d521b86a9c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-d4a6e0f290d521b86a9c">{"x":{"filter":"none","data":[["german.txt","german.txt","german.txt","german.txt","german.txt","german.txt","german.txt","german.txt","german.txt"],["Sprachwissenschaft","untersucht","in","verschiedenen","Herangehensweisen","die","menschliche","Sprache","."],["NN","VVFIN","APPR","ADJA","NN","ART","ADJA","NN","$."],["Sprachwissenschaft","untersuchen","in","verschieden","Herangehensweisen","die","menschlich","Sprache","."],[18,10,2,13,17,3,11,7,1],["noun","verb","preposition","adjective","noun","article","adjective","noun","fullstop"],[null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9],[1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>The German annotation uses the <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/STTS-Tagset.pdf">Stuttgart-Tuebingen tag set</a> (STTS) which is described in great detail <a href="http://www.sfs.uni-tuebingen.de/resources/stts-1999.pdf">here</a>.</p>
</div>
<div id="part-of-speech-tagging-a-french-text" class="section level3 unnumbered">
<h3>Part-of-speech tagging a French text</h3>
<pre class="r"><code># activate package
library(koRpus.lang.fr)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-french.bat&quot;, lang=&quot;fr&quot;) 
postagged_french &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/french.txt&quot;)
# inspect  results
datatable(postagged_french@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-bef3e5790e2ca4c53318" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-bef3e5790e2ca4c53318">{"x":{"filter":"none","data":[["french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt","french.txt"],["La","linguistique","est","une","discipline","scientifique","s’intéressant","à","l’étude","du","langage","."],["DET:ART","ADJ","VER:pres","DET:ART","NOM","ADJ","VER:ppre","PRP","NOM","PRP:det","NOM","SENT"],["le","linguistique","être","un","discipline","scientifique","s’intéressant","à","l’étude","du","langage","."],[2,12,3,3,10,12,13,1,7,2,7,1],["article","adjective","verb","article","noun","adjective","verb","preposition","noun","preposition","noun","fullstop"],[null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9,10,11,12],[1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>The tag set used for pos-tagging French texts is described here and summarized below.</p>
<div id="htmlwidget-09230e38eee3123d0e1c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-09230e38eee3123d0e1c">{"x":{"filter":"none","data":[["BR","ADJ","ADV","DET:ART","DET:POS","INT","KON","NAM","NOM","NUM","PRO","PRO:DEM","PRO:IND","PRO:PER","PRO:POS","PRO:REL","PRP","PRP:det","PUN","PUN:cit","SENT","SYM","VER:cond","VER:futu","VER:impe","VER:impf","VER:infi","VER:pper","VER:ppre","VER:pres","VER:simp","VER:subi","VER:subp"],["abreviation","adjective","adverb","article","possessive pronoun (ma, ta, ...)","interjection","conjunction","proper name","noun","numeral","pronoun","demonstrative pronoun","indefinite pronoun","personal pronoun","possessive pronoun (mien, tien, ...)","relative pronoun","preposition","preposition plus article (au,du,aux,des)","punctuation","punctuation citation","sentence tag","symbol","verb conditional","verb futur","verb imperative","verb imperfect","verb infinitive","verb past participle","verb present participle","verb present","verb simple past","verb subjunctive imperfect","verb subjunctive present"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Tag<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="part-of-speech-tagging-a-spanish-text" class="section level3 unnumbered">
<h3>Part-of-speech tagging a Spanish text</h3>
<pre class="r"><code># activate package
library(koRpus.lang.es)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-spanish.bat&quot;, lang=&quot;es&quot;) 
postagged_spanish &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/spanish.txt&quot;)
# inspect results
datatable(postagged_spanish@tokens, rownames = FALSE, options = list(pageLength = 10, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-e23ff16abe8e009dce9a" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e23ff16abe8e009dce9a">{"x":{"filter":"none","data":[["spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt","spanish.txt"],["La","lingüística","es","el","estudio","científico","del","origen",",","la","evolución","y","la","estructura","del","lenguaje",",","a fin de","deducir","las","leyes","que","rigen","las","lenguas","."],["ART","NC","VSfin","ART","NC","ADJ","PDEL","NC","CM","ART","NC","CC","ART","NC","PDEL","NC","CM","CSUBI","VLinf","ART","NC","CQUE","VLfin","ART","NC","FS"],["el","lingüística","ser","el","estudio","científico","del","origen",",","el","evolución","y","el","estructura","del","lenguaje",",","a~fin~de","deducir","el","ley","que","regir","el","lengua","."],[2,11,2,2,7,10,3,6,1,2,9,1,2,10,3,8,1,8,7,3,5,3,5,3,7,1],["determiner","noun","verb","determiner","noun","adjective","del","noun","comma","determiner","noun","conjunction","determiner","noun","del","noun","comma","conjunction","verb","determiner","noun","conjunction","verb","determiner","noun","fullstop"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>The tag set used for pos-tagging Spanish texts is described <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html">here</a> and summarized below.</p>
<div id="htmlwidget-605c7864bcd82ea3cd81" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-605c7864bcd82ea3cd81">{"x":{"filter":"none","data":[["ACRNM","ADJ","ADV","ALFP","ALFS","ART","BACKSLAS","CARD","CC","CCAD","CCNEG","CM","CODE","COLON","CQUE","CSUBF","CSUBI","CSUBX","DASH","DM","DOTS","FO","FS","INT","ITJN","LP","NC","NEG","NMEA","NMON","NP","ORD","PAL","PDEL","PE","PERCT","PNC","PPC","PPO","PPX","PREP","PREP","PREP/DEL","QT","QU","REL","RP","SE","SEMICOLON","SLASH","SYM","UMMX","VCLIger","VCLIinf","VCLIfin","VEadj","VEfin","VEger","VEinf","VHadj","VHfin","VHger","VHinf","VLadj","VLfin","VLger","VLinf","VMadj","VMfin","VMger","VMinf","VSadj","VSfin","VSger","VSinf"],["acronym (ISO, CEI)","Adjectives (mayores, mayor)","Adverbs (muy, demasiado, cómo)","Plural letter of the alphabet (As/Aes, bes)","Singular letter of the alphabet (A, b)","Articles (un, las, la, unas)","H backslash","Cardinals","Coordinating conjunction (y, o)","Adversative coordinating conjunction (pero)","Negative coordinating conjunction (ni)","comma (,)","Alphanumeric code","colon (:)","que (as conjunction)","Subordinating conjunction that introduces finite clauses (apenas)","Subordinating conjunction that introduces infinite clauses (al)","Subordinating conjunction underspecified for subord-type (aunque)","dash (-)","Demonstrative pronouns (ésas, ése, esta)","pos-tag for ...","Formula","Full stop punctuation marks","Interrogative pronouns (quiénes, cuántas, cuánto)","Interjection (oh, ja)","left parenthesis","Common nouns (mesas, mesa, libro, ordenador)","Negation","measure noun (metros, litros)","month name","Proper nouns","Ordinals (primer, primeras, primera)","Portmanteau word formed by a and el","Portmanteau word formed by de and el","Foreign word","percent sign","Unclassified word","Clitic personal pronoun (le, les)","Possessive pronouns (mi, su, sus)","Clitics and personal pronouns (nos, me, nosotras, te, sí)","Negative preposition (sin)","Preposition","Complex preposition despues del","quotation symbol","Quantifiers (sendas, cada)","Relative pronouns (cuyas, cuyo)","right parenthesis","Se (as particle)","semicolon","slash","Symbols","measure unit (MHz, km, mA)","clitic gerund verb","clitic infinitive verb","clitic finite verb","Verb estar. Past participle","Verb estar. Finite","Verb estar. Gerund","Verb estar. Infinitive","Verb haber. Past participle","Verb haber. Finite","Verb haber. Gerund","Verb haber. Infinitive","Lexical verb. Past participle","Lexical verb. Finite","Lexical verb. Gerund","Lexical verb. Infinitive","Modal verb. Past participle","Modal verb. Finite","Modal verb. Gerund","Modal verb. Infinitive","Verb ser. Past participle","Verb ser. Finite","Verb ser. Gerund","Verb ser. Infinitive"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Tag<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="part-of-speech-tagging-an-italian-text" class="section level3 unnumbered">
<h3>Part-of-speech tagging an Italian text</h3>
<pre class="r"><code># activate package
library(koRpus.lang.it)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-italian.bat&quot;, lang=&quot;it&quot;) 
postagged_italian &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/italian.txt&quot;)
# inspect results
datatable(postagged_italian@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-5a0d26cbc17343f44a7e" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-5a0d26cbc17343f44a7e">{"x":{"filter":"none","data":[["italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt","italian.txt"],["La","linguistica","è","lo","studio","scientifico","del","linguaggio","verbale","umano","e","delle","sue","strutture","."],["DET:def","NOM","VER:pres","DET:def","NOM","ADJ","PRE:det","NOM","ADJ","ADJ","CON","PRE:det","PRO:poss","NOM","SENT"],["il","linguistica","essere","il","studio","scientifico","del","linguaggio","verbale","umano","e","del","suo","struttura","."],[2,11,1,2,6,11,3,10,7,5,1,5,3,9,1],["determiner","noun","verb","determiner","noun","adjective","preposition","noun","adjective","adjective","conjunction","preposition","pronoun","noun","fullstop"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>The tag set used for pos-tagging Italian texts is described <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/italian-tagset.txt">here</a> and summarized below.</p>
<div id="htmlwidget-24193f58d08767cf2354" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-24193f58d08767cf2354">{"x":{"filter":"none","data":[["ABR","ADJ","ADV","CON","DET:def","DET:indef","FW","INT","LS","NOM","NPR","NUM","PON","PRE","PRE:det","PRO","PRO:demo","PRO:indef","PRO:inter","PRO:pers","PRO:poss","PRO:refl","PRO:rela","SENT","SYM","VER:cimp","VER:cond","VER:cpre","VER:futu","VER:geru","VER:impe","VER:impf","VER:infi","VER:pper","VER:ppre","VER:pres","VER:refl:infi","VER:remo"],["abbreviation","adjective","adverb","conjunction","definite article","indefinite article","foreign word","interjection","list symbol","noun","name","numeral","punctuation","preposition","preposition+article","pronoun","demonstrative pronoun","indefinite pronoun","interrogative pronoun","personal pronoun","possessive pronoun","reflexive pronoun","relative pronoun","sentence marker","symbol","verb conjunctive imperfect","verb conditional","verb conjunctive present","verb future tense","verb gerund","verb imperative","verb imperfect","verb infinitive","verb participle perfect","verb participle present","verb present","verb reflexive infinitive","verb simple past"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Tag<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="part-of-speech-tagging-a-dutch-text-1" class="section level3 unnumbered">
<h3>Part-of-speech tagging a Dutch text</h3>
<pre class="r"><code># activate package
library(koRpus.lang.nl)
# perform  POS  tagging
set.kRp.env(TT.cmd=&quot;C:\\TreeTagger\\bin\\tag-dutch.bat&quot;, lang=&quot;nl&quot;) 
postagged_dutch &lt;- treetag(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/dutch.txt&quot;)
# inspect results
datatable(postagged_dutch@tokens, rownames = FALSE, options = list(pageLength = 5, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-e94fd116b999bbc0e5cc" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e94fd116b999bbc0e5cc">{"x":{"filter":"none","data":[["dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt","dutch.txt"],["Taalkunde",",","ook","wel","taalwetenschap","of","linguïstiek",",","is","de","wetenschappelijke","studie","van","de","natuurlijke","talen","."],["nounsg","punc","adv","adv","nounsg","conjcoord","nounsg","punc","verbpressg","det__art","adj","nounsg","prep","det__art","adj","nounpl","$."],["taalkunde",",","ook","wel","taalwetenschap","of","linguïstiek",",","zijn","de","wetenschappelijk","studie","van","de","natuurlijk","taal","."],[9,1,3,3,14,2,11,1,2,2,17,6,3,2,11,5,1],["noun","punctuation","adverb","adverb","noun","conjunction","noun","punctuation","verb","determiner","adjective","noun","preposition","determiner","adjective","noun","fullstop"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>tag<\/th>\n      <th>lemma<\/th>\n      <th>lttr<\/th>\n      <th>wclass<\/th>\n      <th>desc<\/th>\n      <th>stop<\/th>\n      <th>stem<\/th>\n      <th>idx<\/th>\n      <th>sntc<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[4,9,10]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[5,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>The tag set used for pos-tagging Dutch texts is available <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/dutch-tagset.txt">here</a> and summarized below.</p>
<div id="htmlwidget-e841eefcfc28cf794375" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e841eefcfc28cf794375">{"x":{"filter":"none","data":[["$.","adj","adj*kop","adjabbr","adv","advabbr","conjcoord","conjsubo","det__art","det__demo","det__indef","det__poss","det__quest","det__rel","int","noun*kop","nounabbr","nounpl","nounprop","nounsg","num__card","num__ord","partte","prep","prepabbr","pronadv","prondemo","pronindef","pronpers","pronposs","pronquest","pronrefl","pronrel","punc","verbinf","verbpapa","verbpastpl","verbpastsg","verbpresp","verbprespl","verbpressg"],["sentence-final punctuation","adjective","truncated adjective","abbreviated adjective","adverb","abbreviated adverb","coordinating conjunction","subordinating conjunction","article","attributively used demonstrative pronoun","attributively used indefinite pronoun","attributively used possessive pronoun","attributively used question pronoun","attributively used relative pronoun","interjection","truncated noun","abbreviated noun","plural noun","proper name","singular noun","cardinal number","ordinal number","particle te","preposition","abbreviated preposition","pronomial adverb","demonstrative pronoun (used substitutively)","indefined pronoun","personal pronoun","possessive pronoun","question pronoun","reflexive pronoun","relative pronoun","(non-sentential) punctuation","infinitival verb","past participle verb","plural past tense verb","singular past tense verb","present participle verb","plural present tense verb","singular present tense verb"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Tag<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div>
<div id="part-of-speech-tagging-with-spacy" class="section level1">
<h1><span class="header-section-number">4</span> Part-Of-Speech Tagging with spaCy</h1>
<p>Another very interesting option for pos-tagging is interfacing with <code>spaCy</code> which can be done via the <code>spacyr</code> package. Unfortunately, <code>spaCy</code> is Python-based and the interfacing with R requires the installation of Python and the installation of the interface can be tricky. However, there are notable advantages of using <code>spaCy</code> via the <code>spacyr</code> package in that this allows not only pos-tagging texts with different levels of granularity but it also enables you to extract entities and dependencies (syntactical parsing).</p>
<p>As noted above, using <code>spaCy</code> and the installation of the interface with R can be tricky. You can find a very helpful and user-friendly installing instruction <a href="https://cran.r-project.org/web/packages/spacyr/readme/README.html">here</a>. In my case, I initially received some error messages when I installed the <code>spacyr</code> package, when I loaded the <code>spacyr</code> package, and when initializing <code>spaCy</code> via the <code>spacyr</code> package. The trick was to restart the computer an R Studio after each step describe n the installation instructions.</p>
<p>Once you have installed Python, Conda, <code>spaCy</code>, you need to install the <code>spacyr</code> package and initialize the functionalities of <code>spaCy</code> as shown below.</p>
<pre class="r"><code>#install.packages(spacyr)
library(spacyr)
spacy_install()</code></pre>
<p>In a next step, we need to load <code>spacyr</code> package and initialize <code>spaCy</code>.</p>
<pre class="r"><code>library(spacyr)
spacy_initialize()# See Chap 5.1 of the NLTK book, http://www.nltk.org/book/ch05.html</code></pre>
<p>As <code>spacyr</code> automatically loads the relevant functionalities for English, you can annotate an English text and extract dependencies and entities without having to install any further packages as shown below.</p>
<pre class="r"><code>spacytagged &lt;- spacy_parse(text, pos = TRUE, tag = TRUE, dependency = TRUE, entity = TRUE)
# inspect  results
datatable(head(spacytagged, 10), rownames = FALSE, options = list(pageLength = 10, scrollX=T), filter = &quot;none&quot;)</code></pre>
<div id="htmlwidget-1906b0025f8bbd54ed18" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1906b0025f8bbd54ed18">{"x":{"filter":"none","data":[["text1","text1","text1","text1","text1","text1","text1","text1","text1","text1"],[1,1,1,1,1,1,1,1,1,1],[1,2,3,4,5,6,7,8,9,10],["Related","areas","of","study","also","includes","the","disciplines","of","semiotics"],["related","area","of","study","also","include","the","discipline","of","semiotic"],["ADJ","NOUN","ADP","NOUN","ADV","VERB","DET","NOUN","ADP","NOUN"],["JJ","NNS","IN","NN","RB","VBZ","DT","NNS","IN","NNS"],[2,6,2,3,6,6,8,6,8,9],["amod","nsubj","prep","pobj","advmod","ROOT","det","dobj","prep","pobj"],["","","","","","","","","",""]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>sentence_id<\/th>\n      <th>token_id<\/th>\n      <th>token<\/th>\n      <th>lemma<\/th>\n      <th>pos<\/th>\n      <th>tag<\/th>\n      <th>head_token_id<\/th>\n      <th>dep_rel<\/th>\n      <th>entity<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2,7]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Simple pos-tagging of an English text object in R with <code>spacyr</code>.</p>
<pre class="r"><code>txt2 &lt;- c(doc1 = &quot;The fast cat catches mice.\\nThe quick brown dog jumped.&quot;,
          doc2 = &quot;This is the second document.&quot;,
          doc3 = &quot;This is a \\\&quot;quoted\\\&quot; text.&quot; )
spacy_parse(txt2, entity = TRUE, dependency = TRUE)</code></pre>
<pre><code>##    doc_id sentence_id token_id    token    lemma   pos head_token_id  dep_rel
## 1    doc1           1        1      The      the   DET             5      det
## 2    doc1           1        2     fast     fast   ADJ             5     amod
## 3    doc1           1        3      cat      cat  NOUN             4 compound
## 4    doc1           1        4  catches    catch  VERB             5 compound
## 5    doc1           1        5     mice    mouse  NOUN             5     ROOT
## 6    doc1           1        6        .        . PUNCT             5    punct
## 7    doc1           1        7       \n       \n SPACE             6         
## 8    doc1           2        1      The      the   DET             4      det
## 9    doc1           2        2    quick    quick   ADJ             4     amod
## 10   doc1           2        3    brown    brown   ADJ             4     amod
## 11   doc1           2        4      dog      dog  NOUN             5    nsubj
## 12   doc1           2        5   jumped     jump  VERB             5     ROOT
## 13   doc1           2        6        .        . PUNCT             5    punct
## 14   doc2           1        1     This     this   DET             2    nsubj
## 15   doc2           1        2       is       be   AUX             2     ROOT
## 16   doc2           1        3      the      the   DET             5      det
## 17   doc2           1        4   second   second   ADJ             5     amod
## 18   doc2           1        5 document document  NOUN             2     attr
## 19   doc2           1        6        .        . PUNCT             2    punct
## 20   doc3           1        1     This     this   DET             2    nsubj
## 21   doc3           1        2       is       be   AUX             2     ROOT
## 22   doc3           1        3        a        a   DET             7      det
## 23   doc3           1        4        &quot;        &quot; PUNCT             7    punct
## 24   doc3           1        5   quoted    quote  VERB             7     amod
## 25   doc3           1        6        &quot;        &quot; PUNCT             7    punct
## 26   doc3           1        7     text     text  NOUN             2     attr
## 27   doc3           1        8        .        . PUNCT             2    punct
##       entity
## 1           
## 2           
## 3           
## 4           
## 5           
## 6           
## 7           
## 8           
## 9           
## 10          
## 11          
## 12          
## 13          
## 14          
## 15          
## 16          
## 17 ORDINAL_B
## 18          
## 19          
## 20          
## 21          
## 22          
## 23          
## 24          
## 25          
## 26          
## 27</code></pre>
<p>In addition, <code>spacyr</code> also allows to extract or annotate specific elements such as noun phrases.</p>
<pre class="r"><code>txt3 &lt;- &quot;We analyzed the Supreme Court with three natural language processing tools.&quot;
spacy_parse(txt3, entity = TRUE, nounphrase = TRUE)</code></pre>
<pre><code>##    doc_id sentence_id token_id      token      lemma   pos     entity
## 1   text1           1        1         We     -PRON-  PRON           
## 2   text1           1        2   analyzed    analyze  VERB           
## 3   text1           1        3        the        the   DET      ORG_B
## 4   text1           1        4    Supreme    Supreme PROPN      ORG_I
## 5   text1           1        5      Court      Court PROPN      ORG_I
## 6   text1           1        6       with       with   ADP           
## 7   text1           1        7      three      three   NUM CARDINAL_B
## 8   text1           1        8    natural    natural   ADJ           
## 9   text1           1        9   language   language  NOUN           
## 10  text1           1       10 processing processing  NOUN           
## 11  text1           1       11      tools       tool  NOUN           
## 12  text1           1       12          .          . PUNCT           
##    nounphrase whitespace
## 1    beg_root       TRUE
## 2                   TRUE
## 3         beg       TRUE
## 4         mid       TRUE
## 5    end_root       TRUE
## 6                   TRUE
## 7         beg       TRUE
## 8         mid       TRUE
## 9         mid       TRUE
## 10        mid       TRUE
## 11   end_root      FALSE
## 12                 FALSE</code></pre>
<p>Or, we can test if certain elements are of a particular class which can then be used to extract only these elements.</p>
<pre class="r"><code>spacy_parse(txt3, additional_attributes = c(&quot;like_num&quot;, &quot;is_punct&quot;))</code></pre>
<pre><code>##    doc_id sentence_id token_id      token      lemma   pos     entity like_num
## 1   text1           1        1         We     -PRON-  PRON               FALSE
## 2   text1           1        2   analyzed    analyze  VERB               FALSE
## 3   text1           1        3        the        the   DET      ORG_B    FALSE
## 4   text1           1        4    Supreme    Supreme PROPN      ORG_I    FALSE
## 5   text1           1        5      Court      Court PROPN      ORG_I    FALSE
## 6   text1           1        6       with       with   ADP               FALSE
## 7   text1           1        7      three      three   NUM CARDINAL_B     TRUE
## 8   text1           1        8    natural    natural   ADJ               FALSE
## 9   text1           1        9   language   language  NOUN               FALSE
## 10  text1           1       10 processing processing  NOUN               FALSE
## 11  text1           1       11      tools       tool  NOUN               FALSE
## 12  text1           1       12          .          . PUNCT               FALSE
##    is_punct
## 1     FALSE
## 2     FALSE
## 3     FALSE
## 4     FALSE
## 5     FALSE
## 6     FALSE
## 7     FALSE
## 8     FALSE
## 9     FALSE
## 10    FALSE
## 11    FALSE
## 12     TRUE</code></pre>
<p>Now, we use the new variable to extract numbers and punctuation</p>
<pre class="r"><code>spacy_parse(txt3, additional_attributes = c(&quot;like_num&quot;, &quot;is_punct&quot;)) %&gt;%
  filter(is_punct == T | like_num == T)</code></pre>
<pre><code>##   doc_id sentence_id token_id token lemma   pos     entity like_num is_punct
## 1  text1           1        7 three three   NUM CARDINAL_B     TRUE    FALSE
## 2  text1           1       12     .     . PUNCT               FALSE     TRUE</code></pre>
<p>If you want to stop using <code>spaCy</code> you need to finalize, or reverse the initialization, using the <code>spacy_finalize</code> function.</p>
<pre class="r"><code>spacy_finalize()</code></pre>
</div>
<div id="part-of-speech-tagging-with-corenlp" class="section level1">
<h1><span class="header-section-number">5</span> Part-Of-Speech Tagging with coreNLP</h1>
<p>Another package that is very handy when it comes to pos-tagging but more importantly syntactic parsing is the <code>coreNLP</code> package <span class="citation">(see Arnold and Tilton <a href="#ref-arnold2015humanities" role="doc-biblioref">2015</a>)</span>. Unfortunately, we cannot use it at this point as it is not supported by up-to-date versions of R.</p>
<pre class="r"><code>library(coreNLP)
initCoreNLP()

annotation &lt;- annotateString(text)
annotation</code></pre>
</div>
<div id="syntactic-parsing" class="section level1">
<h1><span class="header-section-number">6</span> Syntactic Parsing</h1>
<p>Parsing refers to another type of annotation in which either structural information (as in the case of XML documents) or syntactic relations are added to text. As syntactic parsing is commonly more relevant in the language sciences, the following will focus only on syntactic parsing. syntactic parsing builds on pos-tagging and allows drawing syntactic trees or dependencies. Unfortunately, syntactic parsing still has relatively high error rates when dealing with language that is not very formal. However, syntactic parsing is very reliable when dealing with written language.</p>
<pre class="r"><code>text &lt;- readLines(&quot;D:\\Uni\\UQ\\SLC\\LADAL\\SLCLADAL.github.io\\data/english.txt&quot;)
# convert character to string
s &lt;- as.String(text)
# define sentence and word token annotator
sent_token_annotator &lt;- Maxent_Sent_Token_Annotator()
word_token_annotator &lt;- Maxent_Word_Token_Annotator()
# apply sentence and word annotator
a2 &lt;- annotate(s, list(sent_token_annotator, word_token_annotator))
# define syntactic parsing annotator
parse_annotator &lt;- Parse_Annotator()
# apply parser
p &lt;- parse_annotator(s, a2)
# extract parsed information
ptexts &lt;- sapply(p$features, &#39;[[&#39;, &quot;parse&quot;)
ptexts</code></pre>
<pre><code>## [1] &quot;(TOP (S (S (NP (NNP Linguistics)) (VP (VBZ is) (NP (NP (DT the) (JJ scientific) (NN study)) (PP (IN of) (NP (NN language)))))) (CC and) (S (NP (PRP it)) (VP (VBZ involves) (NP (NP (NP (DT the) (NN analysis)) (PP (IN of) (NP (NN language) (NN form))))(, ,) (NP (NN language) (NN meaning))(, ,) (CC and) (NP (NP (NN language)) (PP (IN in) (NP (NN context)))))))(. .)))&quot;</code></pre>
<pre class="r"><code># read into NLP Tree objects.
ptrees &lt;- lapply(ptexts, Tree_parse)
# show frist tree
ptrees[[1]]</code></pre>
<pre><code>## (TOP
##   (S
##     (S
##       (NP (NNP Linguistics))
##       (VP
##         (VBZ is)
##         (NP
##           (NP (DT the) (JJ scientific) (NN study))
##           (PP (IN of) (NP (NN language))))))
##     (CC and)
##     (S
##       (NP (PRP it))
##       (VP
##         (VBZ involves)
##         (NP
##           (NP
##             (NP (DT the) (NN analysis))
##             (PP (IN of) (NP (NN language) (NN form))))
##           (, ,)
##           (NP (NN language) (NN meaning))
##           (, ,)
##           (CC and)
##           (NP (NP (NN language)) (PP (IN in) (NP (NN context)))))))
##     (. .)))</code></pre>
<p>These trees can, of course, also be shown visually, for instance, in the form of a syntax trees (or tree dendrogram).</p>
<pre class="r"><code># remove punctuation
ptexts[1] &lt;- gsub(&quot;\\(\\. \\.\\)&quot;, &quot;&quot;, ptexts[1])
ptexts[1] &lt;- gsub(&quot;\\(\\, \\,\\)&quot;, &quot;&quot;, ptexts[1])
# load library

source(&quot;https://slcladal.github.io/rscripts/parsetgraph.R&quot;)
parse2graph(ptexts[1], title = &quot;&quot;, margin=-0.2, vertex.color=NA,
 vertex.frame.color=NA, vertex.label.font=2,
 vertex.label.cex=.75, vertex.label.color=&quot;black&quot;, asp=.5,
 edge.width=1, edge.color=&#39;red&#39;, edge.arrow.size=0)</code></pre>
<p><img src="tagging_files/figure-html/pars3-1.png" width="768" /></p>
<p>Syntax trees are very handy because the allow us to check how reliable the parser performed.</p>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2020. <em>POS-Tagging and Syntactic Parsing with R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/tagging.html" class="uri">https://slcladal.github.io/tagging.html</a> (Version 2020/09/29).</p>
<pre><code>@manual{schweinberger2020pos,
  author = {Schweinberger, Martin},
  title = {pos-Tagging and Syntactic Parsing with R},
  note = {https://slcladal.github.io/tagging.html},
  year = {2020},
  organization = &quot;The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {2020/09/29}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19041)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] spacyr_1.2.1          koRpus.lang.nl_0.01-4 koRpus.lang.it_0.1-1 
##  [4] koRpus.lang.es_0.1-1  koRpus.lang.fr_0.1-1  koRpus.lang.de_0.1-1 
##  [7] koRpus.lang.en_0.1-3  koRpus_0.13-2         sylly_0.1-6          
## [10] stringr_1.4.0         openNLPdata_1.5.3-4   openNLP_0.2-7        
## [13] tm_0.7-7              NLP_0.2-0             igraph_1.2.5         
## [16] dplyr_1.0.2           DT_0.15              
## 
## loaded via a namespace (and not attached):
##  [1] reticulate_1.16   tidyselect_1.1.0  xfun_0.16         slam_0.1-47      
##  [5] purrr_0.3.4       rJava_0.9-13      lattice_0.20-41   vctrs_0.3.4      
##  [9] generics_0.0.2    htmltools_0.5.0   yaml_2.2.1        sylly.nl_0.1-2   
## [13] rlang_0.4.7       pillar_1.4.6      glue_1.4.2        rappdirs_0.3.1   
## [17] sylly.es_0.1-2    lifecycle_0.2.0   htmlwidgets_1.5.1 evaluate_0.14    
## [21] knitr_1.30        crosstalk_1.1.0.1 parallel_4.0.2    sylly.en_0.1-3   
## [25] Rcpp_1.0.5        jsonlite_1.7.1    sylly.de_0.1-2    digest_0.6.25    
## [29] stringi_1.5.3     grid_4.0.2        tools_4.0.2       magrittr_1.5     
## [33] tibble_3.0.3      crayon_1.3.4      pkgconfig_2.0.3   ellipsis_0.3.1   
## [37] Matrix_1.2-18     data.table_1.13.0 xml2_1.3.2        sylly.it_0.1-2   
## [41] rmarkdown_2.3     R6_2.4.1          compiler_4.0.2    sylly.fr_0.1-2</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<hr />
<p><a href="https://slcladal.github.io/index.html">Main page</a></p>
<hr />
<div id="refs" class="references">
<div id="ref-arnold2015humanities">
<p>Arnold, Taylor, and Lauren Tilton. 2015. <em>Humanities Data in R: Exploring Networks, Geospatial Data, Images, and Text</em>. Cham: Springer.</p>
</div>
<div id="ref-kumar2016mastering">
<p>Kumar, Ashish, and Avinash Paul. 2016. <em>Mastering Text Mining with R</em>. Packt Publishing Ltd.</p>
</div>
<div id="ref-WN17">
<p>Wiedemann, Gregor, and Andreas Niekler. 2017. “Hands-on: A Five Day Text Mining Course for Humanists and Social Scientists in R.” In <em>Proceedings of the Workshop on Teaching NLP for Digital Humanities (Teach4DH2017), Berlin, Germany, September 12, 2017.</em>, 57–65. <a href="http://ceur-ws.org/Vol-1918/wiedemann.pdf">http://ceur-ws.org/Vol-1918/wiedemann.pdf</a>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
