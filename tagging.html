<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />
<link rel="icon" 
      type="image/x-icon" 
      href="favicon.ico" />


<meta name="author" content="Martin Schweinberger" />

<meta name="date" content="2022-03-18" />

<title>POS-Tagging and Syntactic Parsing with R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>


<!-- added by SKC for LADAL Style -->
<link rel="stylesheet" href="styles.css">
</head>

<body>


<div class="container-fluid main-container">





<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  
  <!-- Added by SKC - LADAL image and thicker top with   -->
  <div class="container-fluid navbar-top" >
    <a href="index.html"> <!-- Make entire top row and text clickable home link  -->
        <div class="row">
            <div class="navbar-brand col-md-12">
              <img src="ladal_icon_cas_tran_white_trimed.png" class="navbar-icon" alt="LADAL"/>
              <span class="navbar-title-note navbar-collapse collapse" >Language Technology and Data Analysis Laboratory</span>
            </div>
        </div>
    </a>
  </div>
  
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!-- SKC removed  navbar brand -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    ABOUT LADAL
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="people.html">People | Collabs</a>
    </li>
    <li>
      <a href="news.html">News</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    EVENTS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="workshops.html">Workshops</a>
    </li>
    <li>
      <a href="webinars2022.html">LADAL Webinar Series 2022</a>
    </li>
    <li>
      <a href="opening.html">LADAL Webinar Series 2021</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    DATA SCIENCE BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to Data Science</li>
    <li>
      <a href="comp.html">Working with Computers</a>
    </li>
    <li>
      <a href="repro.html">Data Management and Reproducibility</a>
    </li>
    <li>
      <a href="introquant.html">Introduction to Quantitative Reasoning</a>
    </li>
    <li>
      <a href="basicquant.html">Basic Concepts in Quantitative Research</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    R BASICS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction to R</li>
    <li>
      <a href="intror.html">Getting started</a>
    </li>
    <li>
      <a href="string.html">String Processing</a>
    </li>
    <li>
      <a href="regex.html">Regular Expressions</a>
    </li>
    <li>
      <a href="table.html">Handling tables in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    TUTORIALS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Data Visualization</li>
    <li>
      <a href="introviz.html">Introduction to Data Viz</a>
    </li>
    <li>
      <a href="dviz.html">Data Visualization with R</a>
    </li>
    <li>
      <a href="maps.html">Displaying Geo-Spatial Data</a>
    </li>
    <li>
      <a href="motion.html">Interactive Charts</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Statistics</li>
    <li>
      <a href="dstats.html">Descriptive Statistics</a>
    </li>
    <li>
      <a href="basicstatz.html">Basic Inferential Statistics</a>
    </li>
    <li>
      <a href="regression.html">Regression Analysis</a>
    </li>
    <li>
      <a href="tree.html">Tree-Based Models</a>
    </li>
    <li>
      <a href="clust.html">Cluster and Correspondence Analysis</a>
    </li>
    <li>
      <a href="lexsim.html">Introduction to Lexical Similarity</a>
    </li>
    <li>
      <a href="svm.html">Semantic Vector Space Models</a>
    </li>
    <li>
      <a href="pwr.html">Power Analysis</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Text Analytics</li>
    <li>
      <a href="textanalysis.html">Text Analysis and Distant Reading</a>
    </li>
    <li>
      <a href="kwics.html">Concordancing (keywords-in-context)</a>
    </li>
    <li>
      <a href="net.html">Network Analysis</a>
    </li>
    <li>
      <a href="coll.html">Co-occurrence and Collocation Analysis</a>
    </li>
    <li>
      <a href="topicmodels.html">Topic Modeling</a>
    </li>
    <li>
      <a href="sentiment.html">Sentiment Analysis</a>
    </li>
    <li>
      <a href="tagging.html">Tagging and Parsing</a>
    </li>
    <li>
      <a href="txtsum.html">Automated Text Summarization</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    FOCUS STUDIES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="corplingr.html">Corpus Linguistics with R</a>
    </li>
    <li>
      <a href="llr.html">Analyzing Learner Language using R</a>
    </li>
    <li>
      <a href="lex.html">Lexicography and Dictionaries with R</a>
    </li>
    <li>
      <a href="surveys.html">Questionnaires and Surveys with R</a>
    </li>
    <li>
      <a href="vc.html">Phonetics: Creating Vowel Charts with Praat and R</a>
    </li>
    <li>
      <a href="litsty.html">Computational Literary Stylistics with R</a>
    </li>
    <li>
      <a href="phylo.html">Phylogenetics for linguistic typology</a>
    </li>
    <li>
      <a href="reinfnlp.html">Reinforcement Learning in NLP</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Useful How-To Tutorials</li>
    <li>
      <a href="pdf2txt.html">Converting PDFs to txt</a>
    </li>
    <li>
      <a href="webcrawling.html">Web Crawling using R</a>
    </li>
    <li>
      <a href="gutenberg.html">Downloading Texts from Project Gutenberg</a>
    </li>
    <li>
      <a href="rename.html">Renaming files with R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    RESOURCES
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="contact.html">Contact</a>
    </li>
    <li>
      <a href="services.html">Services</a>
    </li>
    <li>
      <a href="links.html">Links</a>
    </li>
    <li>
      <a href="base.html">Tutorial stylesheet</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">POS-Tagging and Syntactic Parsing with R</h1>
<h4 class="author">Martin Schweinberger</h4>
<h4 class="date">2022-03-18</h4>

</div>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130562131-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130562131-1');
</script>

<p><img src="https://slcladal.github.io/images/uq1.jpg" width="100%" /></p>
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>This tutorial introduces part-of-speech tagging and syntactic parsing using R.</p>
<p><img src="https://slcladal.github.io/images/gy_chili.jpg" width="15%" style="float:right; padding:10px" /></p>
<p>This tutorial is aimed at beginners and intermediate users of R with the aim of showcasing how to annotate textual data with part-of-speech (pos) tags and how to syntactically parse textual data using R. The aim is not to provide a fully-fledged analysis but rather to show and exemplify selected useful methods associated with pos-tagging and syntactic parsing. Another highly recommendable tutorial on part-of-speech tagging in R with UDPipe is available <a href="https://bnosac.github.io/udpipe/en/">here</a> and another tutorial on pos-tagging and syntactic parsing by Andreas Niekler and Gregor Wiedemann can be found <a href="https://tm4ss.github.io/docs/Tutorial_8_NER_POS.html">here</a> <span class="citation">(see Wiedemann and Niekler <a href="#ref-WN17" role="doc-biblioref">2017</a>)</span>.</p>
<div class="warning" style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
The entire R Notebook for the tutorial can be downloaded <a href="https://slcladal.github.io/tagging.Rmd"><strong>here</strong></a>. If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the <a href="https://slcladal.github.io/bibliography.bib"><strong>bibliography file</strong></a> and store it in the same folder where you store the Rmd file. <br><br> <strong><a href="https://colab.research.google.com/drive/1dVyl0WwxpPpnzBcklILDLSCGimW22u5L?usp=sharing">Here</a></strong> is a <strong>link to an interactive and simplified version of this tutorial on Google Colab</strong>. The interactive tutorial is based on a Jupyter notebook of this tutorial. This interactive Jupyter notebook allows you to execute code yourself and - if you copy the Jupyter notebook - you can also change and edit the notebook, e.g. you can change code and upload your own data.<br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
</div>
<div id="part-of-speech-tagging" class="section level1 unnumbered">
<h1>Part-Of-Speech Tagging</h1>
<p>Many analyses of language data require that we distinguish different parts of speech. In order to determine the word class of a certain word, we use a procedure which is called part-of-speech tagging (commonly referred to as pos-, pos-, or PoS-tagging). pos-tagging is a common procedure when working with natural language data. Despite being used quite frequently, it is a rather complex issue that requires the application of statistical methods that are quite advanced. In the following, we will explore different options for pos-tagging and syntactic parsing.</p>
<p>Parts-of-speech, or word categories, refer to the grammatical nature or category of a lexical item, e.g. in the sentence <em>Jane likes the girl</em> each lexical item can be classified according to whether it belongs to the group of determiners, verbs, nouns, etc. pos-tagging refers to a (computation) process in which information is added to existing text. This process is also called <em>annotation</em>. Annotation can be very different depending on the task at hand. The most common type of annotation when it comes to language data is part-of-speech tagging where the word class is determined for each word in a text and the word class is then added to the word as a tag. However, there are many different ways to tag or annotate texts.</p>
<p>Pos–tagging assigns part-of-speech tags to character strings (these represent mostly words, of course, but also encompass punctuation marks and other elements). This means that pos–tagging is one specific type of annotation, i.e. adding information to data (either by directly adding information to the data itself or by storing information in e.g. a list which is linked to the data). It is important to note that annotation encompasses various types of information such as pauses, overlap, etc. pos–tagging is just one of these many ways in which corpus data can be <em>enriched</em>. Sentiment Analysis, for instance, also annotates texts or words with respect to its or their emotional value or polarity.</p>
<p>Annotation is required in many machine-learning contexts because annotated texts are commonly used as training sets on which machine learning or deep learning models are trained that then predict, for unknown words or texts, what values they would most likely be assigned if the annotation were done manually. Also, it should be mentioned that by many online services offer pos-tagging (e.g. <a href="http://www.infogistics.com/posdemo.htm">here</a> or <a href="https://linguakit.com/en/part-of-speech-tagging">here</a>.</p>
<p>When pos–tagged, the example sentence could look like the example below.</p>
<ol style="list-style-type: decimal">
<li>Jane/NNP likes/VBZ the/DT girl/NN</li>
</ol>
<p>In the example above, <code>NNP</code> stands for proper noun (singular), <code>VBZ</code> stands for 3rd person singular present tense verb, <code>DT</code> for determiner, and <code>NN</code> for noun(singular or mass). The pos-tags used by the <code>openNLPpackage</code> are the <a href="https://dpdearing.com/posts/2011/12/opennlp-part-of-speech-pos-tags-penn-english-treebank/">Penn English Treebank pos-tags</a>. A more elaborate description of the tags can be found here which is summarised below:</p>
<template id="cf32e1e1-c5ef-4172-be7f-85dfd308f88a"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-195f957c{table-layout:auto;width:95%;}.cl-19567546{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-19567547{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-19569c38{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1956ea26{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea27{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea28{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea29{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2a{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2c{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2d{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2e{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea2f{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1956ea30{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-19571104{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-195f957c'>
<caption class="Table Caption">
<p>Overview of Penn English Treebank part-of-speech tags.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-19571104"><p class="cl-19569c38"><span class="cl-19567546">Tag</span></p></td><td class="cl-1956ea30"><p class="cl-19569c38"><span class="cl-19567546">Description</span></p></td><td class="cl-1956ea2f"><p class="cl-19569c38"><span class="cl-19567546">Examples</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">CC</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Coordinating conjunction</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">and, or, but</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">CD</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Cardinal number</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">one, two, three</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">DT</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Determiner</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">a, the</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">EX</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Existential there</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">There/EX was a party in progress</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">FW</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Foreign word</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">persona/FW non/FW grata/FW</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">IN</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Preposition or subordinating con</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">uh, well, yes</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">JJ</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Adjective</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">good, bad, ugly</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">JJR</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Adjective, comparative</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">better, nicer</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">JJS</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Adjective, superlative</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">best, nicest</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">LS</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">List item marker</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">a., b., 1., 2.</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">MD</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Modal</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">can, would, will</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">NN</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Noun, singular or mass</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">tree, chair</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">NNS</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Noun, plural</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">trees, chairs</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">NNP</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Proper noun, singular</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">John, Paul, CIA</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">NNPS</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Proper noun, plural</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">Johns, Pauls, CIAs</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">PDT</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Predeterminer</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">all/PDT this marble, many/PDT a soul</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">POS</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Possessive ending</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">John/NNP 's/POS, the parentss/NNP '/POS distress</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">PRP</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Personal pronoun</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">I, you, he</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">PRP$</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Possessive pronoun</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">mine, yours</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">RB</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Adverb</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">evry, enough, not</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">RBR</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Adverb, comparative</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">later</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">RBS</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Adverb, superlative</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">latest</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">RP</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Particle</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">RP</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">SYM</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Symbol</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">CO2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">TO</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">to</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">to</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">UH</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Interjection</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">uhm, uh</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">VB</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Verb, base form</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">go, walk</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">VBD</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Verb, past tense</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">walked, saw</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">VBG</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Verb, gerund or present particip</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">walking, seeing</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">VBN</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Verb, past participle</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">walked, thought</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">VBP</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Verb, non-3rd person singular pr</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">walk, think</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">VBZ</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Verb, 3rd person singular presen</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">walks, thinks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">WDT</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Wh-determiner</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">which, that</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2b"><p class="cl-19569c38"><span class="cl-19567547">WP</span></p></td><td class="cl-1956ea29"><p class="cl-19569c38"><span class="cl-19567547">Wh-pronoun</span></p></td><td class="cl-1956ea2a"><p class="cl-19569c38"><span class="cl-19567547">what, who, whom (wh-pronoun)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea26"><p class="cl-19569c38"><span class="cl-19567547">WP$</span></p></td><td class="cl-1956ea28"><p class="cl-19569c38"><span class="cl-19567547">Possessive wh-pronoun</span></p></td><td class="cl-1956ea27"><p class="cl-19569c38"><span class="cl-19567547">whose, who (wh-words)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-1956ea2c"><p class="cl-19569c38"><span class="cl-19567547">WRB</span></p></td><td class="cl-1956ea2e"><p class="cl-19569c38"><span class="cl-19567547">Wh-adverb</span></p></td><td class="cl-1956ea2d"><p class="cl-19569c38"><span class="cl-19567547">how, where, why (wh-adverb)</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="59c94421-8aff-4c6f-9599-a55747597f17"></div>
<script>
var dest = document.getElementById("59c94421-8aff-4c6f-9599-a55747597f17");
var template = document.getElementById("cf32e1e1-c5ef-4172-be7f-85dfd308f88a");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>Assigning these pos-tags to words appears to be rather straight forward. However, pos-tagging is quite complex and there are various ways by which a computer can be trained to assign pos-tags. For example, one could use orthographic or morphological information to devise rules such as. . .</p>
<ul>
<li><p>If a word ends in <em>ment</em>, assign the pos-tag <code>NN</code> (for common noun)</p></li>
<li><p>If a word does not occur at the beginning of a sentence but is capitalized, assign the pos-tag <code>NNP</code> (for proper noun)</p></li>
</ul>
<p>Using such rules has the disadvantage that pos-tags can only be assigned to a relatively small number of words as most words will be ambiguous – think of the similarity of the English plural (-<em>(e)s</em>) and the English 3<sup>rd</sup> person, present tense indicative morpheme (-<em>(e)s</em>), for instance, which are orthographically identical.Another option would be to use a dictionary in which each word is as-signed a certain pos-tag and a program could assign the pos-tag if the word occurs in a given text. This procedure has the disadvantage that most words belong to more than one word class and pos-tagging would thus have to rely on additional information.The problem of words that belong to more than one word class can partly be remedied by including contextual information such as. .</p>
<ul>
<li>If the previous word is a determiner and the following word is a common noun, assign the pos-tag <code>JJ</code> (for a common adjective)</li>
</ul>
<p>This procedure works quite well but there are still better options.The best way to pos-tag a text is to create a manually annotated training set which resembles the language variety at hand. Based on the frequency of the association between a given word and the pos-tags it is assigned in the training data, it is possible to tag a word with the pos-tag that is most often assigned to the given word in the training data.All of the above methods can and should be optimized by combining them and additionally including pos–n–grams, i.e. determining a pos-tag of an unknown word based on which sequence of pos-tags is most similar to the sequence at hand and also most common in the training data.This introduction is extremely superficial and only intends to scratch some of the basic procedures that pos-tagging relies on. The interested reader is referred to introductions on machine learning and pos-tagging such as e.g.https://class.coursera.org/nlp/lecture/149.</p>
<p>There are several different R packages that assist with pos-tagging texts <span class="citation">(see Kumar and Paul <a href="#ref-kumar2016mastering" role="doc-biblioref">2016</a>)</span>. In this tutorial, we will use the <code>udpipe</code> <span class="citation">(Wijffels <a href="#ref-udpipe" role="doc-biblioref">2021</a>)</span> and the <code>openNLP</code> packages <span class="citation">(Hornik <a href="#ref-opennlp" role="doc-biblioref">2019</a>)</span>. Each of these has advantages and shortcomings and it is advantageous to try which result best matches one’s needs. That said, the <code>udpipe</code> package is really great as it is easy to use, covers a wide range of languages, is very flexible, and very accurate.</p>
<p><strong>Preparation and session set up</strong></p>
<p>This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R <a href="https://slcladal.github.io/intror.html">here</a>. For this tutorials, we need to install certain <em>packages</em> from an R <em>library</em> so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).</p>
<pre class="r"><code># install packages
install.packages(&quot;tidyverse&quot;)
install.packages(&quot;igraph&quot;)
install.packages(&quot;tm&quot;)
install.packages(&quot;NLP&quot;)
install.packages(&quot;openNLP&quot;)
install.packages(&quot;openNLPdata&quot;)
install.packages(&quot;udpipe&quot;)
install.packages(&quot;textplot&quot;) 
install.packages(&quot;ggraph&quot;) 
install.packages(&quot;ggplot2&quot;) 
install.packages(&quot;pacman&quot;)
install.packages(&quot;flextable&quot;)
# install phrasemachine
phrasemachineurl &lt;- &quot;https://cran.r-project.org/src/contrib/Archive/phrasemachine/phrasemachine_1.1.2.tar.gz&quot;
install.packages(phrasemachineurl, repos=NULL, type=&quot;source&quot;)
# install parsent
pacman::p_load_gh(c(&quot;trinker/textshape&quot;, &quot;trinker/parsent&quot;))
# install klippy for copy-to-clipboard button in code chunks
remotes::install_github(&quot;rlesur/klippy&quot;)</code></pre>
<p>Now that we have installed the packages, we activate them as shown below.</p>
<pre class="r"><code># set options
options(stringsAsFactors = F)         # no automatic data transformation
options(&quot;scipen&quot; = 100, &quot;digits&quot; = 4) # suppress math annotation
# load packages
library(tidyverse)
library(igraph)
library(tm)
library(NLP)
library(openNLP)
library(openNLPdata)
library(udpipe)
library(textplot) 
library(udpipe) 
library(ggraph) 
library(ggplot2) 
library(igraph)
library(phrasemachine)
library(flextable)
# load function for pos-tagging objects in R
source(&quot;https://slcladal.github.io/rscripts/POStagObject.r&quot;) 
# syntax tree drawing function
source(&quot;https://slcladal.github.io/rscripts/parsetgraph.R&quot;)
# activate klippy for copy-to-clipboard button
klippy::klippy()</code></pre>
<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<p>Once you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.</p>
</div>
<div id="pos-tagging-with-udpipe" class="section level1 unnumbered">
<h1>POS-Tagging with UDPipe</h1>
<p>UDPipe was developed at the Charles University in Prague and the <code>udpipe</code> R package <span class="citation">(Wijffels <a href="#ref-udpipe" role="doc-biblioref">2021</a>)</span> is an extremely interesting and really fantastic package as it provides a very easy and handy way for language-agnostic tokenization, pos-tagging, lemmatization and dependency parsing of raw text in R. It is particularly handy because it addresses and remedies major shortcomings that previous methods for pos-tagging had, namely</p>
<ul>
<li>it offers a wide range of language models (64 languages at this point)</li>
<li>it does not rely on external software (like, e.g., TreeTagger, that had to be installed separately and could be challenging when using different operating systems)</li>
<li>it is really easy to implement as one only need to install and load the <code>udpipe</code> package and download and activate the language model one is interested in</li>
<li>it allows to train and tune one’s own models rather easily</li>
</ul>
<p>The available pre-trained language models in UDPipe are:</p>
<ul>
<li>Afrikaans: afrikaans-afribooms<br />
</li>
<li>Ancient Greek:
<ul>
<li>ancient_greek-perseus<br />
</li>
<li>ancient_greek-proiel<br />
</li>
</ul></li>
<li>Arabic: arabic-padt<br />
</li>
<li>Armenian: armenian-armtdp<br />
</li>
<li>Basque: basque-bdt<br />
</li>
<li>Belarusian: belarusian-hse<br />
</li>
<li>bulgarian-btb<br />
</li>
<li>Buryat: buryat-bdt<br />
</li>
<li>Catalan: catalan-ancora<br />
</li>
<li>Chinese:
<ul>
<li>chinese-gsd<br />
</li>
<li>chinese-gsdsimp<br />
</li>
<li>classical_chinese-kyoto<br />
</li>
</ul></li>
<li>Coptic: coptic-scriptorium<br />
</li>
<li>Croatian: croatian-set<br />
</li>
<li>Czech
<ul>
<li>czech-cac<br />
</li>
<li>czech-cltt<br />
</li>
<li>czech-fictree<br />
</li>
<li>czech-pdt<br />
</li>
</ul></li>
<li>Danish: danish-ddt<br />
</li>
<li>Dutch
<ul>
<li>dutch-alpino<br />
</li>
<li>dutch-lassysmall<br />
</li>
</ul></li>
<li>English
<ul>
<li>english-ewt<br />
</li>
<li>english-gum<br />
</li>
<li>english-lines<br />
</li>
<li>english-partut<br />
</li>
</ul></li>
<li>Estonian
<ul>
<li>estonian-edt<br />
</li>
<li>estonian-ewt<br />
</li>
</ul></li>
<li>Finnish
<ul>
<li>finnish-ftb<br />
</li>
<li>finnish-tdt<br />
</li>
</ul></li>
<li>French
<ul>
<li>french-gsd<br />
</li>
<li>french-partut<br />
</li>
<li>french-sequoia<br />
</li>
<li>french-spoken<br />
</li>
</ul></li>
<li>Galician
<ul>
<li>galician-ctg<br />
</li>
<li>galician-treegal<br />
</li>
</ul></li>
<li>German
<ul>
<li>german-gsd<br />
</li>
<li>german-hdt<br />
</li>
</ul></li>
<li>Gothic: gothic-proiel<br />
</li>
<li>Greek: greek-gdt<br />
</li>
<li>Hebrew: hebrew-htb<br />
</li>
<li>Hindi: hindi-hdtb<br />
</li>
<li>Hungarian: hungarian-szeged<br />
</li>
<li>Indonesian: indonesian-gsd<br />
</li>
<li>Irish Gaelic: irish-idt<br />
</li>
<li>Italian
<ul>
<li>italian-isdt<br />
</li>
<li>italian-partut<br />
</li>
<li>italian-postwita<br />
</li>
<li>italian-twittiro<br />
</li>
<li>italian-vit<br />
</li>
</ul></li>
<li>Japanese: japanese-gsd<br />
</li>
<li>Kazakh: kazakh-ktb<br />
</li>
<li>Korean
<ul>
<li>korean-gsd<br />
</li>
<li>korean-kaist<br />
</li>
</ul></li>
<li>Kurmanji: kurmanji-mg<br />
</li>
<li>Latin
<ul>
<li>latin-ittb<br />
</li>
<li>latin-perseus<br />
</li>
<li>latin-proiel<br />
</li>
</ul></li>
<li>Latvian: latvian-lvtb<br />
</li>
<li>Lithuanian
<ul>
<li>lithuanian-alksnis<br />
</li>
<li>lithuanian-hse<br />
</li>
</ul></li>
<li>Maltese: maltese-mudt<br />
</li>
<li>Marathi: marathi-ufal<br />
</li>
<li>North Sami: north_sami-giella<br />
</li>
<li>Norwegian
<ul>
<li>norwegian-bokmaal<br />
</li>
<li>norwegian-nynorsk<br />
</li>
<li>norwegian-nynorsklia<br />
</li>
</ul></li>
<li>old_church_slavonic-proiel<br />
</li>
<li>Old French: old_french-srcmf<br />
</li>
<li>Old Russian: old_russian-torot<br />
</li>
<li>Persian: persian-seraji<br />
</li>
<li>Polish
<ul>
<li>polish-lfg<br />
</li>
<li>polish-pdb<br />
</li>
<li>polish-sz<br />
</li>
</ul></li>
<li>Portugese
<ul>
<li>portuguese-bosque<br />
</li>
<li>portuguese-br<br />
</li>
<li>portuguese-gsd<br />
</li>
</ul></li>
<li>Romanian
<ul>
<li>romanian-nonstandard<br />
</li>
<li>romanian-rrt<br />
</li>
</ul></li>
<li>Russian
<ul>
<li>russian-gsd<br />
</li>
<li>russian-syntagrus<br />
</li>
<li>russian-taiga<br />
</li>
</ul></li>
<li>Sanskrit: sanskrit-ufal<br />
</li>
<li>Scottish Gaelic: scottish_gaelic-arcosg<br />
</li>
<li>Serbian: serbian-set<br />
</li>
<li>Slovak: slovak-snk<br />
</li>
<li>Slovenian
<ul>
<li>slovenian-ssj<br />
</li>
<li>slovenian-sst<br />
</li>
</ul></li>
<li>Spanish
<ul>
<li>spanish-ancora<br />
</li>
<li>spanish-gsd<br />
</li>
</ul></li>
<li>Swedish
<ul>
<li>swedish-lines<br />
</li>
<li>swedish-talbanken<br />
</li>
</ul></li>
<li>Tamil: tamil-ttb<br />
</li>
<li>Telugu: telugu-mtg<br />
</li>
<li>Turkish: turkish-imst<br />
</li>
<li>Ukrainian: ukrainian-iu<br />
</li>
<li>Upper Sorbia: upper_sorbian-ufal<br />
</li>
<li>Urdu: urdu-udtb<br />
</li>
<li>Uyghur: uyghur-udt<br />
</li>
<li>Vietnamese: vietnamese-vtb<br />
</li>
<li>Wolof: wolof-wtb</li>
</ul>
<div class="warning" style="padding:0.1em; background-color:#f2f2f2; color:#51247a">
<span>
<p style="margin-top:1em; text-align:center">
The udipe R package also allows you to easily train your own models, based on data in CONLL-U format, so that you can use these for your own commercial or non-commercial purposes. This is described in the other vignette of this package which you can view by the command <br><br> <code>vignette("udpipe-train", package = "udpipe")</code><br>
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<p><br></p>
<p>To download any of these models, we can use the <code>udpipe_download_model</code> function. For example, to download the <code>english-ewt</code> model, we would use the call: <code>m_eng   &lt;- udpipe::udpipe_download_model(language = "english-ewt")</code>.</p>
<p>We start by loading a text</p>
<pre class="r"><code># load text
text &lt;- readLines(&quot;https://slcladal.github.io/data/testcorpus/linguistics06.txt&quot;, skipNul = T)
# clean data
text &lt;- text %&gt;%
 str_squish() </code></pre>
<p>Now that we have a text that we can work with, we will download a pre-trained language model.</p>
<pre class="r"><code># download language model
m_eng   &lt;- udpipe::udpipe_download_model(language = &quot;english-ewt&quot;)</code></pre>
<p>If you have downloaded a model once, you can also load the model directly from the place where you stored it on your computer. In my case, I have stored the model in a folder called <em>udpipemodels</em></p>
<pre class="r"><code># load language model from your computer after you have downloaded it once
m_eng &lt;- udpipe_load_model(file = here::here(&quot;udpipemodels&quot;, &quot;english-ewt-ud-2.5-191206.udpipe&quot;))</code></pre>
<p>We can now use the model to annotate out text.</p>
<pre class="r"><code># tokenise, tag, dependency parsing
text_anndf &lt;- udpipe::udpipe_annotate(m_eng, x = text) %&gt;%
  as.data.frame() %&gt;%
  dplyr::select(-sentence)
# inspect
head(text_anndf, 10)</code></pre>
<pre><code>##    doc_id paragraph_id sentence_id token_id       token      lemma  upos xpos
## 1    doc1            1           1        1 Linguistics Linguistic  NOUN  NNS
## 2    doc1            1           1        2        also       also   ADV   RB
## 3    doc1            1           1        3       deals       deal  NOUN  NNS
## 4    doc1            1           1        4        with       with   ADP   IN
## 5    doc1            1           1        5         the        the   DET   DT
## 6    doc1            1           1        6      social     social   ADJ   JJ
## 7    doc1            1           1        7           ,          , PUNCT    ,
## 8    doc1            1           1        8    cultural   cultural   ADJ   JJ
## 9    doc1            1           1        9           ,          , PUNCT    ,
## 10   doc1            1           1       10  historical historical   ADJ   JJ
##                        feats head_token_id  dep_rel deps          misc
## 1                Number=Plur             3 compound &lt;NA&gt;          &lt;NA&gt;
## 2                       &lt;NA&gt;             3   advmod &lt;NA&gt;          &lt;NA&gt;
## 3                Number=Plur             0     root &lt;NA&gt;          &lt;NA&gt;
## 4                       &lt;NA&gt;            13     case &lt;NA&gt;          &lt;NA&gt;
## 5  Definite=Def|PronType=Art            13      det &lt;NA&gt;          &lt;NA&gt;
## 6                 Degree=Pos            13     amod &lt;NA&gt; SpaceAfter=No
## 7                       &lt;NA&gt;             8    punct &lt;NA&gt;          &lt;NA&gt;
## 8                 Degree=Pos             6     conj &lt;NA&gt; SpaceAfter=No
## 9                       &lt;NA&gt;            10    punct &lt;NA&gt;          &lt;NA&gt;
## 10                Degree=Pos             6     conj &lt;NA&gt;          &lt;NA&gt;</code></pre>
<p>It can be useful to extract only the words and their pos-tags and convert them back into a text format (rather than a tabular format).</p>
<pre class="r"><code>tagged_text &lt;- paste(text_anndf$token, &quot;/&quot;, text_anndf$xpos, collapse = &quot; &quot;, sep = &quot;&quot;)
# inspect tagged text
tagged_text</code></pre>
<pre><code>## [1] &quot;Linguistics/NNS also/RB deals/NNS with/IN the/DT social/JJ ,/, cultural/JJ ,/, historical/JJ and/CC political/JJ factors/NNS that/WDT influence/VBP language/NN ,/, through/IN which/WDT linguistic/NN and/CC language/NN -/HYPH based/VBN context/NN is/VBZ often/RB determined/JJ ./. Research/VB on/IN language/NN through/IN the/DT sub-branches/NNS of/IN historical/JJ and/CC evolutionary/JJ linguistics/NNS also/RB focus/RB on/IN how/WRB languages/NNS change/VBP and/CC grow/VBP ,/, particularly/RB over/IN an/DT extended/JJ period/NN of/IN time/NN ./. Language/NN documentation/NN combines/VBZ anthropological/JJ inquiry/NN (/-LRB- into/IN the/DT history/NN and/CC culture/NN of/IN language/NN )/-RRB- with/IN linguistic/JJ inquiry/NN ,/, in/IN order/NN to/TO describe/VB languages/NNS and/CC their/PRP$ grammars/NNS ./. Lexicography/NNP involves/VBZ the/DT documentation/NN of/IN words/NNS that/WDT form/VBP a/DT vocabulary/NN ./. Such/PDT a/DT documentation/NN of/IN a/DT linguistic/JJ vocabulary/NN from/IN a/DT particular/JJ language/NN is/VBZ usually/RB compiled/VBN in/IN a/DT dictionary/NN ./. Computational/JJ linguistics/NNS is/VBZ concerned/JJ with/IN the/DT statistical/NN or/CC rule/NN -/HYPH based/VBN modeling/NN of/IN natural/JJ language/NN from/IN a/DT computational/JJ perspective/NN ./. Specific/JJ knowledge/NN of/IN language/NN is/VBZ applied/VBN by/IN speakers/NNS during/IN the/DT act/NN of/IN translation/NN and/CC interpretation/NN ,/, as/RB well/RB as/IN in/IN language/NN education/NN –/, the/DT teaching/NN of/IN a/DT second/JJ or/CC foreign/JJ language/NN ./. Policy/NN makers/NNS work/VBP with/IN governments/NNS to/TO implement/VB new/JJ plans/NNS in/IN education/NN and/CC teaching/NN which/WDT are/VBP based/VBN on/IN linguistic/JJ research/NN ./.&quot;</code></pre>
</div>
<div id="pos-tagging-non-english-texts" class="section level1 unnumbered">
<h1>POS-Tagging non-English texts</h1>
<p>We can apply the same method for annotating, e.g. adding pos-tags, to other languages. For this, we could train our own model, or, we can use one of the many pre-trained language models that <code>udpipe</code> provides.</p>
<p>Let us explore how to do this by using example texts from different languages, here from German and Spanish (but we could also annotate texts from any of the wide variety of languages for which UDPipe provides pre-trained models.</p>
<p>We begin by loading a German and a Dutch text.</p>
<pre class="r"><code># load texts
gertext &lt;- readLines(&quot;https://slcladal.github.io/data/german.txt&quot;) 
duttext &lt;- readLines(&quot;https://slcladal.github.io/data/dutch.txt&quot;) 
# inspect texts
gertext; duttext</code></pre>
<pre><code>## [1] &quot;Sprachwissenschaft untersucht in verschiedenen Herangehensweisen die menschliche Sprache.&quot;</code></pre>
<pre><code>## [1] &quot;Taalkunde, ook wel taalwetenschap of linguÃ¯stiek, is de wetenschappelijke studie van de natuurlijke talen.&quot;</code></pre>
<p>Next, we install the pre-trained language models.</p>
<pre class="r"><code># download language model
m_ger   &lt;- udpipe::udpipe_download_model(language = &quot;german-gsd&quot;)
m_dut   &lt;- udpipe::udpipe_download_model(language = &quot;dutch-alpino&quot;)</code></pre>
<p>Or we load them from our machine (if we have downloaded and saved them before).</p>
<pre class="r"><code># load language model from your computer after you have downloaded it once
m_ger   &lt;- udpipe::udpipe_load_model(file = here::here(&quot;udpipemodels&quot;, &quot;german-gsd-ud-2.5-191206.udpipe&quot;))
m_dut   &lt;- udpipe::udpipe_load_model(file = here::here(&quot;udpipemodels&quot;, &quot;dutch-alpino-ud-2.5-191206.udpipe&quot;))</code></pre>
<p>Now, pos-tag the German text.</p>
<pre class="r"><code># tokenise, tag, dependency parsing of german text
ger_pos &lt;- udpipe::udpipe_annotate(m_ger, x = gertext) %&gt;%
  as.data.frame() %&gt;%
  dplyr::summarise(postxt = paste(token, &quot;/&quot;, xpos, collapse = &quot; &quot;, sep = &quot;&quot;)) %&gt;%
  dplyr::pull(unique(postxt))
# inspect
ger_pos</code></pre>
<pre><code>## [1] &quot;Sprachwissenschaft/NN untersucht/VVFIN in/APPR verschiedenen/ADJA Herangehensweisen/NN die/ART menschliche/NN Sprache/NN ./$.&quot;</code></pre>
<p>And finally, we also pos-tag the Dutch text.</p>
<pre class="r"><code># tokenise, tag, dependency parsing of german text
nl_pos &lt;- udpipe::udpipe_annotate(m_dut, x = duttext) %&gt;%
   as.data.frame() %&gt;%
  dplyr::summarise(postxt = paste(token, &quot;/&quot;, xpos, collapse = &quot; &quot;, sep = &quot;&quot;)) %&gt;%
  dplyr::pull(unique(postxt))
# inspect
nl_pos</code></pre>
<pre><code>## [1] &quot;Taalkunde/N|soort|ev|basis|zijd|stan ,/LET ook/BW wel/BW taalwetenschap/N|soort|ev|basis|zijd|stan of/VG|neven linguïstiek/N|soort|ev|basis|zijd|stan ,/LET is/WW|pv|tgw|ev de/LID|bep|stan|rest wetenschappelijke/ADJ|prenom|basis|met-e|stan studie/N|soort|ev|basis|zijd|stan van/VZ|init de/LID|bep|stan|rest natuurlijke/ADJ|prenom|basis|met-e|stan talen/N|soort|mv|basis ./LET&quot;</code></pre>
</div>
<div id="dependency-parsing-using-udpipe" class="section level1 unnumbered">
<h1>Dependency Parsing Using UDPipe</h1>
<p>In addition to pos-tagging, we can also generate plots showing the syntactic dependencies of the different constituents of a sentence. For this, we generate an object that contains a sentence (in this case, the sentence <em>Linguistics is the scientific study of language</em>), and we then plot (or visualize) the dependencies using the <code>textplot_dependencyparser</code> fucntion.</p>
<pre class="r"><code># parse text
sent &lt;- udpipe::udpipe_annotate(m_eng, x = &quot;Linguistics is the scientific study of language&quot;) %&gt;%
  as.data.frame()
# inspect
head(sent)</code></pre>
<pre><code>##   doc_id paragraph_id sentence_id
## 1   doc1            1           1
## 2   doc1            1           1
## 3   doc1            1           1
## 4   doc1            1           1
## 5   doc1            1           1
## 6   doc1            1           1
##                                          sentence token_id       token
## 1 Linguistics is the scientific study of language        1 Linguistics
## 2 Linguistics is the scientific study of language        2          is
## 3 Linguistics is the scientific study of language        3         the
## 4 Linguistics is the scientific study of language        4  scientific
## 5 Linguistics is the scientific study of language        5       study
## 6 Linguistics is the scientific study of language        6          of
##        lemma upos xpos                                                 feats
## 1 Linguistic NOUN  NNS                                           Number=Plur
## 2         be  AUX  VBZ Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin
## 3        the  DET   DT                             Definite=Def|PronType=Art
## 4 scientific  ADJ   JJ                                            Degree=Pos
## 5      study NOUN   NN                                           Number=Sing
## 6         of  ADP   IN                                                  &lt;NA&gt;
##   head_token_id dep_rel deps misc
## 1             5   nsubj &lt;NA&gt; &lt;NA&gt;
## 2             5     cop &lt;NA&gt; &lt;NA&gt;
## 3             5     det &lt;NA&gt; &lt;NA&gt;
## 4             5    amod &lt;NA&gt; &lt;NA&gt;
## 5             0    root &lt;NA&gt; &lt;NA&gt;
## 6             7    case &lt;NA&gt; &lt;NA&gt;</code></pre>
<p>We now generate the plot.</p>
<pre class="r"><code># generate dependency plot
dplot &lt;- textplot::textplot_dependencyparser(sent, size = 3.5) 
# show plot
dplot</code></pre>
<p><img src="tagging_files/figure-html/udi5-1.png" width="672" /></p>
</div>
<div id="pos-tagging-with-opennlp" class="section level1 unnumbered">
<h1>POS-Tagging with openNLP</h1>
<p>In R we can pos–tag large amounts of text not only by using <code>udpipe</code> but by various means. This section explores pos-tagging using the <code>openNLP</code> package. Using the <code>openNLP</code> package for pos-tagging works particularly well when the aim is to pos-tag newspaper texts as the <code>openNLP</code> package implements the <em>Apache OpenNLPMaxent Part of Speech tagger</em> and it comes with pre-trained models. Ideally, pos-taggers should be trained on data resembling the data to be pos-tagged.However, I do not know how to trained the <em>Apache openNLP pos-tagger</em> via R and it would be great if someone would provide a tutorial on how to do that. Using pre-trained models has the advantage that we do not need to train the pos-tagger ourselves. However, it also means that one has to rely on models trained on data that may not really resemble the data a at hand.This implies that using it for texts that differ from newspaper texts, i.e.the language the models have been trained on, does not work as well, as the model applies the probabilities of newspaper language to the language variety at hand. pos-tagging with the <code>openNLP</code> requires the <code>NLP</code> package and installing the models on which the <code>openNLP</code> package is based.</p>
<p>To pos-tag a text, we start by loading an example text into R.</p>
<pre class="r"><code># load corpus data
text &lt;- readLines(&quot;https://slcladal.github.io/data/testcorpus/linguistics07.txt&quot;, skipNul = T)
# clean data
text &lt;- text %&gt;%
 str_squish() </code></pre>
<template id="ae241d01-3f4d-4b83-9cf3-a7fffe62fb31"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-1f094e1e{table-layout:auto;width:95%;}.cl-1f024c68{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1f024c69{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1f024c6a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1f029a4c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1f029a4d{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-1f094e1e'>
<caption class="Table Caption">
<p>Example text.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-1f029a4d"><p class="cl-1f024c6a"><span class="cl-1f024c68">.</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-1f029a4c"><p class="cl-1f024c6a"><span class="cl-1f024c69">Related areas of study also includes the disciplines of semiotics (the study of direct and indirect language through signs and symbols), literary criticism (the historical and ideological analysis of literature, cinema, art, or published material), translation (the conversion and documentation of meaning in written/spoken text from one language or dialect onto another), and speech-language pathology (a corrective method to cure phonetic disabilities and dis-functions at the cognitive level).</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="d4647003-3882-471a-947d-52ff54feecd4"></div>
<script>
var dest = document.getElementById("d4647003-3882-471a-947d-52ff54feecd4");
var template = document.getElementById("ae241d01-3f4d-4b83-9cf3-a7fffe62fb31");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>Now that the text data has been read into R, we can proceed with the part-of-speech tagging. To perform the pos-tagging, we load the function for pos-tagging, load the <code>NLP</code> and <code>openNLP</code> packages.</p>
<hr />
<div class="warning" style="padding:0.1em; background-color:#51247a; color:#f2f2f2">
<span>
<p style="margin-top:1em; text-align:center">
<b>NOTE</b><br>You need to change the path that is used in the code below and include the path to <code>en-pos-maxent.bin</code> on your computer!
</p>
<p style="margin-left:1em;">
</p>
<p></span></p>
</div>
<hr />
<pre class="r"><code>POStag &lt;- function(object){
  require(&quot;stringr&quot;)
  require(&quot;NLP&quot;)
  require(&quot;openNLP&quot;)
  require(&quot;openNLPdata&quot;)
  # define paths to corpus files
  corpus.tmp &lt;- object
  # define sentence annotator
  sent_token_annotator &lt;- openNLP::Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator &lt;- openNLP::Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator &lt;- openNLP::Maxent_POS_Tag_Annotator(language = &quot;en&quot;, probs = FALSE, 
    # WARNING: YOU NEED TO INCLUDE YOUR OWN PATH HERE!                                            
    model = &quot;C:\\Users\\marti\\OneDrive\\Dokumente\\R\\win-library\\4.1\\openNLPdata\\models\\en-pos-maxent.bin&quot;)
  # convert all file content to strings
  Corpus &lt;- lapply(corpus.tmp, function(x){
    x &lt;- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 &lt;- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2&lt;- NLP::annotate(x, pos_tag_annotator, y1)
    y2w &lt;- subset(y2, type == &quot;word&quot;)
    tags &lt;- sapply(y2w$features, &#39;[[&#39;, &quot;POS&quot;)
    r1 &lt;- sprintf(&quot;%s/%s&quot;, x[y2w], tags)
    r2 &lt;- paste(r1, collapse = &quot; &quot;)
    return(r2)  }  )
  }</code></pre>
<p>We now apply this function to our text.</p>
<pre class="r"><code># pos tagging data
textpos &lt;- POStag(object = text)</code></pre>
<template id="151ecdb8-f385-4a92-ba50-8f7665a8daba"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-1fab236a{table-layout:auto;width:95%;}.cl-1fa4231c{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1fa4231d{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1fa44a0e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1fa4715a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1fa4715b{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-1fab236a'>
<caption class="Table Caption">
<p>Pos-tagged text.</p>
</caption>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-1fa4715b"><p class="cl-1fa44a0e"><span class="cl-1fa4231c">.</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-1fa4715a"><p class="cl-1fa44a0e"><span class="cl-1fa4231d">Related/JJ areas/NNS of/IN study/NN also/RB includes/VBZ the/DT disciplines/NNS of/IN semiotics/NNS (/-LRB- the/DT study/NN of/IN direct/JJ and/CC indirect/JJ language/NN through/IN signs/NNS and/CC symbols/NNS )/-RRB- ,/, literary/JJ criticism/NN (/-LRB- the/DT historical/JJ and/CC ideological/JJ analysis/NN of/IN literature/NN ,/, cinema/NN ,/, art/NN ,/, or/CC published/JJ material/NN )/-RRB- ,/, translation/NN (/-LRB- the/DT conversion/NN and/CC documentation/NN of/IN meaning/NN in/IN written/spoken/VBN text/NN from/IN one/CD language/NN or/CC dialect/NN onto/IN another/DT )/-RRB- ,/, and/CC speech-language/NN pathology/NN (/-LRB- a/DT corrective/JJ method/NN to/TO cure/VB phonetic/JJ disabilities/NNS and/CC dis-functions/NNS at/IN the/DT cognitive/JJ level/NN )/-RRB- ./.</span></p></td></tr></tbody></table></div></template>
<div class="flextable-shadow-host" id="2393cfac-d99e-4de3-92c2-ed65c670096b"></div>
<script>
var dest = document.getElementById("2393cfac-d99e-4de3-92c2-ed65c670096b");
var template = document.getElementById("151ecdb8-f385-4a92-ba50-8f7665a8daba");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>The resulting vector contains the part-of-speech tagged text and shows that the function fulfills its purpose in automatically pos-tagging the text. The pos-tagged text could now be processed further, e.g. by extracting all adjectives in the text or by creating concordances of nouns ending in <em>ment</em>.</p>
</div>
<div id="syntactic-parsing-with-opennlp" class="section level1 unnumbered">
<h1>Syntactic Parsing with openNLP</h1>
<p>Parsing refers to another type of annotation in which either structural information (as in the case of XML documents) or syntactic relations are added to text. As syntactic parsing is commonly more relevant in the language sciences, the following will focus only on syntactic parsing. syntactic parsing builds on pos-tagging and allows drawing syntactic trees or dependencies. Unfortunately, syntactic parsing still has relatively high error rates when dealing with language that is not very formal. However, syntactic parsing is very reliable when dealing with written language.</p>
<pre class="r"><code>text &lt;- readLines(&quot;https://slcladal.github.io/data/english.txt&quot;)
# convert character to string
s &lt;- as.String(text)
# define sentence and word token annotator
sent_token_annotator &lt;- openNLP::Maxent_Sent_Token_Annotator()
word_token_annotator &lt;- openNLP::Maxent_Word_Token_Annotator()
# apply sentence and word annotator
a2 &lt;- NLP::annotate(s, list(sent_token_annotator, word_token_annotator))
# define syntactic parsing annotator
parse_annotator &lt;- openNLP::Parse_Annotator()
# apply parser
p &lt;- parse_annotator(s, a2)
# extract parsed information
ptexts &lt;- sapply(p$features, &#39;[[&#39;, &quot;parse&quot;)
ptexts</code></pre>
<pre><code>## [1] &quot;(TOP (S (S (NP (NNP Linguistics)) (VP (VBZ is) (NP (NP (DT the) (JJ scientific) (NN study)) (PP (IN of) (NP (NN language)))))) (CC and) (S (NP (PRP it)) (VP (VBZ involves) (NP (NP (NP (DT the) (NN analysis)) (PP (IN of) (NP (NN language) (NN form))))(, ,) (NP (NN language) (NN meaning))(, ,) (CC and) (NP (NP (NN language)) (PP (IN in) (NP (NN context)))))))(. .)))&quot;</code></pre>
<pre class="r"><code># read into NLP Tree objects.
ptrees &lt;- lapply(ptexts, Tree_parse)
# show frist tree
ptrees[[1]]</code></pre>
<pre><code>## (TOP
##   (S
##     (S
##       (NP (NNP Linguistics))
##       (VP
##         (VBZ is)
##         (NP
##           (NP (DT the) (JJ scientific) (NN study))
##           (PP (IN of) (NP (NN language))))))
##     (CC and)
##     (S
##       (NP (PRP it))
##       (VP
##         (VBZ involves)
##         (NP
##           (NP
##             (NP (DT the) (NN analysis))
##             (PP (IN of) (NP (NN language) (NN form))))
##           (, ,)
##           (NP (NN language) (NN meaning))
##           (, ,)
##           (CC and)
##           (NP (NP (NN language)) (PP (IN in) (NP (NN context)))))))
##     (. .)))</code></pre>
<p>These trees can, of course, also be shown visually, for instance, in the form of a syntax trees (or tree dendrogram).</p>
<pre class="r"><code># load function
source(&quot;https://slcladal.github.io/rscripts/parsetgraph.R&quot;)
# generate syntax tree
parse2graph(ptexts[1], leaf.color=&#39;red&#39;,
            # to put sentence in title (not advisable for long sentences)
            #title = stringr::str_squish(stringr::str_remove_all(ptexts[1], &quot;\\(\\,{0,1}[A-Z]{0,4}|\\)&quot;)), 
            margin=-0.05,
            vertex.color=NA,
            vertex.frame.color=NA, 
            vertex.label.font=2,
            vertex.label.cex=.75,  
            asp=.8,
            edge.width=.5, 
            edge.color=&#39;gray&#39;, 
            edge.arrow.size=0)</code></pre>
<p><img src="tagging_files/figure-html/pars3-1.png" width="768" /></p>
<p>Syntax trees are very handy because the allow us to check how reliable the parser performed.</p>
<p>We can use the <code>get_phrase_type_regex</code> function from the <code>parsent</code> package written by Tyler Rinker to extract phrases from the parsed tree.</p>
<pre class="r"><code>pacman::p_load_gh(c(&quot;trinker/textshape&quot;, &quot;trinker/parsent&quot;))
nps &lt;- get_phrase_type_regex(ptexts[1], &quot;NP&quot;) %&gt;%
  unlist()
# inspect
nps</code></pre>
<pre><code>## [1] &quot;(NP (NNP Linguistics))&quot;                                                                                                                                                                   
## [2] &quot;(NP (NP (DT the) (JJ scientific) (NN study)) (PP (IN of) (NP (NN language))))&quot;                                                                                                            
## [3] &quot;(NP (PRP it))&quot;                                                                                                                                                                            
## [4] &quot;(NP (NP (NP (DT the) (NN analysis)) (PP (IN of) (NP (NN language) (NN form))))(, ,) (NP (NN language) (NN meaning))(, ,) (CC and) (NP (NP (NN language)) (PP (IN in) (NP (NN context)))))&quot;</code></pre>
<p>We can now extract the leaves from the text to get the parsed object.</p>
<pre class="r"><code>nps_text &lt;- stringr::str_squish(stringr::str_remove_all(nps, &quot;\\(\\,{0,1}[A-Z]{0,4}|\\)&quot;))
# inspect
nps_text</code></pre>
<pre><code>## [1] &quot;Linguistics&quot;                                                               
## [2] &quot;the scientific study of language&quot;                                          
## [3] &quot;it&quot;                                                                        
## [4] &quot;the analysis of language form , language meaning , and language in context&quot;</code></pre>
<p>Unfortunately, we can only extract top level phrases (the NPs with the NPs are npt extracted separately).</p>
<p>In order to extract all phrases, we can use the <code>phrasemachine</code> from the CRAN archive.</p>
<p>We now load the <code>phrasemachine</code> package and pos-tag the text(s) (we will simply re-use the English text we pos-tagged before.)</p>
<pre class="r"><code># pos tag text
tagged_documents &lt;- phrasemachine::POS_tag_documents(text)</code></pre>
<pre><code>## Currently tagging document 1 of 1</code></pre>
<pre class="r"><code># inspect
tagged_documents</code></pre>
<pre><code>## $Document_1
## $Document_1$tokens
##  [1] &quot;Linguistics&quot; &quot;is&quot;          &quot;the&quot;         &quot;scientific&quot;  &quot;study&quot;      
##  [6] &quot;of&quot;          &quot;language&quot;    &quot;and&quot;         &quot;it&quot;          &quot;involves&quot;   
## [11] &quot;the&quot;         &quot;analysis&quot;    &quot;of&quot;          &quot;language&quot;    &quot;form&quot;       
## [16] &quot;,&quot;           &quot;language&quot;    &quot;meaning&quot;     &quot;,&quot;           &quot;and&quot;        
## [21] &quot;language&quot;    &quot;in&quot;          &quot;context&quot;     &quot;.&quot;          
## 
## $Document_1$tags
##  [1] &quot;NNP&quot; &quot;VBZ&quot; &quot;DT&quot;  &quot;JJ&quot;  &quot;NN&quot;  &quot;IN&quot;  &quot;NN&quot;  &quot;CC&quot;  &quot;PRP&quot; &quot;VBZ&quot; &quot;DT&quot;  &quot;NN&quot; 
## [13] &quot;IN&quot;  &quot;NN&quot;  &quot;NN&quot;  &quot;,&quot;   &quot;NN&quot;  &quot;NN&quot;  &quot;,&quot;   &quot;CC&quot;  &quot;NN&quot;  &quot;IN&quot;  &quot;NN&quot;  &quot;.&quot;</code></pre>
<p>In a next step, we can use the <code>extract_phrases</code> function to extract phrases.</p>
<pre class="r"><code>#extract phrases
phrases &lt;- phrasemachine::extract_phrases(tagged_documents,
                                          regex = &quot;(A|N)*N(PD*(A|N)*N)*&quot;,
                                          maximum_ngram_length = 8,
                                          minimum_ngram_length = 1)</code></pre>
<pre><code>## Extracting phrases from document 1 of 1</code></pre>
<pre class="r"><code># inspect
phrases</code></pre>
<pre><code>## [[1]]
##  [1] &quot;Linguistics&quot;                  &quot;scientific_study&quot;            
##  [3] &quot;scientific_study_of_language&quot; &quot;study&quot;                       
##  [5] &quot;study_of_language&quot;            &quot;language&quot;                    
##  [7] &quot;analysis&quot;                     &quot;analysis_of_language&quot;        
##  [9] &quot;analysis_of_language_form&quot;    &quot;language&quot;                    
## [11] &quot;language_form&quot;                &quot;form&quot;                        
## [13] &quot;language&quot;                     &quot;language_meaning&quot;            
## [15] &quot;meaning&quot;                      &quot;language&quot;                    
## [17] &quot;language_in_context&quot;          &quot;context&quot;</code></pre>
<p>Now, we have all noun phrases that occur in the English sample text.</p>
<p>That’s it for this tutorial. We hope that you have enjoyed this tutorial and learned how to annotate texts using language models and perform pos-tagging and dependency parsing of English texts as well as texts in other languages.</p>
</div>
<div id="citation-session-info" class="section level1 unnumbered">
<h1>Citation &amp; Session Info</h1>
<p>Schweinberger, Martin. 2022. <em>POS-Tagging and Syntactic Parsing with R</em>. Brisbane: The University of Queensland. url: <a href="https://slcladal.github.io/tagging.html" class="uri">https://slcladal.github.io/tagging.html</a> (Version 2022.03.18).</p>
<pre><code>@manual{schweinberger2022pos,
  author = {Schweinberger, Martin},
  title = {pos-Tagging and Syntactic Parsing with R},
  note = {https://slcladal.github.io/tagging.html},
  year = {2022},
  organization = &quot;The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {2022.03.18}
}</code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.1.2 (2021-11-01)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19043)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
## [5] LC_TIME=German_Germany.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices datasets  utils     methods   base     
## 
## other attached packages:
##  [1] parsent_0.1.0       textshape_1.7.4     phrasemachine_1.1.2
##  [4] ggraph_2.0.5        textplot_0.2.1      udpipe_0.8.8       
##  [7] openNLPdata_1.5.3-4 openNLP_0.2-7       tm_0.7-8           
## [10] NLP_0.2-1           igraph_1.2.11       forcats_0.5.1      
## [13] stringr_1.4.0       purrr_0.3.4         readr_2.1.2        
## [16] tidyr_1.2.0         tibble_3.1.6        ggplot2_3.3.5      
## [19] tidyverse_1.3.1     dplyr_1.0.8         flextable_0.7.0    
## 
## loaded via a namespace (and not attached):
##  [1] fs_1.5.2           lubridate_1.8.0    httr_1.4.2         rprojroot_2.0.2   
##  [5] tools_4.1.2        backports_1.4.1    utf8_1.2.2         R6_2.5.1          
##  [9] DBI_1.1.2          colorspace_2.0-3   withr_2.5.0        gridExtra_2.3     
## [13] tidyselect_1.1.2   compiler_4.1.2     cli_3.2.0          rvest_1.0.2       
## [17] coreNLPsetup_0.0.1 pacman_0.5.1       xml2_1.3.3         officer_0.4.1     
## [21] labeling_0.4.2     slam_0.1-50        scales_1.1.1       systemfonts_1.0.4 
## [25] digest_0.6.29      rmarkdown_2.5      base64enc_0.1-3    pkgconfig_2.0.3   
## [29] htmltools_0.5.2    dbplyr_2.1.1       fastmap_1.1.0      highr_0.9         
## [33] rlang_1.0.2        readxl_1.3.1       rstudioapi_0.13    farver_2.1.0      
## [37] generics_0.1.2     jsonlite_1.8.0     zip_2.2.0          magrittr_2.0.2    
## [41] Matrix_1.4-0       Rcpp_1.0.8.2       munsell_0.5.0      fansi_1.0.2       
## [45] viridis_0.6.2      gdtools_0.2.4      lifecycle_1.0.1    stringi_1.7.6     
## [49] yaml_2.3.5         MASS_7.3-55        grid_4.1.2         ggrepel_0.9.1     
## [53] parallel_4.1.2     crayon_1.5.0       lattice_0.20-45    graphlayouts_0.8.0
## [57] haven_2.4.3        hms_1.1.1          klippy_0.0.0.9500  knitr_1.37        
## [61] pillar_1.7.0       uuid_1.0-3         reprex_2.0.1       glue_1.6.2        
## [65] evaluate_0.15      data.table_1.14.2  renv_0.15.4        modelr_0.1.8      
## [69] tweenr_1.0.2       vctrs_0.3.8        tzdb_0.2.0         cellranger_1.1.0  
## [73] gtable_0.3.0       polyclip_1.10-0    assertthat_0.2.1   xfun_0.30         
## [77] ggforce_0.3.3      broom_0.7.12       tidygraph_1.2.0    viridisLite_0.4.0 
## [81] rJava_1.0-6        ellipsis_0.3.2     here_1.0.1</code></pre>
<hr />
<p><a href="#introduction">Back to top</a></p>
<p><a href="https://slcladal.github.io/index.html">Back to HOME</a></p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-opennlp">
<p>Hornik, Kurt. 2019. “OpenNLP: Apache Opennlp Tools Interface.” <a href="https://cran.r-project.org/web/packages/openNLP/index.html">https://cran.r-project.org/web/packages/openNLP/index.html</a>.</p>
</div>
<div id="ref-kumar2016mastering">
<p>Kumar, Ashish, and Avinash Paul. 2016. <em>Mastering Text Mining with R</em>. Packt Publishing Ltd.</p>
</div>
<div id="ref-WN17">
<p>Wiedemann, Gregor, and Andreas Niekler. 2017. “Hands-on: A Five Day Text Mining Course for Humanists and Social Scientists in R.” In <em>Proceedings of the Workshop on Teaching NLP for Digital Humanities (Teach4DH2017), Berlin, Germany, September 12, 2017.</em>, 57–65. <a href="http://ceur-ws.org/Vol-1918/wiedemann.pdf">http://ceur-ws.org/Vol-1918/wiedemann.pdf</a>.</p>
</div>
<div id="ref-udpipe">
<p>Wijffels, Jan. 2021. <em>Udpipe: Tokenization, Parts of Speech Tagging, Lemmatization and Dependency Parsing with the ’Udpipe’ ’Nlp’ Toolkit</em>. <a href="https://CRAN.R-project.org/package=udpipe">https://CRAN.R-project.org/package=udpipe</a>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>
</html>
