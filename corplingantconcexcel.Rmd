---
title: "Corpus Linguistics with AntConc, TextPad, and Excel"
author: "UQ SLC Digital Team"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
bibliography: bibliography.bib
---
```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("images/uq1.jpg")
```

# Introduction

This section exemplifies how to perform a corpus analysis using AntConc, TextPad, and Microsoft Excel. In order to follow the steps you need to install certain pieces of software which is described in what follows.

## Installing Neccessary Software

Below you will find descriptions of which pieces of software you need to download and install in order to be able to follow the steps described in this section.

**Installing AntConc**

AntConc is an open source concordance software which can be used to retrieve lists of key words in context (KWICs or concordances) from corpora. AntConc was developed by Laurence Anthony and can be downloaded from (his website) [http://www.laurenceanthony.net/software/antconc/] free of charge. Alternatively, type "antconc download" into your favorite search engine search box. You will then be able to download AntConc from the site which appears as the first result of your search.  The installation process is a very easy, steps-by-step process.

**Installing  TextPad**

To clean the concordances retrieved by AntConc, we will need a text editor. The text editor we will use is TeXtPad because this text editor can handle regular expressions. TextPad can be downloaded form `http://www.textpad.com/download/`. In this tutorial, we will only use the evaluation version of this program. In case you use TextPad more often, you can also purchase it for a small fee. Alternatively, type "textpad download" into your favorite search engine search box. You will then be able to download TextPad from the site which appears as the first result of your search.  The installation process is a very easy, steps-by-step process.

**Downloading corpus data: ICE Ireland**

Um die heutige Übungsaufgabe bearbeiten zu können, müssen sie die Korpusdaten bzw. das Korpus herunterladen. Bei dem Korpus, das wir nutzen, um die Übungsaufgabe zu bearbeiten, handelt es sich um die irische Komponente des *International Corpus of English* (ICE). Das Korpus kann auf folgender Seite heruntergeladen werden: `http://www.martinschweinberger.de/docs/data/ICE-Ireland.zip`


Nachdem Sie das Korpus heruntergeladen haben, entzippen Sie den Ordner und speichern ihn in einem Ordner, den Sie für das heutige Projekt/den Workshop angelegt haben bzw. anlegen.

**Downloading corpus data: BROWN2**

Für die praktischen Aufgaben zur Einführung in AntConc benötigen Sie das *Brown University Standard Corpus of Present-Day American English* (BROWN Korpus) und müssen dieses herunterladen. Das Korpus kann auf folgender Seite heruntergeladen werden: `http://www.martinschweinberger.de/docs/data/BROWN2.zip`


Nachdem Sie das Korpus heruntergeladen haben, entzippen Sie den Ordner und speichern ihn in einem Ordner, den Sie für das heutige Projekt/den Workshop angelegt haben bzw. anlegen.

**Downloading corpus data: INNSBRUC**

Für die praktischen Aufgaben zur Einführung in AntConc benötigen Sie das *Innsbruck Letter Corpus* (INNSBRUC) und müssen dieses herunterladen. Das Korpus kann auf folgender Seite heruntergeladen werden: `http://www.martinschweinberger.de/docs/data/INNSBRUC.zip`

Nachdem Sie das Korpus heruntergeladen haben, entzippen Sie den Ordner und speichern ihn in einem Ordner, den Sie für das heutige Projekt/den Workshop angelegt haben bzw. anlegen.

**Downloading the ICE Ireland metadata**

Um die erste Übungsaufgabe bearbeiten zu können, müssen sie die Sprecherdaten der irische Komponente des *International Corpus of English* (ICE), d.h. Informationen zu den soziolinguistischen Merkmalen der Sprecher wie beispielsweise deren Alter, Geschlecht, etc. Die Sprecherdaten können über folgenden Link heruntergeladen werden: `http://www.martinschweinberger.de/docs/data/BiodataIceIreland.txt`

Nachdem Sie die Sprecherdaten heruntergeladen haben, speichern Sie sie in einem Ordner, den Sie für das heutige Projekt/den Workshop angelegt haben bzw. anlegen.

**Downloading the INNSBRUC metadata**

Um die zweite Übungsaufgabe bearbeiten zu können, müssen sie die Metadaten des INNSBRUC Korpus herunterladen, da Sie Informationen zu den Merkmalen der Briefe wie beispielsweise deren Author, Erscheinungsjahr, etc., benötigen. Die Metadaten können über folgenden Link heruntergeladen werden: `http://www.martinschweinberger.de/docs/data/INNSBRUC_meta.txt`

Nachdem Sie die Metadaten heruntergeladen haben, speichern Sie sie in einem Ordner, den Sie für das heutige Projekt/den Workshop angelegt haben bzw. anlegen.


## Introduction to `AntConc`

Bevor wir uns der Übungsaufgabe widmen, werden wir zunächst einige Übungen durchgehen, die Ihnen helfen sollen die Funktionen von `AntConc` besser kennenzulernen. Starten Sie AntConc und laden Sie das BROWN Korpus ein.

> TIPP: Sie können sich sehr gute Einführungsvideos zu AntConc anschauen auf
> `https://www.youtube.com/playlist?list=PLiRIDpYmiC0Ta0-Hdvc1D7hG6dmiS_TZj`

**`AntConc` Exercises**

1. How often does the word *linguistics* occur in the BROWN corpus?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
5
```

2. Sentence-initial *but*: what do you have to type into the serach box to extract all instances of sentence-inital *but*? (Given that "Words" and "Case" are checked)

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
Two options:

"But" (only if "Case" is checked)

". But" (Problem: does not retrieve instances of sentence-initial *but* after colon, semicolons, and question marks, etc.)
```

3. *seems like* across registers: search for *seems like* (an informal phrase) and *seems that* (are more formal variant) in BROWN J and BROWN A (make sure to unload the BROWN J files after you have searched them!). Based on your findings, can you guess which of the two files represents the genre "science writing" and which file represents "press reportages"?

> TIPP: "press reportages" is less formal!

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
BROWN J appears to be more formal than BROWN A as there is no instance of *seems like* but 7 instances of *seems that* while there is one single instance of *seems like* and no instances of *seems that* in BROWN J. Given this results, it seems likely that BROWN A is press and BROWN J is academic writing.
```

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
library(knitr)
brownseemstb <- matrix(c(1,1,0,7), byrow = F, nrow = 2)
colnames(brownseemstb) <- c("BROWN A", "BROWN J")
rownames(brownseemstb) <- c("seem(s) like", "seem(s) that")
kable(brownseemstb, caption = "Distribution of *seem(s) like* and *seem(s) that* in BROWN A and BROWN J.")
```

4. Which variant (*seem(s) like* or *seem(s) that*) is used more frequently in science writing by speakers of American English? Have you been aware of this phenomenon?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
The construction *seems that* is used more often in academic writing compared with by natives speakers of (American) English. I did not know that *seems that* is more formal than *seems like*!
```


> Wild Cards (Regular Expressions) in `AntConc`
> 
> *Wild Cards*, or *regular expressions*, are symbols that stand in for other (sequences of) signs. For instance, the symbol \* stands for zero to an infinite number of signs while the symbol ? stands for exactly 1 other sign. 

In order to find out which wild cards can be used in `AntConc` and what they stand for, go to `Wildcard Settings` under `Global Settings` in the menu at the top of the `AntConc` GUI.

> Warning: If you want to use wild cards, make sure that the option `Regex`above theseach box is ticked!

5. What would you have to type into the search box to find all instances of all forms of the verb *to walk* (*walk*, *walks*, *walking*, *walked*) with only one search?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
Option 1: "walk*" 

Option 2: "walk|walked|walks|walking"

Option 3: Go to "Advanced" under "Concordance" next to the search box. Write all variants of "to walk" separated by a linebreak in the upper panel after you have checked the box "Use search term(s) from list below".
```

6. What would you have to type into the search box to find all instances of all forms of the verb *to sing* (*sing*, *sings*, *sang*, *sung*, *singing*) with only one search?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
Option 1: "s?ng+*" 

Option 2: "sing|sang|sung|singing|sings"

Option 3: Go to "Advanced" under "Concordance" next to the search box. Write all variants of "to sing" separated by a linebreak in the upper panel after you have checked the box "Use search term(s) from list below".
```

7. ColloCations: search for the term "results" and then go to "Collocates". Now, press "start" again and order the appearing list by "Freq". In addition, limit the context to 1 word to the left and 2 words to the right by setting "1L" and "2R" in the "Window Span". What ar ethe most common collocates of "results"?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
the
```

8. What is most frequent lexical collocate that is not a function word ?

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
obtained
```

9. Counting Types and Tokens: How many word types and word tokens does the BROWN corpus contain? (To answer this question, go to "Word List" and click on "Start")

```{r echo=F, eval = F, message=FALSE, warning=FALSE}
41518 word types and 1143801 word tokens
```

10. Why is this method not really percise?

# Example 1: Swearing in Ireland

As a first task we investigate whether men or women swear more in Irish English. As a first step, we familiarize ourselves with the steps performed during Corpus Analyses. Durng this taks, we will perform the following steps:

1. Load corpus data into `AntConc` 

2. Adapt settings of `AntConc`

3. Search for a list of swearwords in the corpus data.

4. Extract swaerwords with little context  from the corpus data.

5. Search and extract swearwords with a lot of context.

6. Save results in a folder.

7. Clean the extracted data in TextPad.

8. Load data into Microsoft Excel.

9. Find the speakers who used the swear words.

10. Calculate the absolute frequency of swear words.

11. Add biodata of the speakers to our table.

12. Create a table showing the mean relative frequency of swaerwords by gender (and age).

13. Display the results graphically.

14. Determine whteher the differences are statistically significant.

We will now start with the task and go through the steps described above.

## Extract Swear Words

Im folgenden werden die Arbeitsschritte aufgelistet, die notwendig sind, um die Fragestellung zu bearbeiten.

* Erstellen Sie eine Liste mit Schimpfwörtern und speichern Sie diese Liste als txt-Datei in Ihrem Projektordner. WICHTIG: Jedes Wort (bzw. jede Sequenz) muss in einer eignen Zeile stehen.

* Bevor Sie die Suche starten, gehen Sie bitte im Hauptmenü unter \verb!Tool Preferences! auf \verb!Concordance! und klicken Sie \\

\verb!Put delimiter around hits in KWIC display! an. Dies führt dazu, dass der vorherige und der folgende Kontext um die Treffer herum in Excel in anderen Spalten als die Treffer selbst erscheinen und Sie die Daten später besser bearbeiten können.

* Nutzen Sie AntConc, um diese Schimpfwörter im ICE Ireland Korpus zu suchen, indem Sie unter \verb!Advanced! das Kästchen \\ \verb!Use search term(s) from list below! anklicken, dann zu Ihrer Liste mit Schimpfwörtern browsen, dann auf \verb!Apply! klicken und anschließend auf \verb!Start! unter dem Suchfenster. \\
TIPP: Nutzen Sie reguläre Ausdrücke, sodass die Liste alle relevanten Wörter enthält und gleichzeitig nicht zu lang ist.

* Anschließend exportieren sie die Daten, d.h. speichern Sie die txt-Dateien in Ihrem Projektordner indem Sie unter !File! im Hauptmenü auf \verb!Save Output to Text File! klicken und zu Ihrem Ordner navigieren. Nennen Sie die entstehende txt-Datei \\ \verb!cursewords-ire-2015-10-12-short!.

* Nun suchen Sie erneut nach den Schimpfwörtern in Ihrer Liste allerdings erhöhen Sie nun den Kontext und geben dort den Maximalwert (1,000) ein.

* Anschließend exportieren sie die Daten, d.h. speichern Sie die txt-Dateien in Ihrem Projektordner. Nennen Sie die entstehende txt-Datei `cursewords-ire-2015-10-12-long`.


## Cleaning Data Using TextPad

Nachdem wir nun die Daten mit Hilfe von \verb!AntConc! extrahiert haben, müssen wir die daten nun säubern. Dies werden wir mit Hilfe von \verb!TextPad! erledigen. Im folgenden sind die Schritte aufgelistet, sdei nötig sind, um die Daten so zu bearbeiten, dass wir sie im folgenden Schritt mit \verb!Mircosoft Excel! weiterbearbeiten und analysieren können.

* Öffnen Sie die Datei \verb!cursewords-ire-2015-10-12-short.txt! in TextPad. Wie Sie sehen, ist die Formatierung teilweise zerstört. In den nächsten Schritten werden wir die Formatierung wieder herstellen und die Ergebnisse säubern.

*  Klicken Sie auf \verb!f8! - es sollte sich nun ein \textquote{Suchen und Ersetzen} Fenster öffnen. Klicken Sie das Kästchen \textquote{Regulärer Ausdruck} an und suchen Sie anschließend nach \verb!\n<! und ersetzen Sie diese Sequenz durch \verb!<!. Wiederholen Sie dies, bis Ihnen TextPad anzeigt, dass keine Vorkommnisse von \verb!\n<! gefunden wurden.

*  Deaktivieren Sie das Kästchen \textquote{Regulärer Ausdruck} an und suchen Sie anschließend nach \verb! ! (zwei Leerzeichen) und ersetzen Sie diese Sequenz durch \verb! ! (ein Leerzeichen). Wiederholen Sie dies, bis Ihnen TextPad anzeigt, dass keine Vorkommnisse von \verb! ! (zwei Leerzeichen) gefunden wurden.

*  Klicken Sie wieder das Kästchen \verb!Regulärer Ausdruck! an und suchen Sie anschließend nach \verb!\n ! (Leerzeichen nach dem n) und ersetzen Sie diese Sequenz durch \verb!\n! (kein Leerzeichen nach dem \verb!n!). Wiederholen Sie dies, bis Ihnen TextPad anzeigt, dass keine Vorkommnisse von \verb!\n ! gefunden wurden.

*  Suchen Sie anschließend nach \verb!\n\t! und ersetzen Sie diese Sequenz durch \verb! ! (Leerzeichen). Wiederholen Sie dies, bis Ihnen TextPad anzeigt, dass keine Vorkommnisse von \verb!\n\t! gefunden wurden.

*  Markieren sie nun die Daten in TextPad (\verb!Strg!+\verb!a!) und Kopieren Sie sie (\verb!Strg!+\verb!c!) und fügen Sie sie in ein Spreadsheet in Mircosoft Excel (\verb!Strg!+\verb!v!) in die Zelle A2 ein. Löschen Sie leere oder unnötige Spalten und geben Sie den übrigen Spalten die Überschriften \textit{id}, \textit{pre}, \textit{token} und \textit{post}.

*  Wiederholen Sie diese Schritte für die Datei \verb!cursewords-ire-2015-10-12-long.txt!, allerdings fügen Sie diese Daten in das Spreadsheet neben den bereits eingefügten Daten ein und zwar so, dass die erste Zeile des long-Datensatzes neben der ersten Zeile des short-Datensatzes liegt.


### Exercises: Getting to know `TextPad`

1.Erstellen Sie eine Kopie des ICE Ireland Korpus und laden Sie diese Dateien dann in TextPad ein.

2. Ersetzen Sie alle Vorkommnisse von klein \verb!a! mit dem Sequenz \verb!qwertz!.

3. Löschen Sie alle Sonderzeichen in den \textit{Äußerungen}. Welches Problem begegnet Ihnen dabei?

4. Ersetzen Sie alle Zeilenumbrüche und ersetzen Sie diese durch Tab-Stopps.

5. Ersetzen Sie nun alle Tab-Stopps durch Zeilenumbrüche.


## Process Data in Microsoft Excel

Die Daten wurden mittels \verb!AntConc! extrahiert und mit \verb!TextPad! gesäubert und vorbereitet. Die nächsten Schritte zeigen, wie die Daten nun mit \verb!Microsoft Excel! bearbeitet und analysiert werden können.

* Löschen Sie alle Spalten das long-Datensatzes außer die Spalte mit dem vorhergehenden Kontext, der Sie die Überschrift \textit{spk} geben.

*  Markieren Sie die \textit{spk}-Spalte (oben auf den Buchstaben klicken) und klicken Sie unter \verb!Suchen und Auswählen! auf \verb!Ersetzen!. In dem Pop-up Fenster geben Sie unter \textquote{Suchen nach} bitte \verb!*$! und unter \verb!Ersetzen durch! nichts ein. Anschließend klicken Sie auf \verb!Alle ersetzen!.

*  Markieren Sie die \textit{spk}-Spalte (oben auf den Buchstaben klicken) erneut und klicken Sie unter \verb!Suchen und Auswählen! auf \verb!Ersetzen!. In dem Pop-up Fenster geben Sie unter \verb!Suchen nach! bitte \verb!>*! und unter \verb!Ersetzen durch! nichts ein. Anschließend klicken Sie auf \verb!Alle ersetzen!.

*  Sie werden sehen, dass wir nun für sehr viele Schimpfwörter den Sprecher extrahiert haben. Um die restlichen Sprecher zu identifizieren, markieren Sie das gesamte Tabellenblatt (über die 1 und neben das A klicken) und gehen dann unter \verb!Sortieren und Filtern! auf \\ \verb!Benutzerdefiniertes Sortieren!. Klicken Sie das Kästchen \\ \verb!Daten haben Überschriften! an und sortieren Sie die Daten anschließend aufsteigend nach \textit{spk}. Auf diese Weise erscheinen alle Fälle, die keinen eindeutigen Sprecher haben am oberen Ende Ihrer Tabelle.

*  Bevor Sie manuell nach den Sprechern suchen, sollten Sie die Daten danach kodieren, ob der jeweilige Treffer wirklich auch ein Schimpfwort ist. Dies tun Sie, indem Sie in eine leere Spalte gehen, diese mit \textit{hit} überschreiben und dann, wenn es sich bei dem Treffer um ein Schimpfwort handelt, eine 1 eintragen, sonst eine 0.

*  Unglücklicher Weise müssen Sie die fehlenden Sprecher, die ein Schimpfwort verwendet haben, manuell suchen, indem sie einige Wörter (es müssen ganze, vollständige Wörter sein) aus dem Kontext des Treffers, d.h. aus der Zelle neben dem relevanten Token in der Spalte \textit{pre}, kopieren und nach dieser Sequenz im ICE Ireland mit AntConc suchen. Klicken Sie anschließend auf den Treffer im AntConc Konkordanzfenster (dies bringt Sie in Datei an den Ort an dem der Treffer ist) und suchen Sie nach dem Sprecher, den Sie dann manuell in die Excel Tabelle einfügen.


## Join Tables in Excel

Im Folgenden werden die Daten, die wir mit Hilfe von \verb!AntConc! extrahiert, mit \verb!TextPad! gesäubert und mit \verb!Microsoft Excel! bearbeitet haben mit den Sprecherdaten verbunden. Um diesen Schritt durchzuführen, folgen Sie den Arbeitsschritten, die unten aufgeführt sind. Bitte beachten Sie, dass Sie die Zellen für Ihre Analyse wahrscheinlich anpassen müssen.

*  Sie haben nun ein Tabellenblatt mit der Datei aus dem das Schimpfwort stammt, das Schimpfwort selber, den Kontext, in dem es verwendet wird, und den Sprecher, der es geäußert hat. Im nächsten Schritt werden wir bestimmen, ob bzw. wie häufig ein Sprecher Schimpfwörter verwendet hat.

*  Kopieren Sie die Sprecherdaten in ein neues Tabellenblatt und kopieren Sie die Spalten \textit{file}, \textit{spk} und \textit{sum}, die in der Spalte \textit{test} den Wert 1 haben, neben die Spalten mit der Sprecherinformation.

* Nennen Sie die nächste freie Spalte \textit{afreq} und geben Sie folgenden Befehl in die erste Zelle dieser Spalte ein:\\
\verb!=ZÄHLENWENNS($J$2:$J$364;C2;$K$2:$K$364;D2)!

*  Kopieren Sie die Spalte \textquote{afreq} und fügen Sie sie wieder als Werte ein, d.h.: nachdem Sie die Spalten kopiert haben, machen Sie einen rechten Mausklick und geben Sie auf \textquote{Inhalte einfügen} und wählen Sie \textquote{Werte einfügen}.

*  Löschen Sie nun die Splaten \textquote{file}, \textit{spk} und \textit{hit} -- sie werden nicht mehr benötigt.

*  Kopieren Sie das entstandene Tabellenblatt.

*  Sortieren Sie die neue Tabelle aufsteigend nach \textit{word.count} und löschen Sie die Zeilen, die in der Spalte \textit{word.count} eine Wert kleiner als 50 haben. Anschließend sortieren Sie die Tabelle wieder benutzerdefiniert nach \textit{text.id} und als zweites nach \textit{spk.ref}.

*  Nennen Sie die nächste freie Spalte \textit{ptw} und geben Sie in die erste Zelle folgenden Befehl ein:\\
\verb!=J2/I2*1000!

*  Anschließend sortieren Sie die neue Tabelle benutzerdefiniert (mit Überschriften) zuerst nach \textquote{file} und dann nach \textquote{spk}.

*  Nenen Sie nun die nächsten beiden Spalten als \textquote{sum} und \textquote{test} und geben Sie folgenden Befehl in die erste Zelle der Spalte \textquote{sum}:\\

`=WENN(UND(A2=A1;B2=B1);C1+1;1)`

*  Gehen Sie nun mit Ihrem Cursor auf die untere rechte Ecke der Zelle, in den Sie diesen Befehl eingegeben habe, bis ein schwarzes Kreuz erscheint und doppelklicken Sie mit der linken Maustaste.

*  Gehen Sie nun in die erste Zelle der Spalte \textquote{test} und geben Sie folgenden Befehl ein:

`=WENN(UND(A2=A3;B2=B3);0;1)`

*  Gehen Sie nun mit Ihrem Cursor auf die untere rechte Ecke der Zelle, in den Sie diesen Befehl eingegeben habe, bis ein schwarzes Kreuz erscheint und doppelklicken Sie mit der linken Maustaste.

*  Kopieren Sie nun die Spalten \textquote{sum} und \textquote{test} und fügen Sie sie wieder als Werte ein, d.h.: nachdem Sie die Spalten kopiert haben, machen Sie einen rechten Mausklick und geben Sie auf \textquote{Inhalte einfügen} und wählen Sie \textquote{Werte einfügen}.

*  Nun sortieren Sie die Tabelle benutzedefiniert absteigend nach \textquote{test}.


## Visualizations in Microsoft Excel

Wir sind nun soweit die Ergebnisse zusammenfassen und graphisch darstellen zu können. Im ersten Schritt werden wir die Mittelwerte der relativen Häufigkeiten der Textsorten darstellen.

* Um die Textsorten darstellen zu können, müssen Sie die Spalte \textit{text.id} in eine leere Spalte kopieren. Anschlieend ersetzten Sie die Überschrift durch \textit{texttype}. Dann markieren Sie diese neue Spalte und gehen dann unter \verb!Sortieren und Auswählen! auf \textit{Ersetzen}. In dem erscheinenden Fenster geben Sie bitte bei \textit{Suchen nach} \verb!-*! ein und klicken anschließend auf \verb!Alle ersetzen!.

* Im nächsten Schritt ersetzten Sie \textit{S1A} durch \textit{Private}, \textit{S1B} durch \textit{Public}, \textit{S2A} durch \textit{Unscripted} und \textit{S2B} durch \textit{Scripted} indem Sie unter \verb!Sortieren und Auswählen! bei \verb!Suchen nach! und \verb!Ersetzen durch! die jeweiligen Sequenzen eingeben und anschließend auf \verb!Alle ersetzen! klicken.

* Markieren Sie nun die Spalten \textit{texttype} und \textit{ptw} und gehen Sie dann unter der Registerkarte \textquote{Einfügen} auf \verb!Pivot Table! und machen Sie einen Linksklick und klicken Sie in dem sich öffnenden Fenster auf \verb!OK!.

* Sie werden nun auf eine neue Seite dirigiert und Sie können am rechten rand der Tabelle \textit{texttype} in den Bereich \verb!Zeilen! und \textit{ptw} in den Bereich \verb!Werte! ziehen. Dann klicken sie auf das kleine schwarze Pfeilchen neben \verb!Summe von ptw! und klicken \verb!Wertfeldeinstellungen! an. Bei \verb!Wertfeldeinstellungen! wählen Sie bitte \verb!Mittelwert! aus und klicken Sie auf \verb!OK!.

* Kopieren Sie die nun erzeugte Tabelle und fügen Sie wieder (wie bereits oben beschrieben) als Werte erneut in das Tabellenblatt ein. Ersetzen Sie die Überschriften \textit{Zeilenbeschriftungen} durch \textit{Text Type} und \textit{Mittelwert von ptw} durch \textit{Swearwords}. Nun löschen Sie noch die Zeile \textit{Gesamtergebnis}. Nun markieren Sie die Zahlenwerte und machen einen Rechtsklick. Anschließend gehen Sie auf \verb!Zellen formatieren! und wählen unter \verb!Zahl! die Option 3 Nachkommastellen.

* Markieren Sie die entstandene Tabelle und gehen Sie unter \verb!Einfügen! auf \verb!Liniendiagramm einfügen!. Wählen Sie einfach den ersten Liniendiagrammtyp aus.

* Fügen Sie Datenbeschriftungen, einen Titel, Achsenbeschriftungen, eine exponentielle Trendlinie hinzu, entfernen Sie die Linie, formatieren sie Markierungen zu den Datenpunkten hinzu und passen Sie den Y-Achsenabschnitt an. Dies alles tun Sie, indem Sie auf die Grafik klicken und dann auf das Plus-Zeichen welches rechts oben neben der Graphik erschienen ist.

*Ihre Graphik sollte idealer Weise nun so aussehen:\\

%Figure 1
\begin{figure}[H]
\centering
\includegraphics[scale=1]{SW-Reg.png}
\caption{Mean of Irish English Speaker's Relative Frequencies of Swearwords by Text Type including a Eponential Trend Line.}
\label{fig1}
\end{figure}

Im nächsten Schritt werden wir die Geschlechterverteilung graphisch darstellen. Hierzu erstellen Sie bitte eine neue Pivottabelle, kopieren die Werte und fügen Sie als Werte wieder ein und wählen ein Säulendiagramm als Darstellungsart. Fügen Sie Datenbeschriftungen, einen Titel, Achsenbeschriftungen hinzu und passen Sie die Farbe der Säulen an. Dies alles tun Sie, indem Sie auf die Grafik klicken und dann auf das Plus-Zeichen welches rechts oben neben der Graphik erschienen ist.

* Ihre Graphik sollte idealer Weise nun so aussehen:

%Figure 2
\begin{figure}[H]
\centering
\includegraphics[scale=1]{SW-Sex.png}
\caption{Mean of Irish English Speaker's Relative Frequencies of Swearwords by Gender in Private Dialogues.}
\label{fig2}
\end{figure}

Im letzten Schritt werden wir die gleichzeitig die Alters- und Geschlechterverteilung graphisch darstellen. Hierzu erstellen Sie bitte eine neue Pivottabelle, kopieren die Werte und fügen Sie als Werte wieder ein und wählen ein Säulendiagramm als Darstellungsart.
Um mehrere Linien darzustellen müssen die Werte nun anders angeordnet werden: Die Werte für Männer, Frauen und beide zusammen müssen in je einer eigenen Reihe aufgeführt werden. Sie können die Altersgruppen als Überschriften der Spalten einfügen, da dies die Datenbeschriftung einfacher macht.

Fügen Sie Datenbeschriftungen, einen Titel, Achsenbeschriftungen hinzu und passen Sie die Farbe der Säulen an. Dies alles tun Sie, indem Sie auf die Grafik klicken und dann auf das Plus-Zeichen welches rechts oben neben der Graphik erschienen ist.


\item Ihre Graphik sollte idealer Weise nun so aussehen:
%Figure 3
\begin{figure}[H]
\centering
\includegraphics[scale=1]{SW-AgeSex.png}
\caption{Mean of Irish English Speaker's Relative Frequencies of Swearwords by Age and Gender in Private Dialogues.}
\label{fig3}
\end{figure}
\end{enumerate}

### Exercises: Creating Tables and Plots in Microsoft Excel (Sie benötigen für diese Aufgaben die Tabelle mit den Sprecherdaten)

* Erstellen Sie eine Übersichtstabelle mit den Anzahlen der Sprecher in der Textsorte \textit{Private Dialogue} hinsichtlich Alter und Geschlecht.

* Erstellen Sie eine Übersichtstabelle mit den Wörterzahlen der Register und von den gegebenen Altersgruppen sowie getrennt nach Geschlecht.

* Erstellen Sie eine Graphik, in der die Wörterzahlen von den Altersgruppen getrennt nach Männern und Frauen dargestellt werden.


## Statistik mit Microsoft Excel

Um mit Excel komplexere statistische Analysen durchführen zu können, müssen Sie das \verb!Datenanalyse Add-In! Für dieses Beispiel ist allerdings ein einfacher $\chi^{2}$-Test ausreichend.

### Simple Chi-Squrae tests in Microsoft Excel

Da der $\chi^{2}$-Test nur nominale oder kategoriale Variablen akzeptiert, müssen wir unser Datenset etwas modifizieren. Gehen Sie zurück zu der Datentabelle, in der alle Sprecherinformationen und die relativen Häufigkeiten von Schimpfwörtern enthalten sind. Kopieren Sie dieses Datenblatt in ein neues Excel-Fenster und speichern Sie dieses Fenster unter dem Namen. \verb!statz!. Löschen Sie nun alle Spalten bis auf: \verb!file.speaker.id!, \verb!age!, \verb!sex!, \verb!texttype! und \verb!ptw!. Löschen Sie auch alle Zeilen, die nicht zu \verb!texttype Private! gehören. legen Sie dann eine neue Spalte an, die Sie \verb!swear! nennen.


* In der ersten Zelle der \verb!swear! Spalte geben Sie folgenden Befehl ein (unter der Bedingung, dass in Spalte \verb!D! die relativen Häufigkeiten der Schimpfwörter aufgelistet sind):\\
\noindent \verb!=WENN(D2=0; 1; 0)!\\

* Gehen Sie nun mit Ihrem Cursor auf die untere rechte Ecke der Zelle, in den Sie diesen Befehl eingegeben habe, bis ein schwarzes Kreuz erscheint und doppelklicken Sie mit der linken Maustaste. Nachdem nun alle Zellen dieser Spalte angeben, ob der Sprecher Schimpfwörter genutzt hat oder nicht, fügen Sie den Inhalt der Spalte \verb!swear! wieder als Werte ein, d.h.: nachdem Sie die Spalte kopiert haben, machen Sie einen rechten Mausklick und geben Sie auf \textquote{Inhalte einfügen} und wählen Sie \verb!Werte einfügen!.

* Markieren Sie die Tabelle, gehen Sie in der Registerkarte \textquote{Einfügen} auf \verb!Pivot Table! und klicken Sie in dem sich öffnenden Fenster auf \verb!OK!

* Ziehen Sie in dem sich öffnenden Tabellenblatt \verb!sex! in den Bereich \verb!ZEILEN! und \verb!swear! in den Bereich \verb!WERTE!. Ziehen Sie nun \verb!sex! von oben in den Bereich \verb!WERTE! und klicken Sie anschließend auf \verb!OK!.

* Im nächsten Schritt kopieren Sie die Tabelle und fügen Sie wieder als Werte ein, d.h.: nachdem Sie die Tabelle kopiert haben, gehen Sie auf ein freies Feld, machen einen rechten Mausklick, geben auf \verb!Inhalte einfügen! und wählen \verb!Werte einfügen!.

* Gehen Sie nun neben die Zelle, die die Anzahl der weiblichen Sprecher enthält und ziehen Sie die Anzahl der Frauen, die Schimpfwörter genutzt haben, von der Gesamtanzahl der Frauen ab (262-91=171). Tun Sie dasselbe für die Männer. Kopieren Sie die Tabelle und fügen Sie sie als Wertetabelle wieder ein. Nun löschen Sie die Spalte, die die Gesamtzahl der Sprecher nach Geschlecht enthält - sie ist für das weitere Vorgehen irrelevant.

* Berechnen Sie nun die Zeilen- und Spaltensummen, sowie die Gesamtsumme (TIPP: Nutzen Sie die Summenfunktion von Microsoft Excel).

Sie sollten nun folgende Tabelle erzeugt haben:

```{r echo = F, results = 'asis'}
library(knitr)
swaerwordsgendertb <- matrix(c("91", "37", "128","171", "45", "216", "262", "82","344"), nrow = 3, byrow = F)
# add column and row names
colnames(swaerwordsgendertb) <- c("Swear Word Users", "Non Swear Word Users", "Sum")
rownames(swaerwordsgendertb) <- c("Women", "Men", "Sum")
kable(swaerwordsgendertb, caption = "Observed numbers of speakers that have used swear words by gender.")
```

Diese Wertetabelle bildet die Basis für den $\chi^{2}$-Test, da sie die beobachteten Werte enthält. Wir werden nun zwei weitere Tabellen aus dieser Tabelle mittels einfacher Befehle erzeugen.

* Such Sie vier freie Zellen unter der Wertetabelle. Berechnen Sie für jede Zelle den Wert, der zu erwarten wäre, wenn sich Frauen und Männer nicht unterscheiden, indem Sie die Zeilensumme mit der Spaltensumme multiplizieren und durch die Gesamtsumme dividieren.

\begin{equation}

\frac{Spaltensumme*Zeilensumme}{Gesamtsumme}
\label{eq:erw}

\end{equation}

* Sie sollten nun folgende Tabelle errechnet haben:

```{r echo = F, results = 'asis'}
library(knitr)
swaerwordsgenderexptb <- matrix(c(97.49,  164.51,  262, 30.51,  51.49,  82, 128,  216,  344), nrow = 3, byrow = T)
# add column and row names
colnames(swaerwordsgenderexptb) <- c("Swear Word Users", "Non Swear Word Users", "Sum")
rownames(swaerwordsgenderexptb) <- c("Women", "Men", "Sum")
kable(swaerwordsgenderexptb, caption = "Expected numbers of speakers that have used swear words by gender if men and women did not differ in their use of swear words.")
```

* Im nächsten Schritt berechnen wir den $\chi^{2}$-Wert, indem wir für jede Zelle berechnen:\\

\begin{equation}

\frac{(beobachteter Wert – erwarteter Wert)^{2}}{erwarteter Wert}
\label{eq:chi}

\end{equation}

Für die oberste rechte Zelle (Frauen, die Schimpfwörter genutzt haben) ergibt sich dadurch:

\begin{equation}

\frac{(91 – 97.49)^{2}}{97.49} = \frac{(-6.49)^{2}}{97.49} = \frac{42.1201}{97.49} = \frac{42.1201}{97.49} = 0.432
\label{eq:chibsp}

\end{equation}

Sie sollten folgende Tabelle erhalten:

```{r echo = F, results = 'asis'}
library(knitr)
swaerwordsgenderx2tb <- matrix(c(0.432, 0.256,  0.688, 1.812,  1.074,  2.885, 1.380,  0.818,  2.197), nrow = 3, byrow = T)
# add column and row names
colnames(swaerwordsgenderx2tb) <- c("Swear Word Users", "Non Swear Word Users", "Sum")
rownames(swaerwordsgenderx2tb) <- c("Women", "Men", "Sum")
kable(swaerwordsgenderx2tb, caption = "Table of chi-square values.")
```

Die Summe aller $\chi^{2}$-Werte (2.197) ist nun der für uns relevante $\chi^{2}$-Wert. Um zu schauen, ob dieser Wert signifikant ist, müssen Sie zuerst die \textit{Freiheitsgrade} (degrees of freedom) berechnen und anschließend nachschauen, ob ihr Wert größer als ein kritischer $\chi^{2}$-Wert ist (dann sind Ihre Ergebnisse statistisch signifikant) oder ob ihr $\chi^{2}$-Wert kleiner als der kritische $\chi^{2}$-Wert ist (dann sind Ihre Ergebnisse nicht statistisch signifikant).

Die Freiheitsgrade berechnen sich nach Formel (\ref{eq:df}).

\begin{equation}

DF = (Anzahl Zeilen -1) * (Anzahl Spalten – 1) = (2-1) * (2-1) = 1 * 1 = 1
\label{eq:df}

\end{equation}

Nach unserer formal haben wir demnach einen Freiheitsgrad und wir können nun nachschauen, ob unser $\chi^{2}$-Wert (2.197) über oder unter dem kritischen Wert liegt. Sie finden Tabellen mit kritischen $\chi^{2}$-Werten in vielen Statistikeinführungen oder im WorldWideWeb, bspw. unter: `http://www.mesosworld.ch/lerninhalte/Biv_Chi/de/html/unit_SignKritWert.html`

Tabelle (\ref{tab:kritx}) zeigt einen Ausschnitt einer solchen Tabelle.

```{r echo = F, results = 'asis'}
library(knitr)
critx2tb <- matrix(c("1", "3.84", "6.64", "10.83", "2", "5.99", "9.21", "13.82", "3", "7.82", "11.35", "16.27", "4", "9.49", "13.28", "18.47", "5", "11.07", "15.09", "20.52"), nrow = 5, byrow = T)
# add column and row names
colnames(critx2tb) <- c("DF", "p<.05", "p<.01", "p<.001")
kable(critx2tb, caption = "Critical chi-square values at 1 to 5 degrees of freedom.")
```

Da unser errechneter $\chi$^{2}-Wert weit unter dem Wert des kritischen Wertes liegt, können wir die H_{0} nicht verwerfen und müssen somit festhalten, dass kein statistisch signifikanter Zusammenhang zwischen dem Geschlecht der Sprecher und der Verwendung von Schimpfwörtern besteht. Bevor wir allerdings die Ergebnisse zusammenfassen, werden wir zusätzlich die Effektstärke berechnen.

Das Effektstärkemaß, das bei $\chi$^{2}-Tests verwendet wird ist entweder der $\phi$-Koeffizient (phi-Koeffizient) oder Cramer's $\phi$ (Cramer's phi), das verwendet wird, wenn man es mit mehr als vier Tabellenfeldern rechnet. Der $\phi$-Koeffizient lässt sich nach Formel \ref{eq:phi} berechnen (N = Stichprobengröße).

\begin{equation}

\phi = \sqrt{\frac{\chi^{2}}{N}}
\label{eq:phi}

\end{equation}

Es ergibt sich für uns:

\begin{equation}

\phi = \sqrt{\frac{2.197}{344}} = \sqrt{0.00639} = 0.0799
\label{eq:phi2}

\end{equation}

Der Wert von $\phi$ liegt zwischen 0 (kein Zusammenhang) und 1 (perfekter Zusammenhang). Für die Einteilung in schwache, mittlere und starke Effekte kann man der Einteilung für Cohen's $d$ folgen, sodass man bei Werten von .2 bis .3 von kleiner, um einen Wert bei 0.5 von mittlerer und ab .8 von einem starken Effektstärke sprechen kann. Wir haben es in diesem Beispiel also mit einem starken Effekt oder Zusammenhang zu tun.

Man kann das Ergebnis unseres Beispiels wie folgt zusammenfassen: Ein $\chi$^{2}-Test bestätigt keinen signifikanten Zusammenhang zwischen dem Geschlecht der Sprecher und der Verwendung von Schimpfwörtern im irischen Englisch ($\chi$^{2} = 2.197, df = 1, p $\ge$ .05, $\phi$ = .08).


## Excercises

1. Unterscheiden sich Männer und Frauen in bestimmten Altersgruppen hinsichtlich des Gebrauchs von Schimpfwörtern im irischen Englisch?
2. Wir werden hierzu drei weitere $\chi$^{2}-Tests durchführen:

\begin{enumerate}
\item Unterscheiden sich Männer und Frauen in der Altersgruppe 19-25?
\item Unterscheiden sich Männer und Frauen in der Altersgruppe 34-41?
\item Unterscheiden sich Männer und Frauen in der Altersgruppe 50+?
\end{enumerate}
\end{enumerate}

# Example 2: *-ment* across Time

Wir werden uns nun einer zweiten Übungsaufgabe widmen. In dieser Aufgabe wird es darum gehen, die Häufigkeit des Nominalsuffixes *ment* zwischen 1500 und 1700 auf der Grundlage des INNSBRUC Korpus zu bestimmen.

Die notwendigen Schritte, um diese Frage empirisch beantworten zu können, sind folgende:

1. Korpusdaten in AntConc laden.
2. Einstellungen in AntConc anpassen.
3. Suchen nach allen Wörtern mit *ment* in den Daten mit wenig Kontext.
4. Speichern der Daten im Projektordner.
5. Säubern der Daten in TextPad.
6. Daten in Microsoft Excel kopieren.
7. Texte, in denen ein Wort mit *ment* verwendet wird, bestimmen.
8. Absolute Häufigkeiten Wörter mit *ment* pro Text bestimmen.
9. Relative Häufigkeiten der Wörter mit *ment* pro Text bestimmen.
10. Tabellarisieren der relativen Häufigkeiten hinsichtlich des Erstellungsjahrs der Texte.
11. Graphische Darstellung der relativen Häufigkeiten hinsichtlich des des Erstellungsjahrs der Texte.
12. Statistische Auswertung der Ergebnisse mittels der erstellten Häufigkeitstabellen.


Da die einzelnen Arbeitsschritte im vorherigen detailliert beschrieben wurden, wird hier nur noch da auf die statistische Analyse eingegangen, da sich diese Übungsaufgaben substantiell von der ersten Übungsaufgabe unterscheiden.

## Grafische Darstellung der Ergebnisse

Wenn Sie einzelnen Schritte bis zur grafischen Darstellung durchlaufen sind, sollten Sie folgende Grafik erhalten.

\begin{figure}[H]
\centering
\includegraphics[width=.8\textwidth]{images/ment1.png}\\[.25cm]
\caption{Relative Häufigkeit von Wörtern mit dem Suffix {-ment} zwischen 1400 und 1700 basierend auf dem INNSBRUC Korpus.}
\label{fig:ment1}
\end{figure}

## Statistik mit dem Datenanalyse Add-In von Microsoft Excel

Wie bereits oben angemerkt, ist es für komplexere statistische Analysen sinnvoll das \verb!Datenanalyse Add-In! zu installieren. Dieses bietet die Möglichkeit bspw. Regressionen über eine vorgefertigte Maske durchzuführen. Wir werden uns nun damit beschäftigen, wie man das \verb!Datenanalyse Add-In! installiert und eine einfache Analyse damit durchführt.

1. Um das \verb!Datenanalyse Add-In! zu installieren, gehen Sie unter \textquote{Datei} auf \textquote{Optionen} und dann im erscheinenden Fenster auf \textquote{Add-Ins}. Suchen gehen Sie das Add-In mit dem Namen \verb!Analyse-Funktionen! und aktivieren Sie es.
2. Unter dem Reiter \textquote{Daten} erscheint nun ganz rechts die Funktion \textquote{Datenanalyse}.
3. Bevor Sie mit der Analyse beginnen, müssen Sie die Sprecherdaten mit den relativen Frequenzen neu ordnen. Gehen Sie dazu auf das Tabellenblatt mit den Sprecherdaten und den relativen Frequenzen und gehen Sie dann auf \textquote{Sortieren und Filtern}. Sortieren Sie die Daten dann benutzerdefiniert nach Textsorte und dann -- in einer zweiten Ebene -- nach Geschlecht.
4. Um das Datenanalysetool zu verwenden, gehen Sie in dem Reiter \verb!Daten! auf \verb!Datenanalyse! und wählen Sie die Funktion \verb!Regression!. Im erscheinenden Fenster gebe Sie den Tabellenbereich mit den ptw-Werte ein und den Tabellenbereich mit den Jahreszahlen der Texte ein. Klicken Sie auf \textquote{OK} und schauen Sie sich die Ergebnisse an.

Da eine ausführliche Besprechung der Ergebnisse zu ausufernd wäre, sei nur kurz auf die wichtigsten Kennzahlen eingegangen.
Der erscheinenden Tabelle ist zu entnehmen, dass die Regression auf 254 Datenpunkten basiert und, dass die unabhängige Variable \verb!YEAR! 5.1\% der Varianz erklärt (Bestimmtheitsmaß 0.051). Würden Sie die Analyse nicht auf der Grundlage der vorhandenen Stichprobe, sondern anhand der realen Population durchführen (aller Briefe, die zwischen 1400 und 1700 geschrieben wurden, dann ist damit zu rechnen, dass dieselbe Regression 4.7\% der Varianz erklären würde (Adjustiertes Bestimmtheitsmaß = 0.047). Die unabhängige Variable (YEAR) korreliert hoch signifikant positiv mit der relativen Häufigkeit von Wörtern mit dem Suffix -ment (Koeffizient (YEAR) = 0.00948, P-Wert (YEAR) = 0.002766291). Die Regression sagt die beobachteten relativen Häufigkeiten hoch signifikant besser voraus, als würde man den Mittelwert der relativen Häufigkeiten zu Grunde legen (P-Wert (Schnittpunkt) = 0.002762).
\end{enumerate}

# Using Macros in Microsoft Excel

Makros sind kleine Programme, die insbesondere dann nützlich sind, wenn man aufgaben wiederholt durchführen muss. Der große Vorteil von Makros in Microsoft Excel ist, dass man nicht programmieren muss, sondern Analyse einfach einmal aufzeichnet, die Schritte mit einer Tastenfolge versieht und dann die Tastenfolge dazu nutzt, dieselben Analyseschritte automatisch von Excel ausführen zu lassen.

Um diese Funktionalität zu verdeutlichen, werden wir die Anzahl der Wörter der Briefe im *Innsbruck Letter Corpus* zählen.

## Preparation

Sie benötigen für die folgende Analyse das *INNSBRUC Korpus*, \verb!TextPad! und ein Fenster, in dem Microsoft Excel geöffnet ist.
Bevor Sie beginnen, kopieren Sie das INNSBRUC Korpus und laden sie die kopierte Version in TextPad ein. Klicken Sie auf \verb!f8!, wählen Sie \verb!Alle Dokumente! und ersetzen Sie alle Sonderzeichen und anschließend alle Doppelten Leerzeichen durch nichts. Dann speichern Sie die Ergebnisse, indem Sie unter \verb!Datei! auf \verb!Alle speichern! klicken.

1. Klicken Sie in Zelle \verb!A1! und gehen Sie dann auf den Reiter \verb!ANSICHT! und klicken Sie unter \verb!Makros! auf \verb!Makro aufzeichnen!.
2. Geben Sie bei \verb!Tastenkombination! ein Fach ein kleines \verb!o! ein (Sie können jeden anderen Buchstaben wählen, aber \verb!o! bietet sich an, des es bislang nicht durch andere Shortcuts belegt ist). Anschließend können Sie die Aufgabe des Makros beschreiben. Sie könne bspw. schreiben: Dieses Makro zählt die Wörter in Zelle \verb!A1! und gibt das Ergebnis in Zelle \verb!B1! aus.
3. Öffnen Sie die erste Datei des kopierten INNSBRUC Korpus und markieren Sie den Inhalt der Datei (\verb!Strg! + \verb!a!), kopieren Sie den Inhalt der Datei (\verb!Strg! + \verb!c!) und fügen Sie den kopierten Inhalt in die Zelle \verb!A1! ein (\verb!Strg! + \verb!v!).
4. Geben Sie nun in Zelle \verb!B1! folgenden Befehl ein:\\

\verb!=WENN(LÄNGE(A1)=0;0;LÄNGE(A1)-LÄNGE(WECHSELN(A1;" ";"")))!

Sobald Sie \verb!Enter! klicken, erscheint die Wörterzahl des Texts in Zelle \verb!A1!.

5. Gehen Sie nun erneut auf Zelle \verb!A1!, gehen Sie dann auf den Reiter \verb!ANSICHT! und klicken Sie unter \verb!Makros! auf \verb!Aufzeichnen beenden!.
6. Sie können nun die zweite Datei den INNSBRUC Korpus in Zelle \verb!A1! einfügen, dann \verb!Strg! + \verb!o! klicken und Microsoft Excel gibt Ihnen die Wörterzahl des zweiten Datei.
7. TIPP: Wenn Sie die Ergebnisse kopieren und in eine andere Datei schreiben wollen, dann kopieren Sie den Inhalt der Zelle \verb!B1! und fügen Sie ihn als Werte ein!

Sie können mit Makros auch sehr viel komplexere Befehlsabfolgen aufzeichnen und ausführen lassen. Ich habe dazu ein Videotutorium auf meinem YouTube-Kanal: `https://www.youtube.com/watch?v=wzTT15ESGGg!`

# References
