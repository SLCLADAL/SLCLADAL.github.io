![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)


# Part-of-speech tagging and syntactic parsing with R


This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *POS-Tagging and Syntactic Parsing with R*](https://ladal.edu.au/postag.html). The tutorial provides more details and background information while this interactive notebook focuses strictly on practical aspects.


**Preparation and session set up**

We set up our session by activating the packages we need for this tutorial. 

```{r prep2, message=FALSE, warning=FALSE}
# activate packages
library(dplyr)
library(stringr)
library(udpipe) 
```

Once you have initiated the session by executing the code shown above, you are good to go.

If you are using this notebook on your own computer and you have not already installed the R packages listed above, you need to install them. You can install them by replacing the `library` command with `install.packages` and putting the name of the package into quotation marks like this: `install.packages("dplyr")`. Then, you simply run this command and R will install the package you specified.


# Part-Of-Speech Tagging

Many analyses of language data require that we distinguish different parts of speech. In order to determine the word class of a certain word, we use a procedure which is called part-of-speech tagging (commonly referred to as pos-, pos-, or PoS-tagging). 

Parts-of-speech, or word categories, refer to the grammatical nature or category of a lexical item, e.g. in the sentence *Jane likes the girl* each lexical item can be classified according to whether it belongs to the group of determiners, verbs, nouns, etc.  

When posâ€“tagged, the example sentence could look like the example below.

1. Jane/NNP likes/VBZ the/DT girl/NN

In the example above, `NNP` stands for proper noun (singular), `VBZ` stands for 3rd person singular present tense verb, `DT` for determiner, and `NN` for noun(singular or mass). The pos-tags used by the `openNLPpackage` are the [Penn English Treebank pos-tags](https://dpdearing.com/posts/2011/12/opennlp-part-of-speech-pos-tags-penn-english-treebank/). A more elaborate description of the tags can be found here which is summarized below:

Tag | Description | Examples
----|-------------|---------
CC | Coordinating conjunction | and, or, but
CD | Cardinal number | one, two, three
DT | Determiner | a, the
EX | Existential there | There/EX was a party in progress
FW | Foreign word | persona/FW non/FW grata/FW
IN | Preposition or subordinating con | uh, well, yes
JJ | Adjective | good, bad, ugly
JJR | Adjective, comparative | better, nicer
JJS | Adjective, superlative | best, nicest
LS | List item marker | a., b., 1., 2.
MD | Modal | can, would, will
NN | Noun, singular or mass | tree, chair
NNS | Noun, plural | trees, chairs
NNP | Proper noun, singular | John, Paul, CIA
NNPS | Proper noun, plural | Johns, Pauls, CIAs
PDT | Predeterminer | all/PDT this marble, many/PDT a soul
POS | Possessive ending | John/NNP 's/POS, the parents/NNP '/POS distress
PRP | Personal pronoun | I, you, he
PRP\$ | Possessive pronoun | mine, yours
RB | Adverb | every, enough, not
RBR | Adverb, comparative | later
RBS | Adverb, superlative | latest
RP | Particle | RP
SYM | Symbol | CO2
TO | to | to
UH | Interjection | uhm, uh
VB | Verb, base form | go, walk
VBD | Verb, past tense | walked, saw
VBG | Verb, gerund or present part. | walking, seeing
VBN | Verb, past participle | walked, thought
VBP | Verb, non-3rd person singular pr | walk, think
VBZ | Verb, 3rd person singular present | walks, thinks
WDT | Wh-determiner | which, that
WP | Wh-pronoun | what, who, whom (wh-pronoun)
WP\$ | Possessive wh-pronoun | whose, who (wh-words)
WRB | Wh-adverb | how, where, why (wh-adverb)

There are several different R packages that assist with pos-tagging texts [see @kumar2016mastering]. In this tutorial, we will use the `udpipe` [@udpipe]. The `udpipe` package is really great as it is easy to use, covers a wide range of languages, is very flexible, and very accurate.  It is particularly handy because it addresses and remedies major shortcomings that previous methods for pos-tagging had, namely

* it offers a wide range of language models (64 languages at this point)
* it does not rely on external software (like, e.g., TreeTagger, that had to be installed separately and could be challenging when using different operating systems)
* it is really easy to implement as one only need to install and load the `udpipe` package and download and activate the language model one is interested in
* it allows to train and tune one's own models rather easily

The available pre-trained language models in UDPipe are:

Languages | Models 
----------|-------
Afrikaans | afrikaans-afribooms
Ancient Greek | ancient_greek-perseus, ancient_greek-proiel
Arabic | arabic-padt
Armenian | armenian-armtdp
Basque | basque-bdt
Belarusian | belarusian-hse
Bulgarian | bulgarian-btb
Buryat | buryat-bdt
Catalan | catalan-ancora
Chinese | chinese-gsd, chinese-gsdsimp, classical_chinese-kyoto
Coptic | coptic-scriptorium
Croatian | croatian-set
Czech | czech-cac, czech-cltt, czech-fictree, czech-pdt
Danish | danish-ddt
Dutch | dutch-alpino, dutch-lassysmall
English | english-ewt, english-gum, english-lines, english-partut
Estonian | estonian-edt, estonian-ewt
Finnish | finnish-ftb, finnish-tdt
French | french-gsd, french-partut, french-sequoia, french-spoken
Galician | galician-ctg, galician-treegal
German | german-gsd, german-hdt
Gothic | gothic-proiel
Greek | greek-gdt
Hebrew | hebrew-htb
Hindi | hindi-hdtb
Hungarian | hungarian-szeged
Indonesian | indonesian-gsd
Irish Gaelic | irish-idt
Italian | italian-isdt, italian-partut, italian-postwita, italian-twittiro, italian-vit
Japanese | japanese-gsd
Kazakh | kazakh-ktb
Korean | korean-gsd, korean-kaist
Kurmanji | kurmanji-mg
Latin | latin-ittb, latin-perseus, latin-proiel
Latvian | latvian-lvtb
Lithuanian | lithuanian-alksnis, lithuanian-hse
Maltese | maltese-mudt
Marathi | marathi-ufal
North Sami | north_sami-giella
Norwegian | norwegian-bokmaal, norwegian-nynorsk, norwegian-nynorsklia
Old Church Slavonic | old_church_slavonic-proiel
Old French | old_french-srcmf
Old Russian | old_russian-torot
Persian | persian-seraji
Polish | polish-lfg, polish-pdb, polish-sz
Portugese | portuguese-bosque, portuguese-br, portuguese-gsd
Romanian | romanian-nonstandard, romanian-rrt
Russian | russian-gsd, russian-syntagrus, russian-taiga
Sanskrit | sanskrit-ufal
Scottish Gaelic | scottish_gaelic-arcosg
Serbian | serbian-set
Slovak | slovak-snk
Slovenian | slovenian-ssj, slovenian-sst
Spanish | spanish-ancora, spanish-gsd
Swedish | swedish-lines, swedish-talbanken
Tamil | tamil-ttb
Telugu | telugu-mtg
Turkish | turkish-imst
Ukrainian | ukrainian-iu
Upper Sorbia | upper_sorbian-ufal
Urdu | urdu-udtb
Uyghur | uyghur-udt
Vietnamese | vietnamese-vtb
Wolof | wolof-wtb


 

To download any of these models, we can use the `udpipe_download_model` function. For example, to download the `english-ewt` model, we would use the call: `m_eng	<- udpipe::udpipe_download_model(language = "english-ewt")`. 

We start by loading  a text

```{r udi1a, message=FALSE, warning=FALSE}
# load text
text <- readLines("https://slcladal.github.io/data/testcorpus/linguistics06.txt", skipNul = T)
# clean data
text <- text %>%
 str_squish() 
# inspect
text
```



## Using your own data

While the tutorial uses data from the LADAL website, you can also use your own data. You can see below what you need to do to upload and use your own data.

The code chunk below allows you to upload two files from your own computer. To be able to load your own data, you need to click on the folder symbol to the left of the screen:

![Binder Folder Symbol](https://slcladal.github.io/images/binderfolder.JPG)


Then, when the menu has unfolded, click on the smaller folder symbol (encircled in red in the picture below).

![Small Binder Folder Symbol](https://slcladal.github.io/images/upload2.png)


Now, you are in the main menu and can click on the 'MyData' folder.

![MyData Folder Symbol](https://slcladal.github.io/images/upload3.png)

Now, that you are in the MyData folder, you can click on the upload symbol.

![Binder Upload Symbol](https://slcladal.github.io/images/binderupload.JPG)

Select and upload the files you want to analyze (**IMPORTANT: here, we assume that you upload some form of text data - not tabular data! You can upload only txt and docx files!**). When you then execute the code chunk below, you will upload your own data and you can then use it in this notebook.

```{r}
myfiles <- list.files(here::here("MyData"), # path to the corpus data
                          # full paths - not just the names of the files
                          full.names = T) 
# load colt files
mytext <- sapply(myfiles, function(x){
  x <- scan(x, 
            what = "char", 
            sep = "", 
            quote = "", 
            quiet = T, 
            skipNul = T)
  x <- paste0(x, sep = " ", collapse = " ")
  x <- stringr::str_squish(x)
})
# inspect
str(mytext)
```


**Keep in mind though that you need to adapt the names of the texts in the code chunks below so that the code below work on your own texts!**

***


Now that we have a text that we can work with, we will download a pre-trained language model.

```{r udi1b, eval = F, message=FALSE, warning=FALSE}
# download language model
m_eng	<- udpipe::udpipe_download_model(language = "english-ewt")
```

If you have downloaded a model once, you can also load the model directly. Here, we have downloaded it into the main directory so we can acll it directly with only the file name.

```{r udi1c, message=FALSE, warning=FALSE}
# load language model from your computer after you have downloaded it once
m_eng <- udpipe_load_model(file = "english-ewt-ud-2.5-191206.udpipe")
```

We can now use the model to annotate out text.

```{r udi1d, message=FALSE, warning=FALSE}
# tokenise, tag, dependency parsing
text_anndf <- udpipe::udpipe_annotate(m_eng, x = text) %>%
  as.data.frame() %>%
  dplyr::select(-sentence)
# inspect
head(text_anndf, 10)
```

It can be useful to extract only the words and their pos-tags and convert them back into a text format (rather than a tabular format). 

```{r udi2, message=FALSE, warning=FALSE}
tagged_text <- paste(text_anndf$token, "/", text_anndf$xpos, collapse = " ", sep = "")
# inspect tagged text
tagged_text
```

# POS-Tagging non-English texts 

We can apply the same method for annotating, e.g. adding pos-tags, to other languages. For this, we could train our own model, or, we can use one of the many pre-trained language models that `udpipe` provides.

Let us explore how to do this by using  example texts from different languages, here from German and Spanish (but we could also annotate texts from any of the wide variety of languages for which UDPipe provides pre-trained models.


We begin by loading a German and a Dutch text.

```{r txts, warning=F, message=F}
# load texts
gertext <- readLines("https://slcladal.github.io/data/german.txt") 
duttext <- readLines("https://slcladal.github.io/data/dutch.txt") 
# inspect texts
gertext; duttext
```


Next, we install the pre-trained language models.

```{r udi_mod2, eval = F, message=FALSE, warning=FALSE}
# download language model
m_ger	<- udpipe::udpipe_download_model(language = "german-gsd")
m_dut	<- udpipe::udpipe_download_model(language = "dutch-alpino")
```

Or we load them from our machine (if we have downloaded and saved them before).

```{r udi_mod4, message=FALSE, warning=FALSE}
# load language model from your computer after you have downloaded it once
m_ger	<- udpipe::udpipe_load_model(file = "german-gsd-ud-2.5-191206.udpipe")
m_dut	<- udpipe::udpipe_load_model(file = "dutch-alpino-ud-2.5-191206.udpipe")
```


Now, pos-tag the German text.


```{r pos_ger, warning=F, message=F}
# tokenise, tag, dependency parsing of german text
ger_pos <- udpipe::udpipe_annotate(m_ger, x = gertext) %>%
  as.data.frame() %>%
  dplyr::summarise(postxt = paste(token, "/", xpos, collapse = " ", sep = "")) %>%
  dplyr::pull(unique(postxt))
# inspect
ger_pos
```

And finally, we also pos-tag the Dutch text.


```{r pos_nl, warning=F, message=F}
# tokenise, tag, dependency parsing of german text
nl_pos <- udpipe::udpipe_annotate(m_dut, x = duttext) %>%
   as.data.frame() %>%
  dplyr::summarise(postxt = paste(token, "/", xpos, collapse = " ", sep = "")) %>%
  dplyr::pull(unique(postxt))
# inspect
nl_pos
```

# Dependency Parsing Using UDPipe

In addition to pos-tagging, we can also generate plots showing the syntactic dependencies of the different constituents of a sentence. For this, we generate an object that contains a sentence (in this case, the sentence *Linguistics is the scientific study of language*), and we then plot (or visualize) the dependencies using the `textplot_dependencyparser` function.  

```{r udi3, message=FALSE, warning=FALSE}
# parse text
sent <- udpipe::udpipe_annotate(m_eng, x = "Linguistics is the scientific study of language") %>%
  as.data.frame()
# inspect
head(sent)
```

We now generate the plot.

```{r udi5, fig.width=5, message=FALSE, warning=FALSE}
# generate dependency plot
dplot <- textplot::textplot_dependencyparser(sent, size = 3) 
# show plot
dplot
```



***

[Back to LADAL](https://ladal.edu.au/postag.html)

***