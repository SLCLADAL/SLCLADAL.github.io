{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "# String processing and cleaning data in R\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *String Processing in R*](https://ladal.edu.au/coll.html). \n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "We set up our session by activating the packages we need for this tutorial. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(warn=-1)  # do not show warnings or messages\n",
                "# load packages\n",
                "library(dplyr)         # data manipulation and transformation\n",
                "library(stringr)       # string manipulation functions\n",
                "library(here)          # for generating relative paths\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using your own data\n",
                "\n",
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "\n",
                "While the tutorial uses example data, you can also **use your own data**. To use your own data, click on the folder called `MyTexts` (it is in the menu to the left of the screen) and then simply drag and drop your txt-files into the folder. When you then execute the code chunk below, you will upload your own data and you can then use it in this notebook.<br>\n",
                "<br>\n",
                "You can upload <b>only txt-files<\/b> (simple unformatted files created in or saved by a text editor)! The notebook assumes that you upload some form of text data - not tabular data! <br>\n",
                "<br>\n",
                "<b>IMPORTANT<\/b>: Be sure to <b>replace `mytext` with `text` in the code chunk below and  do not execute the code chunk which loads an example text<\/b> so that you work with your and not the sample data!<\/b><br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "myfiles <- list.files(here::here(\"notebooks/MyTexts\"), # path to the corpus data\n",
                "                          # full paths - not just the names of the files\n",
                "                          full.names = T) \n",
                "# loop over the vector 'myfiles' that contains paths to the data\n",
                "mytext <- sapply(myfiles, function(x){\n",
                "\n",
                "  # read the content of each file using 'scan'\n",
                "  x <- scan(x, \n",
                "            what = \"char\",    # specify that the input is characters\n",
                "            sep = \"\",         # set separator to an empty string (read entire content)\n",
                "            quote = \"\",       # set quote to an empty string (no quoting)\n",
                "            quiet = T,        # suppress scan messages\n",
                "            skipNul = T)      # skip NUL bytes if encountered\n",
                "\n",
                "  # combine the character vector into a single string with spaces\n",
                "  x <- paste0(x, sep = \" \", collapse = \" \")\n",
                "\n",
                "  # remove extra whitespaces using 'str_squish' from the 'stringr' package\n",
                "  x <- stringr::str_squish(x)\n",
                "\n",
                "})\n",
                "\n",
                "# inspect the structure of the text object\n",
                "str(mytext)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading the example data\n",
                "\n",
                "We begin by loading the example data which represents three files, reprsentinf transcripts of conversations of the Irish component of the [*International Corpus of English*](https://www.ice-corpora.uzh.ch/en.html). \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load text\n",
                "texts <- base::readRDS(url(\"https://slcladal.github.io/data/iceire_sample.rda\", \"rb\"))\n",
                "# inspect data\n",
                "str(texts); substring(texts, 1, 200)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>The aim of this notebook is to showcase, how you can clean text data and then export the cleaned text for further analysis.<\/b> <br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "## Reformatting\n",
                "\n",
                "In a first step, we will reformat the data so that each speech unit is on a separate line. As speech units start with the sequence `<S1A`, we can use this as our starting point.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "texts_split <- stringr::str_replace_all(texts, \"<[S|s]1[A|a]\", \"~~~<S1A\") %>%\n",
                "  stringr::str_split(\"~~~\") %>%\n",
                "  unlist() \n",
                "# create data frame with id, file, speaker, text \n",
                "texts_df <- tibble(id = 1:length(texts_split),\n",
                "                  corpus = rep(\"ICE-IRE\", length(texts_split)),\n",
                "                  file = str_remove_all(texts_split, \"#.*\"),\n",
                "                  speaker = str_remove_all(texts_split, \">.*\"), \n",
                "                  texts_split)\n",
                "# inspect\n",
                "head(texts_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleaning\n",
                "\n",
                "Now that we have the data in tabular format, it is easy to clean it.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create data frame with id, file, speaker, text \n",
                "texts_df %>%\n",
                "  dplyr::mutate(file = stringr::str_replace_all(file, \"<\", \"\"),\n",
                "                file = stringr::str_replace_all(file, \"[ |\\\\$].*\", \"\"),\n",
                "                # speaker\n",
                "                speaker = stringr::str_replace_all(speaker, \".*\\\\$\", \"\"),\n",
                "                # text\n",
                "                t_clean = stringr::str_remove_all(texts_split, \"<.*?>\")) %>%\n",
                "  # remove unneccessary rows\n",
                "  dplyr::filter(!nchar(speaker) < 1,\n",
                "                !nchar(speaker) > 2) -> clean_df \n",
                "# inspect\n",
                "head(clean_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clean_df %>%\n",
                "  dplyr::group_by(corpus, file) %>%\n",
                "  dplyr::summarise(text = paste0(t_clean, collapse = \" \")) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::pull(text) %>%\n",
                "  tolower() %>%\n",
                "  stringr::str_squish()-> ctexts\n",
                "# inspect\n",
                "str(ctexts)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now save the clean data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "writeLines(ctexts, here::here(\"notebooks/MyOutput\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/string.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
