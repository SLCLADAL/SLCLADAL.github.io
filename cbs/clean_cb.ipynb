{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "# String processing and cleaning data in R\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *String Processing in R*](https://ladal.edu.au/coll.html). \n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "We set up our session by activating the packages we need for this tutorial. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(warn=-1)  # do not show warnings or messages\n",
                "# load packages\n",
                "library(dplyr)         # data manipulation and transformation\n",
                "library(stringr)       # string manipulation functions\n",
                "library(here)          # for generating relative paths\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using your own data\n",
                "\n",
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "\n",
                "While the tutorial uses example data, you can also **use your own data**. To use your own data, click on the folder called `MyTexts` (it is in the menu to the left of the screen) and then simply drag and drop your txt-files into the folder. When you then execute the code chunk below, you will upload your own data and you can then use it in this notebook.<br>\n",
                "<br>\n",
                "You can upload <b>only txt-files<\/b> (simple unformatted files created in or saved by a text editor)! The notebook assumes that you upload some form of text data - not tabular data! <br>\n",
                "<br>\n",
                "<b>IMPORTANT<\/b>: Be sure to <b>replace `mytext` with `text` in the code chunk below and  do not execute the code chunk which loads an example text<\/b> so that you work with your and not the sample data!<\/b><br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "myfiles <- list.files(here::here(\"notebooks/MyTexts\"), # path to the corpus data\n",
                "                          # full paths - not just the names of the files\n",
                "                          full.names = T) \n",
                "# loop over the vector 'myfiles' that contains paths to the data\n",
                "mytext <- sapply(myfiles, function(x){\n",
                "\n",
                "  # read the content of each file using 'scan'\n",
                "  x <- scan(x, \n",
                "            what = \"char\",    # specify that the input is characters\n",
                "            sep = \"\",         # set separator to an empty string (read entire content)\n",
                "            quote = \"\",       # set quote to an empty string (no quoting)\n",
                "            quiet = T,        # suppress scan messages\n",
                "            skipNul = T)      # skip NUL bytes if encountered\n",
                "\n",
                "  # combine the character vector into a single string with spaces\n",
                "  x <- paste0(x, sep = \" \", collapse = \" \")\n",
                "\n",
                "  # remove extra whitespaces using 'str_squish' from the 'stringr' package\n",
                "  x <- stringr::str_squish(x)\n",
                "\n",
                "})\n",
                "\n",
                "# inspect the structure of the text object\n",
                "str(mytext)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading the example data\n",
                "\n",
                "We begin by loading the example data which represents three files, reprsentinf transcripts of conversations of the Irish component of the [*International Corpus of English*](https://www.ice-corpora.uzh.ch/en.html). \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load text\n",
                "texts <- base::readRDS(url(\"https://slcladal.github.io/data/iceire_sample.rda\", \"rb\"))\n",
                "# inspect data\n",
                "str(texts); substring(texts, 1, 200)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>The aim of this notebook is to showcase, how you can clean text data and then export the cleaned text for further analysis.<\/b> <br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "## Reformatting\n",
                "\n",
                "In a first step, we will reformat the data so that each speech unit is on a separate line. As speech units start with the sequence `<S1A`, we can use this as our starting point.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# replace instances of \"<[S|s]1[A|a]\" with \"~~~<S1A\", split the resulting text, and unlist\n",
                "texts_split <- stringr::str_replace_all(texts, \"<[S|s]1[A|a]\", \"~~~<S1A\") %>%\n",
                "  stringr::str_split(\"~~~\") %>%\n",
                "  unlist() \n",
                "\n",
                "# create a data frame with 'id', 'file', 'speaker', and 'text' columns\n",
                "texts_df <- tibble(id = 1:length(texts_split),\n",
                "                  corpus = rep(\"ICE-IRE\", length(texts_split)),\n",
                "                  file = str_remove_all(texts_split, \"#.*\"),\n",
                "                  speaker = str_remove_all(texts_split, \">.*\"), \n",
                "                  texts_split)\n",
                "\n",
                "# inspect the first 10 rows of the created data frame\n",
                "head(texts_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleaning\n",
                "\n",
                "Now that we have the data in tabular format, it is easy to clean it.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a data frame with 'id', 'file', 'speaker', and 'text' columns\n",
                "texts_df %>%\n",
                "  \n",
                "  # clean 'file' column by removing \"<\" and anything after \"|$\"\n",
                "  dplyr::mutate(file = stringr::str_replace_all(file, \"<\", \"\"),\n",
                "                file = stringr::str_replace_all(file, \"[ |\\\\$].*\", \"\"),\n",
                "                \n",
                "                # clean 'speaker' column by removing anything before \"$\"\n",
                "                speaker = stringr::str_replace_all(speaker, \".*\\\\$\", \"\"),\n",
                "                \n",
                "                # clean 'text' column by removing \"<.*?>\"\n",
                "                t_clean = stringr::str_remove_all(texts_split, \"<.*?>\")) %>%\n",
                "  \n",
                "  # filter out unnecessary rows based on speaker length\n",
                "  dplyr::filter(!nchar(speaker) < 1,\n",
                "                !nchar(speaker) > 2) -> clean_df  # assign the result to 'clean_df'\n",
                "  \n",
                "# inspect the first 10 rows of the cleaned data frame\n",
                "head(clean_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# group the 'clean_df' dataframe by 'corpus' and 'file'\n",
                "clean_df %>%\n",
                "  dplyr::group_by(corpus, file) %>%\n",
                "  \n",
                "  # concatenate the cleaned text ('t_clean') into a single string for each group\n",
                "  dplyr::summarise(text = paste0(t_clean, collapse = \" \")) %>%\n",
                "  \n",
                "  # remove grouping\n",
                "  dplyr::ungroup() %>%\n",
                "  \n",
                "  # extract the 'text' column\n",
                "  dplyr::pull(text) %>%\n",
                "  \n",
                "  # convert the text to lowercase\n",
                "  tolower() %>%\n",
                "  \n",
                "  # remove extra spaces in the resulting character vector\n",
                "  stringr::str_squish() -> ctexts  # Assign the cleaned and formatted text to 'ctexts'\n",
                "  \n",
                "# inspect the structure of the resulting character vector\n",
                "str(ctexts)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We create names for the files.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# group the 'clean_df' dataframe by 'corpus' and 'file'\n",
                "clean_df %>%\n",
                "  dplyr::group_by(corpus, file) %>%\n",
                "  \n",
                "  # concatenate the cleaned text ('t_clean') into a single string for each group\n",
                "  dplyr::summarise(text = unique(paste0(t_clean, collapse = \" \"))) %>%\n",
                "  \n",
                "  # create a new column 'cfile' by combining 'corpus' and 'file', remove spaces and hyphens\n",
                "  dplyr::mutate(cfile = paste0(corpus, \"_\", file, \".txt\"),\n",
                "                cfile = stringr::str_remove_all(cfile, \" \"),\n",
                "                cfile = stringr::str_remove_all(cfile, \"-\")) %>%\n",
                "  \n",
                "  # remove grouping\n",
                "  dplyr::ungroup() %>%\n",
                "  \n",
                "  # extract the 'cfile' column and squish the resulting character vector\n",
                "  dplyr::pull(cfile) %>%\n",
                "  # remove superfluous white spaces and save the results as names of the elements of 'ctexts'\n",
                "  stringr::str_squish() -> nms -> names(ctexts)\n",
                "  \n",
                "# 'nms' contains the cleaned and formatted file names\n",
                "nms\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save result to disc\n",
                "# Use lapply to iterate over the indices of ctexts\n",
                "# and write each text to a separate file in the MyOutput folder\n",
                "\n",
                "lapply(seq_along(ctexts), function(i) {\n",
                "  # unlist the i-th element in ctexts to get the text content\n",
                "  text_content <- unlist(ctexts[i])\n",
                "\n",
                "  # construct the file path using the 'here' package\n",
                "  file_path <- paste0(here::here(\"notebooks/MyOutput/\"), names(ctexts)[i])\n",
                "\n",
                "  # write the text content to the specified file\n",
                "  writeLines(text = text_content, con = file_path)\n",
                "})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>You will find the txt-files in the `MyOutput` folder (located on the left side of the screen).<\/b> <br><br>Simply double-click the `MyOutput` folder icon, then highlight the files, and choose *Download* from the dropdown menu to download the files. <br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/string.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
