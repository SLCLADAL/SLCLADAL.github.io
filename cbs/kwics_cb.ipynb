{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "# Concordancing with R\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial **Concordancing with R**](https://ladal.edu.au/kwics.html). \n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "We start by activating the packages we need for this tutorial.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(warn=-1)  # do not show warnings or messages\n",
                "# activate packages\n",
                "library(quanteda) # for concordancing\n",
                "library(dplyr)    # for table processing\n",
                "library(stringr)  # for text processing\n",
                "library(writexl)  # for saving data\n",
                "library(here)     # for easy pathing\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using your own data\n",
                "\n",
                "\n",
                "\n",
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "\n",
                "While the tutorial uses example data (Lewis Carroll's *Alice in Wonderland*), you can also **use your own data**. To use your own data, click on the folder called `MyTexts` (it is in the menu to the left of the screen) and then simply drag and drop your txt-files into the folder. When you then execute the code chunk below, you will upload your own data and you can then use it in this notebook.<br>\n",
                "<br>\n",
                "You can upload <b>only txt-files<\/b> (simple unformatted files created in or saved by a text editor)! The notebook assumes that you upload some form of text data - not tabular data! <br>\n",
                "<br>\n",
                "<b>IMPORTANT<\/p>: Be sure to to then <b>replace `mytext` with `text` in the code chunk below and not execute the code chunk which loads an example text<\/b> from the LADAL repository so that you work with your and not the sample data!<\/b><br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "myfiles <- list.files(here::here(\"notebooks/MyTexts\"), # path to the corpus data\n",
                "                          # full paths - not just the names of the files\n",
                "                          full.names = T) \n",
                "# loop over the vector 'myfiles' that contains paths to the data\n",
                "mytext <- sapply(myfiles, function(x){\n",
                "\n",
                "  # read the content of each file using 'scan'\n",
                "  x <- scan(x, \n",
                "            what = \"char\",    # specify that the input is characters\n",
                "            sep = \"\",         # set separator to an empty string (read entire content)\n",
                "            quote = \"\",       # set quote to an empty string (no quoting)\n",
                "            quiet = T,        # suppress scan messages\n",
                "            skipNul = T)      # skip NUL bytes if encountered\n",
                "\n",
                "  # combine the character vector into a single string with spaces\n",
                "  x <- paste0(x, sep = \" \", collapse = \" \")\n",
                "\n",
                "  # remove extra whitespaces using 'str_squish' from the 'stringr' package\n",
                "  x <- stringr::str_squish(x)\n",
                "\n",
                "})\n",
                "\n",
                "# inspect the structure of the text object\n",
                "str(mytext)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>If you are using your own data, do not execute the next code chunk and change `mytext` into `text` in the code chunk above.<\/b><br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "\n",
                "## Loading the example data\n",
                "\n",
                "If you do not use your own data, you can load the default data, Lewis Caroll's  *Alice's Adventures in Wonderland*, by executing the following code chunk.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text <- base::readRDS(url(\"https://slcladal.github.io/data/alice.rda\", \"rb\"))\n",
                "# inspect first 6 text elements\n",
                "head(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data consists of many separate text elements. \n",
                "\n",
                "## Creating simple concordances\n",
                "\n",
                "Now we can extract concordances using the `kwic` function from the `quanteda` package. This function has the following arguments: \n",
                "\n",
                "+ `x`: a text or collection of texts. The text needs to be tokenised, i.e. split it into individual words, which is why we use the *text* in the `tokens()` function. \n",
                "+ `pattern`: a keyword defined by a search pattern  \n",
                "+ `window`: the size of the context window (how many word before and after)  \n",
                "+ `valuetype`: the type of pattern matching  \n",
                "  + \"glob\" for \"glob\"-style wildcard expressions;  \n",
                "  + \"regex\" for regular expressions; or  \n",
                "  + \"fixed\" for exact matching  \n",
                "+ `separator`: a character to separate words in the output  \n",
                "+ `case_insensitive`: logical; if TRUE, ignore case when matching a pattern or dictionary values\n",
                "\n",
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>You can easily change and adapt the concordance. For instance, you can search for a different word, like *speak*, by substituting *alice* with *speak* as the pattern. Additionally, if you wish to widen the context window, just replace the '5' with '10'. This adjustment will extend the context around the keyword by 5 additional words in both the preceding and following context. <\/b><br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mykwic <- kwic(\n",
                "  # tokenise and define text\n",
                "  tokens(text), \n",
                "  # define target word (this is called the \"search pattern\")\n",
                "  pattern = phrase(\"alice\"),\n",
                "  # 5 words before and after\n",
                "  window = 5,\n",
                "  # no regex\n",
                "  valuetype = \"fixed\",\n",
                "  # words separated by whitespace\n",
                "  separator = \" \",\n",
                "  # search should be case insensitive\n",
                "  case_insensitive = TRUE)\n",
                "\n",
                "# inspect resulting kwic\n",
                "mykwic %>%\n",
                "  # convert into a data frame\n",
                "  as.data.frame() %>%\n",
                "  # show only first 10 results\n",
                "  head(10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exporting concordances\n",
                "\n",
                "To export a concordance table as an MS Excel spreadsheet, we use `write_xlsx`. Be aware that we use the `here` function to  save the file in the current working directory.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save data for MyOutput folder\n",
                "write_xlsx(mykwic, here::here(\"notebooks/MyOutput/mykwic.xlsx\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>You will find the generated MS Excel spreadsheet named *mykwic.xlsx* in the `MyOutput` folder (located on the left side of the screen).<\/b> <br><br>Simply double-click the `MyOutput` folder icon, then right-click on the *mykwic.xlsx* file, and choose Download from the dropdown menu to download the file. <br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/kwics.html)\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
