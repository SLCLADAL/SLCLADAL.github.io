{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "# String processing and cleaning data in R\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *String Processing in R*](https://ladal.edu.au/coll.html). \n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "We set up our session by activating the packages we need for this tutorial. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(warn=-1)  # do not show warnings or messages\n",
                "# load packages\n",
                "library(dplyr)         # data manipulation and transformation\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using your own data\n",
                "\n",
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "\n",
                "Here, you can **use your own data**. To use your own data, click on the folder called `MyTexts` (it is in the menu to the left of the screen) and then simply drag and drop your txt-files into the folder. When you then execute the code chunk below, you will upload your own data and you can then use it in this notebook.<br>\n",
                "<br>\n",
                "You can upload <b>only txt-files<\/b> (simple unformatted files created in or saved by a text editor)! The notebook assumes that you upload some form of text data - not tabular data! <br>\n",
                "<br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load function that helps loading texts\n",
                "source(\"https://slcladal.github.io/rscripts/loadtxts.R\")\n",
                "# load texts\n",
                "text <- loadtxts(\"notebooks/MyTexts\")\n",
                "# inspect the structure of the text object\n",
                "str(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reformatting\n",
                "\n",
                "In a first step, we generate file names from the paths. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# extract names of texts\n",
                "nms <- names(texts) %>%\n",
                "  stringr::str_remove_all(\".*/\") %>%\n",
                "  stringr::str_remove_all(\".txt\")\n",
                "# inspect names\n",
                "nms\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we split the text into speech units (this is optional).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# replace instances of \"<[S|s]1[A|a]\" with \"~~~<S1A\", split the resulting text\n",
                "texts_split <- stringr::str_replace_all(texts, \"<[S|s]1[A|a]\", \"~~~<S1A\") %>%\n",
                "  stringr::str_split(\"~~~\")\n",
                "# inspect\n",
                "str(texts_split)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The text now is in a list format which each speech unit being an element in the list.\n",
                "\n",
                "We now repeat the names as often as there are elements in the list items because we want to create a data frame with the file, the original text, and the clean text.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# extract how many items are in each text\n",
                "lngth <- sapply(texts_split, function(x) length(x) )\n",
                "# repeat name as many times as there are elements\n",
                "files <- rep(nms, lngth) \n",
                "# inspect\n",
                "table(files)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now clean the split test.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a data frame of split texts\n",
                "stexts <- unlist(texts_split) %>% tibble()\n",
                "# add the file names\n",
                "stexts_df <- data.frame(files, stexts) %>%\n",
                "  # add column names\n",
                "  dplyr::rename(file = 1, \n",
                "                text = 2)\n",
                "# inspect the first 10 rows of the created data frame\n",
                "head(stexts_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleaning\n",
                "\n",
                "Now that we've organized the data into a tabular format, the cleaning process becomes straightforward. We work with the data frame, employing `str_remove_all` and `str_replace_all` to eliminate undesired text sequences from the column contents. The distinction lies in their usage:\n",
                "\n",
                "+ `str_remove_all` requires specifying the column to clean and indicating what to remove.  \n",
                "\n",
                "+ while `str_replace_all` additionally needs information on the replacement pattern for the specified pattern.  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a data frame with 'id', 'file', 'speaker', and 'text' columns\n",
                "stexts_df %>%\n",
                "  \n",
                "  # # clean 'text' column by removing \"<.*?>\"\n",
                "  dplyr::mutate(text_clean = stringr::str_remove_all(text, \"<.*?>\"),\n",
                "                \n",
                "                # convert 't_clean' to lower case)\n",
                "                text_clean = tolower(text_clean)) -> clean_df  # assign the result to 'clean_df'\n",
                "  \n",
                "# inspect the first 10 rows of the cleaned data frame\n",
                "head(clean_df, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "With the data now arranged in tabular form, the cleaning process becomes straightforward. In the subsequent step, we aggregate the cleaned texts from the 'text_clean' column by file, ensuring we obtain a single consolidated clean text for each file. After this, we extract the cleaned text and store it in an object named 'ctexts.'\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# group the 'clean_df' dataframe by 'corpus' and 'file'\n",
                "clean_df %>%\n",
                "  dplyr::group_by(file) %>%\n",
                "  \n",
                "  # concatenate the cleaned text ('t_clean') into a single string for each group\n",
                "  dplyr::summarise(text = paste0(text_clean, collapse = \" \")) %>%\n",
                "  \n",
                "  # remove grouping\n",
                "  dplyr::ungroup() %>%\n",
                "  \n",
                "  # extract the 'text' column\n",
                "  dplyr::pull(text) %>%\n",
                "  \n",
                "  # convert the text to lowercase\n",
                "  tolower() %>%\n",
                "  \n",
                "  # remove extra spaces in the resulting character vector\n",
                "  stringr::str_squish() -> ctexts  # Assign the cleaned and formatted text to 'ctexts'\n",
                "  \n",
                "# inspect the structure of the resulting character vector\n",
                "str(ctexts)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now add names to the cleaned texts.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nms -> names(ctexts)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Saving to MyOutput\n",
                "\n",
                "As a concluding step, we save the outcomes – the three files housing our cleaned texts – in the 'MyOutput' folder, conveniently visible on the left side of the screen.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load function that helps loading texts\n",
                "source(\"https://slcladal.github.io/rscripts/savetxts.R\")\n",
                "savetxts(ctexts)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"warning\" style='padding:0.1em; background-color: rgba(215,209,204,.3); color:#51247a'>\n",
                "<span>\n",
                "<p style='margin-top:1em; text-align:center'>\n",
                "<b>You will find the txt-files in the `MyOutput` folder (located on the left side of the screen).<\/b> <br><br>Simply double-click the `MyOutput` folder icon, then highlight the files, and choose *Download* from the dropdown menu to download the files. <br>\n",
                "<\/p>\n",
                "<p style='margin-left:1em;'>\n",
                "<\/p><\/span>\n",
                "<\/div>\n",
                "\n",
                "<br>\n",
                "\n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/string.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
