{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "***\n",
                "\n",
                "Please copy this Jupyter notebook so that you are able to edit it.\n",
                "\n",
                "Simply go to: File > Save a copy in Drive.\n",
                "\n",
                "Once you have done that, you are good to go.\n",
                "\n",
                "***\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [*Language Technology and Data Analysis Laboratory* (LADAL) tutorial *Converting PDFs to txt files with R*](https://ladal.edu.au/pdf2txt.html). \n",
                "\n",
                "***\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "If you are using this notebook on Google Colab or your own computer and you have not already installed the R packages listed below, you need to install them. You can install them by running the code chunk below. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# install packages\n",
                "install.packages(\"tesseract\")\n",
                "install.packages(\"dplyr\")\n",
                "install.packages(\"hunspell\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# activate packages\n",
                "library(tesseract)\n",
                "library(dplyr)\n",
                "library(hunspell)\n",
                "# set tesseract engine\n",
                "eng <- tesseract(\"eng\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have initiated the session by executing the code shown above, you are good to go.\n",
                "\n",
                "\n",
                "# OCR with tesseract\n",
                "\n",
                "In this section, we use the `tesseract` package for optical character recognition (OCR) (see [here](https://cran.r-project.org/web/packages/tesseract/vignettes/intro.html) for more information and a more thorough tutorial on using the `tesseract` package). The `tesseract` package provides powerful OCR engine that supports over 100 languages. \n",
                "\n",
                "We start by creating a vector of paths to the pdf-files that we want to extract the text from.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pdf0 <- \"https://slcladal.github.io/data/PDFs/pdf0.pdf\"\n",
                "pdf1 <- \"https://slcladal.github.io/data/PDFs/pdf1.pdf\"\n",
                "\n",
                "fls <- c(pdf0, pdf1)\n",
                "# load\n",
                "ocrs <- sapply(fls, function(x){\n",
                "  # store name\n",
                "  nm <- stringr::str_replace_all(x, \".*/(.*?).pdf\", \"\\\\1\")\n",
                "  # perform ocr\n",
                "  x <- tesseract::ocr(x, engine = eng) %>%\n",
                "    paste0(collapse = \" \")\n",
                "})\n",
                "# show data\n",
                "ocrs %>%\n",
                "  substr(start=1, stop=500) %>%\n",
                "  as.data.frame()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Although the results already look very promising, we want to see how we can combine automated spell-checking/correction with OCR as this is necessary when dealing with less pristine documents.\n",
                "\n",
                "## Spell correction\n",
                "\n",
                "In a first step, we write a function that loops over each text and checks which words occur in a English language dictionary (which we do not specify as it is the default). This spell checking makes use of the the `hunspell` package (see [here](https://cran.r-project.org/web/packages/hunspell/vignettes/intro.html) for more information). Hunspell is based on *MySpell* and is backward-compatible with *MySpell* and *aspell* dictionaries. This means that we can import and/or make use of many different language dictionaries and it is quite likely that the dictionaries for other languages may already available on your system!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create token list\n",
                "tokens_ocr <- sapply(ocrs, function(x){\n",
                "  x <- hunspell::hunspell_parse(x)\n",
                "})\n",
                "# show data\n",
                "tokens_ocr %>%\n",
                "  substr(start=1, stop=500) %>%\n",
                "  as.data.frame()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In a next step, we can correct errors resulting from the OCR process, correct the errors and paste th texts back together (which is all done by the code chunk below). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# clean\n",
                "clean_ocrtext <- sapply(tokens_ocr, function(x){\n",
                "  correct <- hunspell::hunspell_check(x)\n",
                "  x <- ifelse(correct == F, \n",
                "              x[hunspell::hunspell_check(x)],\n",
                "              x)\n",
                "  x <- paste0(x, collapse = \" \")\n",
                "})\n",
                "# show data\n",
                "clean_ocrtext %>%\n",
                "  substr(start=1, stop=500) %>%\n",
                "  as.data.frame()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Saving the texts\n",
                "\n",
                "To save the texts in txt-files on your disc, you can simply replace the predefined location (the data folder of your Rproject located by the string `here::here(\"data\")` with the folder where you want to store the txt-files and then execute the code below. Also, we will name the texts (or the txt-files if you like) as *pdftext* plus their index number.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# add names to txt files\n",
                "names(txts) <- paste0(\"txt\", 1:length(txts), sep = \"\")\n",
                "# save result to disc\n",
                "lapply(seq_along(txts), function(i)writeLines(text = unlist(txts[i]),\n",
                "    con = paste(names(txts)[i],\".txt\", sep = \"\")))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have reached the end of this tutorial and we hope that the tutorial helps you in performing OCR on your own pdfs.\n",
                "\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/pdf2txt.html)\n",
                "\n",
                "***\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
