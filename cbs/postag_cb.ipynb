{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![An interactive LADAL notebook](https://slcladal.github.io/images/uq1.jpg)\n",
                "\n",
                "***\n",
                "\n",
                "Please copy this Jupyter notebook so that you are able to edit it.\n",
                "\n",
                "Simply go to: File > Save a copy in Drive.\n",
                "\n",
                "Once you have done that, you are good to go.\n",
                "\n",
                "***\n",
                "\n",
                "This tutorial is the interactive Jupyter notebook accompanying the [Language Technology and Data Analysis Laboratory (LADAL) tutorial on part-of-speech tagging and dependency parsing with R](https://ladal.edu.au/postag.html). \n",
                "\n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "\n",
                "**Preparation and session set up**\n",
                "\n",
                "If you are using this notebook on Google Colab or your own computer and you have not already installed the R packages listed below, you need to install them. You can install them by running the code chunk below. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# install packages\n",
                "install.packages(\"dplyr\") \n",
                "install.packages(\"stringr\")\n",
                "install.packages(\"udpipe\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# activate packages\n",
                "library(dplyr)\n",
                "library(stringr) \n",
                "library(udpipe) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have initiated the session by executing the code shown above, you are good to go.\n",
                "\n",
                "# POS-Tagging with UDPipe\n",
                "\n",
                "UDPipe allows you to access numerous language models for 64 languages (for an overview of the supported languages and language models see [here](https://ladal.edu.au/postag.html#POS-Tagging_with_UDPipe)). \n",
                "\n",
                "To download any of these models, we can use the `udpipe_download_model` function. For example, to download the `english-ewt` model, we would use the call: `m_eng\t<- udpipe::udpipe_download_model(language = \"english-ewt\")`. \n",
                "\n",
                "We start by loading  a text\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load text\n",
                "text <- readLines(\"https://slcladal.github.io/data/testcorpus/linguistics06.txt\", skipNul = T) %>%\n",
                " str_squish() %>%\n",
                "  .[1]\n",
                "# inspect\n",
                "text\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have a text that we can work with, we will download a pre-trained language model.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# download language model\n",
                "m_eng\t<- udpipe::udpipe_download_model(language = \"english-ewt\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now load language model.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load language model\n",
                "m_eng <- udpipe_load_model(file = \"/content/english-ewt-ud-2.5-191206.udpipe\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now use the model to annotate out text.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# tokenise, tag, dependency parsing\n",
                "text_anndf <- udpipe::udpipe_annotate(m_eng, x = text) %>%\n",
                "  as.data.frame() %>%\n",
                "  dplyr::select(-sentence)\n",
                "# inspect\n",
                "head(text_anndf, 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It can be useful to extract only the words and their pos-tags and convert them back into a text format (rather than a tabular format). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tagged_text <- paste(text_anndf$token, \"/\", text_anndf$xpos, collapse = \" \", sep = \"\")\n",
                "# inspect tagged text\n",
                "tagged_text\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# POS-Tagging non-English texts\n",
                "\n",
                "We can apply the same method for annotating, e.g. adding pos-tags, to other languages. For this, we could train our own model, or, we can use one of the many pre-trained language models that `udpipe` provides.\n",
                "\n",
                "Let us explore how to do this by using  example texts from different languages, here from German and Spanish (but we could also annotate texts from any of the wide variety of languages for which UDPipe provides pre-trained models.\n",
                "\n",
                "\n",
                "We begin by loading a German and a Dutch text.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load texts\n",
                "gertext <- readLines(\"https://slcladal.github.io/data/german.txt\") \n",
                "duttext <- readLines(\"https://slcladal.github.io/data/dutch.txt\") \n",
                "# inspect texts\n",
                "gertext; duttext\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we install the pre-trained language models.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# download language model\n",
                "m_ger\t<- udpipe::udpipe_download_model(language = \"german-gsd\")\n",
                "m_dut\t<- udpipe::udpipe_download_model(language = \"dutch-alpino\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or we load them from our machine (if we have downloaded and saved them before).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load language model from your computer after you have downloaded it once\n",
                "m_ger\t<- udpipe::udpipe_load_model(file = \"/content/german-gsd-ud-2.5-191206.udpipe\")\n",
                "m_dut\t<- udpipe::udpipe_load_model(file = \"/content/dutch-alpino-ud-2.5-191206.udpipe\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, pos-tag the German text.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ger_pos <- udpipe::udpipe_annotate(m_ger, x = gertext) %>%\n",
                "  as.data.frame() %>%\n",
                "  dplyr::summarise(postxt = paste(token, \"/\", xpos, collapse = \" \", sep = \"\")) %>%\n",
                "  dplyr::pull(unique(postxt))\n",
                "# inspect\n",
                "ger_pos\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And finally, we also pos-tag the Dutch text.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nl_pos <- udpipe::udpipe_annotate(m_dut, x = duttext) %>%\n",
                "   as.data.frame() %>%\n",
                "  dplyr::summarise(postxt = paste(token, \"/\", xpos, collapse = \" \", sep = \"\")) %>%\n",
                "  dplyr::pull(unique(postxt))\n",
                "# inspect\n",
                "nl_pos\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dependency Parsing Using UDPipe\n",
                "\n",
                "In addition to pos-tagging, we can also generate plots showing the syntactic dependencies of the different constituents of a sentence. For this, we generate an object that contains a sentence (in this case, the sentence *Linguistics is the scientific study of language*), and we then plot (or visualize) the dependencies using the `textplot_dependencyparser` function.  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# parse text\n",
                "sent <- udpipe::udpipe_annotate(m_eng, x = \"Linguistics is the scientific study of language\") %>%\n",
                "  as.data.frame()\n",
                "# inspect\n",
                "head(sent)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before we can generate the plot, we need to install additional packages.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# install and activate necessary packages\n",
                "install.packages(\"igraph\")\n",
                "install.packages(\"ggraph\")\n",
                "install.packages(\"textplot\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now generate the plot.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load package\n",
                "library(textplot)\n",
                "# generate dependency plot\n",
                "dplot <- textplot_dependencyparser(sent, size = 5) \n",
                "# show plot\n",
                "dplot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "That's it for this tutorial. We hope that you have enjoyed this tutorial and learned how to annotate texts using language models and perform pos-tagging and dependency parsing.\n",
                "\n",
                "\n",
                "\n",
                "[Back to LADAL](https://ladal.edu.au/postag.html)\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
